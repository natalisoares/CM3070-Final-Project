Discipline,Subfield,Methodology,Title,Abstract,URL,Source,clean_title,clean_abstract,clean_text,noun_ratio,verb_ratio,adj_ratio,adv_ratio,avg_sentence_length,ner_org,ner_gpe,ner_date,ner_person
Computer Science,Algorithms and Data Structures,Quantitative,Data structures for maintaining set partitions,"<jats:title>Abstract</jats:title><jats:p>Efficiently maintaining the partition induced by a set of features is an important problem in building decision‐tree classifiers. In order to identify a small set of discriminating features, we need the capability of efficiently adding and removing specific features and determining the effect of these changes on the induced classification or partition. In this paper we introduce a variety of randomized and deterministic data structures to support these operations on both general and geometrically induced set partitions. We give both Monte Carlo and Las Vegas data structures that realize near‐optimal time bounds and are practical to implement. We then provide a faster solution to this problem in the geometric setting. Finally, we present a data structure that efficiently estimates the number of partitions separating elements. © 2004 Wiley Periodicals, Inc. Random Struct. Alg., 2004</jats:p>",https://doi.org/10.1002/rsa.20025,CrossRef,datum structure maintain set partition,jatstitleabstractjatstitlejatspefficiently maintain partition induce set feature important problem build classifier order identify small set discriminating feature need capability efficiently add remove specific feature determine effect change induced classification partition paper introduce variety randomized deterministic datum structure support operation general geometrically induce set partition give monte carlo las vegas data structure realize time bound practical implement provide fast solution problem geometric setting finally present data structure efficiently estimate number partition separate element wiley periodicals inc random struct alg jatsp,datum structure maintain set partition jatstitleabstractjatstitlejatspefficiently maintain partition induce set feature important problem build classifier order identify small set discriminating feature need capability efficiently add remove specific feature determine effect change induced classification partition paper introduce variety randomized deterministic datum structure support operation general geometrically induce set partition give monte carlo las vegas data structure realize time bound practical implement provide fast solution problem geometric setting finally present data structure efficiently estimate number partition separate element wiley periodicals inc random struct alg jatsp,0.41025641025641024,0.23076923076923078,0.14102564102564102,0.0641025641025641,78.0,2.0,1.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Quantitative,Segment-Based Clustering of Hyperspectral Images Using Tree-Based Data Partitioning Structures,"<jats:p>Hyperspectral image classification has been increasingly used in the field of remote sensing. In this study, a new clustering framework for large-scale hyperspectral image (HSI) classification is proposed. The proposed four-step classification scheme explores how to effectively use the global spectral information and local spatial structure of hyperspectral data for HSI classification. Initially, multidimensional Watershed is used for pre-segmentation. Region-based hierarchical hyperspectral image segmentation is based on the construction of Binary partition trees (BPT). Each segmented region is modeled while using first-order parametric modelling, which is then followed by a region merging stage using HSI regional spectral properties in order to obtain a BPT representation. The tree is then pruned to obtain a more compact representation. In addition, principal component analysis (PCA) is utilized for HSI feature extraction, so that the extracted features are further incorporated into the BPT. Finally, an efficient variant of k-means clustering algorithm, called filtering algorithm, is deployed on the created BPT structure, producing the final cluster map. The proposed method is tested over eight publicly available hyperspectral scenes with ground truth data and it is further compared with other clustering frameworks. The extensive experimental analysis demonstrates the efficacy of the proposed method.</jats:p>",https://doi.org/10.3390/a13120330,CrossRef,segmentbase cluster hyperspectral image use treebase datum partition structure,jatsphyperspectral image classification increasingly use field remote sensing study new cluster framework largescale hyperspectral image hsi classification propose propose fourstep classification scheme explore effectively use global spectral information local spatial structure hyperspectral datum hsi classification initially multidimensional watershed use presegmentation regionbase hierarchical hyperspectral image segmentation base construction binary partition tree bpt segment region model use firstorder parametric modelling follow region merging stage use hsi regional spectral property order obtain bpt representation tree prune obtain compact representation addition principal component analysis pca utilize hsi feature extraction extract feature far incorporate bpt finally efficient variant kmean cluster algorithm call filter algorithm deploy create bpt structure produce final cluster map propose method test eight publicly available hyperspectral scene ground truth datum far compare clustering framework extensive experimental analysis demonstrate efficacy propose methodjatsp,segmentbase cluster hyperspectral image use treebase datum partition structure jatsphyperspectral image classification increasingly use field remote sensing study new cluster framework largescale hyperspectral image hsi classification propose propose fourstep classification scheme explore effectively use global spectral information local spatial structure hyperspectral datum hsi classification initially multidimensional watershed use presegmentation regionbase hierarchical hyperspectral image segmentation base construction binary partition tree bpt segment region model use firstorder parametric modelling follow region merging stage use hsi regional spectral property order obtain bpt representation tree prune obtain compact representation addition principal component analysis pca utilize hsi feature extraction extract feature far incorporate bpt finally efficient variant kmean cluster algorithm call filter algorithm deploy create bpt structure produce final cluster map propose method test eight publicly available hyperspectral scene ground truth datum far compare clustering framework extensive experimental analysis demonstrate efficacy propose methodjatsp,0.5116279069767442,0.13178294573643412,0.1937984496124031,0.05426356589147287,64.5,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Quantitative,Efficient Data Structures for Range Shortest Unique Substring Queries,"<jats:p>Let T[1,n] be a string of length n and T[i,j] be the substring of T starting at position i and ending at position j. A substring T[i,j] of T is a repeat if it occurs more than once in T; otherwise, it is a unique substring of T. Repeats and unique substrings are of great interest in computational biology and information retrieval. Given string T as input, the Shortest Unique Substring problem is to find a shortest substring of T that does not occur elsewhere in T. In this paper, we introduce the range variant of this problem, which we call the Range Shortest Unique Substring problem. The task is to construct a data structure over T answering the following type of online queries efficiently. Given a range [α,β], return a shortest substring T[i,j] of T with exactly one occurrence in [α,β]. We present an O(nlogn)-word data structure with O(logwn) query time, where w=Ω(logn) is the word size. Our construction is based on a non-trivial reduction allowing for us to apply a recently introduced optimal geometric data structure [Chan et al., ICALP 2018]. Additionally, we present an O(n)-word data structure with O(nlogϵn) query time, where ϵ&gt;0 is an arbitrarily small constant. The latter data structure relies heavily on another geometric data structure [Nekrich and Navarro, SWAT 2012].</jats:p>",https://doi.org/10.3390/a13110276,CrossRef,efficient datum structure range shortest unique substring query,jatsplet string length tij substring start position end position substre tij repeat occur otherwise unique substring repeat unique substring great interest computational biology information retrieval give string input shortest unique substring problem find short substring occur elsewhere paper introduce range variant problem call range shortest unique substring problem task construct data structure answer following type online query efficiently give range return short substring tij exactly one occurrence present onlognword datum structure ologwn query time wωlogn word size construction base nontrivial reduction allow apply recently introduce optimal geometric data structure chan icalp additionally present onword datum structure onlogϵn query time ϵgt arbitrarily small constant latter datum structure rely heavily another geometric datum structure nekrich navarro swat jatsp,efficient datum structure range shortest unique substring query jatsplet string length tij substring start position end position substre tij repeat occur otherwise unique substring repeat unique substring great interest computational biology information retrieval give string input shortest unique substring problem find short substring occur elsewhere paper introduce range variant problem call range shortest unique substring problem task construct data structure answer following type online query efficiently give range return short substring tij exactly one occurrence present onlognword datum structure ologwn query time wωlogn word size construction base nontrivial reduction allow apply recently introduce optimal geometric data structure chan icalp additionally present onword datum structure onlogϵn query time ϵgt arbitrarily small constant latter datum structure rely heavily another geometric datum structure nekrich navarro swat jatsp,0.47413793103448276,0.13793103448275862,0.15517241379310345,0.08620689655172414,116.0,1.0,0.0,0.0,2.0
Computer Science,Algorithms and Data Structures,Quantitative,Voxelisation Algorithms and Data Structures: A Review,"<jats:p>Voxel-based data structures, algorithms, frameworks, and interfaces have been used in computer graphics and many other applications for decades. There is a general necessity to seek adequate digital representations, such as voxels, that would secure unified data structures, multi-resolution options, robust validation procedures and flexible algorithms for different 3D tasks. In this review, we evaluate the most common properties and algorithms for voxelisation of 2D and 3D objects. Thus, many voxelisation algorithms and their characteristics are presented targeting points, lines, triangles, surfaces and solids as geometric primitives. For lines, we identify three groups of algorithms, where the first two achieve different voxelisation connectivity, while the third one presents voxelisation of curves. We can say that surface voxelisation is a more desired voxelisation type compared to solid voxelisation, as it can be achieved faster and requires less memory if voxels are stored in a sparse way. At the same time, we evaluate in the paper the available voxel data structures. We split all data structures into static and dynamic grids considering the frequency to update a data structure. Static grids are dominated by SVO-based data structures focusing on memory footprint reduction and attributes preservation, where SVDAG and SSVDAG are the most advanced methods. The state-of-the-art dynamic voxel data structure is NanoVDB which is superior to the rest in terms of speed as well as support for out-of-core processing and data management, which is the key to handling large dynamically changing scenes. Overall, we can say that this is the first review evaluating the available voxelisation algorithms for different geometric primitives as well as voxel data structures.</jats:p>",https://doi.org/10.3390/s21248241,CrossRef,voxelisation algorithm data structure review,jatspvoxelbase datum structure algorithm framework interface use computer graphic many application decade general necessity seek adequate digital representation voxel would secure unified data structure multiresolution option robust validation procedure flexible algorithm different task review evaluate common property algorithm voxelisation object thus many voxelisation algorithm characteristic present target point line triangle surface solid geometric primitive line identify three group algorithm first two achieve different voxelisation connectivity third one present voxelisation curve say surface voxelisation desire voxelisation type compare solid voxelisation achieve fast require less memory voxel store sparse way time evaluate paper available voxel datum structure split data structure static dynamic grid consider frequency update data structure static grid dominate svobase data structure focus memory footprint reduction attribute preservation svdag ssvdag advanced method stateoftheart dynamic voxel datum structure nanovdb superior rest term speed well support outofcore processing datum management key handle large dynamically change scene overall say first review evaluate available voxelisation algorithm different geometric primitive well voxel datum structuresjatsp,voxelisation algorithm data structure review jatspvoxelbase datum structure algorithm framework interface use computer graphic many application decade general necessity seek adequate digital representation voxel would secure unified data structure multiresolution option robust validation procedure flexible algorithm different task review evaluate common property algorithm voxelisation object thus many voxelisation algorithm characteristic present target point line triangle surface solid geometric primitive line identify three group algorithm first two achieve different voxelisation connectivity third one present voxelisation curve say surface voxelisation desire voxelisation type compare solid voxelisation achieve fast require less memory voxel store sparse way time evaluate paper available voxel datum structure split data structure static dynamic grid consider frequency update data structure static grid dominate svobase data structure focus memory footprint reduction attribute preservation svdag ssvdag advanced method stateoftheart dynamic voxel datum structure nanovdb superior rest term speed well support outofcore processing datum management key handle large dynamically change scene overall say first review evaluate available voxelisation algorithm different geometric primitive well voxel datum structuresjatsp,0.5471698113207547,0.1069182389937107,0.20125786163522014,0.0440251572327044,79.5,0.0,0.0,0.0,1.0
Computer Science,Algorithms and Data Structures,Quantitative,"Key Concepts, Weakness and Benchmark on Hash Table Data Structures","<jats:p>Most computer programs or applications need fast data structures. The performance of a data structure is necessarily influenced by the complexity of its common operations; thus, any data-structure that exhibits a theoretical complexity of amortized constant time in several of its main operations should draw a lot of attention. Such is the case of a family of data structures that is called hash tables. However, what is the real efficiency of these hash tables? That is an interesting question with no simple answer and there are some issues to be considered. Of course, there is not a unique hash table; in fact, there are several sub-groups of hash tables, and, even more, not all programming languages use the same variety of hash tables in their default hash table implementation, neither they have the same interface. Nevertheless, all hash tables do have a common issue: they have to solve hash collisions; that is a potential weakness and it also induces a classification of hash tables according to the strategy to solve collisions. In this paper, some key concepts about hash tables are exposed and some definitions about those key concepts are reviewed and clarified, especially in order to study the characteristics of the main strategies to implement hash tables and how they deal with hash collisions. Then, some benchmark cases are designed and presented to assess the performance of hash tables. The cases have been designed to be randomized, to be self-tested, to be representative of a real user cases, and to expose and analyze the impact of different factors over the performance across different hash tables and programming languages. Then, all cases have been programmed using C++, Java and Python and analyzed in terms of interfaces and efficiency (time and memory). The benchmark yields important results about the performance of these structures and its (lack of) relationship with complexity analysis.</jats:p>",https://doi.org/10.3390/a15030100,CrossRef,key concept weakness benchmark hash table datum structure,jatspmost computer program application need fast data structure performance data structure necessarily influence complexity common operation thus datastructure exhibit theoretical complexity amortize constant time several main operation draw lot attention case family datum structure call hash table however real efficiency hash table interesting question simple answer issue consider course unique hash table fact several subgroup hash table even programming language use variety hash table default hash table implementation neither interface nevertheless hash table common issue solve hash collision potential weakness also induce classification hash table accord strategy solve collision paper key concept hash table expose definition key concept review clarify especially order study characteristic main strategy implement hash table deal hash collision benchmark case design present assess performance hash table case design randomize selfteste representative real user case expose analyze impact different factor performance across different hash table programming language case program use java python analyze term interface efficiency time memory benchmark yield important result performance structure lack relationship complexity analysisjatsp,key concept weakness benchmark hash table datum structure jatspmost computer program application need fast data structure performance data structure necessarily influence complexity common operation thus datastructure exhibit theoretical complexity amortize constant time several main operation draw lot attention case family datum structure call hash table however real efficiency hash table interesting question simple answer issue consider course unique hash table fact several subgroup hash table even programming language use variety hash table default hash table implementation neither interface nevertheless hash table common issue solve hash collision potential weakness also induce classification hash table accord strategy solve collision paper key concept hash table expose definition key concept review clarify especially order study characteristic main strategy implement hash table deal hash collision benchmark case design present assess performance hash table case design randomize selfteste representative real user case expose analyze impact different factor performance across different hash table programming language case program use java python analyze term interface efficiency time memory benchmark yield important result performance structure lack relationship complexity analysisjatsp,0.6645962732919255,0.10559006211180125,0.14285714285714285,0.049689440993788817,161.0,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Qualitative,ANALYSIS OF ALGORITHMS FOR THE FORMATION OF CODE STRUCTURES AFFECTING THE QUALITY OF DATA TRANSMISSION IN INFOCOMMUNICATION SYSTEMS,"<jats:p>Achieving the best quality indicators of transmission through the channels of modern communication systems is always of urgent importance for developers and users of information communication systems. At the same time, to ensure high transmission reliability and performance, various coding methods and methods of converting the transmitted data can be used. Accordingly, each of the proposed data processing methods has its advantages and disadvantages, which determines their attractiveness or application limitations for the data being transmitted. In this paper, the analysis of algorithms for forming signal code structures of traditional interference-resistant positional codes, codes with an even number of units, and a nine-element Hamming code is carried out. Classical positional coding is inferior in such important data transmission parameters as information capacity and entropy. However, in some cases, for example, when the results of data transfer quality parameters calculations are significantly influenced by the language of the transmitted textual information or the volume of the analyzed text (the influence is more likely to be noticeable in individual cases, and not in general), then an important value acquires the possibility of applying a certain/adapted type of encoding of the transmitted data. The article conducts theoretical research and calculates the main qualitative parameters of the studied code constructions for various initial conditions. A comparative analysis and assessment of the influence of the studied parameters on the quality of data transmission was carried out. Conducted theoretical studies show that, under certain conditions, positional coding provides a significant gain in the main quality indicators of data processing and can be successfully applied for coding and transmission of digital data through the channels of modern information transmission systems. In order to practically confirm the reliability of the obtained results, relevant studies should be conducted, for example, with simulation on a software model of a virtual transmission system with different coding principles on modern computer systems.</jats:p>",https://doi.org/10.28925/2663-4023.2024.24.9098,CrossRef,analysis algorithm formation code structure affect quality datum transmission infocommunication system,jatspachieve good quality indicator transmission channel modern communication system always urgent importance developer user information communication system time ensure high transmission reliability performance various code method method convert transmit datum use accordingly propose datum processing method advantage disadvantage determine attractiveness application limitation datum transmit paper analysis algorithm form signal code structure traditional interferenceresistant positional code code even number unit nineelement hamming code carry classical positional coding inferior important data transmission parameter information capacity entropy however case example result datum transfer quality parameter calculation significantly influence language transmit textual information volume analyzed text influence likely noticeable individual case general important value acquire possibility apply certainadapte type encoding transmit datum article conduct theoretical research calculate main qualitative parameter studied code construction various initial condition comparative analysis assessment influence study parameter quality datum transmission carry conduct theoretical study show certain condition positional coding provide significant gain main quality indicator datum processing successfully apply coding transmission digital datum channel modern information transmission system order practically confirm reliability obtain result relevant study conduct example simulation software model virtual transmission system different code principle modern computer systemsjatsp,analysis algorithm formation code structure affect quality datum transmission infocommunication system jatspachieve good quality indicator transmission channel modern communication system always urgent importance developer user information communication system time ensure high transmission reliability performance various code method method convert transmit datum use accordingly propose datum processing method advantage disadvantage determine attractiveness application limitation datum transmit paper analysis algorithm form signal code structure traditional interferenceresistant positional code code even number unit nineelement hamming code carry classical positional coding inferior important data transmission parameter information capacity entropy however case example result datum transfer quality parameter calculation significantly influence language transmit textual information volume analyzed text influence likely noticeable individual case general important value acquire possibility apply certainadapte type encoding transmit datum article conduct theoretical research calculate main qualitative parameter studied code construction various initial condition comparative analysis assessment influence study parameter quality datum transmission carry conduct theoretical study show certain condition positional coding provide significant gain main quality indicator datum processing successfully apply coding transmission digital datum channel modern information transmission system order practically confirm reliability obtain result relevant study conduct example simulation software model virtual transmission system different code principle modern computer systemsjatsp,0.6077348066298343,0.1270718232044199,0.1878453038674033,0.04419889502762431,181.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Qualitative,Avoiding a giant component,"<jats:title>Abstract</jats:title><jats:p>Let<jats:italic>e</jats:italic><jats:sub>1</jats:sub>, <jats:italic>e</jats:italic>′<jats:sub>1</jats:sub>;<jats:italic>e</jats:italic><jats:sub>2</jats:sub>, <jats:italic>e</jats:italic>′<jats:sub>2</jats:sub>;…;<jats:italic>e<jats:sub>i</jats:sub></jats:italic>, <jats:italic>e</jats:italic>′<jats:sub><jats:italic>i</jats:italic></jats:sub>;⋅⋅⋅ be a sequence of ordered pairs of edges chosen uniformly at random from the edge set of the complete graph<jats:italic>K<jats:sub>n</jats:sub></jats:italic>(i.e. we sample with replacement). This sequence is used to form a graph by choosing at stage<jats:italic>i</jats:italic>,<jats:italic>i</jats:italic>=1,…, one edge from<jats:italic>e<jats:sub>i</jats:sub></jats:italic>,<jats:italic>e</jats:italic>′<jats:sub><jats:italic>i</jats:italic></jats:sub>to be an edge in the graph, where the choice at stage<jats:italic>i</jats:italic>is based only on the observation of the edges that have appeared by stage<jats:italic>i</jats:italic>. We show that these choices can be made so that<jats:bold>whp</jats:bold>the size of the largest component of the graph formed at stage 0.535<jats:italic>n</jats:italic>is polylogarithmic in<jats:italic>n</jats:italic>. This resolves a question of Achlioptas. © 2001 John Wiley &amp; Sons, Inc. Random Struct. Alg., 19, 75–85, 2001</jats:p>",https://doi.org/10.1002/rsa.1019,CrossRef,avoid giant component,jatstitleabstractjatstitlejatspletjatsitalicejatsitalicjatssubjatssub jatsitalicejatssubijatssubjatsitalic sequence order pair edge choose uniformly random edge set complete graphjatsitalickjatssubnjatssubjatsitalicie sample replacement sequence use form graph choose stagejatsitalicijatsitalicjatsitalicijatsitalic one edge edge graph choice stagejatsitalicijatsitalicis base observation edge appear stagejatsitalicijatsitalic show choice make thatjatsboldwhpjatsboldthe size large component graph form stage jatsitalicnjatsitalicis polylogarithmic injatsitalicnjatsitalic resolve question achliopta john wiley amp sons inc random struct alg jatsp,avoid giant component jatstitleabstractjatstitlejatspletjatsitalicejatsitalicjatssubjatssub jatsitalicejatssubijatssubjatsitalic sequence order pair edge choose uniformly random edge set complete graphjatsitalickjatssubnjatssubjatsitalicie sample replacement sequence use form graph choose stagejatsitalicijatsitalicjatsitalicijatsitalic one edge edge graph choice stagejatsitalicijatsitalicis base observation edge appear stagejatsitalicijatsitalic show choice make thatjatsboldwhpjatsboldthe size large component graph form stage jatsitalicnjatsitalicis polylogarithmic injatsitalicnjatsitalic resolve question achliopta john wiley amp sons inc random struct alg jatsp,0.5087719298245614,0.10526315789473684,0.10526315789473684,0.017543859649122806,57.0,0.0,0.0,0.0,3.0
Computer Science,Algorithms and Data Structures,Qualitative,Feasibility of machine learning algorithms for classifying damaged offshore jacket structures using SCADA data,"<jats:title>Abstract</jats:title>
               <jats:p>The best practise for structural damage detection currently relies on the installation of structural health monitoring systems for the collection of dedicated high frequency measurements. Switching to the employment of the wind turbine’s SCADA (Supervisory Control and Data Acquisition) signals and their commonly recorded low frequency statistics can lead to a reduction in the number of ad-hoc monitoring sensors and quantity of data required. In this paper, aero-hydro-servo-elastic simulations for a model of a turbine are used to assess its loads and any changes in the dynamics under healthy state and a damaged configuration case study. To prove the feasibility of the damage detection through low-resolution data, the statistics of the typically recorded signals from the SCADA and the structural monitoring systems are fed into a database for training and testing of classification algorithms. The ability of the machine learning models to generalise the classification for both stochasticity and uncertainties in the environmental conditions are tested. Decision tree-based classifiers showed the capability to capture the damage for the majority of the operating conditions considered. Though the setup of the traditional SCADA sensors had to be supplemented with an additional structural health monitoring sensor, the detection of the damage has been shown feasible by referring to low-frequency statistics only.</jats:p>",https://doi.org/10.1088/1742-6596/1669/1/012021,CrossRef,feasibility machine learn algorithm classify damage offshore jacket structure use scada datum,jatstitleabstractjatstitle jatspthe good practise structural damage detection currently rely installation structural health monitoring system collection dedicated high frequency measurement switch employment wind turbine scada supervisory control datum acquisition signal commonly record low frequency statistic lead reduction number adhoc monitor sensor quantity datum require paper aerohydroservoelastic simulation model turbine use assess load change dynamic healthy state damaged configuration case study prove feasibility damage detection lowresolution datum statistic typically record signal scada structural monitoring system feed database training testing classification algorithm ability machine learn model generalise classification stochasticity uncertainty environmental condition test decision treebase classifier show capability capture damage majority operating condition consider though setup traditional scada sensor supplement additional structural health monitoring sensor detection damage show feasible refer lowfrequency statistic onlyjatsp,feasibility machine learn algorithm classify damage offshore jacket structure use scada datum jatstitleabstractjatstitle jatspthe good practise structural damage detection currently rely installation structural health monitoring system collection dedicated high frequency measurement switch employment wind turbine scada supervisory control datum acquisition signal commonly record low frequency statistic lead reduction number adhoc monitor sensor quantity datum require paper aerohydroservoelastic simulation model turbine use assess load change dynamic healthy state damaged configuration case study prove feasibility damage detection lowresolution datum statistic typically record signal scada structural monitoring system feed database training testing classification algorithm ability machine learn model generalise classification stochasticity uncertainty environmental condition test decision treebase classifier show capability capture damage majority operating condition consider though setup traditional scada sensor supplement additional structural health monitoring sensor detection damage show feasible refer lowfrequency statistic onlyjatsp,0.6333333333333333,0.10833333333333334,0.125,0.03333333333333333,120.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Qualitative,Infinite paths in randomly oriented lattices,"<jats:title>Abstract</jats:title><jats:p>The square lattice is used to generate an oriented graph in which a rightward or upward arrow is present on each edge with probability <jats:italic>a</jats:italic>, and a leftward or downward arrow with probability <jats:italic>b</jats:italic>. Independence between different edges of the square lattice is assumed, but nothing is assumed concerning the dependence between the two possible orientations at any given edge. A property of self‐duality is exploited to show that, when <jats:italic>a</jats:italic>+<jats:italic>b</jats:italic>=1, the process is, in a sense to be made precise, either critical or supercritical, but not subcritical. This observation enables progress with the percolation problem in which each horizontal edge is oriented rightward with probability <jats:italic>p</jats:italic> and otherwise leftward, and each vertical edge is oriented upward with probability <jats:italic>p</jats:italic> and otherwise downward. © 2001 John Wiley &amp; Sons, Inc. Random Struct. Alg., 18, 257–266, 2001</jats:p>",https://doi.org/10.1002/rsa.1007,CrossRef,infinite path randomly orient lattice,jatstitleabstractjatstitlejatspthe square lattice use generate orient graph rightward upward arrow present edge probability jatsitalicajatsitalic leftward downward arrow probability jatsitalicbjatsitalic independence different edge square lattice assume nothing assume concern dependence two possible orientation give edge property exploit show jatsitalicajatsitalicjatsitalicbjatsitalic process sense make precise either critical supercritical subcritical observation enable progress percolation problem horizontal edge orient rightward probability jatsitalicpjatsitalic otherwise leftward vertical edge orient upward probability jatsitalicpjatsitalic otherwise downward john wiley amp sons inc random struct alg jatsp,infinite path randomly orient lattice jatstitleabstractjatstitlejatspthe square lattice use generate orient graph rightward upward arrow present edge probability jatsitalicajatsitalic leftward downward arrow probability jatsitalicbjatsitalic independence different edge square lattice assume nothing assume concern dependence two possible orientation give edge property exploit show jatsitalicajatsitalicjatsitalicbjatsitalic process sense make precise either critical supercritical subcritical observation enable progress percolation problem horizontal edge orient rightward probability jatsitalicpjatsitalic otherwise leftward vertical edge orient upward probability jatsitalicpjatsitalic otherwise downward john wiley amp sons inc random struct alg jatsp,0.35526315789473684,0.11842105263157894,0.19736842105263158,0.06578947368421052,76.0,0.0,0.0,0.0,3.0
Computer Science,Algorithms and Data Structures,Qualitative,Temporal Multimodal Data-Processing Algorithms Based on Algebraic System of Aggregates,"<jats:p>In many tasks related to an object’s observation or real-time monitoring, the gathering of temporal multimodal data is required. Such data sets are semantically connected as they reflect different aspects of the same object. However, data sets of different modalities are usually stored and processed independently. This paper presents an approach based on the application of the Algebraic System of Aggregates (ASA) operations that enable the creation of an object’s complex representation, referred to as multi-image (MI). The representation of temporal multimodal data sets as the object’s MI yields simple data-processing procedures as it provides a solid semantic connection between data describing different features of the same object, process, or phenomenon. In terms of software development, the MI is a complex data structure used for data processing with ASA operations. This paper provides a detailed presentation of this concept.</jats:p>",https://doi.org/10.3390/a16040186,CrossRef,temporal multimodal dataprocessing algorithm base algebraic system aggregate,jatspin many task relate object observation realtime monitor gathering temporal multimodal datum require data set semantically connect reflect different aspect object however datum set different modality usually store process independently paper present approach base application algebraic system aggregate asa operation enable creation object complex representation refer multiimage representation temporal multimodal data set object yield simple dataprocessing procedure provide solid semantic connection datum describe different feature object process phenomenon term software development complex data structure use datum processing asa operation paper provide detailed presentation conceptjatsp,temporal multimodal dataprocessing algorithm base algebraic system aggregate jatspin many task relate object observation realtime monitor gathering temporal multimodal datum require data set semantically connect reflect different aspect object however datum set different modality usually store process independently paper present approach base application algebraic system aggregate asa operation enable creation object complex representation refer multiimage representation temporal multimodal data set object yield simple dataprocessing procedure provide solid semantic connection datum describe different feature object process phenomenon term software development complex data structure use datum processing asa operation paper provide detailed presentation conceptjatsp,0.5119047619047619,0.20238095238095238,0.20238095238095238,0.047619047619047616,84.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Mixed Methods,Data Mining Algorithms for Smart Cities: A Bibliometric Analysis,"<jats:p>Smart cities connect people and places using innovative technologies such as Data Mining (DM), Machine Learning (ML), big data, and the Internet of Things (IoT). This paper presents a bibliometric analysis to provide a comprehensive overview of studies associated with DM technologies used in smart cities applications. The study aims to identify the main DM techniques used in the context of smart cities and how the research field of DM for smart cities evolves over time. We adopted both qualitative and quantitative methods to explore the topic. We used the Scopus database to find relative articles published in scientific journals. This study covers 197 articles published over the period from 2013 to 2021. For the bibliometric analysis, we used the Biliometrix library, developed in R. Our findings show that there is a wide range of DM technologies used in every layer of a smart city project. Several ML algorithms, supervised or unsupervised, are adopted for operating the instrumentation, middleware, and application layer. The bibliometric analysis shows that DM for smart cities is a fast-growing scientific field. Scientists from all over the world show a great interest in researching and collaborating on this interdisciplinary scientific field.</jats:p>",https://doi.org/10.3390/a14080242,CrossRef,datum mining algorithm smart city bibliometric analysis,jatspsmart city connect people place use innovative technology datum mining machine learning big datum internet thing iot paper present bibliometric analysis provide comprehensive overview study associate technology use smart city application study aim identify main technique use context smart city research field smart city evolve time adopt qualitative quantitative method explore topic use scopus database find relative article publish scientific journal study cover article publish period bibliometric analysis use biliometrix library develop finding show wide range technology use every layer smart city project several algorithm supervise unsupervised adopt operate instrumentation middleware application layer bibliometric analysis show smart city fastgrowe scientific field scientist world show great interest research collaborate interdisciplinary scientific fieldjatsp,datum mining algorithm smart city bibliometric analysis jatspsmart city connect people place use innovative technology datum mining machine learning big datum internet thing iot paper present bibliometric analysis provide comprehensive overview study associate technology use smart city application study aim identify main technique use context smart city research field smart city evolve time adopt qualitative quantitative method explore topic use scopus database find relative article publish scientific journal study cover article publish period bibliometric analysis use biliometrix library develop finding show wide range technology use every layer smart city project several algorithm supervise unsupervised adopt operate instrumentation middleware application layer bibliometric analysis show smart city fastgrowe scientific field scientist world show great interest research collaborate interdisciplinary scientific fieldjatsp,0.5315315315315315,0.14414414414414414,0.1981981981981982,0.0,111.0,1.0,1.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Mixed Methods,Hunting for sharp thresholds,"<jats:title>Abstract</jats:title><jats:p>A basic phenomenon in random structures such as random graphs is the threshold phenomenon, where a system undergoes a swift qualitative change as result of a small change in a parameter guiding its probabilistic structure. In an earlier paper [J Amer Math Soc 12 (1999), 1017–1054] a general criterion was presented for structures to undergo such a phase transition. In this paper we give a survey of the state of the art in applying the aforementioned criterion, exemplify the techniques by proving the existence of a sharp threshold for hypergraph colorability, and present some related open problems. © 2004 Wiley Periodicals, Inc. Random Struct. Alg., 26, 2005</jats:p>",https://doi.org/10.1002/rsa.20042,CrossRef,hunt sharp threshold,jatstitleabstractjatstitlejatspa basic phenomenon random structure random graph threshold phenomenon system undergo swift qualitative change result small change parameter guide probabilistic structure early paper amer math soc general criterion present structure undergo phase transition paper give survey state art apply aforementioned criterion exemplify technique prove existence sharp threshold hypergraph colorability present relate open problem wiley periodicals inc random struct alg jatsp,hunt sharp threshold jatstitleabstractjatstitlejatspa basic phenomenon random structure random graph threshold phenomenon system undergo swift qualitative change result small change parameter guide probabilistic structure early paper amer math soc general criterion present structure undergo phase transition paper give survey state art apply aforementioned criterion exemplify technique prove existence sharp threshold hypergraph colorability present relate open problem wiley periodicals inc random struct alg jatsp,0.55,0.11666666666666667,0.23333333333333334,0.0,60.0,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Mixed Methods,Graph‐based data structures for skeleton‐based refinement algorithms,"<jats:title>Abstract</jats:title><jats:p>In this paper, we discuss a class of adaptive refinement algorithms for generating unstructured meshes in two and three dimensions. We focus on skeleton‐based refinement (SBR) algorithms as proposed by Plaza and Carey (<jats:italic>Appl. Numer. Math.</jats:italic> 2000; <jats:bold>32</jats:bold>:195) and provide an extension that involves the introduction of the graph of the skeleton for meshes consisting of simplex cells. By the use of data structures derived from the graph of the skeleton, we reformulate the SBR scheme and devise a more natural and consistent approach for this class of adaptive refinement algorithms. As an illustrative case, we discuss in detail the graphs for 2D refinement of triangulations and for 3D we propose a corresponding new face‐based data structure for tetrahedra. Experiments using the 2D algorithm and exploring the properties of the associated graph are provided. Copyright © 2001 John Wiley &amp; Sons, Ltd.</jats:p>",https://doi.org/10.1002/cnm.460,CrossRef,data structure refinement algorithm,jatstitleabstractjatstitlejatspin paper discuss class adaptive refinement algorithm generate unstructured mesh two three dimension focus refinement sbr algorithm propose plaza carey jatsitalicappl numer mathjatsitalic jatsboldjatsbold provide extension involve introduction graph skeleton mesh consist simplex cell use datum structure derive graph skeleton reformulate sbr scheme devise natural consistent approach class adaptive refinement algorithm illustrative case discuss detail graph refinement triangulation propose corresponding new datum structure tetrahedra experiment use algorithm explore property associated graph provide copyright john wiley amp son ltdjatsp,data structure refinement algorithm jatstitleabstractjatstitlejatspin paper discuss class adaptive refinement algorithm generate unstructured mesh two three dimension focus refinement sbr algorithm propose plaza carey jatsitalicappl numer mathjatsitalic jatsboldjatsbold provide extension involve introduction graph skeleton mesh consist simplex cell use datum structure derive graph skeleton reformulate sbr scheme devise natural consistent approach class adaptive refinement algorithm illustrative case discuss detail graph refinement triangulation propose corresponding new datum structure tetrahedra experiment use algorithm explore property associated graph provide copyright john wiley amp son ltdjatsp,0.358974358974359,0.1282051282051282,0.05128205128205128,0.0,78.0,1.0,0.0,0.0,3.0
Computer Science,Algorithms and Data Structures,Mixed Methods,Percolation critical probabilities of matching lattice‐pairs,"<jats:title>Abstract</jats:title><jats:p>A necessary and sufficient condition is established for the strict inequality  between the critical probabilities of site percolation on a one‐ended, quasi‐transitive, plane graph  and on its matching graph . When  is transitive, strict inequality holds if and only if  is not a triangulation. The basic approach is the standard method of enhancements, but its implementation has complexity arising from the non‐Euclidean (hyperbolic) space, the study of site (rather than bond) percolation, and the generality of the assumption of quasi‐transitivity. This result is complementary to the work of the authors (“Hyperbolic site percolation,” <jats:styled-content>arXiv:2203.00981</jats:styled-content>) on the equality , where  is the critical probability for the existence of a unique infinite open cluster. It implies for transitive, one‐ended  that , with equality if and only if  is a triangulation.</jats:p>",https://doi.org/10.1002/rsa.21226,CrossRef,percolation critical probability match,jatstitleabstractjatstitlejatspa necessary sufficient condition establish strict inequality critical probability site percolation plane graph matching graph transitive strict inequality hold triangulation basic approach standard method enhancement implementation complexity arise hyperbolic space study site rather bond percolation generality assumption result complementary work author hyperbolic site percolation jatsstyledcontentarxivjatsstyledcontent equality critical probability existence unique infinite open cluster imply transitive equality triangulationjatsp,percolation critical probability match jatstitleabstractjatstitlejatspa necessary sufficient condition establish strict inequality critical probability site percolation plane graph matching graph transitive strict inequality hold triangulation basic approach standard method enhancement implementation complexity arise hyperbolic space study site rather bond percolation generality assumption result complementary work author hyperbolic site percolation jatsstyledcontentarxivjatsstyledcontent equality critical probability existence unique infinite open cluster imply transitive equality triangulationjatsp,0.631578947368421,0.08771929824561403,0.24561403508771928,0.017543859649122806,57.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Mixed Methods,"Entropy, Triangulation, and Point Location in Planar Subdivisions","A data structure is presented for point location in connected planar
subdivisions when the distribution of queries is known in advance. The data
structure has an expected query time that is within a constant factor of
optimal. More specifically, an algorithm is presented that preprocesses a
connected planar subdivision G of size n and a query distribution D to produce
a point location data structure for G. The expected number of point-line
comparisons performed by this data structure, when the queries are distributed
according to D, is H + O(H^{2/3}+1) where H=H(G,D) is a lower bound on the
expected number of point-line comparisons performed by any linear decision tree
for point location in G under the query distribution D. The preprocessing
algorithm runs in O(n log n) time and produces a data structure of size O(n).
These results are obtained by creating a Steiner triangulation of G that has
near-minimum entropy.",http://arxiv.org/abs/0901.1908v1,arXiv,entropy triangulation point location planar subdivision,data structure present point location connected planar subdivision distribution query know advance datum structure expect query time within constant factor optimal specifically algorithm present preprocesse connect planar subdivision size query distribution produce point location datum structure expected number pointline comparison perform datum structure query distribute accord hhgd lower bind expect number pointline comparison perform linear decision tree point location query distribution preprocessing algorithm run log time produce data structure size result obtain create steiner triangulation nearminimum entropy,entropy triangulation point location planar subdivision data structure present point location connected planar subdivision distribution query know advance datum structure expect query time within constant factor optimal specifically algorithm present preprocesse connect planar subdivision size query distribution produce point location datum structure expected number pointline comparison perform datum structure query distribute accord hhgd lower bind expect number pointline comparison perform linear decision tree point location query distribution preprocessing algorithm run log time produce data structure size result obtain create steiner triangulation nearminimum entropy,0.6363636363636364,0.18181818181818182,0.11688311688311688,0.012987012987012988,77.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Design and Development,Note on distance matrix hashing,"Hashing algorithm of dynamical set of distances is described. Proposed
hashing function is residual. Data structure which implementation accelerates
computations is presented",http://arxiv.org/abs/1901.09505v2,arXiv,note distance matrix hashing,hash algorithm dynamical set distance describe propose hash function residual datum structure implementation accelerate computation present,note distance matrix hashing hash algorithm dynamical set distance describe propose hash function residual datum structure implementation accelerate computation present,0.5,0.125,0.1875,0.0,16.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Design and Development,"Efficient algorithms for enumerating maximal common subsequences of two
  strings","We propose efficient algorithms for enumerating maximal common subsequences
(MCSs) of two strings. Efficiency of the algorithms are estimated by the
preprocessing-time, space, and delay-time complexities. One algorithm prepares
a cubic-space data structure in cubic time to output each MCS in linear time.
This data structure can be used to search for particular MCSs satisfying some
condition without performing an explicit enumeration. Another prepares a
quadratic-space data structure in quadratic time to output each MCS in linear
time, and the other prepares a linear-space data structure in quadratic time to
output each MCS in linearithmic time.",http://arxiv.org/abs/2307.10552v1,arXiv,efficient algorithm enumerate maximal common subsequence two string,propose efficient algorithm enumerate maximal common subsequence mcss two string efficiency algorithm estimate preprocessingtime space delaytime complexity one algorithm prepare cubicspace datum structure cubic time output mcs linear time datum structure use search particular mcss satisfy condition without perform explicit enumeration another prepare quadraticspace datum structure quadratic time output mcs linear time prepare linearspace datum structure quadratic time output mcs linearithmic time,efficient algorithm enumerate maximal common subsequence two string propose efficient algorithm enumerate maximal common subsequence mcss two string efficiency algorithm estimate preprocessingtime space delaytime complexity one algorithm prepare cubicspace datum structure cubic time output mcs linear time datum structure use search particular mcss satisfy condition without perform explicit enumeration another prepare quadraticspace datum structure quadratic time output mcs linear time prepare linearspace datum structure quadratic time output mcs linearithmic time,0.5161290322580645,0.0967741935483871,0.1935483870967742,0.04838709677419355,62.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Design and Development,3-Coloring in Time O(1.3217^n),"We propose a new algorithm for 3-coloring that runs in time O(1.3217^n). For
this algorithm, we make use of the time O(1.3289^n) algorithm for 3-coloring by
Beigel and Eppstein. They described a structure in all graphs, whose vertices
could be colored relatively easily. In this paper, we improve upon this
structure and present new ways to determine how the involved vertices reduce
the runtime of the algorithm.",http://arxiv.org/abs/2302.13644v1,arXiv,color time,propose new algorithm color run time algorithm make use time algorithm color beigel eppstein describe structure graph whose vertex could color relatively easily paper improve upon structure present new way determine involve vertex reduce runtime algorithm,color time propose new algorithm color run time algorithm make use time algorithm color beigel eppstein describe structure graph whose vertex could color relatively easily paper improve upon structure present new way determine involve vertex reduce runtime algorithm,0.3888888888888889,0.16666666666666666,0.08333333333333333,0.05555555555555555,36.0,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Design and Development,"A Note on the Performance of Algorithms for Solving Linear Diophantine
  Equations in the Naturals","We implement four algorithms for solving linear Diophantine equations in the
naturals: a lexicographic enumeration algorithm, a completion procedure, a
graph-based algorithm, and the Slopes algorithm. As already known, the
lexicographic enumeration algorithm and the completion procedure are slower
than the other two algorithms. We compare in more detail the graph-based
algorithm and the Slopes algorithm. In contrast to previous comparisons, our
work suggests that they are equally fast on small inputs, but the graph-based
algorithm gets much faster as the input grows. We conclude that implementations
of AC-unification algorithms should use the graph-based algorithm for maximum
efficiency.",http://arxiv.org/abs/2104.05200v1,arXiv,note performance algorithm solve linear diophantine equation natural,implement four algorithm solve linear diophantine equation natural lexicographic enumeration algorithm completion procedure graphbased algorithm slope algorithm already know lexicographic enumeration algorithm completion procedure slow two algorithm compare detail graphbased algorithm slope algorithm contrast previous comparison work suggest equally fast small input graphbased algorithm get much fast input grow conclude implementation acunification algorithm use graphbased algorithm maximum efficiency,note performance algorithm solve linear diophantine equation natural implement four algorithm solve linear diophantine equation natural lexicographic enumeration algorithm completion procedure graphbased algorithm slope algorithm already know lexicographic enumeration algorithm completion procedure slow two algorithm compare detail graphbased algorithm slope algorithm contrast previous comparison work suggest equally fast small input graphbased algorithm get much fast input grow conclude implementation acunification algorithm use graphbased algorithm maximum efficiency,0.3103448275862069,0.1724137931034483,0.1896551724137931,0.05172413793103448,58.0,3.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Design and Development,"Evolving Categories: Consistent Framework for Representation of Data and
  Algorithms","A concept of ""evolving categories"" is suggested to build a simple, scalable,
mathematically consistent framework for representing in uniform way both data
and algorithms. A state machine for executing algorithms becomes clear, rich
and powerful semantics, based on category theory, and still allows easy
implementation. Moreover, it gives an original insight into the nature and
semantics of algorithms.",http://arxiv.org/abs/cs/0412089v1,arXiv,evolve category consistent framework representation datum algorithm,concept evolve category suggest build simple scalable mathematically consistent framework represent uniform way datum algorithm state machine execute algorithm become clear rich powerful semantic base category theory still allow easy implementation moreover give original insight nature semantic algorithm,evolve category consistent framework representation datum algorithm concept evolve category suggest build simple scalable mathematically consistent framework represent uniform way datum algorithm state machine execute algorithm become clear rich powerful semantic base category theory still allow easy implementation moreover give original insight nature semantic algorithm,0.34210526315789475,0.13157894736842105,0.2631578947368421,0.07894736842105263,38.0,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Theoretical / Conceptual,Fast Clustering using MapReduce,"Clustering problems have numerous applications and are becoming more
challenging as the size of the data increases. In this paper, we consider
designing clustering algorithms that can be used in MapReduce, the most popular
programming environment for processing large datasets. We focus on the
practical and popular clustering problems, $k$-center and $k$-median. We
develop fast clustering algorithms with constant factor approximation
guarantees. From a theoretical perspective, we give the first analysis that
shows several clustering algorithms are in $\mathcal{MRC}^0$, a theoretical
MapReduce class introduced by Karloff et al. \cite{KarloffSV10}. Our algorithms
use sampling to decrease the data size and they run a time consuming clustering
algorithm such as local search or Lloyd's algorithm on the resulting data set.
Our algorithms have sufficient flexibility to be used in practice since they
run in a constant number of MapReduce rounds. We complement these results by
performing experiments using our algorithms. We compare the empirical
performance of our algorithms to several sequential and parallel algorithms for
the $k$-median problem. The experiments show that our algorithms' solutions are
similar to or better than the other algorithms' solutions. Furthermore, on data
sets that are sufficiently large, our algorithms are faster than the other
parallel algorithms that we tested.",http://arxiv.org/abs/1109.1579v1,arXiv,fast cluster use mapreduce,cluster problem numerous application become challenging size data increase paper consider design cluster algorithm use mapreduce popular programming environment process large dataset focus practical popular cluster problem kcenter kmedian develop fast cluster algorithm constant factor approximation guarantee theoretical perspective give first analysis show several clustering algorithm mathcalmrc theoretical mapreduce class introduce karloff citekarloffsv algorithm use sampling decrease data size run time consume cluster algorithm local search lloyd algorithm result datum set algorithm sufficient flexibility use practice since run constant number mapreduce round complement result perform experiment use algorithm compare empirical performance algorithm several sequential parallel algorithm kmedian problem experiment show algorithms solution similar well algorithm solution furthermore datum set sufficiently large algorithm fast parallel algorithm test,fast cluster use mapreduce cluster problem numerous application become challenging size data increase paper consider design cluster algorithm use mapreduce popular programming environment process large dataset focus practical popular cluster problem kcenter kmedian develop fast cluster algorithm constant factor approximation guarantee theoretical perspective give first analysis show several clustering algorithm mathcalmrc theoretical mapreduce class introduce karloff citekarloffsv algorithm use sampling decrease data size run time consume cluster algorithm local search lloyd algorithm result datum set algorithm sufficient flexibility use practice since run constant number mapreduce round complement result perform experiment use algorithm compare empirical performance algorithm several sequential parallel algorithm kmedian problem experiment show algorithms solution similar well algorithm solution furthermore datum set sufficiently large algorithm fast parallel algorithm test,0.4482758620689655,0.16379310344827586,0.1810344827586207,0.02586206896551724,116.0,1.0,0.0,0.0,2.0
Computer Science,Algorithms and Data Structures,Theoretical / Conceptual,"Optimally selecting the top $k$ values from $X+Y$ with layer-ordered
  heaps","Selection and sorting the Cartesian sum, $X+Y$, are classic and important
problems. Here, a new algorithm is presented, which generates the top $k$
values of the form $X_i+Y_j$. The algorithm relies only on median-of-medians
and is simple to implement. Furthermore, it uses data structures contiguous in
memory, and is fast in practice. The presented algorithm is demonstrated to be
theoretically optimal.",http://arxiv.org/abs/2001.11607v2,arXiv,optimally select top value layerordere heap,selection sort cartesian sum classic important problem new algorithm present generate top value form xiyj algorithm rely medianofmedians simple implement furthermore use data structure contiguous memory fast practice present algorithm demonstrate theoretically optimal,optimally select top value layerordere heap selection sort cartesian sum classic important problem new algorithm present generate top value form xiyj algorithm rely medianofmedians simple implement furthermore use data structure contiguous memory fast practice present algorithm demonstrate theoretically optimal,0.3333333333333333,0.12121212121212122,0.3333333333333333,0.06060606060606061,33.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Theoretical / Conceptual,Theories of Hypergraph-Graph (HG(2)) Data Structure,"Current paper introduces a Hypergraph Graph model of data storage which can
be represented as a hybrid data structure based on Hypergraph and Graph. The
pro-posed data structure is claimed to realize complex combinatorial
structures. The formal definition of the data structure is presented along with
the proper justification from real world scenarios. The paper reports some
elementary concepts of Hypergraph and presents theoretical aspects of the
proposed data structure including the concepts of Path, Cycle etc. The detailed
analysis of weighted HG 2 is presented along with discussions on Cost involved
with HG 2 paths.",http://arxiv.org/abs/1311.7201v1,arXiv,theory hypergraphgraph datum structure,current paper introduce hypergraph graph model datum storage represent hybrid datum structure base hypergraph graph propose datum structure claim realize complex combinatorial structure formal definition data structure present along proper justification real world scenario paper report elementary concept hypergraph present theoretical aspect propose datum structure include concept path cycle etc detail analysis weight present along discussion cost involve path,theory hypergraphgraph datum structure current paper introduce hypergraph graph model datum storage represent hybrid datum structure base hypergraph graph propose datum structure claim realize complex combinatorial structure formal definition data structure present along proper justification real world scenario paper report elementary concept hypergraph present theoretical aspect propose datum structure include concept path cycle etc detail analysis weight present along discussion cost involve path,0.5084745762711864,0.13559322033898305,0.1864406779661017,0.0,59.0,0.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Theoretical / Conceptual,Efficient Kernelization Algorithm for Bipartite Graph Matching,"Finding the maximum matching in bipartite graphs is a fundamental graph
operation widely used in various fields. To expedite the acquisition of the
maximum matching, Karp and Sipser introduced two data reduction rules aimed at
decreasing the input size. However, the KaSi algorithm, which implements the
two data reduction rules, has several drawbacks: a high upper bound on time
complexity and inefficient storage structure. The poor upper bound on time
complexity makes the algorithm lack robustness when dealing with extreme cases,
and the inefficient storage structure struggles to balance vertex merging and
neighborhood traversal operations, leading to poor performance on real-life
graphs. To address these issues, we introduced MVM, an algorithm incorporating
three novel optimization strategies to implement the data reduction rules. Our
theoretical analysis proves that the MVM algorithm, even when using data
structures with the worst search efficiency, can still maintain near-linear
time complexity, ensuring the algorithm's robustness. Additionally, we designed
an innovative storage format that supports efficient vertex merging operations
while preserving the locality of edge sets, thus ensuring the efficiency of
neighborhood traversals in graph algorithms. Finally, we conduct evaluations on
both real-life and synthetic graphs. Extensive experiments demonstrate the
superiority of our method.",http://arxiv.org/abs/2412.00704v1,arXiv,efficient kernelization algorithm bipartite graph matching,find maximum matching bipartite graph fundamental graph operation widely use various field expedite acquisition maximum matching karp sipser introduce two datum reduction rule aim decrease input size however kasi algorithm implement two datum reduction rule several drawback high upper bind time complexity inefficient storage structure poor upper bind time complexity make algorithm lack robustness deal extreme case inefficient storage structure struggle balance vertex merging neighborhood traversal operation lead poor performance reallife graph address issue introduce mvm algorithm incorporate three novel optimization strategy implement data reduction rule theoretical analysis prove mvm algorithm even use datum structure bad search efficiency still maintain nearlinear time complexity ensure algorithms robustness additionally design innovative storage format support efficient vertex merging operation preserve locality edge set thus ensure efficiency neighborhood traversal graph algorithm finally conduct evaluation reallife synthetic graph extensive experiment demonstrate superiority method,efficient kernelization algorithm bipartite graph matching find maximum matching bipartite graph fundamental graph operation widely use various field expedite acquisition maximum matching karp sipser introduce two datum reduction rule aim decrease input size however kasi algorithm implement two datum reduction rule several drawback high upper bind time complexity inefficient storage structure poor upper bind time complexity make algorithm lack robustness deal extreme case inefficient storage structure struggle balance vertex merging neighborhood traversal operation lead poor performance reallife graph address issue introduce mvm algorithm incorporate three novel optimization strategy implement data reduction rule theoretical analysis prove mvm algorithm even use datum structure bad search efficiency still maintain nearlinear time complexity ensure algorithms robustness additionally design innovative storage format support efficient vertex merging operation preserve locality edge set thus ensure efficiency neighborhood traversal graph algorithm finally conduct evaluation reallife synthetic graph extensive experiment demonstrate superiority method,0.5579710144927537,0.14492753623188406,0.14492753623188406,0.057971014492753624,138.0,1.0,0.0,0.0,0.0
Computer Science,Algorithms and Data Structures,Theoretical / Conceptual,Nearest Neighbor based Clustering Algorithm for Large Data Sets,"Clustering is an unsupervised learning technique in which data or objects are
grouped into sets based on some similarity measure. Most of the clustering
algorithms assume that the main memory is infinite and can accommodate the set
of patterns. In reality many applications give rise to a large set of patterns
which does not fit in the main memory. When the data set is too large, much of
the data is stored in the secondary memory. Input/Outputs (I/O) from the disk
are the major bottleneck in designing efficient clustering algorithms for large
data sets. Different designing techniques have been used to design clustering
algorithms for large data sets. External memory algorithms are one class of
algorithms which can be used for large data sets. These algorithms exploit the
hierarchical memory structure of the computers by incorporating locality of
reference directly in the algorithm. This paper makes some contribution towards
designing clustering algorithms in the external memory model (Proposed by
Aggarwal and Vitter 1988) to make the algorithms scalable. In this paper, it is
shown that the Shared near neighbors algorithm is not very I/O efficient since
the computational complexity is same as the I/O complexity. The algorithm is
designed in the external memory model and I/O complexity is reduced. The
computational complexity remains same. We substantiate the theoretical analysis
by showing the performance of the algorithms with their traditional counterpart
by implementing in STXXL library.",http://arxiv.org/abs/1505.05962v1,arXiv,near neighbor base cluster algorithm large datum set,clustering unsupervised learning technique datum object group set base similarity measure cluster algorithm assume main memory infinite accommodate set pattern reality many application give rise large set pattern fit main memory datum set large much data store secondary memory inputoutput disk major bottleneck design efficient clustering algorithm large data set different designing technique use design cluster algorithm large datum set external memory algorithm one class algorithm use large datum set algorithm exploit hierarchical memory structure computer incorporate locality reference directly algorithm paper make contribution towards design cluster algorithm external memory model propose aggarwal vitter make algorithm scalable paper show share near neighbor algorithm efficient since computational complexity complexity algorithm design external memory model complexity reduce computational complexity remain substantiate theoretical analysis show performance algorithm traditional counterpart implement stxxl library,near neighbor base cluster algorithm large datum set clustering unsupervised learning technique datum object group set base similarity measure cluster algorithm assume main memory infinite accommodate set pattern reality many application give rise large set pattern fit main memory datum set large much data store secondary memory inputoutput disk major bottleneck design efficient clustering algorithm large data set different designing technique use design cluster algorithm large datum set external memory algorithm one class algorithm use large datum set algorithm exploit hierarchical memory structure computer incorporate locality reference directly algorithm paper make contribution towards design cluster algorithm external memory model propose aggarwal vitter make algorithm scalable paper show share near neighbor algorithm efficient since computational complexity complexity algorithm design external memory model complexity reduce computational complexity remain substantiate theoretical analysis show performance algorithm traditional counterpart implement stxxl library,0.4806201550387597,0.15503875968992248,0.20155038759689922,0.007751937984496124,129.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Quantitative,Creativity and Artificial Intelligence: A Digital Art Perspective,"This paper describes the application of artificial intelligence to the
creation of digital art. AI is a computational paradigm that codifies
intelligence into machines. There are generally three types of artificial
intelligence and these are machine learning, evolutionary programming and soft
computing. Machine learning is the statistical approach to building intelligent
systems. Evolutionary programming is the use of natural evolutionary systems to
design intelligent machines. Some of the evolutionary programming systems
include genetic algorithm which is inspired by the principles of evolution and
swarm optimization which is inspired by the swarming of birds, fish, ants etc.
Soft computing includes techniques such as agent based modelling and fuzzy
logic. Opportunities on the applications of these to digital art are explored.",http://arxiv.org/abs/1807.08195v1,arXiv,creativity artificial intelligence digital art perspective,paper describe application artificial intelligence creation digital art computational paradigm codify intelligence machine generally three type artificial intelligence machine learn evolutionary programming soft computing machine learning statistical approach build intelligent system evolutionary programming use natural evolutionary system design intelligent machine evolutionary programming system include genetic algorithm inspire principle evolution swarm optimization inspire swarming bird fish ant etc soft computing include technique agent base modelling fuzzy logic opportunity application digital art explore,creativity artificial intelligence digital art perspective paper describe application artificial intelligence creation digital art computational paradigm codify intelligence machine generally three type artificial intelligence machine learn evolutionary programming soft computing machine learning statistical approach build intelligent system evolutionary programming use natural evolutionary system design intelligent machine evolutionary programming system include genetic algorithm inspire principle evolution swarm optimization inspire swarming bird fish ant etc soft computing include technique agent base modelling fuzzy logic opportunity application digital art explore,0.5492957746478874,0.14084507042253522,0.2535211267605634,0.014084507042253521,71.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Quantitative,Comprehensible Artificial Intelligence on Knowledge Graphs: A survey,"Artificial Intelligence applications gradually move outside the safe walls of
research labs and invade our daily lives. This is also true for Machine
Learning methods on Knowledge Graphs, which has led to a steady increase in
their application since the beginning of the 21st century. However, in many
applications, users require an explanation of the Artificial Intelligences
decision. This led to increased demand for Comprehensible Artificial
Intelligence. Knowledge Graphs epitomize fertile soil for Comprehensible
Artificial Intelligence, due to their ability to display connected data, i.e.
knowledge, in a human- as well as machine-readable way. This survey gives a
short history to Comprehensible Artificial Intelligence on Knowledge Graphs.
Furthermore, we contribute by arguing that the concept Explainable Artificial
Intelligence is overloaded and overlapping with Interpretable Machine Learning.
By introducing the parent concept Comprehensible Artificial Intelligence, we
provide a clear-cut distinction of both concepts while accounting for their
similarities. Thus, we provide in this survey a case for Comprehensible
Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine
Learning on Knowledge Graphs and Explainable Artificial Intelligence on
Knowledge Graphs. This leads to the introduction of a novel taxonomy for
Comprehensible Artificial Intelligence on Knowledge Graphs. In addition, a
comprehensive overview of the research on Comprehensible Artificial
Intelligence on Knowledge Graphs is presented and put into the context of the
taxonomy. Finally, research gaps in the field of Comprehensible Artificial
Intelligence on Knowledge Graphs are identified for future research.",http://arxiv.org/abs/2404.03499v1,arXiv,comprehensible artificial intelligence knowledge graph survey,artificial intelligence application gradually move outside safe wall research lab invade daily life also true machine learn method knowledge graph lead steady increase application since beginning century however many application user require explanation artificial intelligence decision lead increase demand comprehensible artificial intelligence knowledge graph epitomize fertile soil comprehensible artificial intelligence due ability display connected datum knowledge human well machinereadable way survey give short history comprehensible artificial intelligence knowledge graph furthermore contribute argue concept explainable artificial intelligence overload overlap interpretable machine learning introduce parent concept comprehensible artificial intelligence provide clearcut distinction concept account similarity thus provide survey case comprehensible artificial intelligence knowledge graph consist interpretable machine learning knowledge graph explainable artificial intelligence knowledge graph lead introduction novel taxonomy comprehensible artificial intelligence knowledge graph addition comprehensive overview research comprehensible artificial intelligence knowledge graph present put context taxonomy finally research gap field comprehensible artificial intelligence knowledge graph identify future research,comprehensible artificial intelligence knowledge graph survey artificial intelligence application gradually move outside safe wall research lab invade daily life also true machine learn method knowledge graph lead steady increase application since beginning century however many application user require explanation artificial intelligence decision lead increase demand comprehensible artificial intelligence knowledge graph epitomize fertile soil comprehensible artificial intelligence due ability display connected datum knowledge human well machinereadable way survey give short history comprehensible artificial intelligence knowledge graph furthermore contribute argue concept explainable artificial intelligence overload overlap interpretable machine learning introduce parent concept comprehensible artificial intelligence provide clearcut distinction concept account similarity thus provide survey case comprehensible artificial intelligence knowledge graph consist interpretable machine learning knowledge graph explainable artificial intelligence knowledge graph lead introduction novel taxonomy comprehensible artificial intelligence knowledge graph addition comprehensive overview research comprehensible artificial intelligence knowledge graph present put context taxonomy finally research gap field comprehensible artificial intelligence knowledge graph identify future research,0.5306122448979592,0.12244897959183673,0.2653061224489796,0.047619047619047616,147.0,0.0,0.0,1.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Quantitative,"Surveying the reach and maturity of machine learning and artificial
  intelligence in astronomy","Machine learning (automated processes that learn by example in order to
classify, predict, discover or generate new data) and artificial intelligence
(methods by which a computer makes decisions or discoveries that would usually
require human intelligence) are now firmly established in astronomy. Every
week, new applications of machine learning and artificial intelligence are
added to a growing corpus of work. Random forests, support vector machines, and
neural networks (artificial, deep, and convolutional) are now having a genuine
impact for applications as diverse as discovering extrasolar planets, transient
objects, quasars, and gravitationally-lensed systems, forecasting solar
activity, and distinguishing between signals and instrumental effects in
gravitational wave astronomy. This review surveys contemporary, published
literature on machine learning and artificial intelligence in astronomy and
astrophysics. Applications span seven main categories of activity:
classification, regression, clustering, forecasting, generation, discovery, and
the development of new scientific insight. These categories form the basis of a
hierarchy of maturity, as the use of machine learning and artificial
intelligence emerges, progresses or becomes established.",http://arxiv.org/abs/1912.02934v1,arXiv,survey reach maturity machine learning artificial intelligence astronomy,machine learn automate process learn example order classify predict discover generate new datum artificial intelligence method computer make decision discovery would usually require human intelligence firmly establish astronomy every week new application machine learning artificial intelligence add grow corpus work random forest support vector machine neural network artificial deep convolutional genuine impact application diverse discover extrasolar planet transient object quasar gravitationallylensed system forecast solar activity distinguishing signal instrumental effect gravitational wave astronomy review survey contemporary publish literature machine learning artificial intelligence astronomy astrophysic application span seven main category activity classification regression cluster forecasting generation discovery development new scientific insight category form basis hierarchy maturity use machine learning artificial intelligence emerge progress becomes establish,survey reach maturity machine learning artificial intelligence astronomy machine learn automate process learn example order classify predict discover generate new datum artificial intelligence method computer make decision discovery would usually require human intelligence firmly establish astronomy every week new application machine learning artificial intelligence add grow corpus work random forest support vector machine neural network artificial deep convolutional genuine impact application diverse discover extrasolar planet transient object quasar gravitationallylensed system forecast solar activity distinguishing signal instrumental effect gravitational wave astronomy review survey contemporary publish literature machine learning artificial intelligence astronomy astrophysic application span seven main category activity classification regression cluster forecasting generation discovery development new scientific insight category form basis hierarchy maturity use machine learning artificial intelligence emerge progress becomes establish,0.5309734513274337,0.168141592920354,0.22123893805309736,0.017699115044247787,113.0,0.0,0.0,1.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Quantitative,"Design of a dynamic and self adapting system, supported with artificial
  intelligence, machine learning and real time intelligence for predictive
  cyber risk analytics in extreme environments, cyber risk in the colonisation
  of Mars","Multiple governmental agencies and private organisations have made
commitments for the colonisation of Mars. Such colonisation requires complex
systems and infrastructure that could be very costly to repair or replace in
cases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber
security and risk models, and established mathematical formulas to identify the
best approach for developing a dynamic and self adapting system for predictive
cyber risk analytics supported with Artificial Intelligence and Machine
Learning and real time intelligence in edge computing. The paper presents a new
mathematical approach for integrating concepts for cognition engine design,
edge computing and Artificial Intelligence and Machine Learning to automate
anomaly detection. This engine instigates a step change by applying Artificial
Intelligence and Machine Learning embedded at the edge of IoT networks, to
deliver safe and functional real time intelligence for predictive cyber risk
analytics. This will enhance capacities for risk analytics and assists in the
creation of a comprehensive and systematic understanding of the opportunities
and threats that arise when edge computing nodes are deployed, and when
Artificial Intelligence and Machine Learning technologies are migrated to the
periphery of the internet and into local IoT networks.",http://arxiv.org/abs/2005.12150v2,arXiv,design dynamic self adapt system support artificial intelligence machine learning real time intelligence predictive cyber risk analytic extreme environment cyber risk colonisation mar,multiple governmental agency private organisation make commitment colonisation mar colonisation require complex system infrastructure could costly repair replace case cyber attack paper survey deep learning algorithm iot cyber security risk model establish mathematical formula identify good approach develop dynamic self adapt system predictive cyber risk analytic support artificial intelligence machine learning real time intelligence edge compute paper present new mathematical approach integrate concept cognition engine design edge computing artificial intelligence machine learning automate anomaly detection engine instigate step change apply artificial intelligence machine learning embed edge iot network deliver safe functional real time intelligence predictive cyber risk analytic enhance capacity risk analytic assist creation comprehensive systematic understanding opportunity threat arise edge computing node deploy artificial intelligence machine learning technology migrate periphery internet local iot network,design dynamic self adapt system support artificial intelligence machine learning real time intelligence predictive cyber risk analytic extreme environment cyber risk colonisation mar multiple governmental agency private organisation make commitment colonisation mar colonisation require complex system infrastructure could costly repair replace case cyber attack paper survey deep learning algorithm iot cyber security risk model establish mathematical formula identify good approach develop dynamic self adapt system predictive cyber risk analytic support artificial intelligence machine learning real time intelligence edge compute paper present new mathematical approach integrate concept cognition engine design edge computing artificial intelligence machine learning automate anomaly detection engine instigate step change apply artificial intelligence machine learning embed edge iot network deliver safe functional real time intelligence predictive cyber risk analytic enhance capacity risk analytic assist creation comprehensive systematic understanding opportunity threat arise edge computing node deploy artificial intelligence machine learning technology migrate periphery internet local iot network,0.536,0.136,0.24,0.0,125.0,1.0,2.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Quantitative,Physics Enhanced Artificial Intelligence,"We propose that intelligently combining models from the domains of Artificial
Intelligence or Machine Learning with Physical and Expert models will yield a
more ""trustworthy"" model than any one model from a single domain, given a
complex and narrow enough problem. Based on mean-variance portfolio theory and
bias-variance trade-off analysis, we prove combining models from various
domains produces a model that has lower risk, increasing user trust. We call
such combined models - physics enhanced artificial intelligence (PEAI), and
suggest use cases for PEAI.",http://arxiv.org/abs/1903.04442v1,arXiv,physics enhance artificial intelligence,propose intelligently combine model domain artificial intelligence machine learning physical expert model yield trustworthy model one model single domain give complex narrow enough problem base meanvariance portfolio theory biasvariance tradeoff analysis prove combine model various domain produce model low risk increase user trust call combined model physics enhance artificial intelligence peai suggest use case peai,physics enhance artificial intelligence propose intelligently combine model domain artificial intelligence machine learning physical expert model yield trustworthy model one model single domain give complex narrow enough problem base meanvariance portfolio theory biasvariance tradeoff analysis prove combine model various domain produce model low risk increase user trust call combined model physics enhance artificial intelligence peai suggest use case peai,0.6181818181818182,0.14545454545454545,0.18181818181818182,0.01818181818181818,55.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Qualitative,"B-SMART: A Reference Architecture for Artificially Intelligent Autonomic
  Smart Buildings","The pervasive application of artificial intelligence and machine learning
algorithms is transforming many industries and aspects of the human experience.
One very important industry trend is the move to convert existing human
dwellings to smart buildings, and to create new smart buildings. Smart
buildings aim to mitigate climate change by reducing energy consumption and
associated carbon emissions. To accomplish this, they leverage artificial
intelligence, big data, and machine learning algorithms to learn and optimize
system performance. These fields of research are currently very rapidly
evolving and advancing, but there has been very little guidance to help
engineers and architects working on smart buildings apply artificial
intelligence algorithms and technologies in a systematic and effective manner.
In this paper we present B-SMART: the first reference architecture for
autonomic smart buildings. B-SMART facilitates the application of artificial
intelligence techniques and technologies to smart buildings by decoupling
conceptually distinct layers of functionality and organizing them into an
autonomic control loop. We also present a case study illustrating how B-SMART
can be applied to accelerate the introduction of artificial intelligence into
an existing smart building.",http://arxiv.org/abs/2211.03219v1,arXiv,bsmart reference architecture artificially intelligent autonomic smart building,pervasive application artificial intelligence machine learning algorithm transform many industry aspect human experience one important industry trend move convert exist human dwelling smart building create new smart building smart building aim mitigate climate change reduce energy consumption associate carbon emission accomplish leverage artificial intelligence big datum machine learning algorithm learn optimize system performance field research currently rapidly evolve advance little guidance help engineer architect work smart building apply artificial intelligence algorithm technology systematic effective manner paper present bsmart first reference architecture autonomic smart building bsmart facilitate application artificial intelligence technique technology smart building decouple conceptually distinct layer functionality organize autonomic control loop also present case study illustrate bsmart apply accelerate introduction artificial intelligence exist smart building,bsmart reference architecture artificially intelligent autonomic smart building pervasive application artificial intelligence machine learning algorithm transform many industry aspect human experience one important industry trend move convert exist human dwelling smart building create new smart building smart building aim mitigate climate change reduce energy consumption associate carbon emission accomplish leverage artificial intelligence big datum machine learning algorithm learn optimize system performance field research currently rapidly evolve advance little guidance help engineer architect work smart building apply artificial intelligence algorithm technology systematic effective manner paper present bsmart first reference architecture autonomic smart building bsmart facilitate application artificial intelligence technique technology smart building decouple conceptually distinct layer functionality organize autonomic control loop also present case study illustrate bsmart apply accelerate introduction artificial intelligence exist smart building,0.5086206896551724,0.11206896551724138,0.2672413793103448,0.034482758620689655,116.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Qualitative,Seeding the Singularity for A.I,"The singularity refers to an idea that once a machine having an artificial
intelligence surpassing the human intelligence capacity is created, it will
trigger explosive technological and intelligence growth. I propose to test the
hypothesis that machine intelligence capacity can grow autonomously starting
with an intelligence comparable to that of bacteria - microbial intelligence.
The goal will be to demonstrate that rapid growth in intelligence capacity can
be realized at all in artificial computing systems. I propose the following
three properties that may allow an artificial intelligence to exhibit a steady
growth in its intelligence capacity: (i) learning with the ability to modify
itself when exposed to more data, (ii) acquiring new functionalities (skills),
and (iii) expanding or replicating itself. The algorithms must demonstrate a
rapid growth in skills of dataprocessing and analysis and gain qualitatively
different functionalities, at least until the current computing technology
supports their scalable development. The existing algorithms that already
encompass some of these or similar properties, as well as missing abilities
that must yet be implemented, will be reviewed in this work. Future
computational tests could support or oppose the hypothesis that artificial
intelligence can potentially grow to the level of superintelligence which
overcomes the limitations in hardware by producing necessary processing
resources or by changing the physical realization of computation from using
chip circuits to using quantum computing principles.",http://arxiv.org/abs/1908.01766v1,arXiv,seed singularity,singularity refer idea machine artificial intelligence surpass human intelligence capacity create trigger explosive technological intelligence growth propose test hypothesis machine intelligence capacity grow autonomously start intelligence comparable bacteria microbial intelligence goal demonstrate rapid growth intelligence capacity realize artificial computing system propose follow three property may allow artificial intelligence exhibit steady growth intelligence capacity learn ability modify expose datum acquire new functionality skill iii expand replicate algorithm must demonstrate rapid growth skill dataprocessing analysis gain qualitatively different functionality least current computing technology support scalable development exist algorithm already encompass similar property well miss ability must yet implement review work future computational test could support oppose hypothesis artificial intelligence potentially grow level superintelligence overcome limitation hardware produce necessary processing resource change physical realization computation use chip circuit use quantum computing principle,seed singularity singularity refer idea machine artificial intelligence surpass human intelligence capacity create trigger explosive technological intelligence growth propose test hypothesis machine intelligence capacity grow autonomously start intelligence comparable bacteria microbial intelligence goal demonstrate rapid growth intelligence capacity realize artificial computing system propose follow three property may allow artificial intelligence exhibit steady growth intelligence capacity learn ability modify expose datum acquire new functionality skill iii expand replicate algorithm must demonstrate rapid growth skill dataprocessing analysis gain qualitatively different functionality least current computing technology support scalable development exist algorithm already encompass similar property well miss ability must yet implement review work future computational test could support oppose hypothesis artificial intelligence potentially grow level superintelligence overcome limitation hardware produce necessary processing resource change physical realization computation use chip circuit use quantum computing principle,0.5193798449612403,0.18604651162790697,0.17829457364341086,0.046511627906976744,129.0,0.0,0.0,0.0,1.0
Computer Science,Artificial Intelligence and Machine Learning,Qualitative,Towards A Rigorous Science of Interpretable Machine Learning,"As machine learning systems become ubiquitous, there has been a surge of
interest in interpretable machine learning: systems that provide explanation
for their outputs. These explanations are often used to qualitatively assess
other criteria such as safety or non-discrimination. However, despite the
interest in interpretability, there is very little consensus on what
interpretable machine learning is and how it should be measured. In this
position paper, we first define interpretability and describe when
interpretability is needed (and when it is not). Next, we suggest a taxonomy
for rigorous evaluation and expose open questions towards a more rigorous
science of interpretable machine learning.",http://arxiv.org/abs/1702.08608v2,arXiv,towards rigorous science interpretable machine learning,machine learn system become ubiquitous surge interest interpretable machine learn system provide explanation output explanation often use qualitatively assess criterion safety nondiscrimination however despite interest interpretability little consensus interpretable machine learning measure position paper first define interpretability describe interpretability need next suggest taxonomy rigorous evaluation expose open question towards rigorous science interpretable machine learning,towards rigorous science interpretable machine learning machine learn system become ubiquitous surge interest interpretable machine learn system provide explanation output explanation often use qualitatively assess criterion safety nondiscrimination however despite interest interpretability little consensus interpretable machine learning measure position paper first define interpretability describe interpretability need next suggest taxonomy rigorous evaluation expose open question towards rigorous science interpretable machine learning,0.5185185185185185,0.2037037037037037,0.14814814814814814,0.09259259259259259,54.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Qualitative,Probabilistic Artificial Intelligence,"Artificial intelligence commonly refers to the science and engineering of
artificial systems that can carry out tasks generally associated with requiring
aspects of human intelligence, such as playing games, translating languages,
and driving cars. In recent years, there have been exciting advances in
learning-based, data-driven approaches towards AI, and machine learning and
deep learning have enabled computer systems to perceive the world in
unprecedented ways. Reinforcement learning has enabled breakthroughs in complex
games such as Go and challenging robotics tasks such as quadrupedal locomotion.
  A key aspect of intelligence is to not only make predictions, but reason
about the uncertainty in these predictions, and to consider this uncertainty
when making decisions. This is what this manuscript on ""Probabilistic
Artificial Intelligence"" is about. The first part covers probabilistic
approaches to machine learning. We discuss the differentiation between
""epistemic"" uncertainty due to lack of data and ""aleatoric"" uncertainty, which
is irreducible and stems, e.g., from noisy observations and outcomes. We
discuss concrete approaches towards probabilistic inference and modern
approaches to efficient approximate inference.
  The second part of the manuscript is about taking uncertainty into account in
sequential decision tasks. We consider active learning and Bayesian
optimization -- approaches that collect data by proposing experiments that are
informative for reducing the epistemic uncertainty. We then consider
reinforcement learning and modern deep RL approaches that use neural network
function approximation. We close by discussing modern approaches in model-based
RL, which harness epistemic and aleatoric uncertainty to guide exploration,
while also reasoning about safety.",http://arxiv.org/abs/2502.05244v1,arXiv,probabilistic artificial intelligence,artificial intelligence commonly refer science engineering artificial system carry task generally associate require aspect human intelligence play game translate language drive car recent year exciting advance learningbase datadriven approach towards machine learning deep learning enable computer system perceive world unprecedented way reinforcement learning enable breakthrough complex game challenging robotic task quadrupedal locomotion key aspect intelligence make prediction reason uncertainty prediction consider uncertainty make decision manuscript probabilistic artificial intelligence first part cover probabilistic approach machine learning discuss differentiation epistemic uncertainty due lack datum aleatoric uncertainty irreducible stem noisy observation outcome discuss concrete approach towards probabilistic inference modern approach efficient approximate inference second part manuscript take uncertainty account sequential decision task consider active learning bayesian optimization approach collect datum propose experiment informative reduce epistemic uncertainty consider reinforcement learning modern deep approach use neural network function approximation close discuss modern approach modelbase harness epistemic aleatoric uncertainty guide exploration also reason safety,probabilistic artificial intelligence artificial intelligence commonly refer science engineering artificial system carry task generally associate require aspect human intelligence play game translate language drive car recent year exciting advance learningbase datadriven approach towards machine learning deep learning enable computer system perceive world unprecedented way reinforcement learning enable breakthrough complex game challenging robotic task quadrupedal locomotion key aspect intelligence make prediction reason uncertainty prediction consider uncertainty make decision manuscript probabilistic artificial intelligence first part cover probabilistic approach machine learning discuss differentiation epistemic uncertainty due lack datum aleatoric uncertainty irreducible stem noisy observation outcome discuss concrete approach towards probabilistic inference modern approach efficient approximate inference second part manuscript take uncertainty account sequential decision task consider active learning bayesian optimization approach collect datum propose experiment informative reduce epistemic uncertainty consider reinforcement learning modern deep approach use neural network function approximation close discuss modern approach modelbase harness epistemic aleatoric uncertainty guide exploration also reason safety,0.5135135135135135,0.1554054054054054,0.25,0.02702702702702703,148.0,0.0,0.0,1.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Qualitative,SELM: Software Engineering of Machine Learning Models,"One of the pillars of any machine learning model is its concepts. Using
software engineering, we can engineer these concepts and then develop and
expand them. In this article, we present a SELM framework for Software
Engineering of machine Learning Models. We then evaluate this framework through
a case study. Using the SELM framework, we can improve a machine learning
process efficiency and provide more accuracy in learning with less processing
hardware resources and a smaller training dataset. This issue highlights the
importance of an interdisciplinary approach to machine learning. Therefore, in
this article, we have provided interdisciplinary teams' proposals for machine
learning.",http://arxiv.org/abs/2103.11249v1,arXiv,selm software engineering machine learning model,one pillar machine learning model concept use software engineering engineer concept develop expand article present selm framework software engineering machine learning model evaluate framework case study use selm framework improve machine learning process efficiency provide accuracy learn less processing hardware resource small training dataset issue highlight importance interdisciplinary approach machine learn therefore article provide interdisciplinary team proposal machine learning,selm software engineering machine learning model one pillar machine learning model concept use software engineering engineer concept develop expand article present selm framework software engineering machine learning model evaluate framework case study use selm framework improve machine learning process efficiency provide accuracy learn less processing hardware resource small training dataset issue highlight importance interdisciplinary approach machine learn therefore article provide interdisciplinary team proposal machine learning,0.6779661016949152,0.1864406779661017,0.1016949152542373,0.01694915254237288,59.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Mixed Methods,"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",http://arxiv.org/abs/2111.11295v1,arXiv,artificial intelligence technology analysis use artificial intelligence patent deep learning model vector space model,thank rapid development artificial intelligence technology recent year current artificial intelligence technology contribute many part society education environment medical care military tourism economy politic etc large impact society whole example field education artificial intelligence tutoring system automatically assign tutor base student level field economic quantitative investment method automatically analyze large amount datum find investment law create investment model predict change financial market artificial intelligence technology use various field important know exactly factor important influence field artificial intelligence technology relationship field connect therefore necessary analyze artificial intelligence technology field paper analyze patent document relate artificial intelligence technology propose method keyword analysis within factor use artificial intelligence patent datum set artificial intelligence technology analysis model rely feature engineering base deep learning model name keybert use vector space model case study collect analyze artificial intelligence patent datum conduct show propose model apply real world problem,artificial intelligence technology analysis use artificial intelligence patent deep learning model vector space model thank rapid development artificial intelligence technology recent year current artificial intelligence technology contribute many part society education environment medical care military tourism economy politic etc large impact society whole example field education artificial intelligence tutoring system automatically assign tutor base student level field economic quantitative investment method automatically analyze large amount datum find investment law create investment model predict change financial market artificial intelligence technology use various field important know exactly factor important influence field artificial intelligence technology relationship field connect therefore necessary analyze artificial intelligence technology field paper analyze patent document relate artificial intelligence technology propose method keyword analysis within factor use artificial intelligence patent datum set artificial intelligence technology analysis model rely feature engineering base deep learning model name keybert use vector space model case study collect analyze artificial intelligence patent datum conduct show propose model apply real world problem,0.6126760563380281,0.11971830985915492,0.20422535211267606,0.028169014084507043,142.0,0.0,0.0,2.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Mixed Methods,Using Artificial Intelligence to Improve Classroom Learning Experience,"This paper explores advancements in Artificial Intelligence technologies to
enhance classroom learning, highlighting contributions from companies like IBM,
Microsoft, Google, and ChatGPT, as well as the potential of brain signal
analysis. The focus is on improving students learning experiences by using
Machine Learning algorithms to : identify a student preferred learning style
and predict academic dropout risk. A Logistic Regression algorithm is applied
for binary classification using six predictor variables, such as assessment
scores, lesson duration, and preferred learning style, to accurately identify
learning preferences. A case study, with 76,519 candidates and 35 predictor
variables, assesses academic dropout risk using Logistic Regression, achieving
a test accuracy of 87.39%. In comparison, the Stochastic Gradient Descent
classifier achieved an accuracy of 83.1% on the same dataset.",http://arxiv.org/abs/2503.05709v1,arXiv,use artificial intelligence improve classroom learning experience,paper explore advancement artificial intelligence technology enhance classroom learning highlight contribution company like ibm microsoft google chatgpt well potential brain signal analysis focus improve student learn experience use machine learning algorithm identify student prefer learning style predict academic dropout risk logistic regression algorithm apply binary classification use six predictor variable assessment score lesson duration preferred learning style accurately identify learning preference case study candidate predictor variable assess academic dropout risk use logistic regression achieve test accuracy comparison stochastic gradient descent classifier achieve accuracy dataset,use artificial intelligence improve classroom learning experience paper explore advancement artificial intelligence technology enhance classroom learning highlight contribution company like ibm microsoft google chatgpt well potential brain signal analysis focus improve student learn experience use machine learning algorithm identify student prefer learning style predict academic dropout risk logistic regression algorithm apply binary classification use six predictor variable assessment score lesson duration preferred learning style accurately identify learning preference case study candidate predictor variable assess academic dropout risk use logistic regression achieve test accuracy comparison stochastic gradient descent classifier achieve accuracy dataset,0.5833333333333334,0.17857142857142858,0.10714285714285714,0.011904761904761904,84.0,1.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Mixed Methods,"The Top 10 Topics in Machine Learning Revisited: A Quantitative
  Meta-Study","Which topics of machine learning are most commonly addressed in research?
This question was initially answered in 2007 by doing a qualitative survey
among distinguished researchers. In our study, we revisit this question from a
quantitative perspective. Concretely, we collect 54K abstracts of papers
published between 2007 and 2016 in leading machine learning journals and
conferences. We then use machine learning in order to determine the top 10
topics in machine learning. We not only include models, but provide a holistic
view across optimization, data, features, etc. This quantitative approach
allows reducing the bias of surveys. It reveals new and up-to-date insights
into what the 10 most prolific topics in machine learning research are. This
allows researchers to identify popular topics as well as new and rising topics
for their research.",http://arxiv.org/abs/1703.10121v1,arXiv,top topic machine learning revisit quantitative metastudy,topic machine learning commonly address research question initially answer qualitative survey among distinguished researcher study revisit question quantitative perspective concretely collect abstract paper publish lead machine learn journal conference use machine learn order determine top topic machine learn include model provide holistic view across optimization datum feature etc quantitative approach allow reduce bias survey reveal new uptodate insight prolific topic machine learning research allow researcher identify popular topic well new rise topic research,top topic machine learning revisit quantitative metastudy topic machine learning commonly address research question initially answer qualitative survey among distinguished researcher study revisit question quantitative perspective concretely collect abstract paper publish lead machine learn journal conference use machine learn order determine top topic machine learn include model provide holistic view across optimization datum feature etc quantitative approach allow reduce bias survey reveal new uptodate insight prolific topic machine learning research allow researcher identify popular topic well new rise topic research,0.5342465753424658,0.2191780821917808,0.136986301369863,0.0410958904109589,73.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Mixed Methods,A Falsificationist Account of Artificial Neural Networks,"Machine learning operates at the intersection of statistics and computer
science. This raises the question as to its underlying methodology. While much
emphasis has been put on the close link between the process of learning from
data and induction, the falsificationist component of machine learning has
received minor attention. In this paper, we argue that the idea of
falsification is central to the methodology of machine learning. It is commonly
thought that machine learning algorithms infer general prediction rules from
past observations. This is akin to a statistical procedure by which estimates
are obtained from a sample of data. But machine learning algorithms can also be
described as choosing one prediction rule from an entire class of functions. In
particular, the algorithm that determines the weights of an artificial neural
network operates by empirical risk minimization and rejects prediction rules
that lack empirical adequacy. It also exhibits a behavior of implicit
regularization that pushes hypothesis choice toward simpler prediction rules.
We argue that taking both aspects together gives rise to a falsificationist
account of artificial neural networks.",http://arxiv.org/abs/2205.01421v1,arXiv,falsificationist account artificial neural network,machine learning operate intersection statistic computer science raise question underlie methodology much emphasis put close link process learn datum induction falsificationist component machine learning receive minor attention paper argue idea falsification central methodology machine learn commonly think machine learn algorithm infer general prediction rule past observation akin statistical procedure estimate obtain sample datum machine learning algorithm also describe choose one prediction rule entire class function particular algorithm determine weight artificial neural network operate empirical risk minimization reject prediction rule lack empirical adequacy also exhibit behavior implicit regularization push hypothesis choice toward simple prediction rule argue take aspect together give rise falsificationist account artificial neural network,falsificationist account artificial neural network machine learning operate intersection statistic computer science raise question underlie methodology much emphasis put close link process learn datum induction falsificationist component machine learning receive minor attention paper argue idea falsification central methodology machine learn commonly think machine learn algorithm infer general prediction rule past observation akin statistical procedure estimate obtain sample datum machine learning algorithm also describe choose one prediction rule entire class function particular algorithm determine weight artificial neural network operate empirical risk minimization reject prediction rule lack empirical adequacy also exhibit behavior implicit regularization push hypothesis choice toward simple prediction rule argue take aspect together give rise falsificationist account artificial neural network,0.5619047619047619,0.1619047619047619,0.1619047619047619,0.0380952380952381,105.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Mixed Methods,Towards Benchmarking Explainable Artificial Intelligence Methods,"The currently dominating artificial intelligence and machine learning
technology, neural networks, builds on inductive statistical learning. Neural
networks of today are information processing systems void of understanding and
reasoning capabilities, consequently, they cannot explain promoted decisions in
a humanly valid form. In this work, we revisit and use fundamental philosophy
of science theories as an analytical lens with the goal of revealing, what can
be expected, and more importantly, not expected, from methods that aim to
explain decisions promoted by a neural network. By conducting a case study we
investigate a selection of explainability method's performance over two mundane
domains, animals and headgear. Through our study, we lay bare that the
usefulness of these methods relies on human domain knowledge and our ability to
understand, generalise and reason. The explainability methods can be useful
when the goal is to gain further insights into a trained neural network's
strengths and weaknesses. If our aim instead is to use these explainability
methods to promote actionable decisions or build trust in ML-models they need
to be less ambiguous than they are today. In this work, we conclude from our
study, that benchmarking explainability methods, is a central quest towards
trustworthy artificial intelligence and machine learning.",http://arxiv.org/abs/2208.12120v1,arXiv,towards benchmarke explainable artificial intelligence method,currently dominate artificial intelligence machine learn technology neural network build inductive statistical learning neural network today information processing system void understanding reasoning capability consequently explain promote decision humanly valid form work revisit use fundamental philosophy science theory analytical lens goal reveal expect importantly expect method aim explain decision promote neural network conduct case study investigate selection explainability method performance two mundane domain animal headgear study lay bare usefulness method rely human domain knowledge ability understand generalise reason explainability method useful goal gain insight train neural network strength weakness aim instead use explainability method promote actionable decision build trust mlmodel need less ambiguous today work conclude study benchmarke explainability method central quest towards trustworthy artificial intelligence machine learning,towards benchmarke explainable artificial intelligence method currently dominate artificial intelligence machine learn technology neural network build inductive statistical learning neural network today information processing system void understanding reasoning capability consequently explain promote decision humanly valid form work revisit use fundamental philosophy science theory analytical lens goal reveal expect importantly expect method aim explain decision promote neural network conduct case study investigate selection explainability method performance two mundane domain animal headgear study lay bare usefulness method rely human domain knowledge ability understand generalise reason explainability method useful goal gain insight train neural network strength weakness aim instead use explainability method promote actionable decision build trust mlmodel need less ambiguous today work conclude study benchmarke explainability method central quest towards trustworthy artificial intelligence machine learning,0.5811965811965812,0.15384615384615385,0.17094017094017094,0.05128205128205128,117.0,0.0,0.0,2.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Design and Development,"ARTIFICIAL INTELLIGENCE, MACHINE LEARNING AND ROBOTICS: THE CORE OF TOMORROW’S INDUSTRIES","<jats:p>The second issue of AI, ML, and Robotics in Business arrives amid global uncertainty and rapid technological evolution. As industries confront climate instability, labor shortages, and digital transformation, artificial intelligence, machine learning, and robotics are becoming essential engines of resilience and reinvention. This issue highlights sector-specific advances—from AI-driven precision agriculture and ethical frameworks in hospitality to team science and prevention strategies in healthcare. Contributors illustrate how these technologies move beyond automation to elevate human intelligence, ethics, and collaboration. Central themes include the integration of AI into trust-based services, interdisciplinary innovation, and the cultivation of diverse intelligences to navigate the Intelligence Era. NVIDIA’s GTC 2025 conference emphasizes this paradigm shift, revealing AI’s potential to build adaptive, human-augmenting systems across industries. These works signal a new frontier: one where progress lies not in replacing human effort, but in preparing society to lead with vision, empathy, and collective intelligence.</jats:p>",https://doi.org/10.32473/aimlrb.1.2.139237,CrossRef,artificial intelligence machine learning robotic core tomorrow industry,jatspthe second issue robotic business arrive amid global uncertainty rapid technological evolution industry confront climate instability labor shortage digital transformation artificial intelligence machine learning robotic become essential engine resilience reinvention issue highlight sectorspecific advance aidriven precision agriculture ethical framework hospitality team science prevention strategy healthcare contributor illustrate technology move beyond automation elevate human intelligence ethic collaboration central theme include integration trustbase service interdisciplinary innovation cultivation diverse intelligence navigate intelligence era nvidia gtc conference emphasize paradigm shift reveal potential build adaptive humanaugmenting system across industry work signal new frontier one progress lie replace human effort prepare society lead vision empathy collective intelligencejatsp,artificial intelligence machine learning robotic core tomorrow industry jatspthe second issue robotic business arrive amid global uncertainty rapid technological evolution industry confront climate instability labor shortage digital transformation artificial intelligence machine learning robotic become essential engine resilience reinvention issue highlight sectorspecific advance aidriven precision agriculture ethical framework hospitality team science prevention strategy healthcare contributor illustrate technology move beyond automation elevate human intelligence ethic collaboration central theme include integration trustbase service interdisciplinary innovation cultivation diverse intelligence navigate intelligence era nvidia gtc conference emphasize paradigm shift reveal potential build adaptive humanaugmenting system across industry work signal new frontier one progress lie replace human effort prepare society lead vision empathy collective intelligencejatsp,0.5544554455445545,0.10891089108910891,0.18811881188118812,0.0,101.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Design and Development,Artificial Intelligence and Deep Learning Applications: A Review,"<jats:p>Deep Learning, a buzz in the artificial intelligence field, is the subset of machine learning. It teaches computers to learn from examples in order to perform a task that is intuitive to humans. It is also known as a deep neural network or deep neural learning. In deep learning, neural networks have a significant role. These are a set of algorithms that we implement to identify relevant relationships in datasets, and they follow the process that imitates the human brain. Neural networks depict the behavior of the human brain and enable computer algorithms to identify trends. It also solves complex problems in the domain of machine learning, AI, and data science.Deep learning deploys artificial neural networks to recognize the hidden patterns of data in the dataset provided. These algorithms are trained over an adequate amount of time and applied to a data set.</jats:p>",https://doi.org/10.55529/jaimlnn.12.10.13,CrossRef,artificial intelligence deep learning application review,jatspdeep learn buzz artificial intelligence field subset machine learn teach computer learn example order perform task intuitive human also know deep neural network deep neural learn deep learning neural network significant role set algorithm implement identify relevant relationship dataset follow process imitate human brain neural network depict behavior human brain enable computer algorithm identify trend also solve complex problem domain machine learning datum sciencedeep learning deploy artificial neural network recognize hide pattern datum dataset provide algorithm train adequate amount time apply data setjatsp,artificial intelligence deep learning application review jatspdeep learn buzz artificial intelligence field subset machine learn teach computer learn example order perform task intuitive human also know deep neural network deep neural learn deep learning neural network significant role set algorithm implement identify relevant relationship dataset follow process imitate human brain neural network depict behavior human brain enable computer algorithm identify trend also solve complex problem domain machine learning datum sciencedeep learning deploy artificial neural network recognize hide pattern datum dataset provide algorithm train adequate amount time apply data setjatsp,0.4819277108433735,0.25301204819277107,0.1927710843373494,0.024096385542168676,41.5,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Design and Development,Topic: How Artificial Intelligence and Machine Learning Can Impact Market Design,"<jats:p>Background: This research examines how market knowledge and artificial intelligence (AI) interact in different market designs such as business-to-business (B2B) settings while taking emerging technologies and the changing digitalization landscape into account. Objective: The main goal is to understand how AI affects market knowledge in different market designs such as businessto-business (B2B) contexts, taking into account language barriers, practical difficulties, and the revolutionary effects on decision-making and customer interactions. Result: They underscore the transformative potential of artificial intelligence (AI) by highlighting how it shapes market knowledge, encourages customized approaches, and improves marketing efficacy in the business-to-business (B2B) space. Conclusion: In order to create a path for responsible AI integration in B2B marketing, the study concludes with recommendations for standardized terminology related to AI, practical insights into implementation challenges, and ethical issues</jats:p>",https://doi.org/10.33140/aurdp.01.01.03,CrossRef,topic artificial intelligence machine learning impact market design,jatspbackground research examine market knowledge artificial intelligence interact different market design businesstobusiness setting take emerge technology change digitalization landscape account objective main goal understand affect market knowledge different market design businesstobusiness contexts take account language barrier practical difficulty revolutionary effect decisionmake customer interaction result underscore transformative potential artificial intelligence highlight shape market knowledge encourage customize approach improve marketing efficacy businesstobusiness space conclusion order create path responsible integration marketing study conclude recommendation standardized terminology relate practical insight implementation challenge ethical issuesjatsp,topic artificial intelligence machine learning impact market design jatspbackground research examine market knowledge artificial intelligence interact different market design businesstobusiness setting take emerge technology change digitalization landscape account objective main goal understand affect market knowledge different market design businesstobusiness contexts take account language barrier practical difficulty revolutionary effect decisionmake customer interaction result underscore transformative potential artificial intelligence highlight shape market knowledge encourage customize approach improve marketing efficacy businesstobusiness space conclusion order create path responsible integration marketing study conclude recommendation standardized terminology relate practical insight implementation challenge ethical issuesjatsp,0.6625,0.125,0.175,0.0,80.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Design and Development,Applications of Artificial Intelligence to Cryptography,"<jats:p>This paper considers some recent advances in the field of Cryptography using Artificial Intelligence (AI) It specifically considers the applications of Machine Learning (ML) and Evolutionary Computing (EC) concepts used to generate ciphers. A short overview is given on Artificial Neural Networks (ANNs) and the principles of Deep Learning (DL) using Deep ANNs.  In this context, the paper considers: (i) the implementation of EC and ANNs to generate unique and unclonable ciphers; (ii) ML strategies for detecting the genuine randomness (or otherwise) of binary streams for applications in Cryptanalysis.  The paper aims to provide an overview on how AI can be applied for encrypting data and undertaking cryptanalysis of such data and other encrypted data classes in order to assess the cryptographic strength of an encryption algorithm. For example, to detect patterns of intercepted data streams that are signatures of encrypted data. An application is presented which includes authentication of high-value documents such as bank notes, using smartphones.  Using an antenna of a smartphone to read (in the near field) an embedded flexible integrate circuit with a non-programmable coprocessor, ultra-strong encrypted information can be used on-line for validation.</jats:p>",https://doi.org/10.14738/tmlai.83.8219,CrossRef,application artificial intelligence cryptography,jatspthis paper consider recent advance field cryptography use artificial intelligence specifically consider application machine learn evolutionary compute concept use generate cipher short overview give artificial neural network ann principle deep learning use deep ann context paper consider implementation ann generate unique unclonable cipher strategy detect genuine randomness otherwise binary stream application cryptanalysis paper aim provide overview apply encrypt datum undertake cryptanalysis datum encrypt data class order assess cryptographic strength encryption algorithm example detect pattern intercept data stream signature encrypt datum application present include authentication highvalue document bank note use smartphone use antenna smartphone read near field embed flexible integrate circuit nonprogrammable coprocessor ultrastrong encrypt information use online validationjatsp,application artificial intelligence cryptography jatspthis paper consider recent advance field cryptography use artificial intelligence specifically consider application machine learn evolutionary compute concept use generate cipher short overview give artificial neural network ann principle deep learning use deep ann context paper consider implementation ann generate unique unclonable cipher strategy detect genuine randomness otherwise binary stream application cryptanalysis paper aim provide overview apply encrypt datum undertake cryptanalysis datum encrypt data class order assess cryptographic strength encryption algorithm example detect pattern intercept data stream signature encrypt datum application present include authentication highvalue document bank note use smartphone use antenna smartphone read near field embed flexible integrate circuit nonprogrammable coprocessor ultrastrong encrypt information use online validationjatsp,0.5555555555555556,0.18518518518518517,0.14814814814814814,0.018518518518518517,108.0,0.0,0.0,0.0,1.0
Computer Science,Artificial Intelligence and Machine Learning,Design and Development,The Theory of Natural-Artificial Intelligence,"<jats:p>In recent times, mankind is seeking for certain peculiar solutions to multiple facets containing an identically very fundamental philosophy i.e., certainly intend to have indeterminism as a primordial prerequisite; however, that indeterminism is itself like a void filled with determinism as analogous to the quantum computing as qubits and the corresponding complexity. In the meantime, there are algorithms and mathematical frameworks and those in general; yield the required distinctions in the underlying theories constructed upon principles which then give rise to respective objectifications. But, when it comes to the Artificial Intelligence and Machine Learning, then there find some mathematical gaps in order to connect other regimes in relation of one and the other. The proposed discovery in this paper is about quilting some of those gaps as like the whole structure of Artificial Intelligence is yet to be developed in the realm concerning with responsive analysis in betwixt to humans and machines or beyond to such analogy. Hence, the entire introduction &amp; incitement of this theory is to mathematically determine the deep rationality as responsive manifestation of human brain with a designed computing and both with the highest potential degree of attributions or overlaps and both the conditions will be shown mathematically herewith as identifications that make each other separate and clear to persuade.</jats:p>",https://doi.org/10.24018/ejai.2022.1.1.2,CrossRef,theory naturalartificial intelligence,jatspin recent time mankind seek certain peculiar solution multiple facet contain identically fundamental philosophy certainly intend indeterminism primordial prerequisite however indeterminism like void fill determinism analogous quantum computing qubit correspond complexity meantime algorithm mathematical framework general yield require distinction underlie theory construct upon principle give rise respective objectification come artificial intelligence machine learning find mathematical gap order connect regime relation one propose discovery paper quilt gap like whole structure artificial intelligence yet develop realm concern responsive analysis betwixt human machine beyond analogy hence entire introduction amp incitement theory mathematically determine deep rationality responsive manifestation human brain design computing high potential degree attribution overlap condition show mathematically herewith identification make separate clear persuadejatsp,theory naturalartificial intelligence jatspin recent time mankind seek certain peculiar solution multiple facet contain identically fundamental philosophy certainly intend indeterminism primordial prerequisite however indeterminism like void fill determinism analogous quantum computing qubit correspond complexity meantime algorithm mathematical framework general yield require distinction underlie theory construct upon principle give rise respective objectification come artificial intelligence machine learning find mathematical gap order connect regime relation one propose discovery paper quilt gap like whole structure artificial intelligence yet develop realm concern responsive analysis betwixt human machine beyond analogy hence entire introduction amp incitement theory mathematically determine deep rationality responsive manifestation human brain design computing high potential degree attribution overlap condition show mathematically herewith identification make separate clear persuadejatsp,0.49107142857142855,0.125,0.25,0.0625,112.0,0.0,0.0,0.0,1.0
Computer Science,Artificial Intelligence and Machine Learning,Theoretical / Conceptual,Research and Analysis of Machine Learning Algorithm in Artificial Intelligence,"<jats:p>This article firstly explains the concepts of artificial intelligence and algorithm separately, then determines the research status of artificial in-telligence and machine learning in the background of the increasing pop-ularity of artificial intelligence, and finally briefly describes the machine learning algorithm in the field of artificial intelligence, as well as puts for-ward appropriate development prospects, in order to provide theoretical reference for industry insider</jats:p>",https://doi.org/10.30564/aia.v2i2.1801,CrossRef,research analysis machine learn algorithm artificial intelligence,jatspthis article firstly explain concept artificial intelligence algorithm separately determine research status artificial intelligence machine learning background increase popularity artificial intelligence finally briefly describe machine learn algorithm field artificial intelligence well put forward appropriate development prospect order provide theoretical reference industry insiderjatsp,research analysis machine learn algorithm artificial intelligence jatspthis article firstly explain concept artificial intelligence algorithm separately determine research status artificial intelligence machine learning background increase popularity artificial intelligence finally briefly describe machine learn algorithm field artificial intelligence well put forward appropriate development prospect order provide theoretical reference industry insiderjatsp,0.42857142857142855,0.19047619047619047,0.14285714285714285,0.14285714285714285,42.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Theoretical / Conceptual,Application of the EDAS Method in Artificial Intelligence A Comprehensive Analysis,"<jats:p>The rapid advancement of artificial intelligence (AI) raises critical questions about its values, ethics, and societal impact. Different philosophical perspectives, including utilitarianism, Kantian ethics, and human agency, guide the debate on how AI systems should operate. AI involves creating intelligent agents that learn and make decisions to achieve specific goals. Its transformative potential spans various industries, influencing productivity, innovation, and even ethical considerations in autonomous systems. This paper explores these complexities, offering insights into AI's evolving landscape.

Research significance:This research is significant as it explores the ethical, philosophical, and practical implications of artificial intelligence (AI), impacting technology, society, and human decision-making. By examining value alignment, human agency, and adaptive learning, the study advances our understanding of how AI can enhance productivity, innovation, and daily life. Additionally, addressing transparency and explain ability in AI systems is crucial for fostering trust, especially in critical domains like healthcare and security, influencing policy and future AI development.

Methology: Alternatives:Building information modelling (BIM), Robotics and automation, Computer vision, AI-Driven Construction Analytics, Cognitive Automation, and Visual AI Systems.

Evaluation Parameters:Complexity, Aesthetics, sufficient budget, Regulatory measures.

Result: The results show that Visual AI Systems received the highest ranking, whereas Computer vision received the lowest ranking.

Conclusion: Visual AI Systems has the highest value for artificial intelligence according to the EDAS approach.</jats:p>",https://doi.org/10.55124/jaim.v1i2.254,CrossRef,application eda method artificial intelligence comprehensive analysis,jatspthe rapid advancement artificial intelligence raise critical question value ethic societal impact different philosophical perspective include utilitarianism kantian ethic human agency guide debate system operate involve create intelligent agent learn make decision achieve specific goal transformative potential span various industry influence productivity innovation even ethical consideration autonomous system paper explore complexity offer insight ais evolve landscape research significancethis research significant explore ethical philosophical practical implication artificial intelligence impact technology society human decisionmaking examine value alignment human agency adaptive learn study advance understanding enhance productivity innovation daily life additionally address transparency explain ability system crucial foster trust especially critical domain like healthcare security influence policy future development methology alternativesbuilde information modelling bim robotic automation computer vision aidriven construction analytic cognitive automation visual system evaluation parameterscomplexity aesthetic sufficient budget regulatory measure result result show visual system receive highest ranking whereas computer vision receive low rank conclusion visual system high value artificial intelligence accord eda approachjatsp,application eda method artificial intelligence comprehensive analysis jatspthe rapid advancement artificial intelligence raise critical question value ethic societal impact different philosophical perspective include utilitarianism kantian ethic human agency guide debate system operate involve create intelligent agent learn make decision achieve specific goal transformative potential span various industry influence productivity innovation even ethical consideration autonomous system paper explore complexity offer insight ais evolve landscape research significancethis research significant explore ethical philosophical practical implication artificial intelligence impact technology society human decisionmaking examine value alignment human agency adaptive learn study advance understanding enhance productivity innovation daily life additionally address transparency explain ability system crucial foster trust especially critical domain like healthcare security influence policy future development methology alternativesbuilde information modelling bim robotic automation computer vision aidriven construction analytic cognitive automation visual system evaluation parameterscomplexity aesthetic sufficient budget regulatory measure result result show visual system receive highest ranking whereas computer vision receive low rank conclusion visual system high value artificial intelligence accord eda approachjatsp,0.5228758169934641,0.13071895424836602,0.24183006535947713,0.026143790849673203,153.0,3.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Theoretical / Conceptual,A Historical Review and Philosophical Examination of the two Paradigms in Artificial Intelligence Research,"<jats:p>Artificial intelligence (AI) is a field that has undergone significant changes and challenges over time. This paper reviews the historical development of AI and representative philosophical thinking, and also considers the methodology and applications of AI, and anticipates its continued advancement. It discusses two main paradigms: symbolism and connectionism, which differ in how they explain and implement intelligence through symbols or artificial neural networks. However, neither paradigm is the final answer to AI research but rather reflects the best answer at a given time. The paper also analyzes the shortcomings of both paradigms from a philosophical perspective and argues that the most fundamental philosophical issue therein is understanding the difference between biological and artificial intelligence.</jats:p>",https://doi.org/10.24018/ejai.2023.2.2.23,CrossRef,historical review philosophical examination two paradigm artificial intelligence research,jatspartificial intelligence field undergo significant change challenge time paper review historical development representative philosophical thinking also consider methodology application anticipate continued advancement discuss two main paradigms symbolism connectionism differ explain implement intelligence symbol artificial neural network however neither paradigm final answer research rather reflect good answer give time paper also analyze shortcoming paradigm philosophical perspective argue fundamental philosophical issue therein understand difference biological artificial intelligencejatsp,historical review philosophical examination two paradigm artificial intelligence research jatspartificial intelligence field undergo significant change challenge time paper review historical development representative philosophical thinking also consider methodology application anticipate continued advancement discuss two main paradigms symbolism connectionism differ explain implement intelligence symbol artificial neural network however neither paradigm final answer research rather reflect good answer give time paper also analyze shortcoming paradigm philosophical perspective argue fundamental philosophical issue therein understand difference biological artificial intelligencejatsp,0.4307692307692308,0.18461538461538463,0.23076923076923078,0.07692307692307693,65.0,0.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Theoretical / Conceptual,The democratization of innovation in africa - A perspective driven by artificial intelligence trends,"<jats:p xml:lang=""en"">This paper provides a unique perspective on the democratization of innovation in Africa through Artificial Intelligence (AI) trends. This work avoids a problem statement and methodology, instead providing a holistic view of Africa's evolving innovation landscape, particularly in relation to AI. This unconventional approach serves as a preface to future study in the growing field of AI in Africa. By examining the intersection of AI trends and democratization of innovation, this paper offers insights into the transformative potential of AI technologies in addressing societal challenges, empowering local communities, and driving inclusive growth across the continent. As Africa embraces AI as a catalyst for progress, this abstract sets the stage for further exploration of the implications, opportunities, and challenges that lie ahead in harnessing the power of AI to unlock Africa's vast potential for innovation and development.</jats:p>",https://doi.org/10.26634/jaim.3.1.20923,CrossRef,democratization innovation africa perspective drive artificial intelligence trend,jatsp xmllangenthis paper provide unique perspective democratization innovation africa artificial intelligence trend work avoid problem statement methodology instead provide holistic view africa evolve innovation landscape particularly relation unconventional approach serve preface future study grow field africa examine intersection trend democratization innovation paper offer insight transformative potential technology address societal challenge empower local community drive inclusive growth across continent africa embrace catalyst progress abstract set stage exploration implication opportunity challenge lie ahead harness power unlock africa vast potential innovation developmentjatsp,democratization innovation africa perspective drive artificial intelligence trend jatsp xmllangenthis paper provide unique perspective democratization innovation africa artificial intelligence trend work avoid problem statement methodology instead provide holistic view africa evolve innovation landscape particularly relation unconventional approach serve preface future study grow field africa examine intersection trend democratization innovation paper offer insight transformative potential technology address societal challenge empower local community drive inclusive growth across continent africa embrace catalyst progress abstract set stage exploration implication opportunity challenge lie ahead harness power unlock africa vast potential innovation developmentjatsp,0.46835443037974683,0.13924050632911392,0.16455696202531644,0.02531645569620253,79.0,1.0,0.0,0.0,0.0
Computer Science,Artificial Intelligence and Machine Learning,Theoretical / Conceptual,Progression of artificial intelligence/machine learning in geotechnical engineering,"<jats:sec>
<jats:title>Purpose</jats:title>
<jats:p>This short review paper aims to examine the evolution of artificial intelligence (AI)/machine learning (ML) in the realm of geotechnical engineering.</jats:p>
</jats:sec>
<jats:sec>
<jats:title>Design/methodology/approach</jats:title>
<jats:p>This paper gives a brief overview of AI/ML technology and discusses its current trend and future directions in geotechnical engineering.</jats:p>
</jats:sec>
<jats:sec>
<jats:title>Findings</jats:title>
<jats:p>Despite limitations, the use of AI/ML techniques has several significant benefits that make them powerful and practical tools in the field of geotechnical engineering.</jats:p>
</jats:sec>
<jats:sec>
<jats:title>Originality/value</jats:title>
<jats:p>This paper explored the integration of AI/ML promising technology into geotechnical design and practice and highlighted its transformative impacts in terms of benefits, limitations and potential future directions.</jats:p>
</jats:sec>",https://doi.org/10.1108/mlag-10-2024-0010,CrossRef,progression artificial intelligencemachine learn geotechnical engineering,jatssec jatstitlepurposejatstitle jatspthis short review paper aim examine evolution artificial intelligence aimachine learn realm geotechnical engineeringjatsp jatssec jatssec jatstitledesignmethodologyapproachjatstitle jatspthis paper give brief overview aiml technology discuss current trend future direction geotechnical engineeringjatsp jatssec jatssec jatstitlefindingsjatstitle jatspdespite limitation use aiml technique several significant benefit make powerful practical tool field geotechnical engineeringjatsp jatssec jatssec jatstitleoriginalityvaluejatstitle jatspthis paper explore integration aiml promising technology geotechnical design practice highlight transformative impact term benefit limitation potential future directionsjatsp jatssec,progression artificial intelligencemachine learn geotechnical engineering jatssec jatstitlepurposejatstitle jatspthis short review paper aim examine evolution artificial intelligence aimachine learn realm geotechnical engineeringjatsp jatssec jatssec jatstitledesignmethodologyapproachjatstitle jatspthis paper give brief overview aiml technology discuss current trend future direction geotechnical engineeringjatsp jatssec jatssec jatstitlefindingsjatstitle jatspdespite limitation use aiml technique several significant benefit make powerful practical tool field geotechnical engineeringjatsp jatssec jatssec jatstitleoriginalityvaluejatstitle jatspthis paper explore integration aiml promising technology geotechnical design practice highlight transformative impact term benefit limitation potential future directionsjatsp jatssec,0.44594594594594594,0.0945945945945946,0.1891891891891892,0.0,37.0,1.0,0.0,0.0,3.0
Computer Science,Computer Systems and Architecture,Quantitative,"Architectural Design Alternatives based on Cloud/Edge/Fog Computing for
  Connected Vehicles","As vehicles playing an increasingly important role in people's daily life,
requirements on safer and more comfortable driving experience have arisen.
Connected vehicles (CVs) can provide enabling technologies to realize these
requirements and have attracted widespread attentions from both academia and
industry. These requirements ask for a well-designed computing architecture to
support the Quality-of-Service (QoS) of CV applications. Computation offloading
techniques, such as cloud, edge, and fog computing, can help CVs process
computation-intensive and large-scale computing tasks. Additionally, different
cloud/edge/fog computing architectures are suitable for supporting different
types of CV applications with highly different QoS requirements, which
demonstrates the importance of the computing architecture design. However, most
of the existing surveys on cloud/edge/fog computing for CVs overlook the
computing architecture design, where they (i) only focus on one specific
computing architecture and (ii) lack discussions on benefits, research
challenges, and system requirements of different architectural alternatives. In
this paper, we provide a comprehensive survey on different architectural design
alternatives based on cloud/edge/fog computing for CVs. The contributions of
this paper are: (i) providing a comprehensive literature survey on existing
proposed architectural design alternatives based on cloud/edge/fog computing
for CVs, (ii) proposing a new classification of computing architectures based
on cloud/edge/fog computing for CVs: computation-aided and computation-enabled
architectures, (iii) presenting a holistic comparison among different
cloud/edge/fog computing architectures for CVs based on functional requirements
of CV systems, including advantages, disadvantages, and research challenges.",http://arxiv.org/abs/2009.12509v1,arXiv,architectural design alternative base cloudedgefog computing connect vehicle,vehicle play increasingly important role people daily life requirement safe comfortable driving experience arise connect vehicle cvs provide enable technology realize requirement attract widespread attention academia industry requirement ask welldesigned compute architecture support qualityofservice qos application computation offload technique cloud edge fog computing help cvs process computationintensive largescale computing task additionally different cloudedgefog computing architecture suitable support different type application highly different qos requirement demonstrate importance compute architecture design however exist survey cloudedgefog computing cvs overlook compute architecture design focus one specific compute architecture lack discussion benefit research challenge system requirement different architectural alternative paper provide comprehensive survey different architectural design alternative base cloudedgefog computing cvs contribution paper provide comprehensive literature survey exist propose architectural design alternative base cloudedgefog computing cvs propose new classification compute architecture base cloudedgefog computing cvs computationaide computationenable architecture iii present holistic comparison among different cloudedgefog computing architecture cvs base functional requirement system include advantage disadvantage research challenge,architectural design alternative base cloudedgefog computing connect vehicle vehicle play increasingly important role people daily life requirement safe comfortable driving experience arise connect vehicle cvs provide enable technology realize requirement attract widespread attention academia industry requirement ask welldesigned compute architecture support qualityofservice qos application computation offload technique cloud edge fog computing help cvs process computationintensive largescale computing task additionally different cloudedgefog computing architecture suitable support different type application highly different qos requirement demonstrate importance compute architecture design however exist survey cloudedgefog computing cvs overlook compute architecture design focus one specific compute architecture lack discussion benefit research challenge system requirement different architectural alternative paper provide comprehensive survey different architectural design alternative base cloudedgefog computing cvs contribution paper provide comprehensive literature survey exist propose architectural design alternative base cloudedgefog computing cvs propose new classification compute architecture base cloudedgefog computing cvs computationaide computationenable architecture iii present holistic comparison among different cloudedgefog computing architecture cvs base functional requirement system include advantage disadvantage research challenge,0.5526315789473685,0.07894736842105263,0.21052631578947367,0.02631578947368421,152.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Quantitative,"The failure tolerance of mechatronic software systems to random and
  targeted attacks","This paper describes a complex networks approach to study the failure
tolerance of mechatronic software systems under various types of hardware
and/or software failures. We produce synthetic system architectures based on
evidence of modular and hierarchical modular product architectures and known
motifs for the interconnection of physical components to software. The system
architectures are then subject to various forms of attack. The attacks simulate
failure of critical hardware or software. Four types of attack are
investigated: degree centrality, betweenness centrality, closeness centrality
and random attack. Failure tolerance of the system is measured by a 'robustness
coefficient', a topological 'size' metric of the connectedness of the attacked
network. We find that the betweenness centrality attack results in the most
significant reduction in the robustness coefficient, confirming betweenness
centrality, rather than the number of connections (i.e. degree), as the most
conservative metric of component importance. A counter-intuitive finding is
that ""designed"" system architectures, including a bus, ring, and star
architecture, are not significantly more failure-tolerant than interconnections
with no prescribed architecture, that is, a random architecture. Our research
provides a data-driven approach to engineer the architecture of mechatronic
software systems for failure tolerance.",http://arxiv.org/abs/1310.1050v1,arXiv,failure tolerance mechatronic software system random target attack,paper describe complex network approach study failure tolerance mechatronic software system various type hardware andor software failure produce synthetic system architecture base evidence modular hierarchical modular product architecture know motif interconnection physical component software system architecture subject various form attack attack simulate failure critical hardware software four type attack investigate degree centrality betweenness centrality closeness centrality random attack failure tolerance system measure robustness coefficient topological size metric connectedness attack network find betweenness centrality attack result significant reduction robustness coefficient confirm betweenness centrality rather number connection degree conservative metric component importance counterintuitive finding design system architecture include bus ring star architecture significantly failuretolerant interconnection prescribed architecture random architecture research provide datadriven approach engineer architecture mechatronic software system failure tolerance,failure tolerance mechatronic software system random target attack paper describe complex network approach study failure tolerance mechatronic software system various type hardware andor software failure produce synthetic system architecture base evidence modular hierarchical modular product architecture know motif interconnection physical component software system architecture subject various form attack attack simulate failure critical hardware software four type attack investigate degree centrality betweenness centrality closeness centrality random attack failure tolerance system measure robustness coefficient topological size metric connectedness attack network find betweenness centrality attack result significant reduction robustness coefficient confirm betweenness centrality rather number connection degree conservative metric component importance counterintuitive finding design system architecture include bus ring star architecture significantly failuretolerant interconnection prescribed architecture random architecture research provide datadriven approach engineer architecture mechatronic software system failure tolerance,0.6610169491525424,0.09322033898305085,0.211864406779661,0.01694915254237288,118.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Quantitative,Knowledge-aware Evolutionary Graph Neural Architecture Search,"Graph neural architecture search (GNAS) can customize high-performance graph
neural network architectures for specific graph tasks or datasets. However,
existing GNAS methods begin searching for architectures from a zero-knowledge
state, ignoring the prior knowledge that may improve the search efficiency. The
available knowledge base (e.g. NAS-Bench-Graph) contains many rich
architectures and their multiple performance metrics, such as the accuracy
(#Acc) and number of parameters (#Params). This study proposes exploiting such
prior knowledge to accelerate the multi-objective evolutionary search on a new
graph dataset, named knowledge-aware evolutionary GNAS (KEGNAS). KEGNAS employs
the knowledge base to train a knowledge model and a deep multi-output Gaussian
process (DMOGP) in one go, which generates and evaluates transfer architectures
in only a few GPU seconds. The knowledge model first establishes a
dataset-to-architecture mapping, which can quickly generate candidate transfer
architectures for a new dataset. Subsequently, the DMOGP with architecture and
dataset encodings is designed to predict multiple performance metrics for
candidate transfer architectures on the new dataset. According to the predicted
metrics, non-dominated candidate transfer architectures are selected to
warm-start the multi-objective evolutionary algorithm for optimizing the #Acc
and #Params on a new dataset. Empirical studies on NAS-Bench-Graph and five
real-world datasets show that KEGNAS swiftly generates top-performance
architectures, achieving 4.27% higher accuracy than advanced evolutionary
baselines and 11.54% higher accuracy than advanced differentiable baselines. In
addition, ablation studies demonstrate that the use of prior knowledge
significantly improves the search performance.",http://arxiv.org/abs/2411.17339v1,arXiv,knowledgeaware evolutionary graph neural architecture search,graph neural architecture search gnas customize highperformance graph neural network architecture specific graph task dataset however exist gnas method begin search architecture zeroknowledge state ignore prior knowledge may improve search efficiency available knowledge base nasbenchgraph contain many rich architecture multiple performance metric accuracy acc number parameter param study propose exploit prior knowledge accelerate multiobjective evolutionary search new graph dataset name knowledgeaware evolutionary gnas kegnas kegnas employ knowledge base train knowledge model deep multioutput gaussian process dmogp one generate evaluate transfer architecture gpu second knowledge model first establish datasettoarchitecture mapping quickly generate candidate transfer architecture new dataset subsequently dmogp architecture dataset encoding design predict multiple performance metric candidate transfer architecture new dataset accord predict metric nondominate candidate transfer architecture select warmstart multiobjective evolutionary algorithm optimize acc param new dataset empirical study nasbenchgraph five realworld dataset show kegnas swiftly generate topperformance architecture achieve high accuracy advanced evolutionary baseline high accuracy advanced differentiable baseline addition ablation study demonstrate use prior knowledge significantly improve search performance,knowledgeaware evolutionary graph neural architecture search graph neural architecture search gnas customize highperformance graph neural network architecture specific graph task dataset however exist gnas method begin search architecture zeroknowledge state ignore prior knowledge may improve search efficiency available knowledge base nasbenchgraph contain many rich architecture multiple performance metric accuracy acc number parameter param study propose exploit prior knowledge accelerate multiobjective evolutionary search new graph dataset name knowledgeaware evolutionary gnas kegnas kegnas employ knowledge base train knowledge model deep multioutput gaussian process dmogp one generate evaluate transfer architecture gpu second knowledge model first establish datasettoarchitecture mapping quickly generate candidate transfer architecture new dataset subsequently dmogp architecture dataset encoding design predict multiple performance metric candidate transfer architecture new dataset accord predict metric nondominate candidate transfer architecture select warmstart multiobjective evolutionary algorithm optimize acc param new dataset empirical study nasbenchgraph five realworld dataset show kegnas swiftly generate topperformance architecture achieve high accuracy advanced evolutionary baseline high accuracy advanced differentiable baseline addition ablation study demonstrate use prior knowledge significantly improve search performance,0.4567901234567901,0.12345679012345678,0.21604938271604937,0.037037037037037035,162.0,0.0,1.0,0.0,1.0
Computer Science,Computer Systems and Architecture,Quantitative,SoK: Microservice Architectures from a Dependability Perspective,"The microservice software architecture leverages the idea of splitting large
monolithic applications into multiple smaller services that interact using
lightweight communication schemes. While the microservice architecture has
proven its ability to support modern business applications, it also introduces
new possible weak points in a system. Some scientific literature surveys have
already addressed fault tolerance or security concerns but most of them lack
analysis on the fault and vulnerability coverage that is introduced by
microservice architectures. We explore the known faults and vulnerabilities
that microservice architecture might suffer from, and the recent scientific
literature that addresses them. We emphasize runtime detection and recovery
mechanisms instead of offline prevention and mitigation mechanisms to limit the
scope of this document.",http://arxiv.org/abs/2503.03392v1,arXiv,sok microservice architecture dependability perspective,microservice software architecture leverage idea split large monolithic application multiple small service interact use lightweight communication scheme microservice architecture prove ability support modern business application also introduce new possible weak point system scientific literature survey already address fault tolerance security concern lack analysis fault vulnerability coverage introduce microservice architecture explore know fault vulnerability microservice architecture might suffer recent scientific literature address emphasize runtime detection recovery mechanism instead offline prevention mitigation mechanism limit scope document,sok microservice architecture dependability perspective microservice software architecture leverage idea split large monolithic application multiple small service interact use lightweight communication scheme microservice architecture prove ability support modern business application also introduce new possible weak point system scientific literature survey already address fault tolerance security concern lack analysis fault vulnerability coverage introduce microservice architecture explore know fault vulnerability microservice architecture might suffer recent scientific literature address emphasize runtime detection recovery mechanism instead offline prevention mitigation mechanism limit scope document,0.6081081081081081,0.14864864864864866,0.17567567567567569,0.04054054054054054,74.0,1.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Quantitative,"Architectures of Meaning, A Systematic Corpus Analysis of NLP Systems","This paper proposes a novel statistical corpus analysis framework targeted
towards the interpretation of Natural Language Processing (NLP) architectural
patterns at scale. The proposed approach combines saturation-based lexicon
construction, statistical corpus analysis methods and graph collocations to
induce a synthesis representation of NLP architectural patterns from corpora.
The framework is validated in the full corpus of Semeval tasks and demonstrated
coherent architectural patterns which can be used to answer architectural
questions on a data-driven fashion, providing a systematic mechanism to
interpret a largely dynamic and exponentially growing field.",http://arxiv.org/abs/2107.08124v1,arXiv,architecture mean systematic corpus analysis nlp system,paper propose novel statistical corpus analysis framework target towards interpretation natural language processing nlp architectural pattern scale propose approach combine saturationbase lexicon construction statistical corpus analysis method graph collocation induce synthesis representation nlp architectural pattern corpora framework validate full corpus semeval task demonstrate coherent architectural pattern use answer architectural question datadriven fashion provide systematic mechanism interpret largely dynamic exponentially grow field,architecture mean systematic corpus analysis nlp system paper propose novel statistical corpus analysis framework target towards interpretation natural language processing nlp architectural pattern scale propose approach combine saturationbase lexicon construction statistical corpus analysis method graph collocation induce synthesis representation nlp architectural pattern corpora framework validate full corpus semeval task demonstrate coherent architectural pattern use answer architectural question datadriven fashion provide systematic mechanism interpret largely dynamic exponentially grow field,0.47540983606557374,0.14754098360655737,0.22950819672131148,0.03278688524590164,61.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Qualitative,Architecture implications of pads as a scarce resource,"<jats:p>Due to non-ideal technology scaling, delivering a stable supply voltage is increasingly challenging. Furthermore, com- petition for limited chip interface resources (i.e., C4 pads) between power supply and I/O, and the loss of such resources to electromigration, means that constructing a power deliverynetwork (PDN) that satisfies noise margins without compromising performance is and will remain a critical problem for architects and circuit designers alike. Simple guardbanding will no longer work, as the consequent performance penalty will grow with technology scaling</jats:p>
          <jats:p>In this paper, we develop a pre-RTL PDN model, VoltSpot, for the purpose of studying the performance and noise tradeoffs among power supply and I/O pad allocation, the effectiveness of noise mitigation techniques, and the consequent implications of electromigration-induced PDN pad failure. Our simulations demonstrate that, despite their integral role in the PDN, power/ground pads can be aggressively reduced (by conversion into I/O pads) to their electromigration limit with minimal performance impact from extra voltage noise - provided the system implements a suitable noise-mitigation strategy. The key observation is that even though reducing power/ground pads significantly increases the number of voltage emergencies, the average noise amplitude increase is small. Overall, we can triple I/O bandwidth while maintaining target lifetimes and incurring only 1.5% slowdown</jats:p>",https://doi.org/10.1145/2678373.2665728,CrossRef,architecture implication pad scarce resource,jatspdue nonideal technology scale deliver stable supply voltage increasingly challenging furthermore com petition limited chip interface resource pad power supply loss resource electromigration mean construct power deliverynetwork pdn satisfy noise margin without compromise performance remain critical problem architect circuit designer alike simple guardbanding long work consequent performance penalty grow technology scalingjatsp jatspin paper develop prertl pdn model voltspot purpose study performance noise tradeoff among power supply pad allocation effectiveness noise mitigation technique consequent implication electromigrationinduce pdn pad failure simulation demonstrate despite integral role pdn powerground pad aggressively reduce conversion pad electromigration limit minimal performance impact extra voltage noise provide system implement suitable noisemitigation strategy key observation even though reduce powerground pad significantly increase number voltage emergency average noise amplitude increase small overall triple bandwidth maintain target lifetime incur slowdownjatsp,architecture implication pad scarce resource jatspdue nonideal technology scale deliver stable supply voltage increasingly challenging furthermore com petition limited chip interface resource pad power supply loss resource electromigration mean construct power deliverynetwork pdn satisfy noise margin without compromise performance remain critical problem architect circuit designer alike simple guardbanding long work consequent performance penalty grow technology scalingjatsp jatspin paper develop prertl pdn model voltspot purpose study performance noise tradeoff among power supply pad allocation effectiveness noise mitigation technique consequent implication electromigrationinduce pdn pad failure simulation demonstrate despite integral role pdn powerground pad aggressively reduce conversion pad electromigration limit minimal performance impact extra voltage noise provide system implement suitable noisemitigation strategy key observation even though reduce powerground pad significantly increase number voltage emergency average noise amplitude increase small overall triple bandwidth maintain target lifetime incur slowdownjatsp,0.6744186046511628,0.11627906976744186,0.13178294573643412,0.03875968992248062,129.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Qualitative,"Towards Reference Architectures for Trustworthy Collaborative
  Cyber-Physical Systems: Reference Architectures as Boundary Objects","This paper presents our work-in-progress study on reference architectures as
boundary objects for realizing trustworthy collaborative Cyber-Physical Systems
(CPS). Furthermore, the preliminary results from interviews with systems
engineering experts from industry and academia are also discussed. The
interview results reveal challenges in using reference architectures during the
system development process. Furthermore, exactly which trustworthiness
attributes (security, availability, reliability, etc.) should be addressed to
realize trustworthy collaborative CPS is identified as an open question, which
we will address in our future work.",http://arxiv.org/abs/2108.12771v1,arXiv,towards reference architecture trustworthy collaborative cyberphysical system reference architecture boundary object,paper present workinprogress study reference architecture boundary object realize trustworthy collaborative cyberphysical system furthermore preliminary result interview system engineering expert industry academia also discuss interview result reveal challenge use reference architecture system development process furthermore exactly trustworthiness attribute security availability reliability etc address realize trustworthy collaborative identify open question address future work,towards reference architecture trustworthy collaborative cyberphysical system reference architecture boundary object paper present workinprogress study reference architecture boundary object realize trustworthy collaborative cyberphysical system furthermore preliminary result interview system engineering expert industry academia also discuss interview result reveal challenge use reference architecture system development process furthermore exactly trustworthiness attribute security availability reliability etc address realize trustworthy collaborative identify open question address future work,0.6346153846153846,0.11538461538461539,0.17307692307692307,0.07692307692307693,52.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Qualitative,Conceptual Modeling for Computer Organization and Architecture,"Understanding computer system hardware, including how computers operate, is
essential for undergraduate students in computer engineering and science.
Literature shows students learning computer organization and assembly language
often find fundamental concepts difficult to comprehend within the topic
materials. Tools have been introduced to improve students comprehension of the
interaction between computer architecture, assembly language, and the operating
system. One such tool is the Little Man Computer (LMC) model that operates in a
way similar to a computer but that is easier to understand. Even though LMC
does not have modern CPUs with multiple cores nor executes multiple
instructions, it nevertheless shows the basic principles of the von Neumann
architecture. LMC aims to introduce students to such concepts as code and
instruction sets. In this paper, LMC is used for an additional purpose: a tool
with which to experiment using a new modeling language (i.e., a thinging
machine; TM) in the area of computer organization and architecture without
involving complexity in the subject. That is, the simplicity of LMC facilitates
the application of TM without going deep into computer
organization/architecture materials. Accordingly, the paper (a) provides a new
way for using the LMC model for whatever purpose (e.g., education) and (b)
demonstrates that TM can be used to build an abstract level of description in
the organization/architect field. The resultant schematics from the TM model of
LMC offer an initial case study that supports our thesis that TM is a viable
method for hardware/software-independent descriptions in the computer
organization and architect field of study.",http://arxiv.org/abs/2103.01773v1,arXiv,conceptual modeling computer organization architecture,understand computer system hardware include computer operate essential undergraduate student computer engineering science literature show student learn computer organization assembly language often find fundamental concept difficult comprehend within topic material tool introduce improve student comprehension interaction computer architecture assembly language operating system one tool little man computer lmc model operate way similar computer easy understand even though lmc modern cpu multiple core execute multiple instruction nevertheless show basic principle von neumann architecture lmc aim introduce student concept code instruction set paper lmc use additional purpose tool experiment use new modeling language thinge machine area computer organization architecture without involve complexity subject simplicity lmc facilitate application without deep computer organizationarchitecture material accordingly paper provide new way use lmc model whatever purpose education demonstrate use build abstract level description organizationarchitect field resultant schematic model lmc offer initial case study support thesis viable method hardwaresoftwareindependent description computer organization architect field study,conceptual modeling computer organization architecture understand computer system hardware include computer operate essential undergraduate student computer engineering science literature show student learn computer organization assembly language often find fundamental concept difficult comprehend within topic material tool introduce improve student comprehension interaction computer architecture assembly language operating system one tool little man computer lmc model operate way similar computer easy understand even though lmc modern cpu multiple core execute multiple instruction nevertheless show basic principle von neumann architecture lmc aim introduce student concept code instruction set paper lmc use additional purpose tool experiment use new modeling language thinge machine area computer organization architecture without involve complexity subject simplicity lmc facilitate application without deep computer organizationarchitecture material accordingly paper provide new way use lmc model whatever purpose education demonstrate use build abstract level description organizationarchitect field resultant schematic model lmc offer initial case study support thesis viable method hardwaresoftwareindependent description computer organization architect field study,0.5743243243243243,0.14189189189189189,0.14864864864864866,0.060810810810810814,148.0,0.0,0.0,0.0,1.0
Computer Science,Computer Systems and Architecture,Qualitative,A System Architecture for Software-Defined Industrial Internet of Things,"Wireless sensor networks have been a driving force of the Industrial Internet
of Things (IIoT) advancement in the process control and manufacturing industry.
The emergence of IIoT opens great potential for the ubiquitous field device
connectivity and manageability with an integrated and standardized architecture
from low-level device operations to high-level data-centric application
interactions. This technological development requires software definability in
the key architectural elements of IIoT, including wireless field devices, IIoT
gateways, network infrastructure, and IIoT sensor cloud services. In this
paper, a novel software-defined IIoT (SD-IIoT) is proposed in order to solve
essential challenges in a holistic IIoT system, such as reliability, security,
timeliness scalability, and quality of service (QoS). A new IIoT system
architecture is proposed based on the latest networking technologies such as
WirelessHART, WebSocket, IETF constrained application protocol (CoAP) and
software-defined networking (SDN). A new scheme based on CoAP and SDN is
proposed to solve the QoS issues. Computer experiments in a case study are
implemented to show the effectiveness of the proposed system architecture.",http://arxiv.org/abs/1507.08810v1,arXiv,system architecture softwaredefine industrial internet thing,wireless sensor network drive force industrial internet thing iiot advancement process control manufacturing industry emergence iiot open great potential ubiquitous field device connectivity manageability integrated standardized architecture lowlevel device operation highlevel datacentric application interaction technological development require software definability key architectural element iiot include wireless field device iiot gateway network infrastructure iiot sensor cloud service paper novel softwaredefine iiot sdiiot propose order solve essential challenge holistic iiot system reliability security timeliness scalability quality service qos new iiot system architecture propose base late network technology wirelesshart websocket ietf constrain application protocol coap softwaredefine network sdn new scheme base coap sdn propose solve qos issue computer experiment case study implement show effectiveness propose system architecture,system architecture softwaredefine industrial internet thing wireless sensor network drive force industrial internet thing iiot advancement process control manufacturing industry emergence iiot open great potential ubiquitous field device connectivity manageability integrated standardized architecture lowlevel device operation highlevel datacentric application interaction technological development require software definability key architectural element iiot include wireless field device iiot gateway network infrastructure iiot sensor cloud service paper novel softwaredefine iiot sdiiot propose order solve essential challenge holistic iiot system reliability security timeliness scalability quality service qos new iiot system architecture propose base late network technology wirelesshart websocket ietf constrain application protocol coap softwaredefine network sdn new scheme base coap sdn propose solve qos issue computer experiment case study implement show effectiveness propose system architecture,0.672566371681416,0.09734513274336283,0.1415929203539823,0.0,113.0,1.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Qualitative,"Adapting the Function Approximation Architecture in Online Reinforcement
  Learning","The performance of a reinforcement learning (RL) system depends on the
computational architecture used to approximate a value function. Deep learning
methods provide both optimization techniques and architectures for
approximating nonlinear functions from noisy, high-dimensional observations.
However, prevailing optimization techniques are not designed for
strictly-incremental online updates. Nor are standard architectures designed
for observations with an a priori unknown structure: for example, light sensors
randomly dispersed in space. This paper proposes an online RL prediction
algorithm with an adaptive architecture that efficiently finds useful nonlinear
features. The algorithm is evaluated in a spatial domain with high-dimensional,
stochastic observations. The algorithm outperforms non-adaptive baseline
architectures and approaches the performance of an architecture given
side-channel information. These results are a step towards scalable RL
algorithms for more general problems, where the observation structure is not
available.",http://arxiv.org/abs/2106.09776v1,arXiv,adapt function approximation architecture online reinforcement learning,performance reinforcement learning system depend computational architecture use approximate value function deep learning method provide optimization technique architecture approximate nonlinear function noisy highdimensional observation however prevail optimization technique design strictlyincremental online update standard architecture design observation priori unknown structure example light sensor randomly disperse space paper propose online prediction algorithm adaptive architecture efficiently find useful nonlinear feature algorithm evaluate spatial domain highdimensional stochastic observation algorithm outperform nonadaptive baseline architecture approach performance architecture give sidechannel information result step towards scalable algorithm general problem observation structure available,adapt function approximation architecture online reinforcement learning performance reinforcement learning system depend computational architecture use approximate value function deep learning method provide optimization technique architecture approximate nonlinear function noisy highdimensional observation however prevail optimization technique design strictlyincremental online update standard architecture design observation priori unknown structure example light sensor randomly disperse space paper propose online prediction algorithm adaptive architecture efficiently find useful nonlinear feature algorithm evaluate spatial domain highdimensional stochastic observation algorithm outperform nonadaptive baseline architecture approach performance architecture give sidechannel information result step towards scalable algorithm general problem observation structure available,0.5058823529411764,0.10588235294117647,0.2823529411764706,0.03529411764705882,85.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Mixed Methods,Architecture of multi-agent systems for generative automatic matching among heterogeneous systems,"<jats:p>This paper presents the generative automatic matching (GAM) approach, implemented through a multi-agent system (MAS), to address the challenges of heterogeneity across meta-models. GAM integrates automatic meta-model matching with model generation, offering a comprehensive solution to complex systems involving diverse architectures. The key innovation lies in its ability to automate both the detection of correspondences and the transformation of models, improving the precision and recall of matching processes. The system's scalability and adaptability are enhanced by MAS, allowing for efficient management of diverse meta-models. The approach was evaluated through relational to big data UML meta-models (RBDU) case study. The results demonstrated high accuracy, with precision and recall metrics approaching 1, underscoring the robustness of GAM in managing heterogeneous systems. Compared to traditional methods, GAM offers significant advantages, including automated matching and generation, adaptability to various domains, and superior performance metrics. The study contributes to the field of model-driven engineering (MDE) by formalizing a method that effectively bridges the gap between heterogeneous meta-models. Future research will focus on refining matching heuristics, expanding case studies.</jats:p>",https://doi.org/10.11591/ijece.v15i2.pp2345-2355,CrossRef,architecture multiagent system generative automatic matching among heterogeneous system,jatspthis paper present generative automatic matching gam approach implement multiagent system mas address challenge heterogeneity across metamodel gam integrate automatic metamodel match model generation offer comprehensive solution complex system involve diverse architecture key innovation lie ability automate detection correspondence transformation model improve precision recall matching process system scalability adaptability enhance mas allow efficient management diverse metamodel approach evaluate relational big datum uml metamodel rbdu case study result demonstrate high accuracy precision recall metric approach underscore robustness gam manage heterogeneous system compare traditional method gam offer significant advantage include automate matching generation adaptability various domain superior performance metric study contribute field modeldriven engineering mde formalize method effectively bridge gap heterogeneous metamodel future research focus refining matching heuristic expand case studiesjatsp,architecture multiagent system generative automatic matching among heterogeneous system jatspthis paper present generative automatic matching gam approach implement multiagent system mas address challenge heterogeneity across metamodel gam integrate automatic metamodel match model generation offer comprehensive solution complex system involve diverse architecture key innovation lie ability automate detection correspondence transformation model improve precision recall matching process system scalability adaptability enhance mas allow efficient management diverse metamodel approach evaluate relational big datum uml metamodel rbdu case study result demonstrate high accuracy precision recall metric approach underscore robustness gam manage heterogeneous system compare traditional method gam offer significant advantage include automate matching generation adaptability various domain superior performance metric study contribute field modeldriven engineering mde formalize method effectively bridge gap heterogeneous metamodel future research focus refining matching heuristic expand case studiesjatsp,0.5294117647058824,0.12605042016806722,0.21008403361344538,0.008403361344537815,119.0,0.0,1.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Mixed Methods,Computer architecture courses in electrical engineering departments,"<jats:p>This paper traces the history of computer architecture courses in electrical engineering departments. Previously unpublished data from the Fall 1972 COSINE survey are given to show current computer architecture course offerings and texts. Computer architecture courses offered in 1972-73 are analyzed, compared with ACM and COSINE recommendations, and classified into five categories: introductory computer engineering courses with a computer architecture flavor, software-oriented computer organization courses, hardware-oriented computer organization courses, case study courses, and topical seminars. Future trends in computer architecture education are predicted.</jats:p>",https://doi.org/10.1145/633642.803984,CrossRef,computer architecture course electrical engineering department,jatspthis paper trace history computer architecture course electrical engineering department previously unpublishe datum fall cosine survey give show current computer architecture course offering text computer architecture course offer analyze compare acm cosine recommendation classify five category introductory computer engineering course computer architecture flavor softwareoriente computer organization course hardwareoriente computer organization course case study course topical seminar future trend computer architecture education predictedjatsp,computer architecture course electrical engineering department jatspthis paper trace history computer architecture course electrical engineering department previously unpublishe datum fall cosine survey give show current computer architecture course offering text computer architecture course offer analyze compare acm cosine recommendation classify five category introductory computer engineering course computer architecture flavor softwareoriente computer organization course hardwareoriente computer organization course case study course topical seminar future trend computer architecture education predictedjatsp,0.7419354838709677,0.08064516129032258,0.08064516129032258,0.016129032258064516,62.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Mixed Methods,Omega: An Architecture for AI Unification,"We introduce the open-ended, modular, self-improving Omega AI unification
architecture which is a refinement of Solomonoff's Alpha architecture, as
considered from first principles. The architecture embodies several crucial
principles of general intelligence including diversity of representations,
diversity of data types, integrated memory, modularity, and higher-order
cognition. We retain the basic design of a fundamental algorithmic substrate
called an ""AI kernel"" for problem solving and basic cognitive functions like
memory, and a larger, modular architecture that re-uses the kernel in many
ways. Omega includes eight representation languages and six classes of neural
networks, which are briefly introduced. The architecture is intended to
initially address data science automation, hence it includes many problem
solving methods for statistical tasks. We review the broad software
architecture, higher-order cognition, self-improvement, modular neural
architectures, intelligent agents, the process and memory hierarchy, hardware
abstraction, peer-to-peer computing, and data abstraction facility.",http://arxiv.org/abs/1805.12069v1,arXiv,omega architecture unification,introduce openende modular selfimprove omega unification architecture refinement solomonoff alpha architecture consider first principle architecture embody several crucial principle general intelligence include diversity representation diversity datum type integrate memory modularity higherorder cognition retain basic design fundamental algorithmic substrate call kernel problem solve basic cognitive function like memory large modular architecture reuse kernel many way omega include eight representation language six class neural network briefly introduce architecture intend initially address datum science automation hence include many problem solve method statistical task review broad software architecture higherorder cognition selfimprovement modular neural architecture intelligent agent process memory hierarchy hardware abstraction peertopeer computing datum abstraction facility,omega architecture unification introduce openende modular selfimprove omega unification architecture refinement solomonoff alpha architecture consider first principle architecture embody several crucial principle general intelligence include diversity representation diversity datum type integrate memory modularity higherorder cognition retain basic design fundamental algorithmic substrate call kernel problem solve basic cognitive function like memory large modular architecture reuse kernel many way omega include eight representation language six class neural network briefly introduce architecture intend initially address datum science automation hence include many problem solve method statistical task review broad software architecture higherorder cognition selfimprovement modular neural architecture intelligent agent process memory hierarchy hardware abstraction peertopeer computing datum abstraction facility,0.5980392156862745,0.11764705882352941,0.20588235294117646,0.029411764705882353,102.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Mixed Methods,Centralization potential of automotive E/E architectures,"Current automotive E/E architectures are subject to significant
transformations: Computing-power-intensive advanced driver-assistance systems,
bandwidth-hungry infotainment systems, the connection of the vehicle with the
internet and the consequential need for cyber-security drives the
centralization of E/E architectures. A centralized architecture is often seen
as a key enabler to master those challenges. Available research focuses mostly
on the different types of E/E architectures and contrasts their advantages and
disadvantages. There is a research gap on guidelines for system designers and
function developers to analyze the potential of their systems for
centralization. The present paper aims to quantify centralization potential
reviewing relevant literature and conducting qualitative interviews with
industry practitioners. In literature, we identified seven key automotive
system properties reaching limitations in current automotive architectures:
busload, functional safety, computing power, feature dependencies, development
and maintenance costs, error rate, modularity and flexibility. These properties
serve as quantitative evaluation criteria to estimate whether centralization
would enhance overall system performance. In the interviews, we have validated
centralization and its fundament - the conceptual systems engineering - as
capabilities to mitigate these limitations. By focusing on practical insights
and lessons learned, this research provides system designers with actionable
guidance to optimize their systems, addressing the outlined challenges while
avoiding monolithic architecture. This paper bridges the gap between
theoretical research and practical application, offering valuable takeaways for
practitioners.",http://arxiv.org/abs/2409.10690v1,arXiv,centralization potential automotive architecture,current automotive architecture subject significant transformation computingpowerintensive advanced driverassistance system bandwidthhungry infotainment system connection vehicle internet consequential need cybersecurity drive centralization architecture centralized architecture often see key enabler master challenge available research focus mostly different type architecture contrast advantage disadvantage research gap guideline system designer function developer analyze potential system centralization present paper aim quantify centralization potential review relevant literature conduct qualitative interview industry practitioner literature identify seven key automotive system property reach limitation current automotive architecture busload functional safety computing power feature dependencie development maintenance cost error rate modularity flexibility property serve quantitative evaluation criterion estimate whether centralization would enhance overall system performance interview validate centralization fundament conceptual system engineering capability mitigate limitation focus practical insight lesson learn research provide system designer actionable guidance optimize system address outlined challenge avoid monolithic architecture paper bridge gap theoretical research practical application offer valuable takeaway practitioner,centralization potential automotive architecture current automotive architecture subject significant transformation computingpowerintensive advanced driverassistance system bandwidthhungry infotainment system connection vehicle internet consequential need cybersecurity drive centralization architecture centralized architecture often see key enabler master challenge available research focus mostly different type architecture contrast advantage disadvantage research gap guideline system designer function developer analyze potential system centralization present paper aim quantify centralization potential review relevant literature conduct qualitative interview industry practitioner literature identify seven key automotive system property reach limitation current automotive architecture busload functional safety computing power feature dependencie development maintenance cost error rate modularity flexibility property serve quantitative evaluation criterion estimate whether centralization would enhance overall system performance interview validate centralization fundament conceptual system engineering capability mitigate limitation focus practical insight lesson learn research provide system designer actionable guidance optimize system address outlined challenge avoid monolithic architecture paper bridge gap theoretical research practical application offer valuable takeaway practitioner,0.6458333333333334,0.09722222222222222,0.2013888888888889,0.013888888888888888,144.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Mixed Methods,Computer Analysis of Architecture Using Automatic Image Understanding,"In the past few years, computer vision and pattern recognition systems have
been becoming increasingly more powerful, expanding the range of automatic
tasks enabled by machine vision. Here we show that computer analysis of
building images can perform quantitative analysis of architecture, and quantify
similarities between city architectural styles in a quantitative fashion.
Images of buildings from 18 cities and three countries were acquired using
Google StreetView, and were used to train a machine vision system to
automatically identify the location of the imaged building based on the image
visual content. Experimental results show that the automatic computer analysis
can automatically identify the geographical location of the StreetView image.
More importantly, the algorithm was able to group the cities and countries and
provide a phylogeny of the similarities between architectural styles as
captured by StreetView images. These results demonstrate that computer vision
and pattern recognition algorithms can perform the complex cognitive task of
analyzing images of buildings, and can be used to measure and quantify visual
similarities and differences between different styles of architectures. This
experiment provides a new paradigm for studying architecture, based on a
quantitative approach that can enhance the traditional manual observation and
analysis. The source code used for the analysis is open and publicly available.",http://arxiv.org/abs/1807.04892v4,arXiv,computer analysis architecture use automatic image understanding,past year computer vision pattern recognition system become increasingly powerful expand range automatic task enable machine vision show computer analysis building image perform quantitative analysis architecture quantify similarity city architectural style quantitative fashion image building city three country acquire use google streetview use train machine vision system automatically identify location image building base image visual content experimental result show automatic computer analysis automatically identify geographical location streetview image importantly algorithm able group city country provide phylogeny similarity architectural style capture streetview image result demonstrate computer vision pattern recognition algorithm perform complex cognitive task analyze image building use measure quantify visual similarity difference different style architecture experiment provide new paradigm study architecture base quantitative approach enhance traditional manual observation analysis source code use analysis open publicly available,computer analysis architecture use automatic image understanding past year computer vision pattern recognition system become increasingly powerful expand range automatic task enable machine vision show computer analysis building image perform quantitative analysis architecture quantify similarity city architectural style quantitative fashion image building city three country acquire use google streetview use train machine vision system automatically identify location image building base image visual content experimental result show automatic computer analysis automatically identify geographical location streetview image importantly algorithm able group city country provide phylogeny similarity architectural style capture streetview image result demonstrate computer vision pattern recognition algorithm perform complex cognitive task analyze image building use measure quantify visual similarity difference different style architecture experiment provide new paradigm study architecture base quantitative approach enhance traditional manual observation analysis source code use analysis open publicly available,0.5555555555555556,0.1349206349206349,0.1746031746031746,0.03968253968253968,126.0,0.0,0.0,1.0,0.0
Computer Science,Computer Systems and Architecture,Design and Development,Applying Slicing Technique to Software Architectures,"Software architecture is receiving increasingly attention as a critical
design level for software systems. As software architecture design resources
(in the form of architectural specifications) are going to be accumulated, the
development of techniques and tools to support architectural understanding,
testing, reengineering, maintenance, and reuse will become an important issue.
This paper introduces a new form of slicing, named architectural slicing, to
aid architectural understanding and reuse. In contrast to traditional slicing,
architectural slicing is designed to operate on the architectural specification
of a software system, rather than the source code of a program. Architectural
slicing provides knowledge about the high-level structure of a software system,
rather than the low-level implementation details of a program. In order to
compute an architectural slice, we present the architecture information flow
graph which can be used to represent information flows in a software
architecture. Based on the graph, we give a two-phase algorithm to compute an
architectural slice.",http://arxiv.org/abs/cs/0105008v1,arXiv,apply slicing technique software architecture,software architecture receive increasingly attention critical design level software system software architecture design resource form architectural specification accumulate development technique tool support architectural understanding testing reengineere maintenance reuse become important issue paper introduce new form slicing name architectural slicing aid architectural understanding reuse contrast traditional slicing architectural slicing design operate architectural specification software system rather source code program architectural slicing provide knowledge highlevel structure software system rather lowlevel implementation detail program order compute architectural slice present architecture information flow graph use represent information flow software architecture base graph give twophase algorithm compute architectural slice,apply slicing technique software architecture software architecture receive increasingly attention critical design level software system software architecture design resource form architectural specification accumulate development technique tool support architectural understanding testing reengineere maintenance reuse become important issue paper introduce new form slicing name architectural slicing aid architectural understanding reuse contrast traditional slicing architectural slicing design operate architectural specification software system rather source code program architectural slicing provide knowledge highlevel structure software system rather lowlevel implementation detail program order compute architectural slice present architecture information flow graph use represent information flow software architecture base graph give twophase algorithm compute architectural slice,0.6702127659574468,0.1276595744680851,0.14893617021276595,0.031914893617021274,94.0,1.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Design and Development,Decision Support Systems Architectures,"This paper presents the main components of the decision assisting systems.
Further on three types of architectures of these systems are described,
analyzed, and respectively compared, namely: the network architecture, the
centralized architecture and the hierarchical architecture.",http://arxiv.org/abs/0906.0863v1,arXiv,decision support system architecture,paper present main component decision assist system far three type architecture system describe analyze respectively compare namely network architecture centralized architecture hierarchical architecture,decision support system architecture paper present main component decision assist system far three type architecture system describe analyze respectively compare namely network architecture centralized architecture hierarchical architecture,0.5652173913043478,0.13043478260869565,0.13043478260869565,0.13043478260869565,23.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Design and Development,"Reliability of fault-tolerant system architectures for automated driving
  systems","Automated driving functions at high levels of autonomy operate without driver
supervision. The system itself must provide suitable responses in case of
hardware element failures. This requires fault-tolerant approaches using domain
ECUs and multicore processors operating in lockstep mode. The selection of a
suitable architecture for fault-tolerant vehicle systems is currently
challenging. Lockstep CPUs enable the implementation of majority redundancy or
M-out-of-N ($M$oo$N$) architectures. In addition to structural redundancy,
diversity redundancy in the ECU architecture is also relevant to fault
tolerance. Two fault-tolerant ECU architecture groups exist: architectures with
one ECU (system on a chip) and architectures consisting of multiple
communicating ECUs. The single-ECU systems achieve higher reliability, whereas
the multi-ECU systems are more robust against dependent failures, such as
common-cause or cascading failures, due to their increased potential for
diversity redundancy. Yet, it remains not fully understood how different types
of architectures influence the system reliability. The work aims to design
architectures with respect to CPU and sensor number, $M$oo$N$ expression, and
hardware element reliability. The results enable a direct comparison of
different architecture types. We calculate their reliability and quantify the
effort to achieve high safety requirements. Markov processes allow comparing
sensor and CPU architectures by varying the number of components and failure
rates. The objective is to evaluate systems' survival probability and fault
tolerance and design suitable sensor-CPU architectures. The results show that
the system architecture strongly influences the reliability. However, a
suitable system architecture must have a trade-off between reliability and
self-diagnostics that parallel systems without majority redundancies do not
provide.",http://arxiv.org/abs/2210.04040v1,arXiv,reliability faulttolerant system architecture automate driving system,automate driving function high level autonomy operate without driver supervision system must provide suitable response case hardware element failure require faulttolerant approach use domain ecus multicore processor operate lockstep mode selection suitable architecture faulttolerant vehicle system currently challenging lockstep cpus enable implementation majority redundancy moutofn moon architecture addition structural redundancy diversity redundancy ecu architecture also relevant fault tolerance two faulttolerant ecu architecture group exist architecture one ecu system chip architecture consist multiple communicating ecus singleecu system achieve high reliability whereas multiecu system robust dependent failure commoncause cascade failure due increase potential diversity redundancy yet remains fully understand different type architecture influence system reliability work aim design architecture respect cpu sensor number moon expression hardware element reliability result enable direct comparison different architecture type calculate reliability quantify effort achieve high safety requirement markov process allow compare sensor cpu architecture vary number component failure rate objective evaluate system survival probability fault tolerance design suitable sensorcpu architecture result show system architecture strongly influence reliability however suitable system architecture must tradeoff reliability selfdiagnostic parallel system without majority redundancy provide,reliability faulttolerant system architecture automate driving system automate driving function high level autonomy operate without driver supervision system must provide suitable response case hardware element failure require faulttolerant approach use domain ecus multicore processor operate lockstep mode selection suitable architecture faulttolerant vehicle system currently challenging lockstep cpus enable implementation majority redundancy moutofn moon architecture addition structural redundancy diversity redundancy ecu architecture also relevant fault tolerance two faulttolerant ecu architecture group exist architecture one ecu system chip architecture consist multiple communicating ecus singleecu system achieve high reliability whereas multiecu system robust dependent failure commoncause cascade failure due increase potential diversity redundancy yet remains fully understand different type architecture influence system reliability work aim design architecture respect cpu sensor number moon expression hardware element reliability result enable direct comparison different architecture type calculate reliability quantify effort achieve high safety requirement markov process allow compare sensor cpu architecture vary number component failure rate objective evaluate system survival probability fault tolerance design suitable sensorcpu architecture result show system architecture strongly influence reliability however suitable system architecture must tradeoff reliability selfdiagnostic parallel system without majority redundancy provide,0.6457142857142857,0.10857142857142857,0.14285714285714285,0.02857142857142857,87.5,0.0,0.0,0.0,1.0
Computer Science,Computer Systems and Architecture,Design and Development,"Functional Augmented State Transfer (FAST) Architecture for
  Computationally Intensive Network Applications","We describe a novel architecture that combines the simplicity of RESTful
architecture with the power of functional programming for delivering
web-services. Although, RESTful architecture has been quite useful in
simplifying the development of scalable systems, it is not suited for all types
of network applications. Our architecture improves upon the RESTful
architecture to provide scalable framework for computationally intensive
network applications. The proposed architecture is ideal for applications that
involve data management and data analysis/calculations on data. Data analytics
and financial calculations are two areas where the architecture can be applied
efficiently.",http://arxiv.org/abs/1607.05075v1,arXiv,functional augmented state transfer fast architecture computationally intensive network application,describe novel architecture combine simplicity restful architecture power functional programming deliver webservice although restful architecture quite useful simplify development scalable system suit type network application architecture improve upon restful architecture provide scalable framework computationally intensive network application propose architecture ideal application involve datum management data analysiscalculation datum datum analytic financial calculation two area architecture apply efficiently,functional augmented state transfer fast architecture computationally intensive network application describe novel architecture combine simplicity restful architecture power functional programming deliver webservice although restful architecture quite useful simplify development scalable system suit type network application architecture improve upon restful architecture provide scalable framework computationally intensive network application propose architecture ideal application involve datum management data analysiscalculation datum datum analytic financial calculation two area architecture apply efficiently,0.5357142857142857,0.14285714285714285,0.19642857142857142,0.05357142857142857,56.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Design and Development,A Survey of Machine Learning for Computer Architecture and Systems,"It has been a long time that computer architecture and systems are optimized
for efficient execution of machine learning (ML) models. Now, it is time to
reconsider the relationship between ML and systems, and let ML transform the
way that computer architecture and systems are designed. This embraces a
twofold meaning: improvement of designers' productivity, and completion of the
virtuous cycle. In this paper, we present a comprehensive review of the work
that applies ML for computer architecture and system design. First, we perform
a high-level taxonomy by considering the typical role that ML techniques take
in architecture/system design, i.e., either for fast predictive modeling or as
the design methodology. Then, we summarize the common problems in computer
architecture/system design that can be solved by ML techniques, and the typical
ML techniques employed to resolve each of them. In addition to emphasis on
computer architecture in a narrow sense, we adopt the concept that data centers
can be recognized as warehouse-scale computers; sketchy discussions are
provided in adjacent computer systems, such as code generation and compiler; we
also give attention to how ML techniques can aid and transform design
automation. We further provide a future vision of opportunities and potential
directions, and envision that applying ML for computer architecture and systems
would thrive in the community.",http://arxiv.org/abs/2102.07952v2,arXiv,survey machine learning computer architecture system,long time computer architecture system optimize efficient execution machine learning model time reconsider relationship system let transform way computer architecture system design embrace twofold meaning improvement designer productivity completion virtuous cycle paper present comprehensive review work apply computer architecture system design first perform highlevel taxonomy consider typical role technique take architecturesystem design either fast predictive modeling design methodology summarize common problem computer architecturesystem design solve technique typical technique employ resolve addition emphasis computer architecture narrow sense adopt concept data center recognize warehousescale computer sketchy discussion provide adjacent computer system code generation compiler also give attention technique aid transform design automation far provide future vision opportunity potential direction envision apply computer architecture system would thrive community,survey machine learning computer architecture system long time computer architecture system optimize efficient execution machine learning model time reconsider relationship system let transform way computer architecture system design embrace twofold meaning improvement designer productivity completion virtuous cycle paper present comprehensive review work apply computer architecture system design first perform highlevel taxonomy consider typical role technique take architecturesystem design either fast predictive modeling design methodology summarize common problem computer architecturesystem design solve technique typical technique employ resolve addition emphasis computer architecture narrow sense adopt concept data center recognize warehousescale computer sketchy discussion provide adjacent computer system code generation compiler also give attention technique aid transform design automation far provide future vision opportunity potential direction envision apply computer architecture system would thrive community,0.6434782608695652,0.1565217391304348,0.13043478260869565,0.034782608695652174,115.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Theoretical / Conceptual,Banyan networks for partitioning multiprocessor systems,"<jats:p>This paper describes a class of partitioning networks, called banyans, whose cost function grows more slowly than that of the crossbar and whose fan-out requirements are independent of network size. Such networks can economically partition the resources of large modular systems into a wide variety of subsystems. Any possible partition can be realized by paralleling several networks or by multiplexing a single network in a manner to be described later. Results will be given indicating that a cost/performance advantage over the crossbar can be obtained for large systems and that the crossbar can, in fact, be considered a non-optimal special case of a banyan network. Inherent fail-soft capability and the existence of rapid control algorithms which can be largely performed by distributed logic within the network are also important attributes of banyans.</jats:p>
          <jats:p>This paper presents fundamental properties and preliminary simulation results of banyan partitioning networks. A more detailed treatment, including proofs of theoretical properties, is reserved for reference (5).</jats:p>",https://doi.org/10.1145/633642.803967,CrossRef,banyan network partition multiprocessor system,jatspthis paper describe class partition network call banyan whose cost function grow slowly crossbar whose fanout requirement independent network size network economically partition resource large modular system wide variety subsystem possible partition realize parallel several network multiplexe single network manner describe later result give indicate costperformance advantage crossbar obtain large system crossbar fact consider nonoptimal special case banyan network inherent failsoft capability existence rapid control algorithm largely perform distribute logic within network also important attribute banyansjatsp jatspthis paper present fundamental property preliminary simulation result banyan partitioning network detailed treatment include proof theoretical property reserve reference jatsp,banyan network partition multiprocessor system jatspthis paper describe class partition network call banyan whose cost function grow slowly crossbar whose fanout requirement independent network size network economically partition resource large modular system wide variety subsystem possible partition realize parallel several network multiplexe single network manner describe later result give indicate costperformance advantage crossbar obtain large system crossbar fact consider nonoptimal special case banyan network inherent failsoft capability existence rapid control algorithm largely perform distribute logic within network also important attribute banyansjatsp jatspthis paper present fundamental property preliminary simulation result banyan partitioning network detailed treatment include proof theoretical property reserve reference jatsp,0.4791666666666667,0.10416666666666667,0.2604166666666667,0.052083333333333336,48.0,0.0,0.0,0.0,0.0
Computer Science,Computer Systems and Architecture,Theoretical / Conceptual,Modeling Network Architecture: A Cloud Case Study,"The Internet s ability to support a wide range of services depends on the
network architecture and theoretical and practical innovations necessary for
future networks. Network architecture in this context refers to the structure
of a computer network system as well as interactions among its physical
components, their configuration, and communication protocols. Various
descriptions of architecture have been developed over the years with an
unusually large number of superficial icons and symbols. This situation has
created a need for more coherent systematic representations of network
architecture. This paper is intended to refine the design, analysis, and
documentation of network architecture by adopting a conceptual model called a
thinging (abstract) machine (TM), which views all components of a network in
terms of a single notion: the flow of things in a TM. Since cloud computing has
become increasingly popular in the last few years as a model for a shared pool
of networks, servers, storage, and applications, we apply the TM to model a
real case study of cloud networks. The resultant model introduces an integrated
representation of computer networks.",http://arxiv.org/abs/2004.10350v1,arXiv,model network architecture cloud case study,internet ability support wide range service depend network architecture theoretical practical innovation necessary future network network architecture context refer structure computer network system well interaction among physical component configuration communication protocol various description architecture develop year unusually large number superficial icon symbol situation create need coherent systematic representation network architecture paper intend refine design analysis documentation network architecture adopt conceptual model call thinge abstract machine view component network term single notion flow thing since cloud computing become increasingly popular last year model share pool network server storage application apply model real case study cloud network resultant model introduce integrate representation computer network,model network architecture cloud case study internet ability support wide range service depend network architecture theoretical practical innovation necessary future network network architecture context refer structure computer network system well interaction among physical component configuration communication protocol various description architecture develop year unusually large number superficial icon symbol situation create need coherent systematic representation network architecture paper intend refine design analysis documentation network architecture adopt conceptual model call thinge abstract machine view component network term single notion flow thing since cloud computing become increasingly popular last year model share pool network server storage application apply model real case study cloud network resultant model introduce integrate representation computer network,0.6568627450980392,0.08823529411764706,0.17647058823529413,0.0196078431372549,102.0,0.0,0.0,1.0,0.0
Computer Science,Computer Systems and Architecture,Theoretical / Conceptual,Assessing Random Dynamical Network Architectures for Nanoelectronics,"Independent of the technology, it is generally expected that future nanoscale
devices will be built from vast numbers of densely arranged devices that
exhibit high failure rates. Other than that, there is little consensus on what
type of technology and computing architecture holds most promises to go far
beyond today's top-down engineered silicon devices. Cellular automata (CA) have
been proposed in the past as a possible class of architectures to the von
Neumann computing architecture, which is not generally well suited for future
parallel and fine-grained nanoscale electronics. While the top-down engineered
semi-conducting technology favors regular and locally interconnected
structures, future bottom-up self-assembled devices tend to have irregular
structures because of the current lack precise control over these processes. In
this paper, we will assess random dynamical networks, namely Random Boolean
Networks (RBNs) and Random Threshold Networks (RTNs), as alternative computing
architectures and models for future information processing devices. We will
illustrate that--from a theoretical perspective--they offer superior properties
over classical CA-based architectures, such as inherent robustness as the
system scales up, more efficient information processing capabilities, and
manufacturing benefits for bottom-up designed devices, which motivates this
investigation. We will present recent results on the dynamic behavior and
robustness of such random dynamical networks while also including manufacturing
issues in the assessment.",http://arxiv.org/abs/0805.2684v1,arXiv,assess random dynamical network architecture nanoelectronic,independent technology generally expect future nanoscale device build vast number densely arrange device exhibit high failure rate little consensus type technology compute architecture hold promise far beyond today topdown engineer silicon device cellular automata propose past possible class architecture von neumann compute architecture generally well suited future parallel finegrained nanoscale electronic topdown engineer semiconducte technology favor regular locally interconnect structure future bottomup selfassemble device tend irregular structure current lack precise control process paper assess random dynamical network namely random boolean network rbns random threshold network rtns alternative computing architecture model future information processing device illustrate thatfrom theoretical perspectivethey offer superior property classical cabased architecture inherent robustness system scale efficient information processing capability manufacturing benefit bottomup design device motivate investigation present recent result dynamic behavior robustness random dynamical network also include manufacturing issue assessment,assess random dynamical network architecture nanoelectronic independent technology generally expect future nanoscale device build vast number densely arrange device exhibit high failure rate little consensus type technology compute architecture hold promise far beyond today topdown engineer silicon device cellular automata propose past possible class architecture von neumann compute architecture generally well suited future parallel finegrained nanoscale electronic topdown engineer semiconducte technology favor regular locally interconnect structure future bottomup selfassemble device tend irregular structure current lack precise control process paper assess random dynamical network namely random boolean network rbns random threshold network rtns alternative computing architecture model future information processing device illustrate thatfrom theoretical perspectivethey offer superior property classical cabased architecture inherent robustness system scale efficient information processing capability manufacturing benefit bottomup design device motivate investigation present recent result dynamic behavior robustness random dynamical network also include manufacturing issue assessment,0.45864661654135336,0.11278195488721804,0.2932330827067669,0.06015037593984962,133.0,0.0,0.0,1.0,1.0
Computer Science,Human-Computer Interaction,Quantitative,The Sensorium: A Multimodal Neurofeedback Environment,"<jats:p>The Sensorium is a neurofeedback environment that allows people to experience signals from their nonperceptible body processes visually and auditorily. Various (neuro-)physiological rhythms and frequencies are projected simultaneously as soundscapes and “lightscapes” into the environment. A wireless physiological amplifier device sends signals such as EEG and ECG to a computer for real-time processing using the modified brain-computer interface software “Thought Translation Device” (TTD). The TTD performs signal filtering, parametric orchestral sonification, and light control. In a pilot study, 20 participants have been exposed to their ongoing brain and heart signals while sitting inside the Sensorium, a small room equipped with a speaker and lighting system. Almost all of them reported an increase in contentment, relaxation, happiness, and inner harmony. They also reported a widening in their body consciousness. In future, therapeutic paradigms will be developed and the treatment effects on people with psychosomatic diseases will be evaluated.</jats:p>",https://doi.org/10.1155/2011/724204,CrossRef,sensorium multimodal neurofeedback environment,jatspthe sensorium neurofeedback environment allow people experience signal nonperceptible body process visually auditorily various neurophysiological rhythm frequency project simultaneously soundscape lightscape environment wireless physiological amplifier device send signal eeg ecg computer realtime processing use modify braincomputer interface software think translation device ttd ttd perform signal filter parametric orchestral sonification light control pilot study participant expose ongoing brain heart signal sit inside sensorium small room equip speaker lighting system almost report increase contentment relaxation happiness inner harmony also report widening body consciousness future therapeutic paradigm develop treatment effect people psychosomatic disease evaluatedjatsp,sensorium multimodal neurofeedback environment jatspthe sensorium neurofeedback environment allow people experience signal nonperceptible body process visually auditorily various neurophysiological rhythm frequency project simultaneously soundscape lightscape environment wireless physiological amplifier device send signal eeg ecg computer realtime processing use modify braincomputer interface software think translation device ttd ttd perform signal filter parametric orchestral sonification light control pilot study participant expose ongoing brain heart signal sit inside sensorium small room equip speaker lighting system almost report increase contentment relaxation happiness inner harmony also report widening body consciousness future therapeutic paradigm develop treatment effect people psychosomatic disease evaluatedjatsp,0.4945054945054945,0.14285714285714285,0.16483516483516483,0.054945054945054944,91.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Quantitative,Wide Bezel Televisions Decrease Immersive Experiences,"<jats:p>This study explored how telepresence could be affected by stimuli from reality that distracts people while they are watching television. The sample comprised of 36 undergraduate and graduate students from a university in South Korea (age range: 18–38 years, <jats:italic>M</jats:italic> = 22.61, and SD = 4.12). A between-subjects experimental design was employed with two types of viewing equipment (a television screen vs. a television screen with side screens that act as stimuli from reality) and two bezel widths (2 cm vs. 10 cm) to examine how each condition influenced the viewers’ perceived telepresence. The results revealed that participants’ perception of telepresence was not affected by the type of viewing equipment. However, the level of telepresence was affected by the bezel width: the thinner the bezel, the more telepresence felt by the viewers. These findings provide important insights that can guide the future designs of screen bezels for televisions and other devices in order to more effectively create immersive virtual worlds. Future studies are needed to examine the relationship between central vision and telepresence.</jats:p>",https://doi.org/10.1155/2020/9349560,CrossRef,wide bezel television decrease immersive experience,jatspthis study explore telepresence could affect stimulus reality distract people watch television sample comprise undergraduate graduate student university south korea age range year jatsitalicmjatsitalic betweensubject experimental design employ two type view equipment television screen television screen side screen act stimulus reality two bezel width examine condition influence viewer perceive telepresence result reveal participant perception telepresence affect type view equipment however level telepresence affect bezel width thin bezel telepresence feel viewer finding provide important insight guide future design screen bezel television device order effectively create immersive virtual world future study need examine relationship central vision telepresencejatsp,wide bezel television decrease immersive experience jatspthis study explore telepresence could affect stimulus reality distract people watch television sample comprise undergraduate graduate student university south korea age range year jatsitalicmjatsitalic betweensubject experimental design employ two type view equipment television screen television screen side screen act stimulus reality two bezel width examine condition influence viewer perceive telepresence result reveal participant perception telepresence affect type view equipment however level telepresence affect bezel width thin bezel telepresence feel viewer finding provide important insight guide future design screen bezel television device order effectively create immersive virtual world future study need examine relationship central vision telepresencejatsp,0.5473684210526316,0.12631578947368421,0.17894736842105263,0.021052631578947368,95.0,0.0,1.0,1.0,0.0
Computer Science,Human-Computer Interaction,Quantitative,"Human Computer Interaction, Cognitive Cybernetic &amp; Captological Education","<jats:p>This paper was inspired by the topics by Marshal McLuhan about cibernetisation media understanding, associated with new findings in intelligent systems that lead towards technological anthropomorphisation, and Larsen's model of cognitive controller mood. The results of research conducted from 1990 to the present day outlining the issues associated with captology are presented, and their transfer to specific areas in education outlined. The objective of the theory is to comprehend, interpret and describe the appearance of various disciplines in the natural and social sciences relating to cognitive cybernetics and Human Computer Interaction. In accordance with the unique principles, multidisciplinarity is replaced by pluriperspectivity, and an approach to integrating research methods with engineering design. The theory answers questions using cognitive cybernetics and its recognition and transformation of Descartes's saying: ""cogito ergo sum"", (I think, therefore I am). Work presents the relationship and correlation between man and technology as Human computer interaction with technological definitions Intelligent Systems and Captology. Special attention is focused on today's modern education with the use of virtual media and the cultural matrix within which the particular media is active. For intelligent educations systems to become more useful and acceptable, we need to consider the “system” as a synergistic composition of software behaviors, and the human interacting.  Human interaction must be dominant and having considered the ruling. This cannot be achieved with today's captological educational media. Captological educational media stifles people, casts their most important, (social), role in education and makes them unhappy? Human Computer Interaction, as a strategy and philosophy, is the future of education!</jats:p>",https://doi.org/10.18063/phci.v1i2.759,CrossRef,human computer interaction cognitive cybernetic amp captological education,jatspthis paper inspire topic marshal mcluhan cibernetisation medium understanding associate new finding intelligent system lead towards technological anthropomorphisation larsen model cognitive controller mood result research conduct present day outline issue associate captology present transfer specific area education outline objective theory comprehend interpret describe appearance various discipline natural social science relate cognitive cybernetic human computer interaction accordance unique principle multidisciplinarity replace pluriperspectivity approach integrate research method engineering design theory answer question use cognitive cybernetic recognition transformation descartess say cogito ergo sum think therefore work present relationship correlation man technology human computer interaction technological definition intelligent system captology special attention focus todays modern education use virtual medium cultural matrix within particular media active intelligent education system become useful acceptable need consider system synergistic composition software behavior human interact human interaction must dominant consider ruling achieve todays captological educational medium captological educational medium stifle people cast important social role education make unhappy human computer interaction strategy philosophy future educationjatsp,human computer interaction cognitive cybernetic amp captological education jatspthis paper inspire topic marshal mcluhan cibernetisation medium understanding associate new finding intelligent system lead towards technological anthropomorphisation larsen model cognitive controller mood result research conduct present day outline issue associate captology present transfer specific area education outline objective theory comprehend interpret describe appearance various discipline natural social science relate cognitive cybernetic human computer interaction accordance unique principle multidisciplinarity replace pluriperspectivity approach integrate research method engineering design theory answer question use cognitive cybernetic recognition transformation descartess say cogito ergo sum think therefore work present relationship correlation man technology human computer interaction technological definition intelligent system captology special attention focus todays modern education use virtual medium cultural matrix within particular media active intelligent education system become useful acceptable need consider system synergistic composition software behavior human interact human interaction must dominant consider ruling achieve todays captological educational medium captological educational medium stifle people cast important social role education make unhappy human computer interaction strategy philosophy future educationjatsp,0.4935897435897436,0.1346153846153846,0.27564102564102566,0.01282051282051282,156.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Quantitative,Pointing Devices for Wearable Computers,"<jats:p>We present a survey of pointing devices for wearable computers, which are body-mounted devices that users can access at any time. Since traditional pointing devices (i.e., mouse, touchpad, and trackpoint) were designed to be used on a steady and flat surface they are inappropriate for wearable computers. Just as the advent of laptops resulted in the development of the touchpad and trackpoint, the emergence of wearable computers is leading to the development of pointing devices designed for them. However, unlike laptops, since wearable computers are operated from different body positions under different environmental conditions for different uses, researchers have developed a variety of innovative pointing devices for wearable computers characterized by their sensing mechanism, control mechanism, and form factor. We survey a representative set of pointing devices for wearable computers using an “adaptation of traditional devices” versus “new devices” dichotomy and study devices according to their control and sensing mechanisms and form factor. The objective of this paper is to showcase a variety of pointing devices developed for wearable computers and bring structure to the design space for wearable pointing devices. We conclude that a de facto pointing device for wearable computers, unlike laptops, is not likely to emerge.</jats:p>",https://doi.org/10.1155/2014/527320,CrossRef,point device wearable computer,jatspwe present survey point device wearable computer bodymounte device user access time since traditional pointing device mouse touchpad trackpoint design use steady flat surface inappropriate wearable computer advent laptop result development touchpad trackpoint emergence wearable computer lead development point device design however unlike laptop since wearable computer operate different body position different environmental condition different use researcher develop variety innovative pointing device wearable computer characterize sense mechanism control mechanism form factor survey representative set point device wearable computer use adaptation traditional device versus new device dichotomy study device accord control sense mechanism form factor objective paper showcase variety point device develop wearable computer bring structure design space wearable pointing device conclude facto point device wearable computer unlike laptop likely emergejatsp,point device wearable computer jatspwe present survey point device wearable computer bodymounte device user access time since traditional pointing device mouse touchpad trackpoint design use steady flat surface inappropriate wearable computer advent laptop result development touchpad trackpoint emergence wearable computer lead development point device design however unlike laptop since wearable computer operate different body position different environmental condition different use researcher develop variety innovative pointing device wearable computer characterize sense mechanism control mechanism form factor survey representative set point device wearable computer use adaptation traditional device versus new device dichotomy study device accord control sense mechanism form factor objective paper showcase variety point device develop wearable computer bring structure design space wearable pointing device conclude facto point device wearable computer unlike laptop likely emergejatsp,0.6416666666666667,0.09166666666666666,0.2,0.008333333333333333,120.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Quantitative,An Intelligent Framework for Website Usability,"<jats:p>With the major advances of the Internet throughout the past couple of years, websites have come to play a central role in the modern marketing business program. However, simply owning a website is not enough for a business to prosper on the Web. Indeed, it is the level of usability of a website that determines if a user stays or abandons it for another competing one. It is therefore crucial to understand the importance of usability on the web, and consequently the need for its evaluation. Nonetheless, there exist a number of obstacles preventing software organizations from successfully applying sound website usability evaluation strategies in practice. From this point of view automation of the latter is extremely beneficial, which not only assists designers in creating more usable websites, but also enhances the Internet users’ experience on the Web and increases their level of satisfaction. As a means of addressing this problem, an Intelligent Usability Evaluation (IUE) tool is proposed that automates the usability evaluation process by employing a Heuristic Evaluation technique in an intelligent manner through the adoption of several research-based AI methods. Experimental results show there exists a high correlation between the tool and human annotators when identifying the considered usability violations.</jats:p>",https://doi.org/10.1155/2014/479286,CrossRef,intelligent framework website usability,jatspwith major advance internet throughout past couple year website come play central role modern marketing business program however simply website enough business prosper web indeed level usability website determine user stay abandon another compete one therefore crucial understand importance usability web consequently need evaluation nonetheless exist number obstacle prevent software organization successfully apply sound website usability evaluation strategy practice point view automation latter extremely beneficial assist designer create usable website also enhance internet user experience web increase level satisfaction means address problem intelligent usability evaluation iue tool propose automate usability evaluation process employ heuristic evaluation technique intelligent manner adoption several researchbase method experimental result show exist high correlation tool human annotator identify consider usability violationsjatsp,intelligent framework website usability jatspwith major advance internet throughout past couple year website come play central role modern marketing business program however simply website enough business prosper web indeed level usability website determine user stay abandon another compete one therefore crucial understand importance usability web consequently need evaluation nonetheless exist number obstacle prevent software organization successfully apply sound website usability evaluation strategy practice point view automation latter extremely beneficial assist designer create usable website also enhance internet user experience web increase level satisfaction means address problem intelligent usability evaluation iue tool propose automate usability evaluation process employ heuristic evaluation technique intelligent manner adoption several researchbase method experimental result show exist high correlation tool human annotator identify consider usability violationsjatsp,0.5565217391304348,0.14782608695652175,0.16521739130434782,0.0782608695652174,115.0,0.0,0.0,1.0,0.0
Computer Science,Human-Computer Interaction,Qualitative,A Common Framework for Audience Interactivity,"Audience interactivity is interpreted differently across domains. This
research develops a framework to describe audience interactivity across a broad
range of experiences. We build on early work characterizing child audience
interactivity experiences, expanding on these findings with an extensive review
of literature in theater, games, and theme parks, paired with expert interviews
in those domains. The framework scaffolds interactivity as nested spheres of
audience influence, and comprises a series of dimensions of audience
interactivity including a Spectrum of Audience Interactivity. This framework
aims to develop a common taxonomy for researchers and practitioners working
with audience interactivity experiences.",http://arxiv.org/abs/1710.03320v2,arXiv,common framework audience interactivity,audience interactivity interpret differently across domain research develop framework describe audience interactivity across broad range experience build early work characterize child audience interactivity experience expand finding extensive review literature theater game theme park pair expert interview domain framework scaffold interactivity nest sphere audience influence comprise series dimension audience interactivity include spectrum audience interactivity framework aim develop common taxonomy researcher practitioner work audience interactivity experience,common framework audience interactivity audience interactivity interpret differently across domain research develop framework describe audience interactivity across broad range experience build early work characterize child audience interactivity experience expand finding extensive review literature theater game theme park pair expert interview domain framework scaffold interactivity nest sphere audience influence comprise series dimension audience interactivity include spectrum audience interactivity framework aim develop common taxonomy researcher practitioner work audience interactivity experience,0.625,0.15625,0.0625,0.015625,64.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Qualitative,Probabilistic Multimodal Modeling for Human-Robot Interaction Tasks,"Human-robot interaction benefits greatly from multimodal sensor inputs as
they enable increased robustness and generalization accuracy. Despite this
observation, few HRI methods are capable of efficiently performing inference
for multimodal systems. In this work, we introduce a reformulation of
Interaction Primitives which allows for learning from demonstration of
interaction tasks, while also gracefully handling nonlinearities inherent to
multimodal inference in such scenarios. We also empirically show that our
method results in more accurate, more robust, and faster inference than
standard Interaction Primitives and other common methods in challenging HRI
scenarios.",http://arxiv.org/abs/1908.04955v1,arXiv,probabilistic multimodal modeling humanrobot interaction task,humanrobot interaction benefit greatly multimodal sensor input enable increase robustness generalization accuracy despite observation hri method capable efficiently perform inference multimodal system work introduce reformulation interaction primitive allow learn demonstration interaction task also gracefully handle nonlinearitie inherent multimodal inference scenario also empirically show method result accurate robust fast inference standard interaction primitive common method challenge hri scenario,probabilistic multimodal modeling humanrobot interaction task humanrobot interaction benefit greatly multimodal sensor input enable increase robustness generalization accuracy despite observation hri method capable efficiently perform inference multimodal system work introduce reformulation interaction primitive allow learn demonstration interaction task also gracefully handle nonlinearitie inherent multimodal inference scenario also empirically show method result accurate robust fast inference standard interaction primitive common method challenge hri scenario,0.49122807017543857,0.15789473684210525,0.17543859649122806,0.10526315789473684,57.0,1.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Qualitative,Understanding Mental Models of AI through Player-AI Interaction,"Designing human-centered AI-driven applications require deep understandings
of how people develop mental models of AI. Currently, we have little knowledge
of this process and limited tools to study it. This paper presents the position
that AI-based games, particularly the player-AI interaction component, offer an
ideal domain to study the process in which mental models evolve. We present a
case study to illustrate the benefits of our approach for explainable AI.",http://arxiv.org/abs/2103.16168v1,arXiv,understand mental model playerai interaction,design humancentere aidriven application require deep understanding people develop mental model currently little knowledge process limited tool study paper present position aibased game particularly playerai interaction component offer ideal domain study process mental model evolve present case study illustrate benefit approach explainable,understand mental model playerai interaction design humancentere aidriven application require deep understanding people develop mental model currently little knowledge process limited tool study paper present position aibased game particularly playerai interaction component offer ideal domain study process mental model evolve present case study illustrate benefit approach explainable,0.5952380952380952,0.09523809523809523,0.19047619047619047,0.07142857142857142,42.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Qualitative,"Clo(o)k: Human-Time Interactions Through a Clock That ""Looks""","What if a clock could do more than tell time - what if it could look around?
This project explores the conceptualization, design, and construction of a
timepiece with visual perception capabilities, featuring three types of
human-time interactions. Informal observations during a demonstration highlight
its unique user experiences. https://www.zhuoyuelyu.com/clook",http://arxiv.org/abs/2303.14557v2,arXiv,clook humantime interaction clock look,clock could tell time could look around project explore conceptualization design construction timepiece visual perception capability feature three type humantime interaction informal observation demonstration highlight unique user experience httpswwwzhuoyuelyucomclook,clook humantime interaction clock look clock could tell time could look around project explore conceptualization design construction timepiece visual perception capability feature three type humantime interaction informal observation demonstration highlight unique user experience httpswwwzhuoyuelyucomclook,0.6206896551724138,0.13793103448275862,0.10344827586206896,0.0,29.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Qualitative,"Interaction-Required Suggestions for Control, Ownership, and Awareness
  in Human-AI Co-Writing","This paper explores interaction designs for generative AI interfaces that
necessitate human involvement throughout the generation process. We argue that
such interfaces can promote cognitive engagement, agency, and thoughtful
decision-making. Through a case study in text revision, we present and analyze
two interaction techniques: (1) using a predictive-text interaction to type the
assistant's response to a revision request, and (2) highlighting potential edit
opportunities in a document. Our implementations demonstrate how these
approaches reveal the landscape of writing possibilities and enable
fine-grained control. We discuss implications for human-AI writing partnerships
and future interaction design directions.",http://arxiv.org/abs/2504.08726v1,arXiv,interactionrequire suggestion control ownership awareness humanai cowriting,paper explore interaction design generative interface necessitate human involvement throughout generation process argue interface promote cognitive engagement agency thoughtful decisionmake case study text revision present analyze two interaction technique use predictivetext interaction type assistant response revision request highlight potential edit opportunity document implementation demonstrate approach reveal landscape write possibility enable finegrained control discuss implication humanai write partnership future interaction design direction,interactionrequire suggestion control ownership awareness humanai cowriting paper explore interaction design generative interface necessitate human involvement throughout generation process argue interface promote cognitive engagement agency thoughtful decisionmake case study text revision present analyze two interaction technique use predictivetext interaction type assistant response revision request highlight potential edit opportunity document implementation demonstrate approach reveal landscape write possibility enable finegrained control discuss implication humanai write partnership future interaction design direction,0.639344262295082,0.11475409836065574,0.18032786885245902,0.0,61.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Mixed Methods,Visual Enhancement for Sports Entertainment by Vision-Based Augmented Reality,"<jats:p>This paper presents visually enhanced sports entertainment applications: AR Baseball Presentation System and Interactive AR Bowling System. We utilize vision-based augmented reality for getting immersive feeling. First application is an observation system of a virtual baseball game on the tabletop. 3D virtual players are playing a game on a real baseball field model, so that users can observe the game from favorite view points through a handheld monitor with a web camera. Second application is a bowling system which allows users to roll a real ball down a real bowling lane model on the tabletop and knock down virtual pins. The users watch the virtual pins through the monitor. The lane and the ball are also tracked by vision-based tracking. In those applications, we utilize multiple 2D markers distributed at arbitrary positions and directions. Even though the geometrical relationship among the markers is unknown, we can track the camera in very wide area.</jats:p>",https://doi.org/10.1155/2008/145363,CrossRef,visual enhancement sport entertainment visionbase augmented reality,jatspthis paper present visually enhance sport entertainment application baseball presentation system interactive bowling system utilize visionbase augmented reality get immersive feeling first application observation system virtual baseball game tabletop virtual player play game real baseball field model user observe game favorite view point handheld monitor web camera second application bowling system allow user roll real ball real bowling lane model tabletop knock virtual pin user watch virtual pin monitor lane ball also track visionbase tracking application utilize multiple marker distribute arbitrary position direction even though geometrical relationship among marker unknown track camera wide areajatsp,visual enhancement sport entertainment visionbase augmented reality jatspthis paper present visually enhance sport entertainment application baseball presentation system interactive bowling system utilize visionbase augmented reality get immersive feeling first application observation system virtual baseball game tabletop virtual player play game real baseball field model user observe game favorite view point handheld monitor web camera second application bowling system allow user roll real ball real bowling lane model tabletop knock virtual pin user watch virtual pin monitor lane ball also track visionbase tracking application utilize multiple marker distribute arbitrary position direction even though geometrical relationship among marker unknown track camera wide areajatsp,0.5851063829787234,0.0851063829787234,0.2127659574468085,0.031914893617021274,94.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Mixed Methods,DeepSI: Interactive Deep Learning for Semantic Interaction,"In this paper, we design novel interactive deep learning methods to improve
semantic interactions in visual analytics applications. The ability of semantic
interaction to infer analysts' precise intents during sensemaking is dependent
on the quality of the underlying data representation. We propose the
$\text{DeepSI}_{\text{finetune}}$ framework that integrates deep learning into
the human-in-the-loop interactive sensemaking pipeline, with two important
properties. First, deep learning extracts meaningful representations from raw
data, which improves semantic interaction inference. Second, semantic
interactions are exploited to fine-tune the deep learning representations,
which then further improves semantic interaction inference. This feedback loop
between human interaction and deep learning enables efficient learning of user-
and task-specific representations. To evaluate the advantage of embedding the
deep learning within the semantic interaction loop, we compare
$\text{DeepSI}_{\text{finetune}}$ against a state-of-the-art but more basic use
of deep learning as only a feature extractor pre-processed outside of the
interactive loop. Results of two complementary studies, a human-centered
qualitative case study and an algorithm-centered simulation-based quantitative
experiment, show that $\text{DeepSI}_{\text{finetune}}$ more accurately
captures users' complex mental models with fewer interactions.",http://arxiv.org/abs/2305.18357v1,arXiv,deepsi interactive deep learning semantic interaction,paper design novel interactive deep learning method improve semantic interaction visual analytic application ability semantic interaction infer analyst precise intent sensemaking dependent quality underlie datum representation propose textdeepsitextfinetune framework integrate deep learning humanintheloop interactive sensemake pipeline two important property first deep learning extract meaningful representation raw datum improve semantic interaction inference second semantic interaction exploit finetune deep learning representation far improve semantic interaction inference feedback loop human interaction deep learning enable efficient learning user taskspecific representation evaluate advantage embed deep learning within semantic interaction loop compare textdeepsitextfinetune stateoftheart basic use deep learning feature extractor preprocesse outside interactive loop result two complementary study humancentere qualitative case study algorithmcentere simulationbase quantitative experiment show textdeepsitextfinetune accurately capture user complex mental model interaction,deepsi interactive deep learning semantic interaction paper design novel interactive deep learning method improve semantic interaction visual analytic application ability semantic interaction infer analyst precise intent sensemaking dependent quality underlie datum representation propose textdeepsitextfinetune framework integrate deep learning humanintheloop interactive sensemake pipeline two important property first deep learning extract meaningful representation raw datum improve semantic interaction inference second semantic interaction exploit finetune deep learning representation far improve semantic interaction inference feedback loop human interaction deep learning enable efficient learning user taskspecific representation evaluate advantage embed deep learning within semantic interaction loop compare textdeepsitextfinetune stateoftheart basic use deep learning feature extractor preprocesse outside interactive loop result two complementary study humancentere qualitative case study algorithmcentere simulationbase quantitative experiment show textdeepsitextfinetune accurately capture user complex mental model interaction,0.5126050420168067,0.08403361344537816,0.2773109243697479,0.03361344537815126,119.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Mixed Methods,"Towards Effective Human-AI Collaboration in GUI-Based Interactive Task
  Learning Agents","We argue that a key challenge in enabling usable and useful interactive task
learning for intelligent agents is to facilitate effective Human-AI
collaboration. We reflect on our past 5 years of efforts on designing,
developing and studying the SUGILITE system, discuss the issues on
incorporating recent advances in AI with HCI principles in mixed-initiative
interactions and multi-modal interactions, and summarize the lessons we
learned. Lastly, we identify several challenges and opportunities, and describe
our ongoing work",http://arxiv.org/abs/2003.02622v1,arXiv,towards effective humanai collaboration guibase interactive task learn agent,argue key challenge enable usable useful interactive task learning intelligent agent facilitate effective humanai collaboration reflect past year effort design develop study sugilite system discuss issue incorporate recent advance hci principle mixedinitiative interaction multimodal interaction summarize lesson learn lastly identify several challenge opportunity describe ongoing work,towards effective humanai collaboration guibase interactive task learn agent argue key challenge enable usable useful interactive task learning intelligent agent facilitate effective humanai collaboration reflect past year effort design develop study sugilite system discuss issue incorporate recent advance hci principle mixedinitiative interaction multimodal interaction summarize lesson learn lastly identify several challenge opportunity describe ongoing work,0.4782608695652174,0.21739130434782608,0.2608695652173913,0.021739130434782608,46.0,0.0,0.0,1.0,0.0
Computer Science,Human-Computer Interaction,Mixed Methods,"Contextualizing Large-Scale Domain Knowledge for Conceptual Modeling and
  Simulation","We present an interactive modeling tool, VERA, that scaffolds the acquisition
of domain knowledge involved in conceptual modeling and agent-based
simulations. We describe the knowledge engineering process of contextualizing
large-scale domain knowledge. Specifically, we use the ontology of biotic
interactions in Global Biotic Interactions, and the trait data of species in
Encyclopedia of Life to facilitate the model construction. Learners can use
VERA to construct qualitative conceptual models of ecological phenomena, run
them as quantitative simulations, and review their predictions.",http://arxiv.org/abs/2209.02579v1,arXiv,contextualizing largescale domain knowledge conceptual modeling simulation,present interactive modeling tool vera scaffold acquisition domain knowledge involve conceptual modeling agentbase simulation describe knowledge engineering process contextualizing largescale domain knowledge specifically use ontology biotic interaction global biotic interaction trait datum specie encyclopedia life facilitate model construction learner use vera construct qualitative conceptual model ecological phenomenon run quantitative simulation review prediction,contextualizing largescale domain knowledge conceptual modeling simulation present interactive modeling tool vera scaffold acquisition domain knowledge involve conceptual modeling agentbase simulation describe knowledge engineering process contextualizing largescale domain knowledge specifically use ontology biotic interaction global biotic interaction trait datum specie encyclopedia life facilitate model construction learner use vera construct qualitative conceptual model ecological phenomenon run quantitative simulation review prediction,0.5961538461538461,0.11538461538461539,0.19230769230769232,0.019230769230769232,52.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Mixed Methods,VizWiz Dataset Browser: A Tool for Visualizing Machine Learning Datasets,"We present a visualization tool to exhaustively search and browse through a
set of large-scale machine learning datasets. Built on the top of the VizWiz
dataset, our dataset browser tool has the potential to support and enable a
variety of qualitative and quantitative research, and open new directions for
visualizing and researching with multimodal information. The tool is publicly
available at https://vizwiz.org/browse.",http://arxiv.org/abs/1912.09336v1,arXiv,vizwiz dataset browser tool visualize machine learn dataset,present visualization tool exhaustively search browse set largescale machine learn dataset build top vizwiz dataset dataset browser tool potential support enable variety qualitative quantitative research open new direction visualize research multimodal information tool publicly available httpsvizwizorgbrowse,vizwiz dataset browser tool visualize machine learn dataset present visualization tool exhaustively search browse set largescale machine learn dataset build top vizwiz dataset dataset browser tool potential support enable variety qualitative quantitative research open new direction visualize research multimodal information tool publicly available httpsvizwizorgbrowse,0.6111111111111112,0.1111111111111111,0.2222222222222222,0.05555555555555555,36.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Design and Development,A Functional Driver Analyzing Concept,"<jats:p>It is evident that a lot of accidents occur because of drowsiness or inattentiveness of the driver. The logical consequence is that we have to find methods to better analyze the driver. A lot of research has been spent on camera-based systems which focus on the driver's eye gaze or his head movement. But there are few systems that provide camera-free driver analyzing. This is the main goal of the work presented here which is structured in three phases, with the operational goal of having a working driver analyzer implemented in a car. The main question is: is it possible to make statements concerning the driver and his state by using vehicle data from the CAN Bus only? This paper describes the current state of driver analyzing, our overall system architecture, as well as future work. At the moment, we focus on detecting the driving style of a person.</jats:p>",https://doi.org/10.1155/2011/413964,CrossRef,functional driver analyze concept,jatspit evident lot accident occur drowsiness inattentiveness driver logical consequence find method well analyze driver lot research spend camerabased system focus driver eye gaze head movement system provide camerafree driver analyze main goal work present structure three phase operational goal work driver analyzer implement car main question possible make statement concern driver state use vehicle datum bus paper describe current state driver analyze overall system architecture well future work moment focus detect drive style personjatsp,functional driver analyze concept jatspit evident lot accident occur drowsiness inattentiveness driver logical consequence find method well analyze driver lot research spend camerabased system focus driver eye gaze head movement system provide camerafree driver analyze main goal work present structure three phase operational goal work driver analyzer implement car main question possible make statement concern driver state use vehicle datum bus paper describe current state driver analyze overall system architecture well future work moment focus detect drive style personjatsp,0.6266666666666667,0.16,0.16,0.013333333333333334,75.0,0.0,0.0,0.0,1.0
Computer Science,Human-Computer Interaction,Design and Development,Developing a Child Friendly Text-to-Speech System,"<jats:p>This paper discusses the implementation details of a child friendly, good quality, English text-to-speech (TTS) system that is phoneme-based, concatenative, easy to set up and use with little memory. Direct waveform concatenation and linear prediction coding (LPC) are used. Most existing TTS systems are unit-selection based, which use standard speech databases available in neutral adult voices. Here reduced memory is achieved by the concatenation of phonemes and by replacing phonetic wave files with their LPC coefficients. Linguistic analysis was used to reduce the algorithmic complexity instead of signal processing techniques. Sufficient degree of customization and generalization catering to the needs of the child user had been included through the provision for vocabulary and voice selection to suit the requisites of the child. Prosody had also been incorporated. This inexpensive TTS system was implemented in MATLAB, with the synthesis presented by means of a graphical user interface (GUI), thus making it child friendly. This can be used not only as an interesting language learning aid for the normal child but it also serves as a speech aid to the vocally disabled child. The quality of the synthesized speech was evaluated using the mean opinion score (MOS).</jats:p>",https://doi.org/10.1155/2008/597971,CrossRef,develop child friendly texttospeech system,jatspthis paper discuss implementation detail child friendly good quality english texttospeech tts system phonemebase concatenative easy set use little memory direct waveform concatenation linear prediction code lpc use exist tts system unitselection base use standard speech database available neutral adult voice reduce memory achieve concatenation phoneme replace phonetic wave file lpc coefficient linguistic analysis use reduce algorithmic complexity instead signal processing technique sufficient degree customization generalization cater need child user include provision vocabulary voice selection suit requisite child prosody also incorporate inexpensive tts system implement matlab synthesis present mean graphical user interface gui thus make child friendly use interesting language learn aid normal child also serve speech aid vocally disabled child quality synthesized speech evaluate use mean opinion score mosjatsp,develop child friendly texttospeech system jatspthis paper discuss implementation detail child friendly good quality english texttospeech tts system phonemebase concatenative easy set use little memory direct waveform concatenation linear prediction code lpc use exist tts system unitselection base use standard speech database available neutral adult voice reduce memory achieve concatenation phoneme replace phonetic wave file lpc coefficient linguistic analysis use reduce algorithmic complexity instead signal processing technique sufficient degree customization generalization cater need child user include provision vocabulary voice selection suit requisite child prosody also incorporate inexpensive tts system implement matlab synthesis present mean graphical user interface gui thus make child friendly use interesting language learn aid normal child also serve speech aid vocally disabled child quality synthesized speech evaluate use mean opinion score mosjatsp,0.5416666666666666,0.15833333333333333,0.225,0.041666666666666664,120.0,0.0,0.0,0.0,1.0
Computer Science,Human-Computer Interaction,Design and Development,Enhancing Human-Computer Interaction in Augmented Reality (AR) and Virtual Reality (VR) Environments: The Role of Adaptive Interfaces and Haptic Feedback Systems,"<jats:p>Human-Computer Interaction (HCI) in Augmented Reality (AR) and Virtual Reality (VR) environments has emerged as a critical area of research, shaping how users interact with immersive technologies. This study explores the design and development of advanced HCI frameworks in AR/VR environments, with a particular focus on adaptive interfaces and haptic feedback systems. Adaptive interfaces employ real-time data to personalize user experiences, while haptic feedback systems provide tactile sensations to bridge the gap between digital and physical interactions. The integration of these technologies enhances user engagement, immersion, and efficiency across applications such as gaming, training simulations, healthcare, and remote collaboration. This research investigates the challenges in creating intuitive, responsive systems and examines cutting-edge solutions in multimodal interactions, gesture recognition, and real-time feedback processing. By analyzing user performance and satisfaction, this study contributes to the refinement of AR/VR systems, paving the way for next-generation immersive environments.</jats:p>",https://doi.org/10.62802/jfxtjt43,CrossRef,enhance humancomputer interaction augmented reality virtual reality environment role adaptive interface haptic feedback system,jatsphumancomputer interaction hci augmented reality virtual reality environment emerge critical area research shape user interact immersive technology study explore design development advanced hci framework arvr environment particular focus adaptive interface haptic feedback system adaptive interface employ realtime datum personalize user experience haptic feedback system provide tactile sensation bridge gap digital physical interaction integration technology enhance user engagement immersion efficiency across application gaming training simulation healthcare remote collaboration research investigate challenge create intuitive responsive system examine cuttingedge solution multimodal interaction gesture recognition realtime feedback processing analyze user performance satisfaction study contribute refinement arvr system pave way nextgeneration immersive environmentsjatsp,enhance humancomputer interaction augmented reality virtual reality environment role adaptive interface haptic feedback system jatsphumancomputer interaction hci augmented reality virtual reality environment emerge critical area research shape user interact immersive technology study explore design development advanced hci framework arvr environment particular focus adaptive interface haptic feedback system adaptive interface employ realtime datum personalize user experience haptic feedback system provide tactile sensation bridge gap digital physical interaction integration technology enhance user engagement immersion efficiency across application gaming training simulation healthcare remote collaboration research investigate challenge create intuitive responsive system examine cuttingedge solution multimodal interaction gesture recognition realtime feedback processing analyze user performance satisfaction study contribute refinement arvr system pave way nextgeneration immersive environmentsjatsp,0.6938775510204082,0.08163265306122448,0.11224489795918367,0.0,98.0,0.0,0.0,0.0,1.0
Computer Science,Human-Computer Interaction,Design and Development,RoboTable: An Infrastructure for Intuitive Interaction with Mobile Robots in a Mixed-Reality Environment,"<jats:p>This paper presents the design, development, and testing of a tabletop interface called RoboTable, which is an infrastructure supporting intuitive interaction with both mobile robots and virtual components in a mixed-reality environment. With a flexible software toolkit and specifically developed robots, the platform enables various modes of interaction with mobile robots. Using this platform, prototype applications are developed for two different application domains:<jats:italic>RoboPong</jats:italic>investigates the efficiency of the RoboTable system in game applications, and<jats:italic>ExploreRobot</jats:italic>explores the possibility of using robots and intuitive interaction to enhance learning.</jats:p>",https://doi.org/10.1155/2012/301608,CrossRef,robotable infrastructure intuitive interaction mobile robot mixedreality environment,jatspthis paper present design development testing tabletop interface call robotable infrastructure support intuitive interaction mobile robot virtual component mixedreality environment flexible software toolkit specifically develop robot platform enable various mode interaction mobile robot use platform prototype application develop two different application domainsjatsitalicrobopongjatsitalicinvestigate efficiency robotable system game application andjatsitalicexplorerobotjatsitalicexplore possibility use robot intuitive interaction enhance learningjatsp,robotable infrastructure intuitive interaction mobile robot mixedreality environment jatspthis paper present design development testing tabletop interface call robotable infrastructure support intuitive interaction mobile robot virtual component mixedreality environment flexible software toolkit specifically develop robot platform enable various mode interaction mobile robot use platform prototype application develop two different application domainsjatsitalicrobopongjatsitalicinvestigate efficiency robotable system game application andjatsitalicexplorerobotjatsitalicexplore possibility use robot intuitive interaction enhance learningjatsp,0.6181818181818182,0.07272727272727272,0.2,0.01818181818181818,55.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Design and Development,A Text-Based Chat System Embodied with an Expressive Agent,"<jats:p>Life-like characters are playing vital role in social computing by making human-computer interaction more easy and spontaneous. Nowadays, use of these characters to interact in online virtual environment has gained immense popularity. In this paper, we proposed a framework for a text-based chat system embodied with a life-like virtual agent that aims at natural communication between the users. To achieve this kind of system, we developed an agent that performs some nonverbal communications such as generating facial expression and motions by analyzing the text messages of the users. More specifically, this agent is capable of generating facial expressions for six basic emotions such as happy, sad, fear, angry, surprise, and disgust along with two additional emotions, irony and determined. Then to make the interaction between the users more realistic and lively, we added motions such as eye blink and head movements. We measured our proposed system from different aspects and found the results satisfactory, which make us believe that this kind of system can play a significant role in making an interaction episode more natural, effective, and interesting. Experimental evaluation reveals that the proposed agent can display emotive expressions correctly 93% of the time by analyzing the users’ text input.</jats:p>",https://doi.org/10.1155/2017/8962762,CrossRef,textbase chat system embody expressive agent,jatsplifelike character play vital role social computing make humancomputer interaction easy spontaneous nowadays use character interact online virtual environment gain immense popularity paper propose framework textbase chat system embody lifelike virtual agent aim natural communication user achieve kind system develop agent perform nonverbal communication generate facial expression motion analyze text message user specifically agent capable generate facial expression six basic emotion happy sad fear angry surprise disgust along two additional emotion irony determine make interaction user realistic lively add motion eye blink head movement measure propose system different aspect find result satisfactory make believe kind system play significant role make interaction episode natural effective interesting experimental evaluation reveal propose agent display emotive expression correctly time analyze user text inputjatsp,textbase chat system embody expressive agent jatsplifelike character play vital role social computing make humancomputer interaction easy spontaneous nowadays use character interact online virtual environment gain immense popularity paper propose framework textbase chat system embody lifelike virtual agent aim natural communication user achieve kind system develop agent perform nonverbal communication generate facial expression motion analyze text message user specifically agent capable generate facial expression six basic emotion happy sad fear angry surprise disgust along two additional emotion irony determine make interaction user realistic lively add motion eye blink head movement measure propose system different aspect find result satisfactory make believe kind system play significant role make interaction episode natural effective interesting experimental evaluation reveal propose agent display emotive expression correctly time analyze user text inputjatsp,0.47058823529411764,0.226890756302521,0.226890756302521,0.03361344537815126,119.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Theoretical / Conceptual,"Transitioning Between Audience and Performer: Co-Designing Interactive
  Music Performances with Children","Live interactions have the potential to meaningfully engage audiences during
musical performances, and modern technologies promise unique ways to facilitate
these interactions. This work presents findings from three co-design sessions
with children that investigated how audiences might want to interact with live
music performances, including design considerations and opportunities. Findings
from these sessions also formed a Spectrum of Audience Interactivity in live
musical performances, outlining ways to encourage interactivity in music
performances from the child perspective.",http://arxiv.org/abs/1702.06236v1,arXiv,transition audience performer codesigning interactive music performance child,live interaction potential meaningfully engage audience musical performance modern technology promise unique way facilitate interaction work present finding three codesign session child investigate audience might want interact live music performance include design consideration opportunity finding session also form spectrum audience interactivity live musical performance outline way encourage interactivity music performance child perspective,transition audience performer codesigning interactive music performance child live interaction potential meaningfully engage audience musical performance modern technology promise unique way facilitate interaction work present finding three codesign session child investigate audience might want interact live music performance include design consideration opportunity finding session also form spectrum audience interactivity live musical performance outline way encourage interactivity music performance child perspective,0.6346153846153846,0.17307692307692307,0.11538461538461539,0.038461538461538464,52.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Theoretical / Conceptual,Interacting with Thoughtful AI,"We envision the concept of Thoughtful AI, a new human-AI interaction paradigm
in which the AI behaves as a continuously thinking entity. Unlike conventional
AI systems that operate on a turn-based, input-output model, Thoughtful AI
autonomously generates, develops, and communicates its evolving thought process
throughout an interaction. In this position paper, we argue that this
thoughtfulness unlocks new possibilities for human-AI interaction by enabling
proactive AI behavior, facilitating continuous cognitive alignment with users,
and fostering more dynamic interaction experiences. We outline the conceptual
foundations of Thoughtful AI, illustrate its potential through example
projects, and envision how this paradigm can transform human-AI interaction in
the future.",http://arxiv.org/abs/2502.18676v2,arXiv,interact thoughtful,envision concept thoughtful new humanai interaction paradigm behave continuously think entity unlike conventional system operate turnbase inputoutput model thoughtful autonomously generate develop communicate evolve thought process throughout interaction position paper argue thoughtfulness unlock new possibility humanai interaction enable proactive behavior facilitate continuous cognitive alignment user foster dynamic interaction experience outline conceptual foundation thoughtful illustrate potential example project envision paradigm transform humanai interaction future,interact thoughtful envision concept thoughtful new humanai interaction paradigm behave continuously think entity unlike conventional system operate turnbase inputoutput model thoughtful autonomously generate develop communicate evolve thought process throughout interaction position paper argue thoughtfulness unlock new possibility humanai interaction enable proactive behavior facilitate continuous cognitive alignment user foster dynamic interaction experience outline conceptual foundation thoughtful illustrate potential example project envision paradigm transform humanai interaction future,0.5079365079365079,0.09523809523809523,0.2857142857142857,0.031746031746031744,63.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Theoretical / Conceptual,Utilising Explanations to Mitigate Robot Conversational Failures,"This paper presents an overview of robot failure detection work from HRI and
adjacent fields using failures as an opportunity to examine robot explanation
behaviours. As humanoid robots remain experimental tools in the early 2020s,
interactions with robots are situated overwhelmingly in controlled
environments, typically studying various interactional phenomena. Such
interactions suffer from real-world and large-scale experimentation and tend to
ignore the 'imperfectness' of the everyday user. Robot explanations can be used
to approach and mitigate failures, by expressing robot legibility and
incapability, and within the perspective of common-ground. In this paper, I
discuss how failures present opportunities for explanations in interactive
conversational robots and what the potentials are for the intersection of HRI
and explainability research.",http://arxiv.org/abs/2307.04462v1,arXiv,utilise explanation mitigate robot conversational failure,paper present overview robot failure detection work hri adjacent field use failure opportunity examine robot explanation behaviour humanoid robot remain experimental tool early interaction robot situate overwhelmingly control environment typically study various interactional phenomenon interaction suffer realworld largescale experimentation tend ignore imperfectness everyday user robot explanation use approach mitigate failure express robot legibility incapability within perspective commonground paper discuss failure present opportunity explanation interactive conversational robot potential intersection hri explainability research,utilise explanation mitigate robot conversational failure paper present overview robot failure detection work hri adjacent field use failure opportunity examine robot explanation behaviour humanoid robot remain experimental tool early interaction robot situate overwhelmingly control environment typically study various interactional phenomenon interaction suffer realworld largescale experimentation tend ignore imperfectness everyday user robot explanation use approach mitigate failure express robot legibility incapability within perspective commonground paper discuss failure present opportunity explanation interactive conversational robot potential intersection hri explainability research,0.5492957746478874,0.1267605633802817,0.15492957746478872,0.04225352112676056,71.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Theoretical / Conceptual,"Inflation of Interactivity? Analyzing and Understanding Embodied
  Interaction in Interactive Art through a New Three-dimensional Model","This insight paper examines embodied interaction in interactive art, focusing
on body embodiment, bodily sensation (i.e., somaesthetic), and audience-artwork
interaction. The authors propose a new three-dimensional descriptive model of
interactive art based on literature and apply to analyze a curated corpus of 49
award-winning artworks from the Prix Ars Electronica between 2009 and 2023. The
analysis reveals emergent patterns of interactive art that deepen the
understanding of interactive art from an embodied perspective and prepare the
ground for future research and art practices. This paper has discovered that
embodied interaction remains under-explored in interactive art rather than an
inflation of interactivity. Notable research gaps persist in exploring virtual
embodiment within sociocultural contexts using immersive technologies.
Furthermore, it also underscores the need to revisit the sociological and
etymological roots of interaction to enhance interpersonality and relationality
and advocates for a paradigm shift in future research and practice in
interactive art.",http://arxiv.org/abs/2409.00047v1,arXiv,inflation interactivity analyze understand embody interaction interactive art new threedimensional model,insight paper examine embody interaction interactive art focus body embodiment bodily sensation somaesthetic audienceartwork interaction author propose new threedimensional descriptive model interactive art base literature apply analyze curate corpus awardwinne artwork prix electronica analysis reveal emergent pattern interactive art deepen understanding interactive art embodied perspective prepare ground future research art practice paper discover embody interaction remain underexplored interactive art rather inflation interactivity notable research gap persist explore virtual embodiment within sociocultural context use immersive technology furthermore also underscore need revisit sociological etymological root interaction enhance interpersonality relationality advocate paradigm shift future research practice interactive art,inflation interactivity analyze understand embody interaction interactive art new threedimensional model insight paper examine embody interaction interactive art focus body embodiment bodily sensation somaesthetic audienceartwork interaction author propose new threedimensional descriptive model interactive art base literature apply analyze curate corpus awardwinne artwork prix electronica analysis reveal emergent pattern interactive art deepen understanding interactive art embodied perspective prepare ground future research art practice paper discover embody interaction remain underexplored interactive art rather inflation interactivity notable research gap persist explore virtual embodiment within sociocultural context use immersive technology furthermore also underscore need revisit sociological etymological root interaction enhance interpersonality relationality advocate paradigm shift future research practice interactive art,0.5368421052631579,0.1368421052631579,0.22105263157894736,0.031578947368421054,95.0,0.0,0.0,0.0,0.0
Computer Science,Human-Computer Interaction,Theoretical / Conceptual,Ten Conceptual Dimensions of Context,"This paper attempts to synthesize various conceptualizations of the term
""context"" as found in computing literature. Ten conceptual dimensions of
context thus emerge -- location; user, task, and system characteristics;
physical, social, organizational, and cultural environments; time-related
aspects, and historical information. Together, the ten dimensions of context
provide a comprehensive view of the notion of context, and allow for a more
systematic examination of the influence of context and contextual information
on human-system or human-AI interactions.",http://arxiv.org/abs/2111.04472v1,arXiv,ten conceptual dimension context,paper attempt synthesize various conceptualization term context find compute literature ten conceptual dimension context thus emerge location user task system characteristic physical social organizational cultural environment timerelate aspect historical information together ten dimension context provide comprehensive view notion context allow systematic examination influence context contextual information humansystem humanai interaction,ten conceptual dimension context paper attempt synthesize various conceptualization term context find compute literature ten conceptual dimension context thus emerge location user task system characteristic physical social organizational cultural environment timerelate aspect historical information together ten dimension context provide comprehensive view notion context allow systematic examination influence context contextual information humansystem humanai interaction,0.4897959183673469,0.10204081632653061,0.2653061224489796,0.04081632653061224,49.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Quantitative,Software metrics and measurement principles,"<jats:p>Software measurement is widely advocated as a fundamental constituent of an engineering approach to planning and controlling software development. Unfortunately, there is a dichotomy between the quantity of developed metrics and those used. This paper provides a tutorial review of software engineering measurement indicating the depth and breadth of the field. Individual metrics are not described due to the interest of this paper being on the measurement process and not the products of that process. Generic problems have been identified within existing measurement processes, these provide learning points for the expression of measurement principles. These principles are classified and described according to their position within the formulation, analysis and application stages of measurement. Conclusions are elaborated that suggest that existing measurement frameworks for applying measurement - often called measurement methods - do not provide sufficient support for the principles and their continued use will only serve to replicate the problems. In order to improve the products i.e. metrics, the measurement process requires improvement through inclusion of these principles in a new method.</jats:p>",https://doi.org/10.1145/181610.181625,CrossRef,software metric measurement principle,jatspsoftware measurement widely advocate fundamental constituent engineering approach plan control software development unfortunately dichotomy quantity develop metric use paper provide tutorial review software engineering measurement indicate depth breadth field individual metric describe due interest paper measurement process product process generic problem identify within exist measurement process provide learning point expression measurement principle principle classify describe accord position within formulation analysis application stage measurement conclusion elaborate suggest exist measurement framework apply measurement often call measurement method provide sufficient support principle continue use serve replicate problem order improve product metric measurement process require improvement inclusion principle new methodjatsp,software metric measurement principle jatspsoftware measurement widely advocate fundamental constituent engineering approach plan control software development unfortunately dichotomy quantity develop metric use paper provide tutorial review software engineering measurement indicate depth breadth field individual metric describe due interest paper measurement process product process generic problem identify within exist measurement process provide learning point expression measurement principle principle classify describe accord position within formulation analysis application stage measurement conclusion elaborate suggest exist measurement framework apply measurement often call measurement method provide sufficient support principle continue use serve replicate problem order improve product metric measurement process require improvement inclusion principle new methodjatsp,0.6041666666666666,0.17708333333333334,0.125,0.03125,96.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Quantitative,Principles and Measurement Models for Software Assurance,<jats:p>Ensuring and sustaining software product integrity requires that all project stakeholders share a common understanding of the status of the product throughout the development and sustainment processes. Accurately measuring the product’s status helps achieve this shared understanding. This paper presents an effective measurement model organized by seven principles that capture the fundamental managerial and technical concerns of development and sustainment. These principles guided the development of the measures presented in the paper. Data from the quantitative measures help organizational stakeholders make decisions about the performance of their overall software assurance processes. Complementary risk-based data help them make decisions relative to the assessment of risk. The quantitative and risk-based measures form a comprehensive model to assess program and organizational performance. An organization using this model will be able to assess its performance to ensure secure and trustworthy products.</jats:p>,https://doi.org/10.4018/jsse.2013010101,CrossRef,principle measurement model software assurance,jatspensuring sustain software product integrity require project stakeholder share common understanding status product throughout development sustainment process accurately measure product status help achieve share understanding paper present effective measurement model organize seven principle capture fundamental managerial technical concern development sustainment principle guide development measure present paper datum quantitative measure help organizational stakeholder make decision performance overall software assurance process complementary riskbase datum help make decision relative assessment risk quantitative riskbase measure form comprehensive model assess program organizational performance organization use model able assess performance ensure secure trustworthy productsjatsp,principle measurement model software assurance jatspensuring sustain software product integrity require project stakeholder share common understanding status product throughout development sustainment process accurately measure product status help achieve share understanding paper present effective measurement model organize seven principle capture fundamental managerial technical concern development sustainment principle guide development measure present paper datum quantitative measure help organizational stakeholder make decision performance overall software assurance process complementary riskbase datum help make decision relative assessment risk quantitative riskbase measure form comprehensive model assess program organizational performance organization use model able assess performance ensure secure trustworthy productsjatsp,0.5681818181818182,0.18181818181818182,0.2159090909090909,0.011363636363636364,88.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Quantitative,TOWARD SOFTWARE ENGINEERING PRINCIPLES BASED ON ISLAMIC ETHICAL VALUES,"<jats:p>Software is the core for Computer-based applications which became  an essential part for critical control systems, health and human life  guard systems, financial and banking systems, educational and other  systems. It requires qualified software engineers professionally and  ethically. L.R and survey results show that software engineering  professionals facing several ethical related problems which are costly,  harmful and affected high ratio of people. Professional organizations  like ACM, IEEE, ABET and CSAC have established codes of ethics to help  software engineering professionals to understand and manage their  ethical responsibilities. Islam considers ethics an essential factor to  build individuals,communities and society. Islamic Ethics are set of  moral principles and guidance that recognizes what is right behavior  from wrong, which are comprehensive, stable, fair, and historically  prove success in building ethically great society. The 1.3 billions of  Muslims with 10s of thousands of software engineers should have an  effective role in software development and life, which requires them to  understand and implement ethics, specially the Islamic ethics in their  work. This paper is a frame-work for modeling software engineering  principle. It focuses mainly on adopting a new version of software  engineering principle based on Islamic ethical values.</jats:p>",https://doi.org/10.31436/iiumej.v9i2.99,CrossRef,toward software engineering principle base islamic ethical value,jatspsoftware core computerbase application become essential part critical control system health human life guard system financial banking system educational system require qualified software engineer professionally ethically survey result show software engineering professional face several ethical relate problem costly harmful affect high ratio people professional organization like acm ieee abet csac establish code ethic help software engineering professional understand manage ethical responsibility islam consider ethic essential factor build individualscommunitie society islamic ethic set moral principle guidance recognize right behavior wrong comprehensive stable fair historically prove success build ethically great society billion muslim thousand software engineer effective role software development life require understand implement ethic specially islamic ethic work paper framework modeling software engineering principle focus mainly adopt new version software engineering principle base islamic ethical valuesjatsp,toward software engineering principle base islamic ethical value jatspsoftware core computerbase application become essential part critical control system health human life guard system financial banking system educational system require qualified software engineer professionally ethically survey result show software engineering professional face several ethical relate problem costly harmful affect high ratio people professional organization like acm ieee abet csac establish code ethic help software engineering professional understand manage ethical responsibility islam consider ethic essential factor build individualscommunitie society islamic ethic set moral principle guidance recognize right behavior wrong comprehensive stable fair historically prove success build ethically great society billion muslim thousand software engineer effective role software development life require understand implement ethic specially islamic ethic work paper framework modeling software engineering principle focus mainly adopt new version software engineering principle base islamic ethical valuesjatsp,0.464,0.144,0.28,0.048,125.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Quantitative,Software engineering principles to improve quality and performance of R software,"<jats:p>Today’s computational researchers are expected to be highly proficient in using software to solve a wide range of problems ranging from processing large datasets to developing personalized treatment strategies from a growing range of options. Researchers are well versed in their own field, but may lack formal training and appropriate mentorship in software engineering principles. Two major themes not covered in most university coursework nor current literature are software testing and software optimization. Through a survey of all currently available Comprehensive R Archive Network packages, we show that reproducible and replicable software tests are frequently not available and that many packages do not appear to employ software performance and optimization tools and techniques. Through use of examples from an existing R package, we demonstrate powerful testing and optimization techniques that can improve the quality of any researcher’s software.</jats:p>",https://doi.org/10.7717/peerj-cs.175,CrossRef,software engineering principle improve quality performance software,jatsptoday computational researcher expect highly proficient use software solve wide range problem range process large dataset develop personalized treatment strategy grow range option researcher well verse field may lack formal training appropriate mentorship software engineering principle two major theme cover university coursework current literature software testing software optimization survey currently available comprehensive archive network package show reproducible replicable software test frequently available many package appear employ software performance optimization tool technique use example exist package demonstrate powerful testing optimization technique improve quality researcher softwarejatsp,software engineering principle improve quality performance software jatsptoday computational researcher expect highly proficient use software solve wide range problem range process large dataset develop personalized treatment strategy grow range option researcher well verse field may lack formal training appropriate mentorship software engineering principle two major theme cover university coursework current literature software testing software optimization survey currently available comprehensive archive network package show reproducible replicable software test frequently available many package appear employ software performance optimization tool technique use example exist package demonstrate powerful testing optimization technique improve quality researcher softwarejatsp,0.5952380952380952,0.11904761904761904,0.17857142857142858,0.03571428571428571,84.0,0.0,0.0,1.0,0.0
Computer Science,Software Engineering Principles,Quantitative,Principles of survey research part 6,"<jats:p>This article is the last of our series of articles on survey research. In it, we discuss how to analyze survey data. We provide examples of correct and incorrect analysis techniques used in software engineering surveys.</jats:p>",https://doi.org/10.1145/638750.638758,CrossRef,principle survey research part,jatspthis article last series article survey research discuss analyze survey datum provide example correct incorrect analysis technique use software engineering surveysjatsp,principle survey research part jatspthis article last series article survey research discuss analyze survey datum provide example correct incorrect analysis technique use software engineering surveysjatsp,0.5238095238095238,0.047619047619047616,0.14285714285714285,0.0,21.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Qualitative,Developing a process framework using principles of value‐based software engineering,"<jats:title>Abstract</jats:title><jats:p>In this article we present a software process framework using the 4 + 1 theory and principles of value‐based software engineering (VBSE). The value‐based process framework serves as a 6‐step process guide, and explains critical interactions between the five theories in the 4 + 1 theory of value‐based software engineering. This article also applies the process framework to a supply chain organization through a case study analysis to illustrate its strength in practice. Copyright © 2007 John Wiley &amp; Sons, Ltd.</jats:p>",https://doi.org/10.1002/spip.333,CrossRef,develop process framework use principle software engineering,jatstitleabstractjatstitlejatspin article present software process framework use theory principle software engineering vbse process framework serve process guide explain critical interaction five theory theory software engineering article also apply process framework supply chain organization case study analysis illustrate strength practice copyright john wiley amp son ltdjatsp,develop process framework use principle software engineering jatstitleabstractjatstitlejatspin article present software process framework use theory principle software engineering vbse process framework serve process guide explain critical interaction five theory theory software engineering article also apply process framework supply chain organization case study analysis illustrate strength practice copyright john wiley amp son ltdjatsp,0.6888888888888889,0.08888888888888889,0.08888888888888889,0.022222222222222223,45.0,1.0,0.0,0.0,1.0
Computer Science,Software Engineering Principles,Qualitative,Research Dojo,"<jats:p>This report summarizes key findings from a workshop held at the 14th International Conference on Agile Software Development (XP2013) called ""Research Dojo: Collaborative Approaches for our Agile Community"".</jats:p>
          <jats:p>Both software development and research are knowledge-intensive endeavors. While agile approaches have been increasingly adopted in software development projects, whether such approaches can beneficially be applied to conducting research is a phenomenon yet to be fully explored.</jats:p>
          <jats:p>The objective of the workshop was to gain a deeper understanding of the similarities and differences between academic research and agile software development, in order to explore whether agile practices can also be used for collaboratively conducted research. The opinions of the workshop participants are summarized and observations of the research dojo session carried out by the participants are reported. We conclude by identifying further areas for investigation.</jats:p>",https://doi.org/10.1145/2507288.2507324,CrossRef,research dojo,jatspthis report summarize key finding workshop hold international conference agile software development call research dojo collaborative approach agile communityjatsp jatspboth software development research knowledgeintensive endeavor agile approach increasingly adopt software development project whether approach beneficially apply conduct research phenomenon yet fully exploredjatsp jatspthe objective workshop gain deep understanding similarity difference academic research agile software development order explore whether agile practice also use collaboratively conduct research opinion workshop participant summarize observation research dojo session carry participant report conclude identify area investigationjatsp,research dojo jatspthis report summarize key finding workshop hold international conference agile software development call research dojo collaborative approach agile communityjatsp jatspboth software development research knowledgeintensive endeavor agile approach increasingly adopt software development project whether approach beneficially apply conduct research phenomenon yet fully exploredjatsp jatspthe objective workshop gain deep understanding similarity difference academic research agile software development order explore whether agile practice also use collaboratively conduct research opinion workshop participant summarize observation research dojo session carry participant report conclude identify area investigationjatsp,0.5125,0.15,0.175,0.0625,80.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Qualitative,"Review of ""Dr. Peeling's principles of management","<jats:p>For agent-based supply chain integration &amp; coordination (SCIC), agent architecture is the foundation and core content. In this paper, agent internal architecture and an infrastructure for SCIC are discussed in detail. For agent internal architecture, generic agent internal architecture reference is given and a concrete agent internal architecture for SCIC is put forward. For infrastructure, agent grid technology is introduced into SCIC. At the same time, agent grid technology and SCIC are bridged, and detail analysis is given. Finally, a case study is showed.</jats:p>",https://doi.org/10.1145/882240.882260,CrossRef,review peeling principle management,jatspfor agentbase supply chain integration amp coordination scic agent architecture foundation core content paper agent internal architecture infrastructure scic discuss detail agent internal architecture generic agent internal architecture reference give concrete agent internal architecture scic put forward infrastructure agent grid technology introduce scic time agent grid technology scic bridge detail analysis give finally case study showedjatsp,review peeling principle management jatspfor agentbase supply chain integration amp coordination scic agent architecture foundation core content paper agent internal architecture infrastructure scic discuss detail agent internal architecture generic agent internal architecture reference give concrete agent internal architecture scic put forward infrastructure agent grid technology introduce scic time agent grid technology scic bridge detail analysis give finally case study showedjatsp,0.5714285714285714,0.08928571428571429,0.10714285714285714,0.017857142857142856,56.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Qualitative,A Process for Monitoring the Impact of Architecture Principles on Sustainability: An Industrial Case Study,"<jats:p>Architecture principles affect a software system holistically. Given their alignment with a business strategy, they should be incorporated within the validation process covering aspects of sustainability. However, current research discusses the influence of architecture principles on sustainability in a limited context. Our objective was to introduce a reusable process for monitoring and evaluating the impact of architecture principles on sustainability from a software architecture perspective. We sought to demonstrate the application of such a process in professional practice. A qualitative case study was conducted in the context of a Dutch airport management company. Data collection involved a case analysis and the execution of two rounds of expert interviews. We (i) identified a set of case-related key performance indicators, (ii) utilized commonly accepted measurement tools, and (iii) employed graphical representations in the form of spider charts to monitor the sustainability impacts. The real-world observations were evaluated through a concluding focus group. Our findings indicated that architecture principles were a feasible mechanism with which to address sustainability across all different architecture layers within the enterprise. The experts considered the sustainability analysis valuable in guiding the software architecture process towards sustainability. With the emphasis on principles, we facilitate industry adoption by embedding sustainability in existing mechanisms.</jats:p>",https://doi.org/10.3390/software3010006,CrossRef,process monitor impact architecture principle sustainability industrial case study,jatsparchitecture principle affect software system holistically give alignment business strategy incorporate within validation process cover aspect sustainability however current research discuss influence architecture principle sustainability limited context objective introduce reusable process monitor evaluate impact architecture principle sustainability software architecture perspective seek demonstrate application process professional practice qualitative case study conduct context dutch airport management company datum collection involve case analysis execution two round expert interview identify set caserelated key performance indicator utilize commonly accept measurement tool iii employ graphical representation form spider chart monitor sustainability impact realworld observation evaluate conclude focus group finding indicate architecture principle feasible mechanism address sustainability across different architecture layer within enterprise expert consider sustainability analysis valuable guide software architecture process towards sustainability emphasis principle facilitate industry adoption embed sustainability exist mechanismsjatsp,process monitor impact architecture principle sustainability industrial case study jatsparchitecture principle affect software system holistically give alignment business strategy incorporate within validation process cover aspect sustainability however current research discuss influence architecture principle sustainability limited context objective introduce reusable process monitor evaluate impact architecture principle sustainability software architecture perspective seek demonstrate application process professional practice qualitative case study conduct context dutch airport management company datum collection involve case analysis execution two round expert interview identify set caserelated key performance indicator utilize commonly accept measurement tool iii employ graphical representation form spider chart monitor sustainability impact realworld observation evaluate conclude focus group finding indicate architecture principle feasible mechanism address sustainability across different architecture layer within enterprise expert consider sustainability analysis valuable guide software architecture process towards sustainability emphasis principle facilitate industry adoption embed sustainability exist mechanismsjatsp,0.6349206349206349,0.14285714285714285,0.10317460317460317,0.023809523809523808,126.0,1.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Qualitative,Morescient GAI for Software Engineering (Extended Version),"The ability of Generative AI (GAI) technology to automatically check,
synthesize and modify software engineering artifacts promises to revolutionize
all aspects of software engineering. Using GAI for software engineering tasks
is consequently one of the most rapidly expanding fields of software
engineering research, with over a hundred LLM-based code models having been
published since 2021. However, the overwhelming majority of existing code
models share a major weakness - they are exclusively trained on the syntactic
facet of software, significantly lowering their trustworthiness in tasks
dependent on software semantics. To address this problem, a new class of
""Morescient"" GAI is needed that is ""aware"" of (i.e., trained on) both the
semantic and static facets of software. This, in turn, will require a new
generation of software observation platforms capable of generating large
quantities of execution observations in a structured and readily analyzable
way. In this paper, we present a vision and roadmap for how such ""Morescient""
GAI models can be engineered, evolved and disseminated according to the
principles of open science.",http://arxiv.org/abs/2406.04710v2,arXiv,morescient gai software engineering extend version,ability generative gai technology automatically check synthesize modify software engineering artifact promise revolutionize aspect software engineering use gai software engineering task consequently one rapidly expand field software engineering research hundred llmbased code model publish since however overwhelming majority exist code model share major weakness exclusively train syntactic facet software significantly lower trustworthiness task dependent software semantic address problem new class morescient gai need aware train semantic static facet software turn require new generation software observation platform capable generate large quantity execution observation structured readily analyzable way paper present vision roadmap morescient gai model engineer evolve disseminate accord principle open science,morescient gai software engineering extend version ability generative gai technology automatically check synthesize modify software engineering artifact promise revolutionize aspect software engineering use gai software engineering task consequently one rapidly expand field software engineering research hundred llmbased code model publish since however overwhelming majority exist code model share major weakness exclusively train syntactic facet software significantly lower trustworthiness task dependent software semantic address problem new class morescient gai need aware train semantic static facet software turn require new generation software observation platform capable generate large quantity execution observation structured readily analyzable way paper present vision roadmap morescient gai model engineer evolve disseminate accord principle open science,0.54,0.12,0.19,0.07,100.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Mixed Methods,Probabilistic Software Modeling,"Software Engineering and the implementation of software has become a
challenging task as many tools, frameworks and languages must be orchestrated
into one functioning piece. This complexity increases the need for testing and
analysis methodologies that aid the developers and engineers as the software
grows and evolves. The amount of resources that companies budget for testing
and analysis is limited, highlighting the importance of automation for economic
software development. We propose Probabilistic Software Modeling, a new
paradigm for software modeling that builds on the fact that software is an
easy-to-monitor environment from which statistical models can be built.
Probabilistic Software Modeling provides increased comprehension for engineers
without changing the level of abstraction. The approach relies on the recursive
decomposition principle of object-oriented programming to build hierarchies of
probabilistic models that are fitted via observations collected at runtime of a
software system. This leads to a network of models that mirror the static
structure of the software system while modeling its dynamic runtime behavior.
The resulting models can be used in applications such as test-case generation,
anomaly and outlier detection, probabilistic program simulation, or state
predictions. Ideally, probabilistic software modeling allows the use of the
entire spectrum of statistical modeling and inference for software, enabling
in-depth analysis and generative procedures for software.",http://arxiv.org/abs/1806.08942v2,arXiv,probabilistic software modeling,software engineering implementation software become challenge task many tool framework language must orchestrate one function piece complexity increase need testing analysis methodology aid developer engineer software grow evolve amount resource company budget testing analysis limited highlight importance automation economic software development propose probabilistic software model new paradigm software modeling build fact software easytomonitor environment statistical model build probabilistic software modeling provide increase comprehension engineer without change level abstraction approach rely recursive decomposition principle objectoriented programming build hierarchy probabilistic model fit via observation collect runtime software system lead network model mirror static structure software system model dynamic runtime behavior result model use application testcase generation anomaly outli detection probabilistic program simulation state prediction ideally probabilistic software modeling allow use entire spectrum statistical modeling inference software enable indepth analysis generative procedure software,probabilistic software modeling software engineering implementation software become challenge task many tool framework language must orchestrate one function piece complexity increase need testing analysis methodology aid developer engineer software grow evolve amount resource company budget testing analysis limited highlight importance automation economic software development propose probabilistic software model new paradigm software modeling build fact software easytomonitor environment statistical model build probabilistic software modeling provide increase comprehension engineer without change level abstraction approach rely recursive decomposition principle objectoriented programming build hierarchy probabilistic model fit via observation collect runtime software system lead network model mirror static structure software system model dynamic runtime behavior result model use application testcase generation anomaly outli detection probabilistic program simulation state prediction ideally probabilistic software modeling allow use entire spectrum statistical modeling inference software enable indepth analysis generative procedure software,0.676923076923077,0.13846153846153847,0.11538461538461539,0.007692307692307693,130.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Mixed Methods,"Scaling Agile Development in Mechatronic Organizations - A Comparative
  Case Study","Agile software development principles enable companies to successfully and
quickly deliver software by meeting their customers' expectations while
focusing on high quality. Many companies working with pure software systems
have adopted these principles, but implementing them in companies dealing with
non-pure software products is challenging. We identified a set of goals and
practices to support large-scale agile development in companies that develop
software-intense mechatronic systems. We used an inductive approach based on
empirical data collected during a longitudinal study with six companies in the
Nordic region. The data collection took place over two years through focus
group workshops, individual on-site interviews, and complementary surveys. The
primary benefit of large-scale agile development is improved quality, enabled
by practices that support regular or continuous integration between teams
delivering software, hardware, and mechanics. In this regard, the most
beneficial integration cycle for deliveries is every four weeks; while
continuous integra- tion on a daily basis would favor software teams, other
disciplines does not seem to benefit from faster integration cycles. We
identified 108 goals and development practices supporting agile principles
among the companies, most of them concerned with integration; therefrom, 26
agile practices are unique to the mechatronics domain to support adopting agile
beyond pure software development teams. 16 of these practices are considered as
key enablers, confirmed by our control cases.",http://arxiv.org/abs/1703.00206v2,arXiv,scale agile development mechatronic organization comparative case study,agile software development principle enable company successfully quickly deliver software meet customer expectation focus high quality many company work pure software system adopt principle implement company deal nonpure software product challenge identify set goal practice support largescale agile development company develop softwareintense mechatronic system use inductive approach base empirical datum collect longitudinal study six company nordic region data collection take place two year focus group workshop individual onsite interview complementary survey primary benefit largescale agile development improve quality enable practice support regular continuous integration team deliver software hardware mechanic regard beneficial integration cycle delivery every four week continuous integra tion daily basis would favor software team discipline seem benefit fast integration cycle identify goal development practice support agile principle among company concerned integration therefrom agile practice unique mechatronic domain support adopt agile beyond pure software development team practice consider key enabler confirm control case,scale agile development mechatronic organization comparative case study agile software development principle enable company successfully quickly deliver software meet customer expectation focus high quality many company work pure software system adopt principle implement company deal nonpure software product challenge identify set goal practice support largescale agile development company develop softwareintense mechatronic system use inductive approach base empirical datum collect longitudinal study six company nordic region data collection take place two year focus group workshop individual onsite interview complementary survey primary benefit largescale agile development improve quality enable practice support regular continuous integration team deliver software hardware mechanic regard beneficial integration cycle delivery every four week continuous integra tion daily basis would favor software team discipline seem benefit fast integration cycle identify goal development practice support agile principle among company concerned integration therefrom agile practice unique mechatronic domain support adopt agile beyond pure software development team practice consider key enabler confirm control case,0.5416666666666666,0.1527777777777778,0.20833333333333334,0.013888888888888888,144.0,0.0,0.0,3.0,0.0
Computer Science,Software Engineering Principles,Mixed Methods,"Guiding Principles for Using Mixed Methods Research in Software
  Engineering","Mixed methods research is often used in software engineering, but researchers
outside of the social or human sciences often lack experience when using these
designs. This paper provides guiding principles and advice on how to design
mixed method research, and to encourage the intentional, rigorous, and
innovative application of mixed methods in software engineering. It also
presents key properties of core mixed method research designs. Through a number
of fictitious but recognizable software engineering research scenarios, we
showcase how to choose suitable designs and consider the inevitable trade-offs
any design choice leads to. We describe several antipatterns that illustrate
what to avoid in mixed method research, and when mixed method research should
be considered over other approaches.",http://arxiv.org/abs/2404.06011v4,arXiv,guide principle use mixed method research software engineering,mixed method research often use software engineering researcher outside social human science often lack experience use design paper provide guide principle advice design mix method research encourage intentional rigorous innovative application mixed method software engineer also present key property core mixed method research design number fictitious recognizable software engineering research scenario showcase choose suitable design consider inevitable tradeoff design choice lead describe several antipattern illustrate avoid mixed method research mixed method research consider approach,guide principle use mixed method research software engineering mixed method research often use software engineering researcher outside social human science often lack experience use design paper provide guide principle advice design mix method research encourage intentional rigorous innovative application mixed method software engineer also present key property core mixed method research design number fictitious recognizable software engineering research scenario showcase choose suitable design consider inevitable tradeoff design choice lead describe several antipattern illustrate avoid mixed method research mixed method research consider approach,0.527027027027027,0.16216216216216217,0.21621621621621623,0.04054054054054054,74.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Mixed Methods,"A sustainable infrastructure concept for improved accessibility,
  reusability, and archival of research software","Research software is an integral part of most research today and it is widely
accepted that research software artifacts should be accessible and
reproducible. However, the sustainable archival of research software artifacts
is an ongoing effort. We identify research software artifacts as snapshots of
the current state of research and an integral part of a sustainable cycle of
software development, research, and publication. We develop requirements and
recommendations to improve the archival, access, and reuse of research software
artifacts based on installable, configurable, extensible research software, and
sustainable public open-access infrastructure. The described goal is to enable
the reuse and exploration of research software beyond published research
results, in parallel with reproducibility efforts, and in line with the FAIR
principles for data and software. Research software artifacts can be reused in
varying scenarios. To this end, we design a multi-modal representation concept
supporting multiple reuse scenarios. We identify types of research software
artifacts that can be viewed as different modes of the same software-based
research result, for example, installation-free configurable browser-based apps
to containerized environments, descriptions in journal publications and
software documentation, or source code with installation instructions. We
discuss how the sustainability and reuse of research software are enhanced or
enabled by a suitable archive infrastructure. Finally, at the example of a
pilot project at the University of Stuttgart, Germany -- a collaborative effort
between research software developers and infrastructure providers -- we outline
practical challenges and experiences",http://arxiv.org/abs/2301.12830v1,arXiv,sustainable infrastructure concept improved accessibility reusability archival research software,research software integral part research today widely accept research software artifact accessible reproducible however sustainable archival research software artifact ongoing effort identify research software artifact snapshot current state research integral part sustainable cycle software development research publication develop requirement recommendation improve archival access reuse research software artifact base installable configurable extensible research software sustainable public openaccess infrastructure describe goal enable reuse exploration research software beyond publish research result parallel reproducibility effort line fair principle datum software research software artifact reuse vary scenario end design multimodal representation concept support multiple reuse scenario identify type research software artifact view different mode softwarebase research result example installationfree configurable browserbase app containerized environment description journal publication software documentation source code installation instruction discuss sustainability reuse research software enhance enable suitable archive infrastructure finally example pilot project university stuttgart germany collaborative effort research software developer infrastructure provider outline practical challenge experience,sustainable infrastructure concept improved accessibility reusability archival research software research software integral part research today widely accept research software artifact accessible reproducible however sustainable archival research software artifact ongoing effort identify research software artifact snapshot current state research integral part sustainable cycle software development research publication develop requirement recommendation improve archival access reuse research software artifact base installable configurable extensible research software sustainable public openaccess infrastructure describe goal enable reuse exploration research software beyond publish research result parallel reproducibility effort line fair principle datum software research software artifact reuse vary scenario end design multimodal representation concept support multiple reuse scenario identify type research software artifact view different mode softwarebase research result example installationfree configurable browserbase app containerized environment description journal publication software documentation source code installation instruction discuss sustainability reuse research software enhance enable suitable archive infrastructure finally example pilot project university stuttgart germany collaborative effort research software developer infrastructure provider outline practical challenge experience,0.6575342465753424,0.07534246575342465,0.1643835616438356,0.02054794520547945,146.0,0.0,1.0,1.0,0.0
Computer Science,Software Engineering Principles,Mixed Methods,Measuring Object-Oriented Design Principles,"The idea of automatizing the assessment of objectoriented design is not new.
Different approaches define and apply their own quality models, which are
composed of single metrics or combinations thereof, to operationalize software
design. However, single metrics are too fine-grained to identify core design
flaws and they cannot provide hints for making design improvements. In order to
deal with these weaknesses of metric-based models, rules-based approaches have
proven successful in the realm of source-code quality. Moreover, for developing
a well-designed software system, design principles play a key role, as they
define fundamental guidelines and help to avoid pitfalls. Therefore, this
thesis will enhance and complete a rule-based quality reference model for
operationalizing design principles and will provide a measuring tool that
implements these rules. The validation of the design quality model and the
measurement tool will be based on various industrial projects. Additionally,
quantitative and qualitative surveys will be conducted in order to get
validated results on the value of object-oriented design principles for
software development",http://arxiv.org/abs/1602.07127v1,arXiv,measure objectoriented design principle,idea automatize assessment objectoriented design new different approach define apply quality model compose single metric combination thereof operationalize software design however single metric finegrained identify core design flaw provide hint make design improvement order deal weakness metricbased model rulesbase approach prove successful realm sourcecode quality moreover develop welldesigned software system design principle play key role define fundamental guideline help avoid pitfall therefore thesis enhance complete rulebase quality reference model operationalizing design principle provide measuring tool implement rule validation design quality model measurement tool base various industrial project additionally quantitative qualitative survey conduct order get validate result value objectoriented design principle software development,measure objectoriented design principle idea automatize assessment objectoriented design new different approach define apply quality model compose single metric combination thereof operationalize software design however single metric finegrained identify core design flaw provide hint make design improvement order deal weakness metricbased model rulesbase approach prove successful realm sourcecode quality moreover develop welldesigned software system design principle play key role define fundamental guideline help avoid pitfall therefore thesis enhance complete rulebase quality reference model operationalizing design principle provide measuring tool implement rule validation design quality model measurement tool base various industrial project additionally quantitative qualitative survey conduct order get validate result value objectoriented design principle software development,0.6078431372549019,0.16666666666666666,0.17647058823529413,0.0392156862745098,102.0,1.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Design and Development,Identify Compliance During Software Development Using System Engineering Principles,"<jats:p>Errors made during the requirements collection and analysis phase make it very difficult to maintain the software product and cost the company extra costs. The difficulty of directly collecting requirements from stakeholders is due to inconsistencies between the major stakeholder groups, as well as related factors in the collection of requirements itself, as well as the selected methodology for the process of converting stakeholder requirements into development requirements. As a solution, it is necessary to use a high level of prioritization in order to distinguish among many requirements the necessary for successful implementation of the product, as well as to correctly allocate compliance with the requirements in such a way that each group of stakeholders is satisfied, but at the same time setting the goals of the supersystem more priority  than the goals of the subsystem. This article discusses the methodology of system engineering to solve issues related to the identification of possible contradictions of requirements.
Keywords: System engineering, requirements engineering, business process, requirements, software product, analysis.</jats:p>",https://doi.org/10.18502/keg.v5i3.6765,CrossRef,identify compliance software development use system engineering principle,jatsperror make requirement collection analysis phase make difficult maintain software product cost company extra cost difficulty directly collect requirement stakeholder due inconsistency major stakeholder group well relate factor collection requirement well select methodology process convert stakeholder requirement development requirement solution necessary use high level prioritization order distinguish among many requirement necessary successful implementation product well correctly allocate compliance requirement way group stakeholder satisfied time set goal supersystem priority goal subsystem article discuss methodology system engineering solve issue relate identification possible contradiction requirement keyword system engineering requirement engineering business process requirement software product analysisjatsp,identify compliance software development use system engineering principle jatsperror make requirement collection analysis phase make difficult maintain software product cost company extra cost difficulty directly collect requirement stakeholder due inconsistency major stakeholder group well relate factor collection requirement well select methodology process convert stakeholder requirement development requirement solution necessary use high level prioritization order distinguish among many requirement necessary successful implementation product well correctly allocate compliance requirement way group stakeholder satisfied time set goal supersystem priority goal subsystem article discuss methodology system engineering solve issue relate identification possible contradiction requirement keyword system engineering requirement engineering business process requirement software product analysisjatsp,0.6451612903225806,0.11827956989247312,0.16129032258064516,0.03225806451612903,93.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Design and Development,Fundamental Principles of Cybersecurity in The Software Testing Process,"<jats:p>The study examines the principles of ensuring cybersecurity during software testing. The focus is placed on the fact that testing should not be limited to validation checks but must also incorporate risk assessment, compliance with standards, and early-stage vulnerability analysis throughout the software development lifecycle. The study reviews key regulatory requirements (GDPR, HIPAA, PCI DSS, ISO/IEC 27001, NIST Cybersecurity Framework) and analyzes their impact on testing strategies and quality control processes. Special attention is given to the CIA triad (confidentiality, integrity, and availability) and proactive incident planning. The necessity of integrating automated tools (SAST/DAST, SIEM, RPA, etc.) and artificial intelligence algorithms is substantiated to optimize protection procedures and enhance vulnerability detection efficiency. The conclusions emphasize that achieving a high level of product resilience is only possible through the close alignment of security requirements with test scenarios and the continuous refinement of testing methodologies. The findings presented in this study will be of interest to researchers and professionals in information security, software testing specialists, and developers seeking to integrate advanced methods into the protection of information assets.</jats:p>",https://doi.org/10.37547/tajet/volume07issue04-14,CrossRef,fundamental principle cybersecurity software testing process,jatspthe study examine principle ensure cybersecurity software test focus place fact testing limit validation check must also incorporate risk assessment compliance standard earlystage vulnerability analysis throughout software development lifecycle study review key regulatory requirement gdpr hipaa pci dss isoiec nist cybersecurity framework analyze impact testing strategy quality control process special attention give cia triad confidentiality integrity availability proactive incident plan necessity integrate automate tool sastdast siem rpa etc artificial intelligence algorithm substantiate optimize protection procedure enhance vulnerability detection efficiency conclusion emphasize achieve high level product resilience possible close alignment security requirement test scenario continuous refinement testing methodology finding present study interest researcher professional information security software testing specialist developer seek integrate advanced method protection information assetsjatsp,fundamental principle cybersecurity software testing process jatspthe study examine principle ensure cybersecurity software test focus place fact testing limit validation check must also incorporate risk assessment compliance standard earlystage vulnerability analysis throughout software development lifecycle study review key regulatory requirement gdpr hipaa pci dss isoiec nist cybersecurity framework analyze impact testing strategy quality control process special attention give cia triad confidentiality integrity availability proactive incident plan necessity integrate automate tool sastdast siem rpa etc artificial intelligence algorithm substantiate optimize protection procedure enhance vulnerability detection efficiency conclusion emphasize achieve high level product resilience possible close alignment security requirement test scenario continuous refinement testing methodology finding present study interest researcher professional information security software testing specialist developer seek integrate advanced method protection information assetsjatsp,0.6379310344827587,0.09482758620689655,0.13793103448275862,0.008620689655172414,116.0,2.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Design and Development,SOLID Principles: Enhancing Maintainability and Scalability in Software Development,"<jats:p>In software development, achieving maintainability and scalability is critical for building robust and future-proof
applications. The SOLID principles, a set of five design guidelines introduced by Robert C. Martin, serve as a
cornerstone for object-oriented design, addressing common challenges in software architecture. This paper explores
the SOLID principles, their significance, and their practical application in enhancing software quality. Real-world
examples and case studies illustrate how adhering to these principles leads to scalable, maintainable, and flexible
software systems.</jats:p>",https://doi.org/10.55041/ijsrem10895,CrossRef,solid principle enhance maintainability scalability software development,jatspin software development achieve maintainability scalability critical build robust futureproof application solid principle set five design guideline introduce robert martin serve cornerstone objectoriented design address common challenge software architecture paper explore solid principle significance practical application enhance software quality realworld example case study illustrate adhere principle lead scalable maintainable flexible software systemsjatsp,solid principle enhance maintainability scalability software development jatspin software development achieve maintainability scalability critical build robust futureproof application solid principle set five design guideline introduce robert martin serve cornerstone objectoriented design address common challenge software architecture paper explore solid principle significance practical application enhance software quality realworld example case study illustrate adhere principle lead scalable maintainable flexible software systemsjatsp,0.5,0.1346153846153846,0.21153846153846154,0.019230769230769232,52.0,1.0,0.0,0.0,1.0
Computer Science,Software Engineering Principles,Design and Development,Separability Principles for a General Theory of Software Engineering,"<jats:p>
            The four GTSE (General Theory of Software Engineering) Workshops have brought awareness to, more or less mature, differing approaches, candidate theories for SE (Software Engineering). But one asks how to appraise the generality of these theories? And in case they are specialized sub-theories, are they amenable to combination into more general theories? The papers of the fourth GTSE Workshop addressed these questions by means of what can be collectively refer to as
            <jats:italic>Separability Principles</jats:italic>
            . In a sense, participants used well known techniques applied to design software systems to design SE theories. Separability is a powerful tool for understanding relations among SE candidate theories and guide how to assemble sub-theories into a general framework. Participants enthusiastically debated a series of related issues. The specialized vs. general theories questions were raised in diverse forms, such as, SE meaning multiple things, good predictive theories for narrow problems, ability of General theories to generate specific theories, and last but not least, whether ""General"" capture the contents of the workshop itself. The 4th GTSE edition was collocated with ICSE 2015 (International Conference of Software Engineering) in Firenze, Italy
          </jats:p>",https://doi.org/10.1145/2853073.2853093,CrossRef,separability principle general theory software engineering,jatsp four gtse general theory software engineering workshop bring awareness less mature differ approach candidate theory software engineering one ask appraise generality theory case specialized subtheorie amenable combination general theory paper fourth gtse workshop address question mean collectively refer jatsitalicseparability principlesjatsitalic sense participant use well know technique apply design software system design theory separability powerful tool understand relation among candidate theory guide assemble subtheorie general framework participant enthusiastically debate series related issue specialized general theory question raise diverse form mean multiple thing good predictive theory narrow problem ability general theory generate specific theory last least whether general capture content workshop gtse edition collocate icse international conference software engineering firenze italy jatsp,separability principle general theory software engineering jatsp four gtse general theory software engineering workshop bring awareness less mature differ approach candidate theory software engineering one ask appraise generality theory case specialized subtheorie amenable combination general theory paper fourth gtse workshop address question mean collectively refer jatsitalicseparability principlesjatsitalic sense participant use well know technique apply design software system design theory separability powerful tool understand relation among candidate theory guide assemble subtheorie general framework participant enthusiastically debate series related issue specialized general theory question raise diverse form mean multiple thing good predictive theory narrow problem ability general theory generate specific theory last least whether general capture content workshop gtse edition collocate icse international conference software engineering firenze italy jatsp,0.4954954954954955,0.12612612612612611,0.17117117117117117,0.04504504504504504,111.0,1.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Design and Development,Optimization design of electronic commerce system based on the basic principles of software engineering,"<jats:p>Based on the basic principles of software engineering, this paper optimizes the design of e-commerce system from the aspects of demand analysis, system design, coding, implementation, testing and maintenance. Specifically, this paper adopts the object-oriented software development method, using the UML modeling tools to model the system, adopted the MVC architecture mode to realize the stratification of the system, using the front-end technology such as HTML, CSS, JavaScript to realize the user interface design of the system, combined with the back-end technology such as Java, JSP, the Servlet system. Through the system test and the use of code quality control tools, the system is accepted, and the maintenance of the system is planned and designed. Finally, this paper realizes an easy-to-use, stable, safe and efficient e-commerce system.</jats:p>",https://doi.org/10.56028/aemr.6.1.403.2023,CrossRef,optimization design electronic commerce system base basic principle software engineering,jatspbase basic principle software engineer paper optimize design ecommerce system aspect demand analysis system design code implementation testing maintenance specifically paper adopt objectoriented software development method use uml modeling tool model system adopt mvc architecture mode realize stratification system use frontend technology html css javascript realize user interface design system combine backend technology java jsp servlet system system test use code quality control tool system accept maintenance system plan design finally paper realize easytouse stable safe efficient ecommerce systemjatsp,optimization design electronic commerce system base basic principle software engineering jatspbase basic principle software engineer paper optimize design ecommerce system aspect demand analysis system design code implementation testing maintenance specifically paper adopt objectoriented software development method use uml modeling tool model system adopt mvc architecture mode realize stratification system use frontend technology html css javascript realize user interface design system combine backend technology java jsp servlet system system test use code quality control tool system accept maintenance system plan design finally paper realize easytouse stable safe efficient ecommerce systemjatsp,0.6582278481012658,0.1518987341772152,0.0759493670886076,0.0379746835443038,79.0,0.0,0.0,0.0,1.0
Computer Science,Software Engineering Principles,Theoretical / Conceptual,Principles for software environments,<jats:p>A large number of software development support environments have been developed during the last few years. Many more are being developed now. This paper presents some principles which should be followed in the development and evolution of such an environment. Stress is placed on the idea that an environment evolves and that the ultimate success or failure of the environment depends on its evolution more than on its initial appearance.</jats:p>,https://doi.org/10.1145/1005968.1005975,CrossRef,principle software environment,jatspa large number software development support environment develop last year many develop paper present principle follow development evolution environment stress place idea environment evolve ultimate success failure environment depend evolution initial appearancejatsp,principle software environment jatspa large number software development support environment develop last year many develop paper present principle follow development evolution environment stress place idea environment evolve ultimate success failure environment depend evolution initial appearancejatsp,0.59375,0.125,0.1875,0.03125,32.0,0.0,0.0,1.0,0.0
Computer Science,Software Engineering Principles,Theoretical / Conceptual,Principles of Software Engineering and their Applications,"<jats:p>Software engineering lacks maturity compared to other engineering disciplines. The research goal of this thesis is to contribute to the software engineering discipline from an engineering perspective, through the identification of software engineering fundamental principles and the description of operational guidelines for these engineering fundamental principles. This research study on the set of candidate fundamental principles will contribute to a better understanding and possibly from an engineering perspective.</jats:p>",https://doi.org/10.4028/www.scientific.net/amm.170-173.3468,CrossRef,principle software engineering application,jatspsoftware engineering lack maturity compare engineering discipline research goal thesis contribute software engineering discipline engineering perspective identification software engineer fundamental principle description operational guideline engineering fundamental principle research study set candidate fundamental principle contribute well understanding possibly engineering perspectivejatsp,principle software engineering application jatspsoftware engineering lack maturity compare engineering discipline research goal thesis contribute software engineering discipline engineering perspective identification software engineer fundamental principle description operational guideline engineering fundamental principle research study set candidate fundamental principle contribute well understanding possibly engineering perspectivejatsp,0.6923076923076923,0.1282051282051282,0.10256410256410256,0.02564102564102564,39.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Theoretical / Conceptual,"Using a Class-Wide, Semester-Long Project to Teach Software Engineering Principles","<jats:title>Abstract</jats:title><jats:p>A senior-level, project-based Software Engineering course taught at the University of Central Arkansas serves as the capstone course for the Computer Science Program and introduces students to the theory, tools, and techniques used to build large-scale software systems in a project-driven setting. Foundational to the course is the use of a class-wide, semesterlong course project to emphasize the theoretical aspects of the software process and the system used for scoring student performance on the project. One project is selected for the entire class with students divided into teams of four to six students to support different functional requirement areas. A milestone-driven approach is used following a modified version of the Unified Process for project development. Student scores on the project are divided into a group score, assignable via a rubric-like grade sheet, and an individual score which is determined by the individual’s effort as assigned using the task-management tool, Issue-Tracker. Experiences gained and lessons learned in teaching the course are provided as a guide for those wishing to follow a similar approach to teaching Software Engineering in the future.</jats:p>",https://doi.org/10.7603/s40601-013-0032-y,CrossRef,use classwide semesterlong project teach software engineering principle,jatstitleabstractjatstitlejatspa seniorlevel projectbase software engineering course teach university central arkansas serve capstone course computer science program introduce student theory tool technique use build largescale software system projectdriven setting foundational course use classwide semesterlong course project emphasize theoretical aspect software process system use score student performance project one project select entire class student divide team four six student support different functional requirement area milestonedriven approach use follow modify version unified process project development student score project divide group score assignable via rubriclike grade sheet individual score determine individual effort assign use taskmanagement tool issuetracker experience gain lesson learn teach course provide guide wish follow similar approach teach software engineering futurejatsp,use classwide semesterlong project teach software engineering principle jatstitleabstractjatstitlejatspa seniorlevel projectbase software engineering course teach university central arkansas serve capstone course computer science program introduce student theory tool technique use build largescale software system projectdriven setting foundational course use classwide semesterlong course project emphasize theoretical aspect software process system use score student performance project one project select entire class student divide team four six student support different functional requirement area milestonedriven approach use follow modify version unified process project development student score project divide group score assignable via rubriclike grade sheet individual score determine individual effort assign use taskmanagement tool issuetracker experience gain lesson learn teach course provide guide wish follow similar approach teach software engineering futurejatsp,0.6238532110091743,0.13761467889908258,0.14678899082568808,0.009174311926605505,109.0,0.0,2.0,0.0,0.0
Computer Science,Software Engineering Principles,Theoretical / Conceptual,Report of the 2nd international workshop on principles of engineering service-oriented systems (PESOS 2010),"<jats:p>The Second International Workshop on Principles of Engineering Service-Oriented Systems (PESOS 2010) was held at the International Conference on Software Engineering, ICSE 2010 on May 1 and 2, 2010. PESOS 2010 provided a forum for presenting and discussing current work and research topics related to serviceoriented systems. The workshop had keynotes on SOA testing challenges and adaptive service-oriented systems. There were four paper sessions on the topics of service development, testing and evolution of service-oriented systems, service adaptation, and quality of service (QoS) and Service-Level Agreements (SLAs) in service-oriented environments. General discussions focused on these overall themes. These discussions resulted in the identification of research challenges for the future.</jats:p>",https://doi.org/10.1145/1838687.1838694,CrossRef,report international workshop principle engineering serviceoriente system peso,jatspthe second international workshop principle engineering serviceoriente system peso hold international conference software engineer icse may peso provide forum present discuss current work research topic relate serviceoriente system workshop keynote soa testing challenge adaptive serviceoriente system four paper session topic service development testing evolution serviceoriente system service adaptation quality service qos servicelevel agreement sla serviceoriente environment general discussion focus overall theme discussion result identification research challenge futurejatsp,report international workshop principle engineering serviceoriente system peso jatspthe second international workshop principle engineering serviceoriente system peso hold international conference software engineer icse may peso provide forum present discuss current work research topic relate serviceoriente system workshop keynote soa testing challenge adaptive serviceoriente system four paper session topic service development testing evolution serviceoriente system service adaptation quality service qos servicelevel agreement sla serviceoriente environment general discussion focus overall theme discussion result identification research challenge futurejatsp,0.6417910447761194,0.05970149253731343,0.1044776119402985,0.0,67.0,0.0,0.0,0.0,0.0
Computer Science,Software Engineering Principles,Theoretical / Conceptual,Software engineering research versus software development,"<jats:p>
            Engineering research differs greatly, both in its aims and in its methods, from traditional ""scientific"" research. While Sciences deal with the study of existing objects and phenomena, be it physically, metaphysically or conceptually, Engineering is based on
            <jats:italic>how</jats:italic>
            to do things,
            <jats:italic>how</jats:italic>
            to create new objects. For this reason, ""scientific"" research methods are not always directly applicable to research problems of an engineering nature.In the present article, we concentrate on the problems and research methods of a specific branch of engineering: Software Engineering, discussing, on the one hand, the nature of the method in this field while and, on the other, the similarity of the methods of research in Software Engineering and those of software development.
          </jats:p>",https://doi.org/10.1145/1082983.1083005,CrossRef,software engineering research versus software development,jatsp engineering research differ greatly aim method traditional scientific research science deal study exist object phenomenon physically metaphysically conceptually engineering base jatsitalichowjatsitalic thing jatsitalichowjatsitalic create new object reason scientific research method always directly applicable research problem engineering naturein present article concentrate problem research method specific branch engineering software engineering discuss one hand nature method field similarity method research software engineering software development jatsp,software engineering research versus software development jatsp engineering research differ greatly aim method traditional scientific research science deal study exist object phenomenon physically metaphysically conceptually engineering base jatsitalichowjatsitalic thing jatsitalichowjatsitalic create new object reason scientific research method always directly applicable research problem engineering naturein present article concentrate problem research method specific branch engineering software engineering discuss one hand nature method field similarity method research software engineering software development jatsp,0.5873015873015873,0.1111111111111111,0.12698412698412698,0.1111111111111111,63.0,1.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Quantitative,A Study on Software Metrics and its Impact on Software Quality,"Software metrics offer a quantitative basis for predicting the software
development process. In this way, software quality can be improved very easily.
Software quality should be achieved to satisfy the customer with decreasing the
software cost and improve there liability of the software product. In this
research, we have discussed how the software metrics affect the quality of the
software and which stages of its development software metrics have applied. We
discussed the different software metrics and how these metrics have an impact
on software quality and reliability. These techniques have been used for
improving the quality of software and increase the revenue.",http://arxiv.org/abs/1905.12922v1,arXiv,study software metric impact software quality,software metric offer quantitative basis predict software development process way software quality improve easily software quality achieve satisfy customer decrease software cost improve liability software product research discuss software metric affect quality software stage development software metric apply discuss different software metric metric impact software quality reliability technique use improve quality software increase revenue,study software metric impact software quality software metric offer quantitative basis predict software development process way software quality improve easily software quality achieve satisfy customer decrease software cost improve liability software product research discuss software metric affect quality software stage development software metric apply discuss different software metric metric impact software quality reliability technique use improve quality software increase revenue,0.7037037037037037,0.14814814814814814,0.1111111111111111,0.018518518518518517,54.0,0.0,0.0,0.0,1.0
Software Engineering,Software Development Processes,Quantitative,"Toward a Better Understanding of How to Develop Software Under Stress -
  Drafting the Lines for Future Research","The software is often produced under significant time constraints. Our idea
is to understand the effects of various software development practices on the
performance of developers working in stressful environments, and identify the
best operating conditions for software developed under stressful conditions
collecting data through questionnaires, non-invasive software measurement tools
that can collect measurable data about software engineers and the software they
develop, without intervening their activities, and biophysical sensors and then
try to recreated also in different processes or key development practices such
conditions.",http://arxiv.org/abs/1804.09044v1,arXiv,toward well understanding develop software stress draft line future research,software often produce significant time constraint idea understand effect various software development practice performance developer work stressful environment identify good operating condition software develop stressful condition collect datum questionnaire noninvasive software measurement tool collect measurable datum software engineer software develop without intervene activity biophysical sensor try recreate also different process key development practice condition,toward well understanding develop software stress draft line future research software often produce significant time constraint idea understand effect various software development practice performance developer work stressful environment identify good operating condition software develop stressful condition collect datum questionnaire noninvasive software measurement tool collect measurable datum software engineer software develop without intervene activity biophysical sensor try recreate also different process key development practice condition,0.6111111111111112,0.14814814814814814,0.18518518518518517,0.037037037037037035,54.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Quantitative,Software Effort Estimation using parameter tuned Models,"Software estimation is one of the most important activities in the software
project. The software effort estimation is required in the early stages of
software life cycle. Project Failure is the major problem undergoing nowadays
as seen by software project managers. The imprecision of the estimation is the
reason for this problem. Assize of software size grows, it also makes a system
complex, thus difficult to accurately predict the cost of software development
process. The greatest pitfall of the software industry was the fast-changing
nature of software development which has made it difficult to develop
parametric models that yield high accuracy for software development in all
domains. We need the development of useful models that accurately predict the
cost of developing a software product. This study presents the novel analysis
of various regression models with hyperparameter tuning to get the effective
model. Nine different regression techniques are considered for model
development",http://arxiv.org/abs/2009.01660v1,arXiv,software effort estimation use parameter tune model,software estimation one important activity software project software effort estimation require early stage software life cycle project failure major problem undergo nowadays see software project manager imprecision estimation reason problem assize software size grow also make system complex thus difficult accurately predict cost software development process great pitfall software industry fastchanging nature software development make difficult develop parametric model yield high accuracy software development domain need development useful model accurately predict cost develop software product study present novel analysis various regression model hyperparameter tune get effective model nine different regression technique consider model development,software effort estimation use parameter tune model software estimation one important activity software project software effort estimation require early stage software life cycle project failure major problem undergo nowadays see software project manager imprecision estimation reason problem assize software size grow also make system complex thus difficult accurately predict cost software development process great pitfall software industry fastchanging nature software development make difficult develop parametric model yield high accuracy software development domain need development useful model accurately predict cost develop software product study present novel analysis various regression model hyperparameter tune get effective model nine different regression technique consider model development,0.6063829787234043,0.14893617021276595,0.13829787234042554,0.05319148936170213,94.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Quantitative,Testing Research Software: A Survey,"Background: Research software plays an important role in solving real-life
problems, empowering scientific innovations, and handling emergency situations.
Therefore, the correctness and trustworthiness of research software are of
absolute importance. Software testing is an important activity for identifying
problematic code and helping to produce high-quality software. However, testing
of research software is difficult due to the complexity of the underlying
science, relatively unknown results from scientific algorithms, and the culture
of the research software community. Aims: The goal of this paper is to better
understand current testing practices, identify challenges, and provide
recommendations on how to improve the testing process for research software
development. Method: We surveyed members of the research software developer
community to collect information regarding their knowledge about and use of
software testing in their projects. Results: We analysed 120 responses and
identified that even though research software developers report they have an
average level of knowledge about software testing, they still find it difficult
due to the numerous challenges involved. However, there are a number of ways,
such as proper training, that can improve the testing process for research
software. Conclusions: Testing can be challenging for any type of software.
This difficulty is especially present in the development of research software,
where software engineering activities are typically given less attention. To
produce trustworthy results from research software, there is a need for a
culture change so that testing is valued and teams devote appropriate effort to
writing and executing tests.",http://arxiv.org/abs/2205.15982v1,arXiv,test research software survey,background research software play important role solve reallife problem empower scientific innovation handle emergency situation therefore correctness trustworthiness research software absolute importance software testing important activity identify problematic code help produce highquality software however testing research software difficult due complexity underlie science relatively unknown result scientific algorithm culture research software community aim goal paper well understand current testing practice identify challenge provide recommendation improve testing process research software development method survey member research software developer community collect information regard knowledge use software testing project result analyse response identify even though research software developer report average level knowledge software testing still find difficult due numerous challenge involve however number way proper training improve testing process research software conclusion testing challenge type software difficulty especially present development research software software engineering activity typically give less attention produce trustworthy result research software need culture change testing value team devote appropriate effort write execute test,test research software survey background research software play important role solve reallife problem empower scientific innovation handle emergency situation therefore correctness trustworthiness research software absolute importance software testing important activity identify problematic code help produce highquality software however testing research software difficult due complexity underlie science relatively unknown result scientific algorithm culture research software community aim goal paper well understand current testing practice identify challenge provide recommendation improve testing process research software development method survey member research software developer community collect information regard knowledge use software testing project result analyse response identify even though research software developer report average level knowledge software testing still find difficult due numerous challenge involve however number way proper training improve testing process research software conclusion testing challenge type software difficulty especially present development research software software engineering activity typically give less attention produce trustworthy result research software need culture change testing value team devote appropriate effort write execute test,0.6357615894039735,0.152317880794702,0.12582781456953643,0.059602649006622516,151.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Quantitative,Challenges and issues in collaborative software developments,"The software development process has evolved with respect to the problems in
developing large and complex applications. There is a paradigm shift towards
collaborative development, which necessitates the need to evaluate this
approach. A number of tools are used for collaborative software development
(CSD) including social media and web 2.0 features. Collaborative development
facilities are provided by IDEs and project hosting websites. In this paper, we
present a survey of collaboratively developed projects and discuss challenges
and issues in CSD. We analyze various issues of communication, coordination,
support, lifecycle management and discuss their effect on software quality.",http://arxiv.org/abs/1904.00721v1,arXiv,challenge issue collaborative software development,software development process evolve respect problem develop large complex application paradigm shift towards collaborative development necessitate need evaluate approach number tool use collaborative software development csd include social medium web feature collaborative development facility provide ide project host website paper present survey collaboratively develop project discuss challenge issue csd analyze various issue communication coordination support lifecycle management discuss effect software quality,challenge issue collaborative software development software development process evolve respect problem develop large complex application paradigm shift towards collaborative development necessitate need evaluate approach number tool use collaborative software development csd include social medium web feature collaborative development facility provide ide project host website paper present survey collaboratively develop project discuss challenge issue csd analyze various issue communication coordination support lifecycle management discuss effect software quality,0.6885245901639344,0.14754098360655737,0.11475409836065574,0.01639344262295082,61.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Qualitative,"Secure Software Engineering in the Financial Services: A Practitioners'
  Perspective","Secure software engineering is a fundamental activity in modern software
development. However, while the field of security research has been advancing
quite fast, in practice, there is still a vast knowledge gap between the
security experts and the software development teams. After all, we cannot
expect developers and other software practitioners to be security experts.
Understanding how software development teams incorporate security in their
processes and the challenges they face is a step towards reducing this gap. In
this paper, we study how financial services companies ensure the security of
their software systems. To that aim, we performed a qualitative study based on
semi-structured interviews with 16 software practitioners from 11 different
financial companies in three continents. Our results shed light on the security
considerations that practitioners take during the different phases of their
software development processes, the different security practices that software
teams make use of to ensure the security of their software systems, the
improvements that practitioners perceive as important in existing
state-of-the-practice security tools, the different knowledge-sharing and
learning practices that developers use to learn more about software security,
and the challenges that software practitioners currently face when it comes to
secure their systems.",http://arxiv.org/abs/2104.03476v1,arXiv,secure software engineering financial service practitioner perspective,secure software engineering fundamental activity modern software development however field security research advance quite fast practice still vast knowledge gap security expert software development team expect developer software practitioner security expert understand software development team incorporate security process challenge face step towards reduce gap paper study financial service company ensure security software system aim perform qualitative study base semistructure interview software practitioner different financial company three continent result shed light security consideration practitioner take different phase software development process different security practice software team make use ensure security software system improvement practitioner perceive important exist stateofthepractice security tool different knowledgesharing learn practice developer use learn software security challenge software practitioner currently face come secure system,secure software engineering financial service practitioner perspective secure software engineering fundamental activity modern software development however field security research advance quite fast practice still vast knowledge gap security expert software development team expect developer software practitioner security expert understand software development team incorporate security process challenge face step towards reduce gap paper study financial service company ensure security software system aim perform qualitative study base semistructure interview software practitioner different financial company three continent result shed light security consideration practitioner take different phase software development process different security practice software team make use ensure security software system improvement practitioner perceive important exist stateofthepractice security tool different knowledgesharing learn practice developer use learn software security challenge software practitioner currently face come secure system,0.6434782608695652,0.14782608695652175,0.13043478260869565,0.034782608695652174,115.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Qualitative,"Guided Support for Collaborative Modeling, Enactment and Simulation of
  Software Development Processes","Recently, the awareness of the importance of distributed software development
has been growing in the software engineering community. Economic constraints,
more and more outsourcing of development activities, and the increasing spatial
distribution of companies come along with challenges of how to organize
distributed development.
  In this article, we reason that a common process understanding is mandatory
for successful distributed development. Integrated process planning, guidance
and enactment are seen as enabling technologies to reach a unique process view.
  We sketch a synthesis of the software process modeling environment SPEARMINT
and the XCHIPS system for web-based process support. Hereby, planners and
developers are provided with collaborative planning and enactment support and
advanced process guidance via electronic process guides (EPGs). We describe the
usage of this integrated environment by using a case study for the development
of a learning system.",http://arxiv.org/abs/1402.4280v1,arXiv,guide support collaborative modeling enactment simulation software development process,recently awareness importance distribute software development grow software engineering community economic constraint outsourcing development activity increase spatial distribution company come along challenge organize distribute development article reason common process understanding mandatory successful distribute development integrate process plan guidance enactment see enable technology reach unique process view sketch synthesis software process modeling environment spearmint xchips system webbase process support hereby planner developer provide collaborative planning enactment support advanced process guidance via electronic process guide epgs describe usage integrate environment use case study development learn system,guide support collaborative modeling enactment simulation software development process recently awareness importance distribute software development grow software engineering community economic constraint outsourcing development activity increase spatial distribution company come along challenge organize distribute development article reason common process understanding mandatory successful distribute development integrate process plan guidance enactment see enable technology reach unique process view sketch synthesis software process modeling environment spearmint xchips system webbase process support hereby planner developer provide collaborative planning enactment support advanced process guidance via electronic process guide epgs describe usage integrate environment use case study development learn system,0.6071428571428571,0.16666666666666666,0.16666666666666666,0.011904761904761904,84.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Qualitative,"LLMs' Reshaping of People, Processes, Products, and Society in Software
  Development: A Comprehensive Exploration with Early Adopters","Large language models (LLMs) like OpenAI ChatGPT, Google Gemini, and GitHub
Copilot are rapidly gaining traction in the software industry, but their full
impact on software engineering remains insufficiently explored. Despite their
growing adoption, there is a notable lack of formal, qualitative assessments of
how LLMs are applied in real-world software development contexts. To fill this
gap, we conducted semi-structured interviews with sixteen early-adopter
professional developers to explore their use of LLMs throughout various stages
of the software development life cycle. Our investigation examines four
dimensions: people - how LLMs affect individual developers and teams; process -
how LLMs alter software engineering workflows; product - LLM impact on software
quality and innovation; and society - the broader socioeconomic and ethical
implications of LLM adoption. Thematic analysis of our data reveals that while
LLMs have not fundamentally revolutionized the development process, they have
substantially enhanced routine coding tasks, including code generation,
refactoring, and debugging. Developers reported the most effective outcomes
when providing LLMs with clear, well-defined problem statements, indicating
that LLMs excel with decomposed problems and specific requirements.
Furthermore, these early-adopters identified that LLMs offer significant value
for personal and professional development, aiding in learning new languages and
concepts. Early-adopters, highly skilled in software engineering and how LLMs
work, identified early and persisting challenges for software engineering, such
as inaccuracies in generated content and the need for careful manual review
before integrating LLM outputs into production environments. Our study provides
a nuanced understanding of how LLMs are shaping the landscape of software
development, with their benefits, limitations, and ongoing implications.",http://arxiv.org/abs/2503.05012v1,arXiv,llm reshape people process product society software development comprehensive exploration early adopter,large language model llm like openai chatgpt google gemini github copilot rapidly gain traction software industry full impact software engineering remains insufficiently explore despite grow adoption notable lack formal qualitative assessment llm apply realworld software development context fill gap conduct semistructure interview sixteen earlyadopter professional developer explore use llm throughout various stage software development life cycle investigation examine four dimension people llm affect individual developer team process llm alter software engineering workflow product llm impact software quality innovation society broad socioeconomic ethical implication llm adoption thematic analysis datum reveal llm fundamentally revolutionize development process substantially enhance routine code task include code generation refactoring debug developer report effective outcome provide llm clear welldefine problem statement indicate llm excel decomposed problem specific requirement furthermore earlyadopter identify llm offer significant value personal professional development aid learn new language concept earlyadopter highly skilled software engineering llm work identify early persisting challenge software engineering inaccuracy generate content need careful manual review integrate llm output production environment study provide nuanced understanding llm shape landscape software development benefit limitation ongoing implication,llm reshape people process product society software development comprehensive exploration early adopter large language model llm like openai chatgpt google gemini github copilot rapidly gain traction software industry full impact software engineering remains insufficiently explore despite grow adoption notable lack formal qualitative assessment llm apply realworld software development context fill gap conduct semistructure interview sixteen earlyadopter professional developer explore use llm throughout various stage software development life cycle investigation examine four dimension people llm affect individual developer team process llm alter software engineering workflow product llm impact software quality innovation society broad socioeconomic ethical implication llm adoption thematic analysis datum reveal llm fundamentally revolutionize development process substantially enhance routine code task include code generation refactoring debug developer report effective outcome provide llm clear welldefine problem statement indicate llm excel decomposed problem specific requirement furthermore earlyadopter identify llm offer significant value personal professional development aid learn new language concept earlyadopter highly skilled software engineering llm work identify early persisting challenge software engineering inaccuracy generate content need careful manual review integrate llm output production environment study provide nuanced understanding llm shape landscape software development benefit limitation ongoing implication,0.5402298850574713,0.13218390804597702,0.14367816091954022,0.06321839080459771,87.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Qualitative,Software Development Processes in Ocean System Modeling,"Scientific modeling provides mathematical abstractions of real-world systems
and builds software as implementations of these mathematical abstractions.
Ocean science is a multidisciplinary discipline developing scientific models
and simulations as ocean system models that are an essential research asset.
  In software engineering and information systems research, modeling is also an
essential activity. In particular, business process modeling for business
process management and systems engineering is the activity of representing
processes of an enterprise, so that the current process may be analyzed,
improved, and automated.
  In this paper, we employ process modeling for analyzing scientific software
development in ocean science to advance the state in engineering of ocean
system models and to better understand how ocean system models are developed
and maintained in ocean science. We interviewed domain experts in
semi-structured interviews, analyzed the results via thematic analysis, and
modeled the results via the business process modeling notation BPMN.
  The processes modeled as a result describe an aspired state of software
development in the domain, which are often not (yet) implemented. This enables
existing processes in simulation-based system engineering to be improved with
the help of these process models.",http://arxiv.org/abs/2108.08589v1,arXiv,software development process ocean system modeling,scientific modeling provide mathematical abstraction realworld system build software implementation mathematical abstraction ocean science multidisciplinary discipline develop scientific model simulation ocean system model essential research asset software engineering information system research modeling also essential activity particular business process modeling business process management system engineering activity represent process enterprise current process may analyze improve automate paper employ process modeling analyze scientific software development ocean science advance state engineering ocean system model well understand ocean system model develop maintain ocean science interview domain expert semistructure interview analyze result via thematic analysis model result via business process model notation bpmn process model result describe aspired state software development domain often yet implement enable exist process simulationbase system engineering improve help process model,software development process ocean system modeling scientific modeling provide mathematical abstraction realworld system build software implementation mathematical abstraction ocean science multidisciplinary discipline develop scientific model simulation ocean system model essential research asset software engineering information system research modeling also essential activity particular business process modeling business process management system engineering activity represent process enterprise current process may analyze improve automate paper employ process modeling analyze scientific software development ocean science advance state engineering ocean system model well understand ocean system model develop maintain ocean science interview domain expert semistructure interview analyze result via thematic analysis model result via business process model notation bpmn process model result describe aspired state software development domain often yet implement enable exist process simulationbase system engineering improve help process model,0.6638655462184874,0.11764705882352941,0.1092436974789916,0.025210084033613446,119.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Qualitative,"Software Architecture Decision-Making Practices and Challenges: An
  Industrial Case Study","Software architecture decision-making is critical to the success of a
software system as software architecture sets the structure of the system,
determines its qualities, and has far-reaching consequences throughout the
system life cycle. The complex nature of the software development context and
the importance of the problem has led the research community to develop several
techniques, tools, and processes to assist software architects in making better
decisions. Despite these effort, the adoption of such systematic approaches
appears to be quite limited in practice. In addition, the practitioners are
also facing new challenges as different software development methods suggest
different approaches for architecture design. In this paper, we study the
current software architecture decision-making practices in the industry using a
case study conducted among professional software architects in three different
companies in Europe. As a result, we identified different software architecture
decision-making practices followed by the software teams as well as their
reasons for following them, the challenges associated with them, and the
possible improvements from the software architects' point of view. Based on
that, we recognized that improving software architecture knowledge management
can address most of the identified challenges and would result in better
software architecture decision-making.",http://arxiv.org/abs/1610.09240v1,arXiv,software architecture decisionmake practice challenge industrial case study,software architecture decisionmake critical success software system software architecture set structure system determine quality farreache consequence throughout system life cycle complex nature software development context importance problem lead research community develop several technique tool process assist software architect make well decision despite effort adoption systematic approach appear quite limited practice addition practitioner also face new challenge different software development method suggest different approach architecture design paper study current software architecture decisionmake practice industry use case study conduct among professional software architect three different company europe result identify different software architecture decisionmake practice follow software team well reason follow challenge associate possible improvement software architect point view base recognize improve software architecture knowledge management address identify challenge would result well software architecture decisionmake,software architecture decisionmake practice challenge industrial case study software architecture decisionmake critical success software system software architecture set structure system determine quality farreache consequence throughout system life cycle complex nature software development context importance problem lead research community develop several technique tool process assist software architect make well decision despite effort adoption systematic approach appear quite limited practice addition practitioner also face new challenge different software development method suggest different approach architecture design paper study current software architecture decisionmake practice industry use case study conduct among professional software architect three different company europe result identify different software architecture decisionmake practice follow software team well reason follow challenge associate possible improvement software architect point view base recognize improve software architecture knowledge management address identify challenge would result well software architecture decisionmake,0.6639344262295082,0.14754098360655737,0.10655737704918032,0.03278688524590164,122.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Mixed Methods,Impact of Artificial Intelligence on Software Development Processes,"<jats:p>The emergence of Artificial Intelligence (AI) has signified a fundamental transformation in software engineering methodologies. Conventional techniques, marked by significant manual involvement, are progressively being enhanced or supplanted by intelligent systems. Artificial intelligence technologies and frameworks streamline development, decrease expenses, and improve precision. Artificial Intelligence (AI) is revolutionizing software development by automating redundant jobs, improving decision-making, and optimizing procedures throughout all phases of development. This study examines the influence of AI on software development using qualitative and quantitative assessments, concentrating on phases such as requirement collecting, coding, testing, and deployment. This analysis employs topic and keyword methodologies to explore AI's contribution to enhancing efficiency, accuracy, and team cooperation, while also addressing integration problems and ethical implications. The study emphasizes the role of AI technologies in minimizing errors, enhancing project timeframes, and elevating overall software quality. These conclusions establish a basis for forthcoming research on AI's capacity to transform software engineering methodologies.</jats:p>",https://doi.org/10.52783/jisem.v10i25s.4039,CrossRef,impact artificial intelligence software development process,jatspthe emergence artificial intelligence signify fundamental transformation software engineering methodology conventional technique mark significant manual involvement progressively enhance supplant intelligent system artificial intelligence technology framework streamline development decrease expense improve precision artificial intelligence revolutionize software development automate redundant job improve decisionmake optimize procedure throughout phase development study examine influence software development use qualitative quantitative assessment concentrate phase requirement collect code testing deployment analysis employ topic keyword methodology explore ais contribution enhance efficiency accuracy team cooperation also address integration problem ethical implication study emphasize role technology minimize error enhance project timeframe elevate overall software quality conclusion establish basis forthcoming research ais capacity transform software engineering methodologiesjatsp,impact artificial intelligence software development process jatspthe emergence artificial intelligence signify fundamental transformation software engineering methodology conventional technique mark significant manual involvement progressively enhance supplant intelligent system artificial intelligence technology framework streamline development decrease expense improve precision artificial intelligence revolutionize software development automate redundant job improve decisionmake optimize procedure throughout phase development study examine influence software development use qualitative quantitative assessment concentrate phase requirement collect code testing deployment analysis employ topic keyword methodology explore ais contribution enhance efficiency accuracy team cooperation also address integration problem ethical implication study emphasize role technology minimize error enhance project timeframe elevate overall software quality conclusion establish basis forthcoming research ais capacity transform software engineering methodologiesjatsp,0.6095238095238096,0.14285714285714285,0.14285714285714285,0.02857142857142857,105.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Mixed Methods,Risk Management in Software Development Projects,"<p>Effective risk management contributes to the success of the software development project. The goal of this work was to identify risk management gaps, perspectives, the evolution of the theme and the study trends, in software development projects, using systematic literature review as a method. For the bibliometric analysis, articles referring to the topic were selected in the period from 2010 to 2018. As tools of analysis, Citespace and VOS Viewer software were used, allowing a comparative evaluation between the articles, as well as the analysis of clusters. Beyond content analysis of articles found. Gaps were identified for performance; team involvement; attention to failures; identification of tools for decision-making; and business strategy. In turn, perspectives were determined for research trends, such as the close relationship between business strategy, risk management and new management models. The research can propose new strategies and perspectives for risk management in software development and show their importance to the academic and practical spheres, demonstrating that the themes are complementary and important in the current technological and innovation sector.</p>",https://doi.org/10.4018/ijossp.2020010101,CrossRef,risk management software development project,peffective risk management contribute success software development project goal work identify risk management gap perspective evolution theme study trend software development project use systematic literature review method bibliometric analysis article refer topic select period tool analysis citespace vos viewer software use allow comparative evaluation article well analysis cluster beyond content analysis article find gap identify performance team involvement attention failure identification tool decisionmake business strategy turn perspective determine research trend close relationship business strategy risk management new management model research propose new strategy perspective risk management software development show importance academic practical sphere demonstrate theme complementary important current technological innovation sectorp,risk management software development project peffective risk management contribute success software development project goal work identify risk management gap perspective evolution theme study trend software development project use systematic literature review method bibliometric analysis article refer topic select period tool analysis citespace vos viewer software use allow comparative evaluation article well analysis cluster beyond content analysis article find gap identify performance team involvement attention failure identification tool decisionmake business strategy turn perspective determine research trend close relationship business strategy risk management new management model research propose new strategy perspective risk management software development show importance academic practical sphere demonstrate theme complementary important current technological innovation sectorp,0.7029702970297029,0.09900990099009901,0.13861386138613863,0.009900990099009901,101.0,1.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Mixed Methods,A business process modeling‐based approach to investigate complex processes,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>The purpose of this paper is to develop a new approach to investigate complex processes, such as software development processes, using business process modeling.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>The paper presents an investigation into the use of role activity diagramming (RAD) to model complex processes in the software industry sector, with reference to the process of TestWarehouse as a case study.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Systematic extension and quantitative analysis to RAD models led to the discovery of process bottlenecks, identification of cross functional boundary problems, and focused discussion about automation of processes.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p>Further work is required to validate and evaluate the proposed approach using several cases with different application domains and thus generalize the adopted approach.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>A new approach has been used successfully to understand and analyze business processes. The tools and techniques that are used to perform the approach are not complicated and do not need much specialist expertise, so the approach is not only oriented toward specialists but also toward organizations' managers and staff.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>New techniques have been developed by using process modelling to deepen the understanding and analyzing of complex organizational processes. This research implements a practical investigation which uses a case study to validate the new techniques.</jats:p></jats:sec>",https://doi.org/10.1108/14637151211215046,CrossRef,business process approach investigate complex process,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper develop new approach investigate complex process software development process use business process modelingjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe paper present investigation use role activity diagram rad model complex process software industry sector reference process testwarehouse case studyjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspsystematic extension quantitative analysis rad model lead discovery process bottleneck identification cross functional boundary problem focus discussion automation processesjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspfurther work require validate evaluate propose approach use several case different application domain thus generalize adopt approachjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspa new approach use successfully understand analyze business process tool technique use perform approach complicated need much specialist expertise approach orient toward specialist also toward organization manager staffjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspnew technique develop use process modelling deepen understanding analyzing complex organizational process research implement practical investigation use case study validate new techniquesjatspjatssec,business process approach investigate complex process jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper develop new approach investigate complex process software development process use business process modelingjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe paper present investigation use role activity diagram rad model complex process software industry sector reference process testwarehouse case studyjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspsystematic extension quantitative analysis rad model lead discovery process bottleneck identification cross functional boundary problem focus discussion automation processesjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspfurther work require validate evaluate propose approach use several case different application domain thus generalize adopt approachjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspa new approach use successfully understand analyze business process tool technique use perform approach complicated need much specialist expertise approach orient toward specialist also toward organization manager staffjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspnew technique develop use process modelling deepen understanding analyzing complex organizational process research implement practical investigation use case study validate new techniquesjatspjatssec,0.536,0.136,0.2,0.024,125.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Mixed Methods,Software development for implementing a model of porous structures based on three periodic surfaces,"<jats:p>Based on the original algorithm for generating three periodic surfaces implemented in the ToposPro information and analytical system, a mathematical model of a porous material was developed. The TPS Extractor software for the computer implementation of this model was developed. This software implements original algorithms for triangulation, translation, smoothing, and model solidifying. The developed triangulation algorithms were used to construct a set of three periodic surfaces, and models of the corresponding porous materials were built on their basis. Based on models of porous materials, a study of the performance of smoothing and translation algorithms was conducted. Using a solidifying algorithm for increasing the model thickness, models of porous material were created that are suitable for 3D printing. Also, samples of porous models were printed out using fused deposition modeling technology.</jats:p>",https://doi.org/10.18469/1810-3189.2022.25.1.71-79,CrossRef,software development implement model porous structure base three periodic surface,jatspbase original algorithm generate three periodic surface implement topospro information analytical system mathematical model porous material develop tps extractor software computer implementation model develop software implement original algorithm triangulation translation smoothing model solidify develop triangulation algorithm use construct set three periodic surface model correspond porous material build basis base model porous material study performance smoothing translation algorithm conduct use solidify algorithm increase model thickness model porous material create suitable print also sample porous model print use fused deposition modeling technologyjatsp,software development implement model porous structure base three periodic surface jatspbase original algorithm generate three periodic surface implement topospro information analytical system mathematical model porous material develop tps extractor software computer implementation model develop software implement original algorithm triangulation translation smoothing model solidify develop triangulation algorithm use construct set three periodic surface model correspond porous material build basis base model porous material study performance smoothing translation algorithm conduct use solidify algorithm increase model thickness model porous material create suitable print also sample porous model print use fused deposition modeling technologyjatsp,0.5375,0.175,0.175,0.0125,80.0,1.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Mixed Methods,FQMaP: Towards a framework quantitative management of processes in small software development organizations,"<jats:p>Software development organizations need to control and improve their practices, seeking to reduce variability when executing the necessary processes to elaborate software; therefore, these organizations implement improvement plans to identify factors that affect the processes. Quantitative Management deals with identification, tracing, and control of those incident factors, using data proactively to predict performance and the effect of possible changes in a process. Reference models in software processes development such as CMMI V2.0 and ISO/IEC 33061:2021 address Quantitative Management, but are aimed at big enterprises. Other models such as MoProSoft, COMPETISOFT, and MPS.BR are aimed at small enterprises, but do not include enough elements on Quantitative Management. Execution of a systematic literature review permitted searching for works on Quantitative Management intended for small software development enterprises, indicating necessary practices and how to perform them. This search showed that a proposal is not available that incorporates Quantitative Management practices for software processes aimed small software development enterprises. The referred aspects make it difficult to adopt a Quantitative Management culture within these organizations, it which has become a problem, consisting in that small software development enterprises that do not execute quantitative management practices will have difficulty identifying and focusing on the factors that impact the process performance and, therefore, on the results of their projects. This work sought to tackle this problem by proposing the “framework for quantitative management of processes in small software development organizations” (FQMaP), which allows incorporating practices and techniques that support Quantitative Management of software development processes in these kinds of enterprises. From the evaluation of FQMaP, carried out by following Focus Group technique guidelines, it can be demonstrated that it is a simple proposal and with elements that can serve a company to quantitatively manage software development processes. Also, it has clearly specified its components, showing that its structure is familiar with other process patterns, that would facilitate their interpretation.</jats:p>",https://doi.org/10.21533/pen.v11.i4.176,CrossRef,fqmap towards framework quantitative management process small software development organization,jatspsoftware development organization need control improve practice seek reduce variability execute necessary process elaborate software therefore organization implement improvement plan identify factor affect process quantitative management deal identification trace control incident factor use datum proactively predict performance effect possible change process reference model software process development cmmi isoiec address quantitative management aim big enterprise model moprosoft competisoft mpsbr aim small enterprise include enough element quantitative management execution systematic literature review permit search work quantitative management intend small software development enterprise indicate necessary practice perform search show proposal available incorporate quantitative management practice software process aim small software development enterprise refer aspect make difficult adopt quantitative management culture within organization become problem consist small software development enterprise execute quantitative management practice difficulty identify focus factor impact process performance therefore result project work seek tackle problem propose framework quantitative management process small software development organization fqmap allow incorporate practice technique support quantitative management software development process kind enterprise evaluation fqmap carry follow focus group technique guideline demonstrate simple proposal element serve company quantitatively manage software development process also clearly specify component show structure familiar process pattern would facilitate interpretationjatsp,fqmap towards framework quantitative management process small software development organization jatspsoftware development organization need control improve practice seek reduce variability execute necessary process elaborate software therefore organization implement improvement plan identify factor affect process quantitative management deal identification trace control incident factor use datum proactively predict performance effect possible change process reference model software process development cmmi isoiec address quantitative management aim big enterprise model moprosoft competisoft mpsbr aim small enterprise include enough element quantitative management execution systematic literature review permit search work quantitative management intend small software development enterprise indicate necessary practice perform search show proposal available incorporate quantitative management practice software process aim small software development enterprise refer aspect make difficult adopt quantitative management culture within organization become problem consist small software development enterprise execute quantitative management practice difficulty identify focus factor impact process performance therefore result project work seek tackle problem propose framework quantitative management process small software development organization fqmap allow incorporate practice technique support quantitative management software development process kind enterprise evaluation fqmap carry follow focus group technique guideline demonstrate simple proposal element serve company quantitatively manage software development process also clearly specify component show structure familiar process pattern would facilitate interpretationjatsp,0.5775401069518716,0.18716577540106952,0.13368983957219252,0.03208556149732621,187.0,2.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Design and Development,Some Long-Standing Quality Practices in Software Development,"The desire to build quality software systems has been the focus of most
software developers and researchers for decades. This has culminated in the
design of practices that promote quality in the designed software. Originating
from the inception of the traditional software development life cycle (SDLC),
through to the object-oriented methods, Iterative development, and now the
agile methods, these practices have persisted through different periods. Such
practices play the same quality role regardless of the perspective of the
software development process they are part of. In this paper we review three
software development methods representative of the software development
history, with the aim of i) identifying key quality practices, ii) identifying
the quality role played by the practice in the method, and iii) noting those
quality practices that have persisted through the software development history.
The identified quality practices that have persisted throughout the history of
the software development processes include prototyping, iterative development,
incremental development, risk-driven development, phase planning, and phase
retrospection. These results would be useful to method engineers who seek to
design high-quality software development methods as these practices serve as
candidates for inclusion in their development processes. Software development
practitioners seeking to design quality software would also benefit from
adopting these practices in developing their software.",http://arxiv.org/abs/2209.08348v1,arXiv,longstanding quality practice software development,desire build quality software system focus software developer researcher decade culminate design practice promote quality design software originate inception traditional software development life cycle sdlc objectoriented method iterative development agile method practice persist different period practice play quality role regardless perspective software development process part paper review three software development method representative software development history aim identify key quality practice identify quality role play practice method iii note quality practice persist software development history identify quality practice persist throughout history software development process include prototype iterative development incremental development riskdriven development phase planning phase retrospection result would useful method engineer seek design highquality software development method practice serve candidate inclusion development process software development practitioner seek design quality software would also benefit adopt practice develop software,longstanding quality practice software development desire build quality software system focus software developer researcher decade culminate design practice promote quality design software originate inception traditional software development life cycle sdlc objectoriented method iterative development agile method practice persist different period practice play quality role regardless perspective software development process part paper review three software development method representative software development history aim identify key quality practice identify quality role play practice method iii note quality practice persist software development history identify quality practice persist throughout history software development process include prototype iterative development incremental development riskdriven development phase planning phase retrospection result would useful method engineer seek design highquality software development method practice serve candidate inclusion development process software development practitioner seek design quality software would also benefit adopt practice develop software,0.6984126984126984,0.14285714285714285,0.05555555555555555,0.015873015873015872,126.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Design and Development,"Comparative Analysis of Software Development Methods between Parallel,
  V-Shaped and Iterative","Any organization that will develop software is faced with a difficult choice
of choosing the right software development method. Whereas the software
development methods used, play a significant role in the overall software
development process. Software development methods are needed so that the
software development process can be systematic so that it is not only completed
within the right time frame but also must have good quality. There are various
methods of software development in System Development Lyfe Cycle (SDLC). Each
SDLC method provides a general guiding line about different software
development and has different characteristics. Each method of software
development has its drawbacks and advantages so that the selection of software
development methods should be compatible with the capacity of the software
developed. This paper will compare three different software development
methods: V-Shaped Model, Parallel Development Model, and Iterative Model with
the aim of providing an understanding of software developers to choose the
right method.",http://arxiv.org/abs/1710.07014v1,arXiv,comparative analysis software development method parallel vshaped iterative,organization develop software face difficult choice choose right software development method whereas software development method use play significant role overall software development process software development method need software development process systematic complete within right time frame also must good quality various method software development system development lyfe cycle sdlc sdlc method provide general guide line different software development different characteristic method software development drawback advantage selection software development method compatible capacity software develop paper compare three different software development method vshape model parallel development model iterative model aim provide understanding software developer choose right method,comparative analysis software development method parallel vshaped iterative organization develop software face difficult choice choose right software development method whereas software development method use play significant role overall software development process software development method need software development process systematic complete within right time frame also must good quality various method software development system development lyfe cycle sdlc sdlc method provide general guide line different software development different characteristic method software development drawback advantage selection software development method compatible capacity software develop paper compare three different software development method vshape model parallel development model iterative model aim provide understanding software developer choose right method,0.6105263157894737,0.12631578947368421,0.16842105263157894,0.010526315789473684,95.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Design and Development,"Importance of Secure Software Development Processes and Tools for
  Developers","In this research paper of secure software systems, authors have discussed
what the proper development process is when it comes to creating a secure
software, which will be suited for developers and relevent stakeholders alike.
Secure Software Development Process for Developers is of crucial importance for
software engineers as more and more software-based devices are becoming
commonly available, and cloud services are evolving which require for the
software to be constantly connected to the internet. With this in mind, Secure
Software Development needs to be transformed to something most developers can
rely upon to make applied software safe and have the capability to mitigate
against potential attacks by hackers. Furthermore, in this paper, existing
Secure Software Development Process ideas and implementations are reviewed and
investigated using the research paper pool available online. Thereafter, an
approach is proposed to enhance the security aspect in software development
process to resolve security issues. Lastly, the paper concludes with final
remarks on practical implementation of security features in software
development phases for production of secure and reliable software programs and
systems.",http://arxiv.org/abs/2012.15153v1,arXiv,importance secure software development process tool developer,research paper secure software system author discuss proper development process come create secure software suit developer relevent stakeholder alike secure software development process developer crucial importance software engineer softwarebase device become commonly available cloud service evolve require software constantly connect internet mind secure software development need transform something developer rely upon make apply software safe capability mitigate potential attack hacker furthermore paper exist secure software development process idea implementation review investigate use research paper pool available online thereafter approach propose enhance security aspect software development process resolve security issue lastly paper conclude final remark practical implementation security feature software development phase production secure reliable software program system,importance secure software development process tool developer research paper secure software system author discuss proper development process come create secure software suit developer relevent stakeholder alike secure software development process developer crucial importance software engineer softwarebase device become commonly available cloud service evolve require software constantly connect internet mind secure software development need transform something developer rely upon make apply software safe capability mitigate potential attack hacker furthermore paper exist secure software development process idea implementation review investigate use research paper pool available online thereafter approach propose enhance security aspect software development process resolve security issue lastly paper conclude final remark practical implementation security feature software development phase production secure reliable software program system,0.5981308411214953,0.16822429906542055,0.14018691588785046,0.04672897196261682,107.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Design and Development,"Think-on-Process: Dynamic Process Generation for Collaborative
  Development of Multi-Agent System","Software development is a collaborative endeavor that requires individuals
from different departments to work together in order to collectively develop a
high-quality software system. In this context, people have begun to explore a
method that leverages multi-agent systems based on LLMs to carry out software
development. However, existing research tends to rigidly fix the software
development process in a framework in code form, thus failing to dynamically
adjust the software development process in real-time to meet the more flexible
and variable software environment. In this paper, we propose a dynamic process
generation framework, named ToP (Think-on-Process). The core idea of ToP is to
leverage experiential knowledge (i.e., process models) to guide LLMs in
generating software development processes (i.e., instances). These instances
will guide multi-agent in software development and employ a compiler to provide
feedback on the development outcomes. Subsequently, we utilize heuristic
algorithms to filter the instances and apply process mining algorithms to
derive process model. Finally, the process model will be converted into text,
formatted as prompts, to enhance the ability of LLMs to generate other
instances. Experiments demonstrate that our framework ToP significantly
enhances the dynamic process generation capability of the GPT-3.5 and GPT-4 for
five categories of software development tasks.",http://arxiv.org/abs/2409.06568v1,arXiv,thinkonprocess dynamic process generation collaborative development multiagent system,software development collaborative endeavor require individual different department work together order collectively develop highquality software system context people begin explore method leverage multiagent system base llm carry software development however exist research tend rigidly fix software development process framework code form thus fail dynamically adjust software development process realtime meet flexible variable software environment paper propose dynamic process generation framework name top thinkonprocess core idea top leverage experiential knowledge process model guide llm generate software development process instance instance guide multiagent software development employ compiler provide feedback development outcome subsequently utilize heuristic algorithm filter instance apply process mining algorithm derive process model finally process model convert text format prompt enhance ability llm generate instance experiment demonstrate framework top significantly enhance dynamic process generation capability gpt gpt five category software development task,thinkonprocess dynamic process generation collaborative development multiagent system software development collaborative endeavor require individual different department work together order collectively develop highquality software system context people begin explore method leverage multiagent system base llm carry software development however exist research tend rigidly fix software development process framework code form thus fail dynamically adjust software development process realtime meet flexible variable software environment paper propose dynamic process generation framework name top thinkonprocess core idea top leverage experiential knowledge process model guide llm generate software development process instance instance guide multiagent software development employ compiler provide feedback development outcome subsequently utilize heuristic algorithm filter instance apply process mining algorithm derive process model finally process model convert text format prompt enhance ability llm generate instance experiment demonstrate framework top significantly enhance dynamic process generation capability gpt gpt five category software development task,0.6183206106870229,0.1450381679389313,0.0916030534351145,0.06870229007633588,131.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Design and Development,SRS BUILDER 1.0: An Upper Type CASE Tool For Requirement Specification,"Software (SW) development is a labor intensive activity. Modern software
projects generally have to deal with producing and managing large and complex
software products. Developing such software has become an extremely challenging
job not only because of inherent complexity, but also mainly for economic
constraints unlike time, quality, maintainability concerns. Hence, developing
modern software within the budget still remains as one of the main software
crisis. The most significant way to reduce the software development cost is to
use the Computer-Aided Software Engineering (CASE) tools over the entire
Software Development Life Cycle (SDLC) process as substitute to expensive human
labor cost. We think that automation of software development methods is a
valuable support for the software engineers in coping with this complexity and
for improving quality too. This paper demonstrates the newly developed CASE
tools name ""SRS Builder 1.0"" for software requirement specification developed
at our university laboratory, University of North Bengal, India. This paper
discusses our new developed product with its functionalities and usages. We
believe the tool has the potential to play an important role in the software
development process.",http://arxiv.org/abs/1109.1651v1,arXiv,srs builder upper type case tool requirement specification,software development labor intensive activity modern software project generally deal produce manage large complex software product develop software become extremely challenging job inherent complexity also mainly economic constraint unlike time quality maintainability concern hence develop modern software within budget still remain one main software crisis significant way reduce software development cost use computeraide software engineering case tool entire software development life cycle sdlc process substitute expensive human labor cost think automation software development method valuable support software engineer cope complexity improve quality paper demonstrate newly develop case tool name srs builder software requirement specification develop university laboratory university north bengal india paper discuss new develop product functionality usage believe tool potential play important role software development process,srs builder upper type case tool requirement specification software development labor intensive activity modern software project generally deal produce manage large complex software product develop software become extremely challenging job inherent complexity also mainly economic constraint unlike time quality maintainability concern hence develop modern software within budget still remain one main software crisis significant way reduce software development cost use computeraide software engineering case tool entire software development life cycle sdlc process substitute expensive human labor cost think automation software development method valuable support software engineer cope complexity improve quality paper demonstrate newly develop case tool name srs builder software requirement specification develop university laboratory university north bengal india paper discuss new develop product functionality usage believe tool potential play important role software development process,0.5726495726495726,0.13675213675213677,0.1282051282051282,0.05982905982905983,117.0,1.0,1.0,0.0,0.0
Software Engineering,Software Development Processes,Theoretical / Conceptual,Open Source Software Development Challenges,"<jats:p>GitHub is the most common code hosting and repository service for open-source software (OSS) projects. Thanks to the great variety of features, researchers benefit from GitHub to solve a wide range of OSS development challenges. In this context, the authors thought that was important to conduct a literature review on studies that used GitHub data. To reach these studies, they conducted this literature review based on a GitHub dataset source study instead of a keyword-based search in digital libraries. Since GHTorrent is the most widely known GitHub dataset according to the literature, they considered the studies that cite this dataset for the systematic literature review. In this study, they reviewed the selected 172 studies according to some criteria that used the dataset as a data source. They classified them within the scope of OSS development challenges thanks to the information they extract from the metadata of studies. They put forward some issues about the dataset and they offered the focused and attention-grabbing fields and open challenges that we encourage the researchers to study on them.</jats:p>",https://doi.org/10.4018/ijossp.2020100101,CrossRef,open source software development challenge,jatspgithub common code hosting repository service opensource software oss project thank great variety feature researcher benefit github solve wide range oss development challenge context author think important conduct literature review study use github datum reach study conduct literature review base github dataset source study instead keywordbase search digital library since ghtorrent widely know github dataset accord literature consider study cite dataset systematic literature review study review select study accord criterion use dataset data source classify within scope oss development challenge thank information extract metadata study put forward issue dataset offer focused attentiongrabbe field open challenge encourage researcher study themjatsp,open source software development challenge jatspgithub common code hosting repository service opensource software oss project thank great variety feature researcher benefit github solve wide range oss development challenge context author think important conduct literature review study use github datum reach study conduct literature review base github dataset source study instead keywordbase search digital library since ghtorrent widely know github dataset accord literature consider study cite dataset systematic literature review study review select study accord criterion use dataset data source classify within scope oss development challenge thank information extract metadata study put forward issue dataset offer focused attentiongrabbe field open challenge encourage researcher study themjatsp,0.43434343434343436,0.1414141414141414,0.08080808080808081,0.020202020202020204,99.0,0.0,0.0,0.0,1.0
Software Engineering,Software Development Processes,Theoretical / Conceptual,An  Overview of Tools for Collecting Data on Software Development and Debugging Processes from Integrated Development Environments,"<jats:p>Purpose. This paper presents the findings of a review of the literature published in the twenty-first century in order to identify and analyze the current state of tools that track developer interactions with integrated development environments, as well as to recommend future research directions based on the actual state. Methodology. By systematically searching in five digital libraries we conducted a systematic review of the literature on data collection tools from integrated development environments published in the twenty-first century. Fifty-five papers were selected as primary studies. Findings. 55 articles were analyzed and the findings show that using an integrated development environment to collect usage data provides more insight into developer activities than it was previously possible. Usage data allows us to analyze how developers spend their time. With usage data, you can learn more about how developers create mental models, investigate code, conduct mini-experiments through trial and error, and what can help everyone improve performance. The research community continues to be highly active in developing tools to track developer activity. The findings indicate that more research is needed in this area to better understand and measure programmer behavior. Originality. For the first time, systematization and analysis of tools for tracking programmer's behavior in an integrated development environment have been carried out. Practical value. Our study contributes to a better understanding of the current state of research on programmer behavior in integrated development environments. An analysis of the study can help define a research agenda as a starting point for the creation of a novel practical tool.</jats:p>",https://doi.org/10.15802/stp2021/242042,CrossRef,overview tool collect datum software development debug process integrated development environment,jatsppurpose paper present finding review literature publish twentyfirst century order identify analyze current state tool track developer interaction integrate development environment well recommend future research direction base actual state methodology systematically search five digital library conduct systematic review literature data collection tool integrated development environment publish twentyfirst century fiftyfive paper select primary study finding article analyze finding show use integrate development environment collect usage datum provide insight developer activity previously possible usage datum allow analyze developer spend time usage datum learn developer create mental model investigate code conduct miniexperiment trial error help everyone improve performance research community continue highly active develop tool track developer activity finding indicate research need area well understand measure programmer behavior originality first time systematization analysis tool tracking programmer behavior integrate development environment carry practical value study contribute well understanding current state research programmer behavior integrate development environment analysis study help define research agenda starting point creation novel practical tooljatsp,overview tool collect datum software development debug process integrated development environment jatsppurpose paper present finding review literature publish twentyfirst century order identify analyze current state tool track developer interaction integrate development environment well recommend future research direction base actual state methodology systematically search five digital library conduct systematic review literature data collection tool integrated development environment publish twentyfirst century fiftyfive paper select primary study finding article analyze finding show use integrate development environment collect usage datum provide insight developer activity previously possible usage datum allow analyze developer spend time usage datum learn developer create mental model investigate code conduct miniexperiment trial error help everyone improve performance research community continue highly active develop tool track developer activity finding indicate research need area well understand measure programmer behavior originality first time systematization analysis tool tracking programmer behavior integrate development environment carry practical value study contribute well understanding current state research programmer behavior integrate development environment analysis study help define research agenda starting point creation novel practical tooljatsp,0.6038961038961039,0.2012987012987013,0.12337662337662338,0.03896103896103896,154.0,0.0,0.0,2.0,1.0
Software Engineering,Software Development Processes,Theoretical / Conceptual,Strategies for Software and Hardware Compatibility Testing in Industrial Controllers,"<jats:p>Mass customization, small batch sizes, high variability of product types and a changing product portfolio during the life cycle of an industrial plant are current trends in the industry. Due to an increasing decoupling of the development of software and hardware components in an industrial context, compatibility problems within industrial control systems arise more and more frequently. In this publication, a strategy concept for compatibility testing is derived and discussed by means of a literature review and applied research. This four-phase strategy concept identifies incompatibilities between software and hardware components in the industrial control environment and enables test engineers to detect problems at an early stage. By automating the compatibility test on an external I-PC, the test can be run both when new software is installed on the industrial controller and when the controller is restarted. Thus, changes to the components are constantly detected and incompatibilities are avoided. Furthermore, early incompatibility detection can ensure that a system remains permanently operational. Based on a discussion, additional strategies are identified to consolidate the robustness and applicability of the presented concept.</jats:p>",https://doi.org/10.3390/pr12030580,CrossRef,strategy software hardware compatibility testing industrial controller,jatspmass customization small batch size high variability product type change product portfolio life cycle industrial plant current trend industry due increase decoupling development software hardware component industrial context compatibility problem within industrial control system arise frequently publication strategy concept compatibility testing derive discuss mean literature review apply research fourphase strategy concept identify incompatibility software hardware component industrial control environment enable test engineer detect problem early stage automate compatibility test external ipc test run new software instal industrial controller controller restart thus change component constantly detect incompatibility avoid furthermore early incompatibility detection ensure system remain permanently operational base discussion additional strategy identify consolidate robustness applicability present conceptjatsp,strategy software hardware compatibility testing industrial controller jatspmass customization small batch size high variability product type change product portfolio life cycle industrial plant current trend industry due increase decoupling development software hardware component industrial context compatibility problem within industrial control system arise frequently publication strategy concept compatibility testing derive discuss mean literature review apply research fourphase strategy concept identify incompatibility software hardware component industrial control environment enable test engineer detect problem early stage automate compatibility test external ipc test run new software instal industrial controller controller restart thus change component constantly detect incompatibility avoid furthermore early incompatibility detection ensure system remain permanently operational base discussion additional strategy identify consolidate robustness applicability present conceptjatsp,0.5849056603773585,0.12264150943396226,0.18867924528301888,0.04716981132075472,106.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Theoretical / Conceptual,Compliance checking of software processes: A systematic literature review,"<jats:title>Abstract</jats:title><jats:p>The processes used to develop software need to comply with normative requirements (e.g., standards and regulations) to align with the market and the law. Manual compliance checking is challenging because there are numerous requirements with changing nature and different purposes. Despite the importance of automated techniques, there is not any systematic study in this field. This lack may hinder organizations from moving toward automated compliance checking practices. In this paper, we characterize the methods for automatic compliance checking of software processes, including used techniques, potential impacts, and challenges. For this, we undertake a systematic literature review (SLR) of studies reporting methods in this field. As a result, we identify solutions that use different techniques (e.g., anthologies and metamodels) to represent processes and their artifacts (e.g., tasks and roles). Various languages, which have diverse capabilities for managing competing and changing norms, and agile strategies, are also used to represent normative requirements. Most solutions require tool‐support concretization and enhanced capabilities to handle processes and normative diversity. Our findings outline compelling areas for future research. In particular, there is a need to select suitable languages for consolidating a generic and normative‐agnostic solution, increase automation levels, tool support, and boost the application in practice by improving usability aspects.</jats:p>",https://doi.org/10.1002/smr.2440,CrossRef,compliance checking software process systematic literature review,jatstitleabstractjatstitlejatspthe process use develop software need comply normative requirement standard regulation align market law manual compliance checking challenging numerous requirement change nature different purpose despite importance automate technique systematic study field lack may hinder organization move toward automate compliance check practice paper characterize method automatic compliance checking software process include use technique potential impact challenge undertake systematic literature review slr study report method field result identify solution use different technique anthology metamodel represent process artifact task role various language diverse capability manage compete change norm agile strategy also use represent normative requirement solution require concretization enhanced capability handle process normative diversity finding outline compelling area future research particular need select suitable language consolidate generic solution increase automation level tool support boost application practice improve usability aspectsjatsp,compliance checking software process systematic literature review jatstitleabstractjatstitlejatspthe process use develop software need comply normative requirement standard regulation align market law manual compliance checking challenging numerous requirement change nature different purpose despite importance automate technique systematic study field lack may hinder organization move toward automate compliance check practice paper characterize method automatic compliance checking software process include use technique potential impact challenge undertake systematic literature review slr study report method field result identify solution use different technique anthology metamodel represent process artifact task role various language diverse capability manage compete change norm agile strategy also use represent normative requirement solution require concretization enhanced capability handle process normative diversity finding outline compelling area future research particular need select suitable language consolidate generic solution increase automation level tool support boost application practice improve usability aspectsjatsp,0.5793650793650794,0.14285714285714285,0.18253968253968253,0.007936507936507936,126.0,0.0,0.0,0.0,0.0
Software Engineering,Software Development Processes,Theoretical / Conceptual,ТЕХНОЛОГИЯ РАЗРАБОТКИ МУЛЬТИПЛАТФОРМЕННЫХ ПРОГРАММ НА ОСНОВЕ ЯВНЫХ СХЕМ ПРОГРАММ,"<jats:p>В статье обосновывается необходимость разработки мультиплатформенных систем - таких, части которых работают на разных платформах. Описана концептуальная схема таких систем.</jats:p>
                                                                                                            <jats:p>The article underpins the devepolment of multiplatform software. Parts of the software in context operate on different platforms. A conceptual schema of the software is discussed.</jats:p>",https://doi.org/10.34706/de-2018-02-04,CrossRef,технология разработки мультиплатформенных программ основе явных схем программ,jatspв статье обосновывается необходимость разработки мультиплатформенных систем таких части которых работают разных платформах описана концептуальная схема таких системjatsp jatspthe article underpin devepolment multiplatform software part software context operate different platform conceptual schema software discussedjatsp,технология разработки мультиплатформенных программ основе явных схем программ jatspв статье обосновывается необходимость разработки мультиплатформенных систем таких части которых работают разных платформах описана концептуальная схема таких системjatsp jatspthe article underpin devepolment multiplatform software part software context operate different platform conceptual schema software discussedjatsp,0.38235294117647056,0.058823529411764705,0.08823529411764706,0.0,34.0,1.0,0.0,0.0,2.0
Software Engineering,Software Design and Architecture,Quantitative,"Applying empirical software engineering to software architecture:
  challenges and lessons learned","In the last 15 years, software architecture has emerged as an important
software engineering field for managing the development and maintenance of
large, software- intensive systems. Software architecture community has
developed numerous methods, techniques, and tools to support the architecture
process (analysis, design, and review). Historically, most advances in software
architecture have been driven by talented people and industrial experience, but
there is now a growing need to systematically gather empirical evidence about
the advantages or otherwise of tools and methods rather than just rely on
promotional anecdotes or rhetoric. The aim of this paper is to promote and
facilitate the application of the empirical paradigm to software architecture.
To this end, we describe the challenges and lessons learned when assessing
software architecture research that used controlled experiments, replications,
expert opinion, systematic literature reviews, obser- vational studies, and
surveys. Our research will support the emergence of a body of knowledge
consisting of the more widely-accepted and well-formed software architecture
theories.",http://arxiv.org/abs/1701.06000v1,arXiv,apply empirical software engineering software architecture challenge lesson learn,last year software architecture emerge important software engineering field manage development maintenance large software intensive system software architecture community develop numerous method technique tool support architecture process analysis design review historically advance software architecture drive talented people industrial experience grow need systematically gather empirical evidence advantage otherwise tool method rather rely promotional anecdote rhetoric aim paper promote facilitate application empirical paradigm software architecture end describe challenge lesson learn assess software architecture research use control experiment replication expert opinion systematic literature review obser vational study survey research support emergence body knowledge consist widelyaccepted wellforme software architecture theory,apply empirical software engineering software architecture challenge lesson learn last year software architecture emerge important software engineering field manage development maintenance large software intensive system software architecture community develop numerous method technique tool support architecture process analysis design review historically advance software architecture drive talented people industrial experience grow need systematically gather empirical evidence advantage otherwise tool method rather rely promotional anecdote rhetoric aim paper promote facilitate application empirical paradigm software architecture end describe challenge lesson learn assess software architecture research use control experiment replication expert opinion systematic literature review obser vational study survey research support emergence body knowledge consist widelyaccepted wellforme software architecture theory,0.6458333333333334,0.13541666666666666,0.125,0.041666666666666664,96.0,0.0,0.0,1.0,0.0
Software Engineering,Software Design and Architecture,Quantitative,Archify: A Recommender System of Architectural Design Decisions,"Software architectures play a critical role in software quality assurance.
However, small and medium companies (SMC) often suffer from the absence of
professionals with skills and expertise in software architecture. That
situation potentially affects the final quality of the software products and
pressures projects budget with extra costs with consulting. This paper presents
a recommender system of architectural design decisions called Archify. The goal
is to support SMC companies in part of the effort of architecturally designing
their products. Archify implements a wizard-styled interface that guides the
developer or project manager through a set of specific questions. While the
user answers these questions, Archify buffers a set of corresponding
architectural decision recommendations. As the final result, the system
recommends a set of architectural decisions matching the project's needs
according to the requirements (as provided by the user) of the software under
development. Nineteen professionals from academia and industry evaluated
Archify through two surveys. The findings reveal that 94.7% of the participants
approved Archify as a supporting tool. Respondents also highlighted the lack of
tools supporting software architecture design, remarking the relevance of the
proposed system.",http://arxiv.org/abs/2106.08115v1,arXiv,archify recommender system architectural design decision,software architecture play critical role software quality assurance however small medium company smc often suffer absence professional skill expertise software architecture situation potentially affect final quality software product pressure project budget extra cost consult paper present recommender system architectural design decision call archify goal support smc company part effort architecturally design product archify implement wizardstyled interface guide developer project manager set specific question user answer question archify buffer set correspond architectural decision recommendation final result system recommend set architectural decision match project need accord requirement provide user software development nineteen professional academia industry evaluate archify two survey finding reveal participant approve archify support tool respondent also highlight lack tool support software architecture design remark relevance propose system,archify recommender system architectural design decision software architecture play critical role software quality assurance however small medium company smc often suffer absence professional skill expertise software architecture situation potentially affect final quality software product pressure project budget extra cost consult paper present recommender system architectural design decision call archify goal support smc company part effort architecturally design product archify implement wizardstyled interface guide developer project manager set specific question user answer question archify buffer set correspond architectural decision recommendation final result system recommend set architectural decision match project need accord requirement provide user software development nineteen professional academia industry evaluate archify two survey finding reveal participant approve archify support tool respondent also highlight lack tool support software architecture design remark relevance propose system,0.6581196581196581,0.11965811965811966,0.1282051282051282,0.042735042735042736,117.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Quantitative,"Architectural Approaches to Overcome Challenges in the Development of
  Data-Intensive Systems","Orientation of modern software systems towards data-intensive processing
raises new difficulties in software engineering on how to build and maintain
such systems. Some of the important challenges concern the design of software
architecture. In this article, we survey the fundamental challenges when
designing data-intensive computing systems and present some of the most popular
software architectural styles together with their potential to tackle these
challenges.",http://arxiv.org/abs/2312.03049v1,arXiv,architectural approach overcome challenge development dataintensive system,orientation modern software system towards dataintensive processing raise new difficulty software engineering build maintain system important challenge concern design software architecture article survey fundamental challenge design dataintensive computing system present popular software architectural style together potential tackle challenge,architectural approach overcome challenge development dataintensive system orientation modern software system towards dataintensive processing raise new difficulty software engineering build maintain system important challenge concern design software architecture article survey fundamental challenge design dataintensive computing system present popular software architectural style together potential tackle challenge,0.6052631578947368,0.07894736842105263,0.2631578947368421,0.02631578947368421,38.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Quantitative,Software Architecture Metrics: a literature review,"In Software Engineering, early detection of architectural issues is key. It
helps mitigate the risk of poor performance, and lowers the cost of repairing
these issues. Metrics give a quick overview of the project which helps
designers with the detection of flaws or degradation in their architecture.
Even though studies unveiled architectural metrics more than 25 years ago, they
have not yet been embraced by the industry nor the open source community. In
this study, we aim at conducting a review of existing metrics focused on the
software architecture for evaluating quality, early in the design flow and
throughout the project's lifetime. We also give guidelines of their usage and
study their relevance in different contexts.",http://arxiv.org/abs/1901.09050v1,arXiv,software architecture metric literature review,software engineer early detection architectural issue key help mitigate risk poor performance lower cost repair issue metric give quick overview project help designer detection flaw degradation architecture even though study unveil architectural metric year ago yet embrace industry open source community study aim conduct review exist metric focus software architecture evaluate quality early design flow throughout project lifetime also give guideline usage study relevance different context,software architecture metric literature review software engineer early detection architectural issue key help mitigate risk poor performance lower cost repair issue metric give quick overview project help designer detection flaw degradation architecture even though study unveil architectural metric year ago yet embrace industry open source community study aim conduct review exist metric focus software architecture evaluate quality early design flow throughout project lifetime also give guideline usage study relevance different context,0.6060606060606061,0.09090909090909091,0.19696969696969696,0.06060606060606061,66.0,0.0,0.0,1.0,0.0
Software Engineering,Software Design and Architecture,Quantitative,Towards physical laws for software architecture,"Starting from the pioneering works on software architecture precious
guidelines have emerged to indicate how computer programs should be organized.
For example the ""separation of concerns"" suggests to split a program into
modules that overlap in functionality as little as possible. However these
recommendations are mainly conceptual and are thus hard to express in a
quantitative form. Hence software architecture relies on the individual
experience and skill of the designers rather than on quantitative laws. In this
article I apply the methods developed for the classification of information on
the World-Wide-Web to study the organization of Open Source programs in an
attempt to establish the statistical laws governing software architecture.",http://arxiv.org/abs/1003.5455v1,arXiv,towards physical law software architecture,start pioneer work software architecture precious guideline emerge indicate computer program organize example separation concern suggest split program module overlap functionality little possible however recommendation mainly conceptual thus hard express quantitative form hence software architecture rely individual experience skill designer rather quantitative law article apply method develop classification information worldwideweb study organization open source program attempt establish statistical law govern software architecture,towards physical law software architecture start pioneer work software architecture precious guideline emerge indicate computer program organize example separation concern suggest split program module overlap functionality little possible however recommendation mainly conceptual thus hard express quantitative form hence software architecture rely individual experience skill designer rather quantitative law article apply method develop classification information worldwideweb study organization open source program attempt establish statistical law govern software architecture,0.532258064516129,0.1774193548387097,0.14516129032258066,0.0967741935483871,62.0,1.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Qualitative,"Software Architecture Decision-Making Practices and Challenges: An
  Industrial Case Study","Software architecture decision-making is critical to the success of a
software system as software architecture sets the structure of the system,
determines its qualities, and has far-reaching consequences throughout the
system life cycle. The complex nature of the software development context and
the importance of the problem has led the research community to develop several
techniques, tools, and processes to assist software architects in making better
decisions. Despite these effort, the adoption of such systematic approaches
appears to be quite limited in practice. In addition, the practitioners are
also facing new challenges as different software development methods suggest
different approaches for architecture design. In this paper, we study the
current software architecture decision-making practices in the industry using a
case study conducted among professional software architects in three different
companies in Europe. As a result, we identified different software architecture
decision-making practices followed by the software teams as well as their
reasons for following them, the challenges associated with them, and the
possible improvements from the software architects' point of view. Based on
that, we recognized that improving software architecture knowledge management
can address most of the identified challenges and would result in better
software architecture decision-making.",http://arxiv.org/abs/1610.09240v1,arXiv,software architecture decisionmake practice challenge industrial case study,software architecture decisionmake critical success software system software architecture set structure system determine quality farreache consequence throughout system life cycle complex nature software development context importance problem lead research community develop several technique tool process assist software architect make well decision despite effort adoption systematic approach appear quite limited practice addition practitioner also face new challenge different software development method suggest different approach architecture design paper study current software architecture decisionmake practice industry use case study conduct among professional software architect three different company europe result identify different software architecture decisionmake practice follow software team well reason follow challenge associate possible improvement software architect point view base recognize improve software architecture knowledge management address identify challenge would result well software architecture decisionmake,software architecture decisionmake practice challenge industrial case study software architecture decisionmake critical success software system software architecture set structure system determine quality farreache consequence throughout system life cycle complex nature software development context importance problem lead research community develop several technique tool process assist software architect make well decision despite effort adoption systematic approach appear quite limited practice addition practitioner also face new challenge different software development method suggest different approach architecture design paper study current software architecture decisionmake practice industry use case study conduct among professional software architect three different company europe result identify different software architecture decisionmake practice follow software team well reason follow challenge associate possible improvement software architect point view base recognize improve software architecture knowledge management address identify challenge would result well software architecture decisionmake,0.6639344262295082,0.14754098360655737,0.10655737704918032,0.03278688524590164,122.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Qualitative,"Impact of requirements volatility on software architecture: How do
  software teams keep up with ever-changing requirements?","Requirements volatility is a major issue in software development, causing
problems such as higher defect density, project delays and cost overruns.
Software architecture that guides the overall vision of software product, is
one of the areas that is greatly affected by requirements volatility. Since
critical architecture decisions are made based on the requirements at hand,
changes in requirements can result signifiant changes in architecture. With the
wide adoption of agile software development, software architectures are
designed to accommodate possible future changes. However, the changes has to be
carefully managed as unnecessary and excessive changes can bring negative
consequences. An exploratory case study was conducted to study the impact of
requirements volatility on software architecture. Fifteen semi-structured,
thematic interviews were conducted in a European software company. The research
revealed poor communication, information distortion, and external dependencies
as the main factors that cause requirement volatility and inadequate
architecture documentation, inability to trace design rationale, and increased
complexity as the main implications of requirements volatility on software
architecture. Insights from software teams' awareness of the requirement
volatility, factors contribute to it, and possible ways to mitigate its
implications will be utilized to improve the management of requirement
volatility during software architecting process.",http://arxiv.org/abs/1904.08164v1,arXiv,impact requirement volatility software architecture software team keep everchanging requirement,requirement volatility major issue software development cause problem high defect density project delay cost overrun software architecture guide overall vision software product one area greatly affect requirement volatility since critical architecture decision make base requirement hand change requirement result signifiant change architecture wide adoption agile software development software architecture design accommodate possible future change however change carefully manage unnecessary excessive change bring negative consequence exploratory case study conduct study impact requirement volatility software architecture fifteen semistructure thematic interview conduct european software company research reveal poor communication information distortion external dependency main factor cause requirement volatility inadequate architecture documentation inability trace design rationale increase complexity main implication requirement volatility software architecture insight software team awareness requirement volatility factor contribute possible way mitigate implication utilize improve management requirement volatility software architecting process,impact requirement volatility software architecture software team keep everchanging requirement requirement volatility major issue software development cause problem high defect density project delay cost overrun software architecture guide overall vision software product one area greatly affect requirement volatility since critical architecture decision make base requirement hand change requirement result signifiant change architecture wide adoption agile software development software architecture design accommodate possible future change however change carefully manage unnecessary excessive change bring negative consequence exploratory case study conduct study impact requirement volatility software architecture fifteen semistructure thematic interview conduct european software company research reveal poor communication information distortion external dependency main factor cause requirement volatility inadequate architecture documentation inability trace design rationale increase complexity main implication requirement volatility software architecture insight software team awareness requirement volatility factor contribute possible way mitigate implication utilize improve management requirement volatility software architecting process,0.7076923076923077,0.06923076923076923,0.16923076923076924,0.023076923076923078,130.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Qualitative,Software Architecture in Practice: Challenges and Opportunities,"Software architecture has been an active research field for nearly four
decades, in which previous studies make significant progress such as creating
methods and techniques and building tools to support software architecture
practice. Despite past efforts, we have little understanding of how
practitioners perform software architecture related activities, and what
challenges they face. Through interviews with 32 practitioners from 21
organizations across three continents, we identified challenges that
practitioners face in software architecture practice during software
development and maintenance. We reported on common software architecture
activities at software requirements, design, construction and testing, and
maintenance stages, as well as corresponding challenges. Our study uncovers
that most of these challenges center around management, documentation, tooling
and process, and collects recommendations to address these challenges.",http://arxiv.org/abs/2308.09978v2,arXiv,software architecture practice challenge opportunity,software architecture active research field nearly four decade previous study make significant progress create method technique building tool support software architecture practice despite past effort little understanding practitioner perform software architecture relate activity challenge face interview practitioner organization across three continent identify challenge practitioner face software architecture practice software development maintenance report common software architecture activity software requirement design construction testing maintenance stage well corresponding challenge study uncover challenge center around management documentation tooling process collect recommendation address challenge,software architecture practice challenge opportunity software architecture active research field nearly four decade previous study make significant progress create method technique building tool support software architecture practice despite past effort little understanding practitioner perform software architecture relate activity challenge face interview practitioner organization across three continent identify challenge practitioner face software architecture practice software development maintenance report common software architecture activity software requirement design construction testing maintenance stage well corresponding challenge study uncover challenge center around management documentation tooling process collect recommendation address challenge,0.7341772151898734,0.08860759493670886,0.08860759493670886,0.02531645569620253,79.0,0.0,0.0,1.0,0.0
Software Engineering,Software Design and Architecture,Qualitative,A Qualitative Study of Architectural Design Issues in DevOps,"Software architecture is critical in succeeding with DevOps. However,
designing software architectures that enable and support DevOps (DevOps-driven
software architectures) is a challenge for organizations. We assert that one of
the essential steps towards characterizing DevOps-driven architectures is to
understand architectural design issues raised in DevOps. At the same time, some
of the architectural issues that emerge in the DevOps context (and their
corresponding architectural practices or tactics) may stem from the context
(i.e., domain) and characteristics of software organizations. To this end, we
conducted a mixed-methods study that consists of a qualitative case study of
two teams in a company during their DevOps transformation and a content
analysis of Stack Overflow and DevOps Stack Exchange posts to understand
architectural design issues in DevOps. Our study found eight specific and
contextual architectural design issues faced by the two teams and classified
architectural design issues discussed in Stack Overflow and DevOps Stack
Exchange into 11 groups. Our aggregated results reveal that the main
characteristics of DevOps-driven architectures are: being loosely coupled and
prioritizing deployability, testability, supportability, and modifiability over
other quality attributes. Finally, we discuss some concrete implications for
research and practice.",http://arxiv.org/abs/2108.06705v2,arXiv,qualitative study architectural design issue devop,software architecture critical succeed devop however design software architecture enable support devop devopsdriven software architecture challenge organization assert one essential step towards characterize devopsdriven architecture understand architectural design issue raise devop time architectural issue emerge devops context corresponding architectural practice tactic may stem context domain characteristic software organization end conduct mixedmethod study consist qualitative case study two team company devop transformation content analysis stack overflow devop stack exchange post understand architectural design issue devop study find eight specific contextual architectural design issue face two team classified architectural design issue discuss stack overflow devop stack exchange group aggregated result reveal main characteristic devopsdriven architecture loosely couple prioritize deployability testability supportability modifiability quality attribute finally discuss concrete implication research practice,qualitative study architectural design issue devop software architecture critical succeed devop however design software architecture enable support devop devopsdriven software architecture challenge organization assert one essential step towards characterize devopsdriven architecture understand architectural design issue raise devop time architectural issue emerge devops context corresponding architectural practice tactic may stem context domain characteristic software organization end conduct mixedmethod study consist qualitative case study two team company devop transformation content analysis stack overflow devop stack exchange post understand architectural design issue devop study find eight specific contextual architectural design issue face two team classified architectural design issue discuss stack overflow devop stack exchange group aggregated result reveal main characteristic devopsdriven architecture loosely couple prioritize deployability testability supportability modifiability quality attribute finally discuss concrete implication research practice,0.5169491525423728,0.211864406779661,0.1440677966101695,0.025423728813559324,118.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Qualitative,"Software Design Pattern Model and Data Structure Algorithm Abilities on
  Microservices Architecture Design in High-tech Enterprises","This study investigates the impact of software design model capabilities and
data structure algorithm abilities on microservices architecture design within
enterprises. Utilizing a qualitative methodology, the research involved
in-depth interviews with software architects and developers who possess
extensive experience in microservices implementation. The findings reveal that
organizations emphasizing robust design models and efficient algorithms achieve
superior scalability, performance, and flexibility in their microservices
architecture. Notably, participants highlighted that a strong foundation in
these areas facilitates better service decomposition, optimizes data
processing, and enhances system responsiveness. Despite these insights, gaps
remain regarding the integration of emerging technologies and the evolving
nature of software design practices. This paper contributes to the existing
literature by underscoring the critical role of these competencies in fostering
effective microservices architectures and suggests avenues for future research
to address identified gaps",http://arxiv.org/abs/2411.04143v1,arXiv,software design pattern model datum structure algorithm ability microservice architecture design hightech enterprise,study investigate impact software design model capability data structure algorithm ability microservice architecture design within enterprise utilize qualitative methodology research involve indepth interview software architect developer possess extensive experience microservice implementation finding reveal organization emphasize robust design model efficient algorithm achieve superior scalability performance flexibility microservice architecture notably participant highlight strong foundation area facilitate well service decomposition optimize datum processing enhance system responsiveness despite insight gap remain regard integration emerge technology evolve nature software design practice paper contribute exist literature underscore critical role competency foster effective microservice architecture suggest avenue future research address identify gap,software design pattern model datum structure algorithm ability microservice architecture design hightech enterprise study investigate impact software design model capability data structure algorithm ability microservice architecture design within enterprise utilize qualitative methodology research involve indepth interview software architect developer possess extensive experience microservice implementation finding reveal organization emphasize robust design model efficient algorithm achieve superior scalability performance flexibility microservice architecture notably participant highlight strong foundation area facilitate well service decomposition optimize datum processing enhance system responsiveness despite insight gap remain regard integration emerge technology evolve nature software design practice paper contribute exist literature underscore critical role competency foster effective microservice architecture suggest avenue future research address identify gap,0.631578947368421,0.12631578947368421,0.1368421052631579,0.010526315789473684,95.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Mixed Methods,"From Requirements to Architecture: An AI-Based Journey to
  Semi-Automatically Generate Software Architectures","Designing domain models and software architectures represents a significant
challenge in software development, as the resulting architectures play a vital
role in fulfilling the system's quality of service. Due to time pressure,
architects often model only one architecture based on their known limited
domain understanding, patterns, and experience instead of thoroughly analyzing
the domain and evaluating multiple candidates, selecting the best fitting.
Existing approaches try to generate domain models based on requirements, but
still require time-consuming manual effort to achieve good results. Therefore,
in this vision paper, we propose a method to generate software architecture
candidates semi-automatically based on requirements using artificial
intelligence techniques. We further envision an automatic evaluation and
trade-off analysis of the generated architecture candidates using, e.g., the
architecture trade-off analysis method combined with large language models and
quantitative analyses. To evaluate this approach, we aim to analyze the quality
of the generated architecture models and the efficiency and effectiveness of
our proposed process by conducting qualitative studies.",http://arxiv.org/abs/2401.14079v1,arXiv,requirement architecture aibased journey semiautomatically generate software architecture,design domain model software architecture represent significant challenge software development result architecture play vital role fulfil system quality service due time pressure architect often model one architecture base know limited domain understand pattern experience instead thoroughly analyze domain evaluate multiple candidate select good fitting exist approach try generate domain model base requirement still require timeconsuming manual effort achieve good result therefore vision paper propose method generate software architecture candidate semiautomatically base requirement use artificial intelligence technique far envision automatic evaluation tradeoff analysis generate architecture candidate use architecture tradeoff analysis method combine large language model quantitative analysis evaluate approach aim analyze quality generate architecture model efficiency effectiveness propose process conduct qualitative study,requirement architecture aibased journey semiautomatically generate software architecture design domain model software architecture represent significant challenge software development result architecture play vital role fulfil system quality service due time pressure architect often model one architecture base know limited domain understand pattern experience instead thoroughly analyze domain evaluate multiple candidate select good fitting exist approach try generate domain model base requirement still require timeconsuming manual effort achieve good result therefore vision paper propose method generate software architecture candidate semiautomatically base requirement use artificial intelligence technique far envision automatic evaluation tradeoff analysis generate architecture candidate use architecture tradeoff analysis method combine large language model quantitative analysis evaluate approach aim analyze quality generate architecture model efficiency effectiveness propose process conduct qualitative study,0.5585585585585585,0.16216216216216217,0.17117117117117117,0.06306306306306306,111.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Mixed Methods,Code smells: A Synthetic Narrative Review,"Code smells are symptoms of poor design and implementation choices, which
might hinder comprehension, increase code complexity and fault-proneness and
decrease maintainability of software systems. The aim of our study was to
perform a triangulation of bibliometric and thematic analysis on code smell
literature production. The search was performed on Scopus (Elsevier,
Netherlands) database using the search string code smells which resulted in 442
publications. The Go-to statement was the first bad code smells identified in
software engineering history in 1968. The literature production trend has been
positive. The most productive countries were the United States, Italy and
Brazil. Eight research themes were identified: Managing software maintenance,
Smell detection-based software refactoring, Architectural smells, Improving
software quality with multi-objective approaches, Technical debt and its
instance, Quality improvement/assurance with mining software repositories,
Programming education, Integrating the concepts of anti-pattern, design defects
and design smells. Some research gaps also emerged, namely, New uncatalogued
smell identification; Smell propagation from architectural, design, code to
test, and other possible smells; and Identification of good smells. The results
of our study can help code smell researchers and practitioners understand the
broader aspects of code smells research and its translation to practice.",http://arxiv.org/abs/2103.01088v1,arXiv,code smell synthetic narrative review,code smell symptom poor design implementation choice might hinder comprehension increase code complexity faultproneness decrease maintainability software system aim study perform triangulation bibliometric thematic analysis code smell literature production search perform scopus elsevi netherlands database use search string code smell result publication goto statement first bad code smell identify software engineering history literature production trend positive productive country united states italy brazil eight research theme identify manage software maintenance smell detectionbase software refactore architectural smell improve software quality multiobjective approach technical debt instance quality improvementassurance mining software repository programming education integrate concept antipattern design defect design smell research gap also emerge namely new uncatalogued smell identification smell propagation architectural design code test possible smell identification good smell result study help code smell researcher practitioner understand broad aspect code smell research translation practice,code smell synthetic narrative review code smell symptom poor design implementation choice might hinder comprehension increase code complexity faultproneness decrease maintainability software system aim study perform triangulation bibliometric thematic analysis code smell literature production search perform scopus elsevi netherlands database use search string code smell result publication goto statement first bad code smell identify software engineering history literature production trend positive productive country united states italy brazil eight research theme identify manage software maintenance smell detectionbase software refactore architectural smell improve software quality multiobjective approach technical debt instance quality improvementassurance mining software repository programming education integrate concept antipattern design defect design smell research gap also emerge namely new uncatalogued smell identification smell propagation architectural design code test possible smell identification good smell result study help code smell researcher practitioner understand broad aspect code smell research translation practice,0.696969696969697,0.09090909090909091,0.12878787878787878,0.015151515151515152,132.0,0.0,3.0,0.0,0.0
Software Engineering,Software Design and Architecture,Mixed Methods,"The Presence and the State-of-Practice of Software Architects in the
  Brazilian Industry -- A Survey","Context: Software architecture intensely impacts the software quality.
Therefore, the professional assigned to carry out the design, maintenance and
evolution of architectures needs to have certain knowledge and skills in order
not to compromise the resulting application. Objective: The aim of this work is
to understand the characteristics of the companies regarding the presence or
absence of software architects in Brazil. Method: This work uses the Survey
research as a means to collect evidence from professionals with the software
architect profile, besides descriptive statistics and thematic analysis to
analyze the results. Results: The study collected data from 105 professionals
distributed in 24 Brazilian states. Results reveal that (i) not all companies
have a software architect, (ii) in some cases, other professionals perform the
activities of a software architect and (iii) there are companies that, even
having a software architecture professional, have other roles also performing
the duties of such a professional. Conclusions: Professionals hired as software
architects have higher salaries than those hired in other roles that carry out
such activity, although many of those other professionals still have duties
that are typical of software architects.",http://arxiv.org/abs/2403.00955v1,arXiv,presence stateofpractice software architect brazilian industry survey,context software architecture intensely impact software quality therefore professional assign carry design maintenance evolution architecture need certain knowledge skill order compromise result application objective aim work understand characteristic company regard presence absence software architect brazil method work use survey research means collect evidence professional software architect profile besides descriptive statistic thematic analysis analyze result result study collect datum professional distribute brazilian state result reveal company software architect case professional perform activity software architect iii company even software architecture professional role also perform duty professional conclusion professional hire software architect high salary hire role carry activity although many professional still duty typical software architect,presence stateofpractice software architect brazilian industry survey context software architecture intensely impact software quality therefore professional assign carry design maintenance evolution architecture need certain knowledge skill order compromise result application objective aim work understand characteristic company regard presence absence software architect brazil method work use survey research means collect evidence professional software architect profile besides descriptive statistic thematic analysis analyze result result study collect datum professional distribute brazilian state result reveal company software architect case professional perform activity software architect iii company even software architecture professional role also perform duty professional conclusion professional hire software architect high salary hire role carry activity although many professional still duty typical software architect,0.6116504854368932,0.10679611650485436,0.18446601941747573,0.04854368932038835,103.0,0.0,1.0,0.0,0.0
Software Engineering,Software Design and Architecture,Mixed Methods,"Self-Confidence of Undergraduate Students in Designing Software
  Architecture","Software architecture students, often, lack self-confidence in their ability
to use their knowledge to design software architectures. This paper
investigates the relations between undergraduate software architecture
students' self-confidence and their course expectations, cognitive levels,
preferred learning methods, and critical thinking. We developed a questionnaire
with open-ended questions to assess the self-confidence levels and related
factors, which was taken by one-hundred ten students in two semesters. The
students answers were coded and analyzed afterward. We found that
self-confidence is weakly associated with the students' critical thinking and
independent from their cognitive levels, preferred learning methods, and
expectations from the course. The results suggest that to improve the
self-confidence of the students, the instructors should work on improving the
students' critical thinking capabilities.",http://arxiv.org/abs/2102.09905v3,arXiv,selfconfidence undergraduate student design software architecture,software architecture student often lack selfconfidence ability use knowledge design software architecture paper investigate relation undergraduate software architecture student selfconfidence course expectation cognitive level prefer learning method critical thinking develop questionnaire openende question assess selfconfidence level related factor take onehundre ten student two semester student answer code analyze afterward find selfconfidence weakly associate student critical thinking independent cognitive level prefer learning method expectation course result suggest improve selfconfidence student instructor work improve student critical thinking capability,selfconfidence undergraduate student design software architecture software architecture student often lack selfconfidence ability use knowledge design software architecture paper investigate relation undergraduate software architecture student selfconfidence course expectation cognitive level prefer learning method critical thinking develop questionnaire openende question assess selfconfidence level related factor take onehundre ten student two semester student answer code analyze afterward find selfconfidence weakly associate student critical thinking independent cognitive level prefer learning method expectation course result suggest improve selfconfidence student instructor work improve student critical thinking capability,0.6710526315789473,0.17105263157894737,0.09210526315789473,0.02631578947368421,76.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Mixed Methods,"Let's Go to the Whiteboard (Again):Perceptions from Software Architects
  on Whiteboard Architecture Meetings","The whiteboard plays a crucial role in the day-to-day lives of software
architects, as they frequently will organize meetings at the whiteboard to
discuss a new architecture, some proposed changes to the architecture, a
mismatch between the architecture and the code, and more. While much has been
studied about software architects, the architectures they produce, and how they
produce them, a detailed understanding of these whiteboards meetings is still
lacking. In this paper, we contribute a mixed-methods study involving
semi-structured interviews and a subsequent survey to understand the
perceptions of software architects on whiteboard architecture meetings. We
focus on five aspects: (1) why do they hold these meetings, what is the impact
of the experience levels of the participants in these meetings, how do the
architects document the meetings, what kinds of changes are made after the
meetings have concluded and their results are moved to implementation, and what
role do digital whiteboards plays? In studying these aspects, we identify 12
observations related to both technical aspects and social aspects of the
meetings. These insights have implications for further research, offer concrete
advice to practitioners, provide guidance for future tool design, and suggest
ways of educating future software architects.",http://arxiv.org/abs/2210.16089v1,arXiv,let whiteboard againperception software architect whiteboard architecture meeting,whiteboard play crucial role daytoday life software architect frequently organize meeting whiteboard discuss new architecture propose change architecture mismatch architecture code much study software architect architecture produce produce detailed understanding whiteboard meeting still lack paper contribute mixedmethod study involve semistructure interview subsequent survey understand perception software architect whiteboard architecture meeting focus five aspect hold meeting impact experience level participant meeting architect document meeting kind change make meeting conclude result move implementation role digital whiteboard play study aspect identify observation relate technical aspect social aspect meeting insight implication research offer concrete advice practitioner provide guidance future tool design suggest way educate future software architect,let whiteboard againperception software architect whiteboard architecture meeting whiteboard play crucial role daytoday life software architect frequently organize meeting whiteboard discuss new architecture propose change architecture mismatch architecture code much study software architect architecture produce produce detailed understanding whiteboard meeting still lack paper contribute mixedmethod study involve semistructure interview subsequent survey understand perception software architect whiteboard architecture meeting focus five aspect hold meeting impact experience level participant meeting architect document meeting kind change make meeting conclude result move implementation role digital whiteboard play study aspect identify observation relate technical aspect social aspect meeting insight implication research offer concrete advice practitioner provide guidance future tool design suggest way educate future software architect,0.6019417475728155,0.18446601941747573,0.10679611650485436,0.019417475728155338,103.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Design and Development,"Collaborative Design and Planning of Software Architecture Changes via
  Software City Visualization","Developers usually use diagrams and source code to jointly discuss and plan
software architecture changes. With this poster, we present our on-going work
on a novel approach that enables developers to collaboratively use software
city visualization to design and plan software architecture changes.",http://arxiv.org/abs/2408.16777v1,arXiv,collaborative design planning software architecture change via software city visualization,developer usually use diagram source code jointly discuss plan software architecture change poster present ongoing work novel approach enable developer collaboratively use software city visualization design plan software architecture change,collaborative design planning software architecture change via software city visualization developer usually use diagram source code jointly discuss plan software architecture change poster present ongoing work novel approach enable developer collaboratively use software city visualization design plan software architecture change,0.6333333333333333,0.13333333333333333,0.1,0.1,30.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Design and Development,Applying Slicing Technique to Software Architectures,"Software architecture is receiving increasingly attention as a critical
design level for software systems. As software architecture design resources
(in the form of architectural specifications) are going to be accumulated, the
development of techniques and tools to support architectural understanding,
testing, reengineering, maintenance, and reuse will become an important issue.
This paper introduces a new form of slicing, named architectural slicing, to
aid architectural understanding and reuse. In contrast to traditional slicing,
architectural slicing is designed to operate on the architectural specification
of a software system, rather than the source code of a program. Architectural
slicing provides knowledge about the high-level structure of a software system,
rather than the low-level implementation details of a program. In order to
compute an architectural slice, we present the architecture information flow
graph which can be used to represent information flows in a software
architecture. Based on the graph, we give a two-phase algorithm to compute an
architectural slice.",http://arxiv.org/abs/cs/0105008v1,arXiv,apply slicing technique software architecture,software architecture receive increasingly attention critical design level software system software architecture design resource form architectural specification accumulate development technique tool support architectural understanding testing reengineere maintenance reuse become important issue paper introduce new form slicing name architectural slicing aid architectural understanding reuse contrast traditional slicing architectural slicing design operate architectural specification software system rather source code program architectural slicing provide knowledge highlevel structure software system rather lowlevel implementation detail program order compute architectural slice present architecture information flow graph use represent information flow software architecture base graph give twophase algorithm compute architectural slice,apply slicing technique software architecture software architecture receive increasingly attention critical design level software system software architecture design resource form architectural specification accumulate development technique tool support architectural understanding testing reengineere maintenance reuse become important issue paper introduce new form slicing name architectural slicing aid architectural understanding reuse contrast traditional slicing architectural slicing design operate architectural specification software system rather source code program architectural slicing provide knowledge highlevel structure software system rather lowlevel implementation detail program order compute architectural slice present architecture information flow graph use represent information flow software architecture base graph give twophase algorithm compute architectural slice,0.6702127659574468,0.1276595744680851,0.14893617021276595,0.031914893617021274,94.0,1.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Design and Development,Top Down Approach: SIMULINK Mixed Hardware / Software Design,"System-level design methodologies have been introduced as a solution to
handle the design complexity of mixed Hardware / Software systems. In this
paper we describe a system-level design flow starting from Simulink
specification, focusing on concurrent hardware and software design and
verification at four different abstraction levels: System Simulink model,
Transaction Simulink model, Macro architecture, and micro architecture. We used
the MP3 CodeC application, to validate our approach and methodology.",http://arxiv.org/abs/1207.3872v1,arXiv,top approach simulink mixed hardware software design,systemlevel design methodology introduce solution handle design complexity mixed hardware software system paper describe systemlevel design flow start simulink specification focus concurrent hardware software design verification four different abstraction level system simulink model transaction simulink model macro architecture micro architecture use codec application validate approach methodology,top approach simulink mixed hardware software design systemlevel design methodology introduce solution handle design complexity mixed hardware software system paper describe systemlevel design flow start simulink specification focus concurrent hardware software design verification four different abstraction level system simulink model transaction simulink model macro architecture micro architecture use codec application validate approach methodology,0.717391304347826,0.06521739130434782,0.06521739130434782,0.0,46.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Design and Development,Using Dependence Analysis to Support Software Architecture Understanding,"Software architecture is receiving increasingly attention as a critical
design level for software systems. As software architecture design resources
(in the form of architectural descriptions) are going to be accumulated, the
development of techniques and tools to support architectural understanding,
testing, reengineering, maintaining, and reusing will become an important
issue. In this paper we introduce a new dependence analysis technique, named
architectural dependence analysis to support software architecture development.
In contrast to traditional dependence analysis, architectural dependence
analysis is designed to operate on an architectural description of a software
system, rather than the source code of a conventional program. Architectural
dependence analysis provides knowledge of dependences for the high-level
architecture of a software system, rather than the low-level implementation
details of a conventional program.",http://arxiv.org/abs/cs/0105009v1,arXiv,use dependence analysis support software architecture understanding,software architecture receive increasingly attention critical design level software system software architecture design resource form architectural description accumulate development technique tool support architectural understanding testing reengineere maintain reusing become important issue paper introduce new dependence analysis technique name architectural dependence analysis support software architecture development contrast traditional dependence analysis architectural dependence analysis design operate architectural description software system rather source code conventional program architectural dependence analysis provide knowledge dependence highlevel architecture software system rather lowlevel implementation detail conventional program,use dependence analysis support software architecture understanding software architecture receive increasingly attention critical design level software system software architecture design resource form architectural description accumulate development technique tool support architectural understanding testing reengineere maintain reusing become important issue paper introduce new dependence analysis technique name architectural dependence analysis support software architecture development contrast traditional dependence analysis architectural dependence analysis design operate architectural description software system rather source code conventional program architectural dependence analysis provide knowledge dependence highlevel architecture software system rather lowlevel implementation detail conventional program,0.6708860759493671,0.12658227848101267,0.1518987341772152,0.0379746835443038,79.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Design and Development,"Selection of Architecture Styles using Analytic Network Process for the
  Optimization of Software Architecture","The continuing process of software systems enlargement in size and complexity
becomes system design extremely important for software production. In this way,
the role of software architecture is significantly important in software
development. It serves as an evaluation and implementation plan for software
development and software evaluation. Consequently, choosing the correct
architecture is a critical issue in software engineering domain.
Moreover,software architecture selection is a multicriteria decision-making
problem in which different goals and objectives must be taken into
consideration. In this paper, more precise and suitable decisions in selection
of architecture styles have been presented by using ANP inference to support
decisions of software architects in order to exploit properties of styles in
the best way to optimize the design of software architecture.",http://arxiv.org/abs/1005.4271v1,arXiv,selection architecture style use analytic network process optimization software architecture,continue process software system enlargement size complexity become system design extremely important software production way role software architecture significantly important software development serve evaluation implementation plan software development software evaluation consequently choose correct architecture critical issue software engineering domain moreoversoftware architecture selection multicriteria decisionmake problem different goal objective must take consideration paper precise suitable decision selection architecture style present use anp inference support decision software architect order exploit property style good way optimize design software architecture,selection architecture style use analytic network process optimization software architecture continue process software system enlargement size complexity become system design extremely important software production way role software architecture significantly important software development serve evaluation implementation plan software development software evaluation consequently choose correct architecture critical issue software engineering domain moreoversoftware architecture selection multicriteria decisionmake problem different goal objective must take consideration paper precise suitable decision selection architecture style present use anp inference support decision software architect order exploit property style good way optimize design software architecture,0.6973684210526315,0.10526315789473684,0.10526315789473684,0.039473684210526314,76.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Theoretical / Conceptual,How do Software Ecosystems Co-Evolve? A view from OpenStack and beyond,"Much research that analyzes the evolution of a software ecosystem is confined
to its own boundaries. Evidence shows, however, that software ecosystems
co-evolve independently with other software ecosystems. In other words,
understanding the evolution of a software ecosystem requires an especially
astute awareness of its competitive landscape and much consideration for other
software ecosystems in related markets. A software ecosystem does not evolve in
insulation but with other software ecosystems. In this research, we analyzed
the OpenStack software ecosystem with a focal perspective that attempted to
understand its evolution as a function of other software ecosystems. We
attempted to understand and explain the evolution of OpenStack in relation to
other software ecosystems in the cloud computing market. Our findings add to
theoretical knowledge in software ecosystems by identifying and discussing
seven different mechanisms by which software ecosystems mutually influence each
other: sedimentation and embeddedness of business relationships, strategic
management of the portfolio of business relationships, firms values and
reputation as a partner, core technological architecture, design of the APIs,
competitive replication of functionality and multi-homing. Research addressing
the evolution of software ecosystem should, therefore, acknowledge that
software ecosystems entangle with other software ecosystems in multiple ways,
even with competing ones. A rigorous analysis of the evolution of a software
ecosystem should not be solely confined to its inner boundaries.",http://arxiv.org/abs/1808.06663v1,arXiv,software ecosystem coevolve view openstack beyond,much research analyze evolution software ecosystem confine boundary evidence show however software ecosystem coevolve independently software ecosystem word understand evolution software ecosystem require especially astute awareness competitive landscape much consideration software ecosystem related market software ecosystem evolve insulation software ecosystem research analyze openstack software ecosystem focal perspective attempt understand evolution function software ecosystem attempt understand explain evolution openstack relation software ecosystem cloud computing market finding add theoretical knowledge software ecosystem identify discuss seven different mechanism software ecosystem mutually influence sedimentation embeddedness business relationship strategic management portfolio business relationship firm value reputation partner core technological architecture design apis competitive replication functionality multihome research address evolution software ecosystem therefore acknowledge software ecosystem entangle software ecosystem multiple way even compete one rigorous analysis evolution software ecosystem solely confine inner boundary,software ecosystem coevolve view openstack beyond much research analyze evolution software ecosystem confine boundary evidence show however software ecosystem coevolve independently software ecosystem word understand evolution software ecosystem require especially astute awareness competitive landscape much consideration software ecosystem related market software ecosystem evolve insulation software ecosystem research analyze openstack software ecosystem focal perspective attempt understand evolution function software ecosystem attempt understand explain evolution openstack relation software ecosystem cloud computing market finding add theoretical knowledge software ecosystem identify discuss seven different mechanism software ecosystem mutually influence sedimentation embeddedness business relationship strategic management portfolio business relationship firm value reputation partner core technological architecture design apis competitive replication functionality multihome research address evolution software ecosystem therefore acknowledge software ecosystem entangle software ecosystem multiple way even compete one rigorous analysis evolution software ecosystem solely confine inner boundary,0.6692913385826772,0.12598425196850394,0.12598425196850394,0.05511811023622047,127.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Theoretical / Conceptual,"Architectural Support for Software Performance in Continuous Software
  Engineering: A Systematic Mapping Study","The continuous software engineering paradigm is gaining popularity in modern
development practices, where the interleaving of design and runtime activities
is induced by the continuous evolution of software systems. In this context,
performance assessment is not easy, but recent studies have shown that
architectural models evolving with the software can support this goal. In this
paper, we present a mapping study aimed at classifying existing scientific
contributions that deal with the architectural support for performance-targeted
continuous software engineering. We have applied the systematic mapping
methodology to an initial set of 215 potentially relevant papers and selected
66 primary studies that we have analyzed to characterize and classify the
current state of research. This classification helps to focus on the main
aspects that are being considered in this domain and, mostly, on the emerging
findings and implications for future research",http://arxiv.org/abs/2304.02489v1,arXiv,architectural support software performance continuous software engineer systematic mapping study,continuous software engineering paradigm gain popularity modern development practice interleaving design runtime activity induce continuous evolution software system context performance assessment easy recent study show architectural model evolve software support goal paper present mapping study aim classify exist scientific contribution deal architectural support performancetargeted continuous software engineering apply systematic mapping methodology initial set potentially relevant paper select primary study analyze characterize classify current state research classification help focus main aspect consider domain mostly emerge finding implication future research,architectural support software performance continuous software engineer systematic mapping study continuous software engineering paradigm gain popularity modern development practice interleaving design runtime activity induce continuous evolution software system context performance assessment easy recent study show architectural model evolve software support goal paper present mapping study aim classify exist scientific contribution deal architectural support performancetargeted continuous software engineering apply systematic mapping methodology initial set potentially relevant paper select primary study analyze characterize classify current state research classification help focus main aspect consider domain mostly emerge finding implication future research,0.6025641025641025,0.15384615384615385,0.20512820512820512,0.02564102564102564,78.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Theoretical / Conceptual,"A Systematic Mapping Study on Contract-based Software Design for
  Dependable Systems","Background: Contract-based Design (CbD) is a valuable methodology for
software design that allows annotation of code and architectural components
with contracts, thereby enhancing clarity and reliability in software
development. It establishes rules that outline the behaviour of software
components and their interfaces and interactions. This modular approach enables
the design process to be segmented into smaller, independently developed,
tested, and verified system components, ultimately leading to more robust and
dependable software. Aim: Despite the significance and well-established
theoretical background of CbD, there is a need for a comprehensive systematic
mapping study for reliable software systems. Our study provides an
evidence-based overview of a method and demonstrates its practical feasibility.
Method: To conduct this study, we systematically searched three different
databases using specially formulated queries, which initially yielded 1,221
primary studies. After voting, we focused on 288 primary studies for more
detailed analysis. Finally, a collaborative review allowed us to gather
relevant evidence and information to address our research questions. Results:
Our findings suggest potential avenues for future research trajectories in CbD,
emphasising its role in improving the dependability of software systems. We
highlight maturity levels across different domains and identify areas that may
benefit from further research. Conclusion: Although CbD is a well-established
software design approach, a more comprehensive literature review is needed to
clarify its theoretical state about dependable systems. Our study addresses
this gap by providing a detailed overview of CbD from various perspectives,
identifying key gaps, and suggesting future research directions.",http://arxiv.org/abs/2505.07542v1,arXiv,systematic mapping study contractbase software design dependable system,background contractbase design cbd valuable methodology software design allow annotation code architectural component contract thereby enhance clarity reliability software development establish rule outline behaviour software component interface interaction modular approach enable design process segment small independently develop tested verify system component ultimately lead robust dependable software aim despite significance wellestablishe theoretical background cbd need comprehensive systematic mapping study reliable software system study provide evidencebase overview method demonstrate practical feasibility method conduct study systematically search three different database use specially formulate query initially yield primary study vote focus primary study detailed analysis finally collaborative review allow gather relevant evidence information address research question result finding suggest potential avenue future research trajectory cbd emphasise role improve dependability software system highlight maturity level across different domain identify area may benefit research conclusion although cbd wellestablished software design approach comprehensive literature review need clarify theoretical state dependable system study address gap provide detailed overview cbd various perspective identify key gap suggest future research direction,systematic mapping study contractbase software design dependable system background contractbase design cbd valuable methodology software design allow annotation code architectural component contract thereby enhance clarity reliability software development establish rule outline behaviour software component interface interaction modular approach enable design process segment small independently develop tested verify system component ultimately lead robust dependable software aim despite significance wellestablishe theoretical background cbd need comprehensive systematic mapping study reliable software system study provide evidencebase overview method demonstrate practical feasibility method conduct study systematically search three different database use specially formulate query initially yield primary study vote focus primary study detailed analysis finally collaborative review allow gather relevant evidence information address research question result finding suggest potential avenue future research trajectory cbd emphasise role improve dependability software system highlight maturity level across different domain identify area may benefit research conclusion although cbd wellestablished software design approach comprehensive literature review need clarify theoretical state dependable system study address gap provide detailed overview cbd various perspective identify key gap suggest future research direction,0.55,0.175,0.16875,0.04375,160.0,0.0,0.0,0.0,1.0
Software Engineering,Software Design and Architecture,Theoretical / Conceptual,Towards a Theory on Architecting for Continuous Deployment,"Context: As the adoption of continuous delivery practices increases in
software organizations, different scenarios struggle to make it scales for
their products in long-term evolution. This study looks at the concrete
software architecture as a relevant factor for successfully achieving
continuous delivery goals. Objective: This study aims to understand how the
design of software architectures impacts the continuous deployment of their
software product. Method: We conducted a systematic literature review to
identify proper evidence regarding the research objective. We analyzed the
selected sources adopting a synthesis and analysis approach based on Grounded
Theory. Results: We selected 14 primary sources. Through our analysis process,
we developed a theory that explains the phenomenon of Architecting for
Continuous Deployment. The theory describes three other phenomena that support
Architecting for Continuous Deployment: Supporting Operations, Continuous
Evolution, and Improving Deployability. Furthermore, the theory comprises the
following elements: contexts, actions and interactions, quality attributes,
principles, and effects. We instantiated these elements and identified their
interrelationships. The theory is supported by providing bi-directional
traceability from the selected sources to the elements and vice-versa.
Conclusions: Developing adequate architecture plays a crucial role in enabling
continuous delivery. Supporting operations becomes vital to increase the
deployability and monitorability of software architecture. These two outcomes
require that developers accept responsibility for maintaining the operations.
The continuous evolution of the architecture is essential, but it must consider
balanced management of technical debt. Finally, improving deployability
requires attention to the test strategy and how it affects downtime to enable
efficient pipelines.",http://arxiv.org/abs/2108.09571v1,arXiv,towards theory architecte continuous deployment,context adoption continuous delivery practice increase software organization different scenario struggle make scale product longterm evolution study look concrete software architecture relevant factor successfully achieve continuous delivery goal objective study aim understand design software architecture impact continuous deployment software product method conduct systematic literature review identify proper evidence regard research objective analyze select source adopt synthesis analysis approach base grounded theory result select primary source analysis process develop theory explain phenomenon architecte continuous deployment theory describe three phenomenon support architecting continuous deployment support operation continuous evolution improve deployability furthermore theory comprise follow element context action interaction quality attribute principle effect instantiate element identify interrelationship theory support provide bidirectional traceability select source element viceversa conclusion develop adequate architecture play crucial role enable continuous delivery support operation become vital increase deployability monitorability software architecture two outcome require developer accept responsibility maintain operation continuous evolution architecture essential must consider balanced management technical debt finally improve deployability require attention test strategy affect downtime enable efficient pipeline,towards theory architecte continuous deployment context adoption continuous delivery practice increase software organization different scenario struggle make scale product longterm evolution study look concrete software architecture relevant factor successfully achieve continuous delivery goal objective study aim understand design software architecture impact continuous deployment software product method conduct systematic literature review identify proper evidence regard research objective analyze select source adopt synthesis analysis approach base grounded theory result select primary source analysis process develop theory explain phenomenon architecte continuous deployment theory describe three phenomenon support architecting continuous deployment support operation continuous evolution improve deployability furthermore theory comprise follow element context action interaction quality attribute principle effect instantiate element identify interrelationship theory support provide bidirectional traceability select source element viceversa conclusion develop adequate architecture play crucial role enable continuous delivery support operation become vital increase deployability monitorability software architecture two outcome require developer accept responsibility maintain operation continuous evolution architecture essential must consider balanced management technical debt finally improve deployability require attention test strategy affect downtime enable efficient pipeline,0.5802469135802469,0.18518518518518517,0.16666666666666666,0.018518518518518517,162.0,0.0,0.0,0.0,0.0
Software Engineering,Software Design and Architecture,Theoretical / Conceptual,Towards a “non-disposable” software infrastructure for participation,"<jats:p>For many years now our research team has been involved in an effort (both theoretical and technological) that can be labeled as an attempt to investigate the notion of cooperation from the ‘participation’ or ‘contribution’ perspective. From our perspective, it encompasses a set of situations in which different actors identified or unidentified, ratified or not, distributed in space and time, contribute to a sometimes ill-defined collective goal, using most of the time low-overhead web-based technologies. Doing so, people participate to a collective design that aims at generating a bunch of perpetually moving collective knowledge and decisions submitted to discussion, negotiation and sometimes dismissal. To avoid the design of services as a repeated ‘one-shot’ process we have gradually built a transverse software infrastructure that can be used in various projects aiming to design participatory services using complex knowledge and cooperations. Thanks to this “non-disposable” infrastructure, the participatory services designed take profit from the scientific outcomes of each previous project.</jats:p>",https://doi.org/10.55612/s-5002-018-005,CrossRef,towards nondisposable software infrastructure participation,jatspfor many year research team involve effort theoretical technological label attempt investigate notion cooperation participation contribution perspective perspective encompass set situation different actor identify unidentified ratify distribute space time contribute sometimes illdefine collective goal use time lowoverhead webbase technology people participate collective design aim generate bunch perpetually move collective knowledge decision submit discussion negotiation sometimes dismissal avoid design service repeat oneshot process gradually build transverse software infrastructure use various project aim design participatory service use complex knowledge cooperation thank nondisposable infrastructure participatory service design take profit scientific outcome previous projectjatsp,towards nondisposable software infrastructure participation jatspfor many year research team involve effort theoretical technological label attempt investigate notion cooperation participation contribution perspective perspective encompass set situation different actor identify unidentified ratify distribute space time contribute sometimes illdefine collective goal use time lowoverhead webbase technology people participate collective design aim generate bunch perpetually move collective knowledge decision submit discussion negotiation sometimes dismissal avoid design service repeat oneshot process gradually build transverse software infrastructure use various project aim design participatory service use complex knowledge cooperation thank nondisposable infrastructure participatory service design take profit scientific outcome previous projectjatsp,0.5666666666666667,0.18888888888888888,0.18888888888888888,0.044444444444444446,90.0,0.0,0.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Quantitative,Quality assurance for TTCN‐3 test specifications,"<jats:title>Abstract</jats:title><jats:p>Comprehensive testing of modern communication systems often requires large and complex test suites, which have to be maintained throughout the system life cycle. Industrial experience, with those written using the standardized <jats:italic>Testing and Test Control Notation</jats:italic> (TTCN‐3), has shown that this maintenance is a non‐trivial task and its burden can be reduced by means of appropriate concepts and tool support. To this aim, Motorola has collaborated with the University of Göttingen to develop TRex, an open‐source TTCN‐3 development environment, which notably provides suitable metrics and refactorings to enable the assessment and automatic restructuring of test suites. This article presents concepts like metrics and refactoring for the quality assurance of TTCN‐3 test suites and their implementation provided by the TRex tool. These means make it far easier to construct and maintain TTCN‐3 tests that are concise and optimally balanced with respect to maintainability quality characteristics. Copyright © 2008 John Wiley &amp; Sons, Ltd.</jats:p>",https://doi.org/10.1002/stvr.379,CrossRef,quality assurance test specification,jatstitleabstractjatstitlejatspcomprehensive testing modern communication system often require large complex test suite maintain throughout system life cycle industrial experience write use standardized jatsitalictesting test control notationjatsitalic show maintenance task burden reduce mean appropriate concept tool support aim motorola collaborate university göttingen develop trex development environment notably provide suitable metric refactoring enable assessment automatic restructuring test suite article present concept like metric refactore quality assurance test suite implementation provide trex tool mean make far easy construct maintain test concise optimally balance respect maintainability quality characteristic copyright john wiley amp son ltdjatsp,quality assurance test specification jatstitleabstractjatstitlejatspcomprehensive testing modern communication system often require large complex test suite maintain throughout system life cycle industrial experience write use standardized jatsitalictesting test control notationjatsitalic show maintenance task burden reduce mean appropriate concept tool support aim motorola collaborate university göttingen develop trex development environment notably provide suitable metric refactoring enable assessment automatic restructuring test suite article present concept like metric refactore quality assurance test suite implementation provide trex tool mean make far easy construct maintain test concise optimally balance respect maintainability quality characteristic copyright john wiley amp son ltdjatsp,0.5056179775280899,0.14606741573033707,0.19101123595505617,0.0449438202247191,89.0,1.0,0.0,0.0,1.0
Software Engineering,Software Testing and Quality Assurance,Quantitative,First step in development and evaluation simultaneous determination of mycotoxins in cereals by liquid chromatography - mass spectrometry,"<jats:p>Currently, solid phase extraction (SPE) with immunoaffinity columns is applied in&amp;nbsp;most standardized methods for mycotoxin determination to purify extracts and analysis by&amp;nbsp;HPLC-FLD, HPLC-UV/VIS or LC-MS/MS. Therefore, sample preparation and analysis by&amp;nbsp;instruments are time-consuming and high operating costs. The novel method allow&amp;nbsp;simultaneously identify nine mycotoxin compounds with selective, stable and accurate&amp;nbsp;results. The new method has been evaluated through three stages including validation as&amp;nbsp;requirements of CEN/TR 16059:2010 (phase 1), comparison with current standard methods&amp;nbsp;(phase 2), evaluate the method using an interlaboratory comparison program (phase 3). Cereal samples were extracted by QuEChERS and analyzed by LC-MS/MS. The limit&amp;nbsp;of quantitation (LOQ) was 0,5 &amp;mu;g/kg for each aflatoxin compound and 40 &amp;mu;g/kg, 25 &amp;mu;g/kg,&amp;nbsp;1 &amp;mu;g/kg, 75 &amp;mu;g/kg for&amp;nbsp;deoxynivalenol, zearalenone, ochratoxin A, each toxin fumonisin (B1&amp;amp;B2), respectively. The recovery is in the range of 70-120%, relative standard deviation&amp;nbsp;RSD &amp;lt; 20%. The novel method also gives the same results compared to the individual&amp;nbsp;standardized methods, using the immunoaffinity column in the extraction stage. At the&amp;nbsp;present, the method is being evaluated through an interlaboratory comparison program with&amp;nbsp;two rounds: round 1 (for survey) and round 2 (official round), which is expected to be&amp;nbsp;implemented in 2022. &amp;nbsp;    </jats:p>",https://doi.org/10.47866/2615-9252/vjfc.3959,CrossRef,first step development evaluation simultaneous determination mycotoxin cereal liquid chromatography mass spectrometry,jatspcurrently solid phase extraction spe immunoaffinity column apply inampnbspmost standardize method mycotoxin determination purify extract analysis byampnbsphplcfld hplcuvvis lcmsm therefore sample preparation analysis byampnbspinstrument timeconsuming high operating cost novel method allowampnbspsimultaneously identify nine mycotoxin compound selective stable accurateampnbspresult new method evaluate three stage include validation asampnbsprequirement centr phase comparison current standard methodsampnbspphase evaluate method use interlaboratory comparison program phase cereal sample extract quecher analyze lcmsm limitampnbspof quantitation loq ampmugkg aflatoxin compound ampmugkg ampmugkgampnbsp ampmugkg ampmugkg forampnbspdeoxynivalenol zearalenone ochratoxin toxin fumonisin bampampb respectively recovery range relative standard deviationampnbsprsd amplt novel method also give result compare individualampnbspstandardize method use immunoaffinity column extraction stage theampnbsppresent method evaluate interlaboratory comparison program withampnbsptwo round round survey round official round expect beampnbspimplemente ampnbsp jatsp,first step development evaluation simultaneous determination mycotoxin cereal liquid chromatography mass spectrometry jatspcurrently solid phase extraction spe immunoaffinity column apply inampnbspmost standardize method mycotoxin determination purify extract analysis byampnbsphplcfld hplcuvvis lcmsm therefore sample preparation analysis byampnbspinstrument timeconsuming high operating cost novel method allowampnbspsimultaneously identify nine mycotoxin compound selective stable accurateampnbspresult new method evaluate three stage include validation asampnbsprequirement centr phase comparison current standard methodsampnbspphase evaluate method use interlaboratory comparison program phase cereal sample extract quecher analyze lcmsm limitampnbspof quantitation loq ampmugkg aflatoxin compound ampmugkg ampmugkgampnbsp ampmugkg ampmugkg forampnbspdeoxynivalenol zearalenone ochratoxin toxin fumonisin bampampb respectively recovery range relative standard deviationampnbsprsd amplt novel method also give result compare individualampnbspstandardize method use immunoaffinity column extraction stage theampnbsppresent method evaluate interlaboratory comparison program withampnbsptwo round round survey round official round expect beampnbspimplemente ampnbsp jatsp,0.4491525423728814,0.13559322033898305,0.15254237288135594,0.05084745762711865,59.0,0.0,0.0,0.0,2.0
Software Engineering,Software Testing and Quality Assurance,Quantitative,A Quasi-Experimental Evaluation of Teaching Software Testing in Software Quality Assurance Subject during a Post-Graduate Computer Science Course,"<jats:p>Software testing is regarded as a key activity in the software development cycle, as it helps information technology professionals to design good quality software. Thus, this is an essential activity for the software industry, although with all its nuances high priority is still not being given to learning about it at an academic level. The purpose of this work is to investigate a teaching strategy for software testing which involves acquiring academic skills within a curriculum based on active teaching methodologies. A teaching model was designed for this to coordinate the different areas of a subject, and then a controlled quasi-experiment was carried out in a post-graduate course to evaluate the application of this model. The results obtained demonstrate that there was a considerable learning gain in the experimental group that adopted the teaching approach when compared with the control group that relied on a traditional approach. The student t-test was employed to determine the learning efficiency.</jats:p>",https://doi.org/10.3991/ijet.v17i05.25673,CrossRef,quasiexperimental evaluation teach software testing software quality assurance subject postgraduate computer science course,jatspsoftware testing regard key activity software development cycle help information technology professional design good quality software thus essential activity software industry although nuance high priority still give learn academic level purpose work investigate teaching strategy software testing involve acquire academic skill within curriculum base active teaching methodology teaching model design coordinate different area subject control quasiexperiment carry postgraduate course evaluate application model result obtain demonstrate considerable learning gain experimental group adopt teaching approach compare control group rely traditional approach student ttest employ determine learning efficiencyjatsp,quasiexperimental evaluation teach software testing software quality assurance subject postgraduate computer science course jatspsoftware testing regard key activity software development cycle help information technology professional design good quality software thus essential activity software industry although nuance high priority still give learn academic level purpose work investigate teaching strategy software testing involve acquire academic skill within curriculum base active teaching methodology teaching model design coordinate different area subject control quasiexperiment carry postgraduate course evaluate application model result obtain demonstrate considerable learning gain experimental group adopt teaching approach compare control group rely traditional approach student ttest employ determine learning efficiencyjatsp,0.5882352941176471,0.18823529411764706,0.1411764705882353,0.023529411764705882,85.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Quantitative,Assuring the Quality of Data Through Laboratory Quality Assurance,"<jats:title>Abstract</jats:title>
               <jats:p>Assuring the quality of data produced by analytical chemistry laboratories is important, not only because analytical chemists have a professional obligation to do so for those using their data, but also because of today's climate of regulations and high public concern over issues involving analytical laboratories. Assurance goes beyond the technical adequacy of methods used to make analyses and the control of the measurement process through calibration and statistical control. It concerns also overall control of operations through various administrative practices. The combination of technical and administrative practices constitutes a quality assurance program that will help assure the quality of data. Such a quality assurance program is described, which is based on nine elements of laboratory quality assurance derived from a nationally established standard on quality assurance. These nine elements are the basis for a new ASTM standard, Standard Guide for Establishing a Quality Assurance Program for Analytical Chemistry Laboratories within the Nuclear Industry (C 1009).</jats:p>",https://doi.org/10.1520/jte10726j,CrossRef,assure quality datum laboratory quality assurance,jatstitleabstractjatstitle jatspassure quality datum produce analytical chemistry laboratory important analytical chemist professional obligation use datum also today climate regulation high public concern issue involve analytical laboratory assurance beyond technical adequacy method use make analysis control measurement process calibration statistical control concern also overall control operation various administrative practice combination technical administrative practice constitute quality assurance program help assure quality datum quality assurance program describe base nine element laboratory quality assurance derive nationally establish standard quality assurance nine element basis new astm standard standard guide establish quality assurance program analytical chemistry laboratory within nuclear industry jatsp,assure quality datum laboratory quality assurance jatstitleabstractjatstitle jatspassure quality datum produce analytical chemistry laboratory important analytical chemist professional obligation use datum also today climate regulation high public concern issue involve analytical laboratory assurance beyond technical adequacy method use make analysis control measurement process calibration statistical control concern also overall control operation various administrative practice combination technical administrative practice constitute quality assurance program help assure quality datum quality assurance program describe base nine element laboratory quality assurance derive nationally establish standard quality assurance nine element basis new astm standard standard guide establish quality assurance program analytical chemistry laboratory within nuclear industry jatsp,0.5684210526315789,0.08421052631578947,0.2,0.031578947368421054,95.0,0.0,0.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Quantitative,Methodology for Quality Assurance of Educational Software,"<jats:p>Evaluating the quality of educational software is a priority given the number of educational systems currently being produced. The article carries out a documentary analysis to search for documents that have addressed these elements. The results address the main documents that have been obtained. Subsequently, a methodology containing a system of metrics to evaluate the quality of educational software is proposed.
</jats:p>",https://doi.org/10.32388/gictbh,CrossRef,methodology quality assurance educational software,jatspevaluate quality educational software priority give number educational system currently produce article carry documentary analysis search document address element result address main document obtain subsequently methodology contain system metric evaluate quality educational software propose jatsp,methodology quality assurance educational software jatspevaluate quality educational software priority give number educational system currently produce article carry documentary analysis search document address element result address main document obtain subsequently methodology contain system metric evaluate quality educational software propose jatsp,0.5714285714285714,0.17142857142857143,0.17142857142857143,0.05714285714285714,35.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Qualitative,The value of a proper software quality assurance methodology,"<jats:p>This paper describes the experiences of a project development team during an attempt to ensure the quality of a new software product. This product was created by a team of software engineers at Digital Equipment Corporation, a mainframe manufacturer. As a result, the definition of “to ensure the quality of a software product” meant minimizing the maintenance costs of the new product. Ease of maintenance and a low bug rate after release to the customer were very important goals from the beginning of the project.</jats:p>
          <jats:p>This paper compares the degree of application and resultant effects of several software quality assurance methodologies upon different parts of the final product. Many of the product's subsystems were created using all of the discussed methodologies rigorously. Some subsystems were created with little or no use of the methodologies. Other subsystems used a mixture. The observed quality of the various subsystems when related to the methodology used to create them provides insights into the interactions between the methodologies. These observations also supply additional experience to reinforce established beliefs concerning the value of quality assurance methodologies.</jats:p>",https://doi.org/10.1145/953579.811118,CrossRef,value proper software quality assurance methodology,jatspthis paper describe experience project development team attempt ensure quality new software product product create team software engineer digital equipment corporation mainframe manufacturer result definition ensure quality software product mean minimize maintenance cost new product ease maintenance low bug rate release customer important goal beginning projectjatsp jatspthis paper compare degree application resultant effect several software quality assurance methodology upon different part final product many product subsystem create use discuss methodology rigorously subsystem create little use methodology subsystem use mixture observed quality various subsystem relate methodology use create provide insight interaction methodology observation also supply additional experience reinforce establish belief concern value quality assurance methodologiesjatsp,value proper software quality assurance methodology jatspthis paper describe experience project development team attempt ensure quality new software product product create team software engineer digital equipment corporation mainframe manufacturer result definition ensure quality software product mean minimize maintenance cost new product ease maintenance low bug rate release customer important goal beginning projectjatsp jatspthis paper compare degree application resultant effect several software quality assurance methodology upon different part final product many product subsystem create use discuss methodology rigorously subsystem create little use methodology subsystem use mixture observed quality various subsystem relate methodology use create provide insight interaction methodology observation also supply additional experience reinforce establish belief concern value quality assurance methodologiesjatsp,0.6730769230769231,0.14423076923076922,0.1346153846153846,0.019230769230769232,104.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Qualitative,A Customized Quality Model for Software Quality Assurance in Agile Environment,"<p>The agile approach grew dramatically over traditional approaches. The methodology focuses more on rapid development, quick evaluation, quantifiable progress and continuous delivery satisfying the customer desire. In view of this, there is a need for measurement of the agile development process. In this respect, the present research work investigates the inter-relationships and inter-dependencies between the identified quality factors (QF), thereby outlining which of these QF have high driving power and dependence power, working indirectly towards the success of agile development process. This paper proposes a new agile quality model, utilizing an interpretive structural modeling (ISM) approach and the identified factors are classifies using Matriced' Impacts Croise's Multiplication Applique´e a UN Classement (MICMAC) approach. The research findings can significantly impact agile development process by understanding how these QF related to each other and how they can be adopted.</p>",https://doi.org/10.4018/ijitwe.2019070104,CrossRef,customize quality model software quality assurance agile environment,pthe agile approach grow dramatically traditional approach methodology focus rapid development quick evaluation quantifiable progress continuous delivery satisfy customer desire view need measurement agile development process respect present research work investigate interrelationship interdependency identify quality factor thereby outline high driving power dependence power work indirectly towards success agile development process paper propose new agile quality model utilize interpretive structural modeling ism approach identify factor classifie use matriced impact croise multiplication classement micmac approach research finding significantly impact agile development process understand relate adoptedp,customize quality model software quality assurance agile environment pthe agile approach grow dramatically traditional approach methodology focus rapid development quick evaluation quantifiable progress continuous delivery satisfy customer desire view need measurement agile development process respect present research work investigate interrelationship interdependency identify quality factor thereby outline high driving power dependence power work indirectly towards success agile development process paper propose new agile quality model utilize interpretive structural modeling ism approach identify factor classifie use matriced impact croise multiplication classement micmac approach research finding significantly impact agile development process understand relate adoptedp,0.5662650602409639,0.1566265060240964,0.1927710843373494,0.04819277108433735,83.0,2.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Qualitative,"Risk Management, Quality Assurance, and Health Care Policy Dilemmas","<jats:p> Editor's Note: The following article, coauthored by the QAUR Case Study Editor, and Reginald F. Wells, Ph.D. (2.) is presented to demonstrate the utility of risk management when, as a component of a comprehensive QA initiative, it is applied to critical policy dilemmas facing health care providers today. The practical application of RM in formulating an AIDS policy for a public MRDD service agency is outlined as a strategic example-the ""case study"" if you will. Paper was presented by the authors at the 112th Annual Meeting of the AAMR, Washington Hilton Hotel, Washington, D. C. </jats:p>",https://doi.org/10.1177/0885713x8900400206,CrossRef,risk management quality assurance health care policy dilemma,jatsp editor note follow article coauthore qaur case study editor reginald wells phd present demonstrate utility risk management component comprehensive initiative apply critical policy dilemma face health care provider today practical application formulate aids policy public mrdd service agency outline strategic examplethe case study paper present author annual meeting aamr washington hilton hotel washington jatsp,risk management quality assurance health care policy dilemma jatsp editor note follow article coauthore qaur case study editor reginald wells phd present demonstrate utility risk management component comprehensive initiative apply critical policy dilemma face health care provider today practical application formulate aids policy public mrdd service agency outline strategic examplethe case study paper present author annual meeting aamr washington hilton hotel washington jatsp,0.509090909090909,0.07272727272727272,0.12727272727272726,0.0,55.0,1.0,2.0,2.0,2.0
Software Engineering,Software Testing and Quality Assurance,Qualitative,A Performance Appraisal System for Quality Assurance and Utilization Review Fellows,"<jats:p> There is now increased interest in developing con tinuing education and career training progams in quality assurance and utilization review. These pro grams frequently involve on-site practicum experi ences for which the performance appraisal system described here was developed. Incorporating a new evaluation technology known as the rating grid, this system is discussed here in terms of its underlying rationale, its rating factors, and the observation and scoring factors used by the observer-evaluator. The system can be used by observers to give feedback to physicians and others undergoing training in quality assurance and utilization review. </jats:p>",https://doi.org/10.1177/0885713x8900400303,CrossRef,performance appraisal system quality assurance utilization review fellow,jatsp increase interest develop con tinue education career training progam quality assurance utilization review pro gram frequently involve onsite practicum experi ence performance appraisal system describe develop incorporate new evaluation technology know rating grid system discuss term underlie rationale rating factor observation scoring factor use observerevaluator system use observer give feedback physician undergo training quality assurance utilization review jatsp,performance appraisal system quality assurance utilization review fellow jatsp increase interest develop con tinue education career training progam quality assurance utilization review pro gram frequently involve onsite practicum experi ence performance appraisal system describe develop incorporate new evaluation technology know rating grid system discuss term underlie rationale rating factor observation scoring factor use observerevaluator system use observer give feedback physician undergo training quality assurance utilization review jatsp,0.6271186440677966,0.1694915254237288,0.06779661016949153,0.01694915254237288,59.0,1.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Qualitative,Quality assurance and student work experience,"<jats:p>This article is based on the premise that owing to the substantial attention given to quality assurance and related initiatives in higher education in recent years, the management, and related practices involved, of student work experience will have improved. To investigate this hypothesis a comparative analysis of the findings of two major research projects, involving similar methods, into student work experience is undertaken. The two studies are discussed, criteria for comparative analysis are identified and key findings presented. This leads to the conclusion, that while there is evidence of substantial improvement in the probability of students gaining experience in the preparation of curricula vitae and of interview situations, little progress has been made in enhancing the realisation of the many other benefits attributable to student work experience. Recommendations to address the identified weaknesses in the system are proposed.</jats:p>",https://doi.org/10.1108/09684889910297712,CrossRef,quality assurance student work experience,jatspthis article base premise owe substantial attention give quality assurance related initiative high education recent year management related practice involve student work experience improve investigate hypothesis comparative analysis finding two major research project involve similar method student work experience undertake two study discuss criterion comparative analysis identify key finding present lead conclusion evidence substantial improvement probability student gain experience preparation curricula vitae interview situation little progress make enhance realisation many benefit attributable student work experience recommendation address identify weakness system proposedjatsp,quality assurance student work experience jatspthis article base premise owe substantial attention give quality assurance related initiative high education recent year management related practice involve student work experience improve investigate hypothesis comparative analysis finding two major research project involve similar method student work experience undertake two study discuss criterion comparative analysis identify key finding present lead conclusion evidence substantial improvement probability student gain experience preparation curricula vitae interview situation little progress make enhance realisation many benefit attributable student work experience recommendation address identify weakness system proposedjatsp,0.5925925925925926,0.19753086419753085,0.1728395061728395,0.0,81.0,0.0,0.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Mixed Methods,Software quality: A Historical and Synthetic Content Analysis,"Interconnected computers and software systems have become an indispensable
part of people's lives, therefore software quality research is becoming more
and more important. There have been multiple attempts to synthesize knowledge
gained in software quality research, however, they were focused mainly on
single aspects of software quality and not to structure the knowledge in a
holistic way. The aim of our study was to close this gap. The software quality
publications were harvested from the Scopus bibliographic database. The
metadata was exported first to CRexlporer, which was employed to identify
historical roots, and next to VOSViewer, which was used as a part of the
synthetic content analysis. In our study we defined synthetic context analysis
as a triangulation of bibliometrics and content analysis. Our search resulted
in 14451 publications. The performance bibliometric study showed that the
production of research publications relating to software quality is currently
following an exponential growth trend and that the software quality research
community is growing. The most productive country was the United States and the
most productive Institution The Florida Atlantic University. The synthetic
content analysis revealed that the published knowledge can be structured into
10 themes, the most important being the themes regarding software quality
improvement with enhancing software engineering, advanced software testing, and
improved defect and fault prediction with machine learning and data mining.
According to the analysis of the hot topics, it seems that future research will
be directed into developing and using a full specter of new artificial
intelligence tools (not just machine learning and data mining) and focusing on
how to assure software quality in agile development paradigms.",http://arxiv.org/abs/2106.14598v1,arXiv,software quality historical synthetic content analysis,interconnect computer software system become indispensable part people live therefore software quality research become important multiple attempt synthesize knowledge gain software quality research however focus mainly single aspect software quality structure knowledge holistic way aim study close gap software quality publication harvest scopus bibliographic database metadata export first crexlporer employ identify historical root next vosviewer use part synthetic content analysis study define synthetic context analysis triangulation bibliometric content analysis search result publication performance bibliometric study show production research publication relate software quality currently follow exponential growth trend software quality research community grow productive country united states productive institution florida atlantic university synthetic content analysis reveal publish knowledge structure theme important theme regard software quality improvement enhance software engineer advanced software testing improve defect fault prediction machine learning datum mining accord analysis hot topic seem future research direct develop use full specter new artificial intelligence tool machine learning datum mining focus assure software quality agile development paradigm,software quality historical synthetic content analysis interconnect computer software system become indispensable part people live therefore software quality research become important multiple attempt synthesize knowledge gain software quality research however focus mainly single aspect software quality structure knowledge holistic way aim study close gap software quality publication harvest scopus bibliographic database metadata export first crexlporer employ identify historical root next vosviewer use part synthetic content analysis study define synthetic context analysis triangulation bibliometric content analysis search result publication performance bibliometric study show production research publication relate software quality currently follow exponential growth trend software quality research community grow productive country united states productive institution florida atlantic university synthetic content analysis reveal publish knowledge structure theme important theme regard software quality improvement enhance software engineer advanced software testing improve defect fault prediction machine learning datum mining accord analysis hot topic seem future research direct develop use full specter new artificial intelligence tool machine learning datum mining focus assure software quality agile development paradigm,0.6217948717948718,0.11538461538461539,0.14743589743589744,0.02564102564102564,156.0,1.0,1.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Mixed Methods,Product Backlog Rating: A Case Study On Measuring Test Quality In Scrum,"Agile software development methodologies focus on software projects which are
behind schedule or highly likely to have a problematic development phase. In
the last decade, Agile methods have transformed from cult techniques to
mainstream methodologies. Scrum, an Agile software development method, has been
widely adopted due to its adaptive nature.
  This paper presents a metric that measures the quality of the testing process
in a Scrum process. As product quality and process quality correlate, improved
test quality can ensure high quality products. Also, gaining experience from
eight years of successful Scrum implementation at SoftwarePeople, we describe
the Scrum process emphasizing the testing process. We propose a metric Product
Backlog Rating (PBR) to assess the testing process in Scrum. PBR considers the
complexity of the features to be developed in an iteration of Scrum, assesses
test ratings and offers a numerical score of the testing process. This metric
is able to provide a comprehensive overview of the testing process over the
development cycle of a product.
  We present a case study which shows how the metric is used at SoftwarePeople.
The case study explains some features that have been developed in a Sprint in
terms of feature complexity and potential test assessment difficulties and
shows how PBR is calculated during the Sprint. We propose a test process
assessment metric that provides insights into the Scrum testing process.
However, the metric needs further evaluation considering associated resources
(e.g., quality assurance engineers, the length of the Scrum cycle).",http://arxiv.org/abs/1310.2545v2,arXiv,product backlog rate case study measure test quality scrum,agile software development methodology focus software project behind schedule highly likely problematic development phase last decade agile method transform cult technique mainstream methodology scrum agile software development method widely adopt due adaptive nature paper present metric measure quality testing process scrum process product quality process quality correlate improve test quality ensure high quality product also gain experience eight year successful scrum implementation softwarepeople describe scrum process emphasize testing process propose metric product backlog rate pbr assess testing process scrum pbr consider complexity feature develop iteration scrum assess test rating offer numerical score testing process metric able provide comprehensive overview testing process development cycle product present case study show metric use softwarepeople case study explain feature develop sprint term feature complexity potential test assessment difficulty show pbr calculate sprint propose test process assessment metric provide insight scrum testing process however metric need evaluation consider associate resource quality assurance engineer length scrum cycle,product backlog rate case study measure test quality scrum agile software development methodology focus software project behind schedule highly likely problematic development phase last decade agile method transform cult technique mainstream methodology scrum agile software development method widely adopt due adaptive nature paper present metric measure quality testing process scrum process product quality process quality correlate improve test quality ensure high quality product also gain experience eight year successful scrum implementation softwarepeople describe scrum process emphasize testing process propose metric product backlog rate pbr assess testing process scrum pbr consider complexity feature develop iteration scrum assess test rating offer numerical score testing process metric able provide comprehensive overview testing process development cycle product present case study show metric use softwarepeople case study explain feature develop sprint term feature complexity potential test assessment difficulty show pbr calculate sprint propose test process assessment metric provide insight scrum testing process however metric need evaluation consider associate resource quality assurance engineer length scrum cycle,0.6291390728476821,0.13245033112582782,0.15894039735099338,0.026490066225165563,151.0,1.0,0.0,2.0,0.0
Software Engineering,Software Testing and Quality Assurance,Mixed Methods,Quality Assurance Practices in Agile Methodology,"The complexity of software is increasing day by day the requirement and need
for a verity of softwareproducts increases, this necessitates the provision of
a strong tool that will make a balance betweenproduction and quality. The
practice of applying software metrics to the development process and to
asoftware product is a critical task and crucial enough that requires study and
discipline and whichbrings knowledge of the status of the process and/or
product of software in regards to the goals toachieve, this discipline is known
as quality assurance which is the key factor behind the success ofevery
software engineering project, the quality assurance activities are what result
in the qualitativeproduct as well as the process in both conventional software
development methodology and agilemethodology. However, agile methodology is now
becoming one of the dominant method adopted bymost of the software industries
because it allows developing of software with very limited requirementand
supports rapid changes in the requirement, the method may produce the product
very fast but wemight not guarantee the quality of the product unless we apply
the SQA activities to the process. Thisresearch paper aimed to study the
quality assurance activities practice in agile software developmentmethodology,
investigate the common problems and key drivers of quality in agile, and
propose asolution to improve the practice of SQA in agile methodology by
analyzing the parameters that assurequality in agile software.",http://arxiv.org/abs/2411.05134v1,arXiv,quality assurance practice agile methodology,complexity software increase day day requirement need verity softwareproduct increase necessitate provision strong tool make balance betweenproduction quality practice apply software metric development process asoftware product critical task crucial enough require study discipline whichbring knowledge status process andor product software regard goal toachieve discipline know quality assurance key factor behind success ofevery software engineering project quality assurance activity result qualitativeproduct well process conventional software development methodology agilemethodology however agile methodology become one dominant method adopt bymost software industry allow develop software limited requirementand support rapid change requirement method may produce product fast wemight guarantee quality product unless apply sqa activity process thisresearch paper aim study quality assurance activity practice agile software developmentmethodology investigate common problem key driver quality agile propose asolution improve practice sqa agile methodology analyze parameter assurequality agile software,quality assurance practice agile methodology complexity software increase day day requirement need verity softwareproduct increase necessitate provision strong tool make balance betweenproduction quality practice apply software metric development process asoftware product critical task crucial enough require study discipline whichbring knowledge status process andor product software regard goal toachieve discipline know quality assurance key factor behind success ofevery software engineering project quality assurance activity result qualitativeproduct well process conventional software development methodology agilemethodology however agile methodology become one dominant method adopt bymost software industry allow develop software limited requirementand support rapid change requirement method may produce product fast wemight guarantee quality product unless apply sqa activity process thisresearch paper aim study quality assurance activity practice agile software developmentmethodology investigate common problem key driver quality agile propose asolution improve practice sqa agile methodology analyze parameter assurequality agile software,0.6030534351145038,0.16030534351145037,0.15267175572519084,0.015267175572519083,131.0,1.0,0.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Mixed Methods,A Hybrid Software Test Automation for Educational Portals,"Educational portal (EP) is a multi-function website that allows access to
activities such as public and private sections, data retrieval and submission,
personalized content and so on for the educational system. This study
investigated the specific requirement for the enhancement of quality and
behavior of EP with regards to time and cost using Obafemi Awolowo University
(OAU), Ile-Ife, Nigeria as a case study. A test automation framework was
designed using unified modelling language and implemented in Java programming
language. MySQL and Excel database were used to store test data. The framework
developed was evaluated using Test Time Performance (TTP), Performance Test
Efficiency (PTE) and Automation Scripting Productivity (ASP) metrics. The
results from the evaluation of the sample data provided showed that ASP
produced a tested outcome of 360 operations per hour, PTE yielded 80% and TTP
was just 4%. Based on the recorded performance, it is evident that the research
can provide quick and firsthand information to quality assurance analyst and
software testers, thereby reducing maintenance cost during software
development.",http://arxiv.org/abs/2111.00222v1,arXiv,hybrid software test automation educational portal,educational portal multifunction website allow access activity public private section data retrieval submission personalize content educational system study investigate specific requirement enhancement quality behavior regard time cost use obafemi awolowo university oau ileife nigeria case study test automation framework design use unified modelling language implement java programming language mysql excel database use store test datum framework develop evaluate use test time performance ttp performance test efficiency pte automation script productivity asp metric result evaluation sample datum provide show asp produce tested outcome operation per hour pte yield ttp base record performance evident research provide quick firsthand information quality assurance analyst software tester thereby reduce maintenance cost software development,hybrid software test automation educational portal educational portal multifunction website allow access activity public private section data retrieval submission personalize content educational system study investigate specific requirement enhancement quality behavior regard time cost use obafemi awolowo university oau ileife nigeria case study test automation framework design use unified modelling language implement java programming language mysql excel database use store test datum framework develop evaluate use test time performance ttp performance test efficiency pte automation script productivity asp metric result evaluation sample datum provide show asp produce tested outcome operation per hour pte yield ttp base record performance evident research provide quick firsthand information quality assurance analyst software tester thereby reduce maintenance cost software development,0.7037037037037037,0.10185185185185185,0.10185185185185185,0.018518518518518517,108.0,1.0,0.0,0.0,2.0
Software Engineering,Software Testing and Quality Assurance,Mixed Methods,Optical quality assurance of GEM foils,"An analysis software was developed for the high aspect ratio optical scanning
system in the Detec- tor Laboratory of the University of Helsinki and the
Helsinki Institute of Physics. The system is used e.g. in the quality assurance
of the GEM-TPC detectors being developed for the beam diagnostics system of the
SuperFRS at future FAIR facility. The software was tested by analyzing five
CERN standard GEM foils scanned with the optical scanning system. The
measurement uncertainty of the diameter of the GEM holes and the pitch of the
hole pattern was found to be 0.5 {\mu}m and 0.3 {\mu}m, respectively. The
software design and the performance are discussed. The correlation between the
GEM hole size distribution and the corresponding gain variation was studied by
comparing them against a detailed gain mapping of a foil and a set of six lower
precision control measurements. It can be seen that a qualitative estimation of
the behavior of the local variation in gain across the GEM foil can be made
based on the measured sizes of the outer and inner holes.",http://arxiv.org/abs/1704.06691v1,arXiv,optical quality assurance gem foil,analysis software develop high aspect ratio optical scanning system detec tor laboratory university helsinki helsinki institute physics system use quality assurance gemtpc detector develop beam diagnostic system superfrs future fair facility software test analyze five cern standard gem foil scan optical scanning system measurement uncertainty diameter gem hole pitch hole pattern find mum mum respectively software design performance discuss correlation gem hole size distribution corresponding gain variation study compare detailed gain mapping foil set six low precision control measurement see qualitative estimation behavior local variation gain across gem foil make base measured size outer inner hole,optical quality assurance gem foil analysis software develop high aspect ratio optical scanning system detec tor laboratory university helsinki helsinki institute physics system use quality assurance gemtpc detector develop beam diagnostic system superfrs future fair facility software test analyze five cern standard gem foil scan optical scanning system measurement uncertainty diameter gem hole pitch hole pattern find mum mum respectively software design performance discuss correlation gem hole size distribution corresponding gain variation study compare detailed gain mapping foil set six low precision control measurement see qualitative estimation behavior local variation gain across gem foil make base measured size outer inner hole,0.6145833333333334,0.13541666666666666,0.14583333333333334,0.010416666666666666,96.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Design and Development,Hybrid software testing model to improve software quality assurance,"<jats:p>Software testing is a very critical factor in determining the quality, robustness and reliability of applications. Testing methods have advanced to accommodate the various software development practices that are being churned out at frequent rates and representing complex systems. One such method is the hybrid software testing model, which combines the strengths of different testing techniques to achieve comprehensive testing coverage. This study provides an in-depth analysis of the hybrid software testing model, exploring its definition, benefits, challenges, and best practices. Furthermore, it discusses various testing techniques commonly used in hybrid testing and presents case studies showcasing the successful implementation of the hybrid model in real-world scenarios.</jats:p>",https://doi.org/10.30574/gjeta.2023.17.1.0206,CrossRef,hybrid software testing model improve software quality assurance,jatspsoftware testing critical factor determine quality robustness reliability application testing method advance accommodate various software development practice churn frequent rate represent complex system one method hybrid software testing model combine strength different testing technique achieve comprehensive testing coverage study provide indepth analysis hybrid software testing model explore definition benefit challenge good practice furthermore discuss various testing technique commonly use hybrid testing present case study showcase successful implementation hybrid model realworld scenariosjatsp,hybrid software testing model improve software quality assurance jatspsoftware testing critical factor determine quality robustness reliability application testing method advance accommodate various software development practice churn frequent rate represent complex system one method hybrid software testing model combine strength different testing technique achieve comprehensive testing coverage study provide indepth analysis hybrid software testing model explore definition benefit challenge good practice furthermore discuss various testing technique commonly use hybrid testing present case study showcase successful implementation hybrid model realworld scenariosjatsp,0.5352112676056338,0.15492957746478872,0.2112676056338028,0.028169014084507043,71.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Design and Development,Study on CMM-Based Software Quality Assurance Process Improvement - A Case of the Educational Software Quality Assurance Model,"<jats:p>This paper mainly make a theoretical research and exploration on software quality assurance quality assurance improvement based on CMM process, with the educational software quality assurance model as an example. It elucidates the relationship between educational software process improvement and quality assurance, and explicits the importance of educational software development process improvement to the quality of educational software. Additionally, it discussed the establishment of educational software development model on the basis of the waterfall model of traditional software development, and construction of process quality management models and platforms based on CMM educational software process improvement.</jats:p>",https://doi.org/10.4028/www.scientific.net/amr.1049-1050.2032,CrossRef,study cmmbase software quality assurance process improvement case educational software quality assurance model,jatspthis paper mainly make theoretical research exploration software quality assurance quality assurance improvement base cmm process educational software quality assurance model example elucidate relationship educational software process improvement quality assurance explicit importance educational software development process improvement quality educational software additionally discuss establishment educational software development model basis waterfall model traditional software development construction process quality management model platform base cmm educational software process improvementjatsp,study cmmbase software quality assurance process improvement case educational software quality assurance model jatspthis paper mainly make theoretical research exploration software quality assurance quality assurance improvement base cmm process educational software quality assurance model example elucidate relationship educational software process improvement quality assurance explicit importance educational software development process improvement quality educational software additionally discuss establishment educational software development model basis waterfall model traditional software development construction process quality management model platform base cmm educational software process improvementjatsp,0.7230769230769231,0.03076923076923077,0.15384615384615385,0.03076923076923077,65.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Design and Development,Generative AI for software testing: Harnessing large language models for automated and intelligent quality assurance,"<jats:p>Software testing is indispensable for ensuring that modern applications meet rigorous standards of functionality, reliability, and security. However, the complexity and pace of contemporary software development often overwhelm traditional and even AI-based testing approaches, leading to gaps in coverage, delayed feedback, and increased maintenance costs. Recent breakthroughs in Generative AI, particularly Large Language Models (LLMs), offer a new avenue for automating and optimizing testing processes. These models can dynamically generate test cases, predict system vulnerabilities, handle continuous software changes, and reduce the burden on human testers. This paper explores how Generative AI complements and advances established AI-driven testing frameworks, outlines the associated challenges of data preparation and governance, and proposes future directions for fully autonomous, trustworthy testing solutions.</jats:p>",https://doi.org/10.30574/ijsra.2025.14.1.0266,CrossRef,generative software testing harness large language model automated intelligent quality assurance,jatspsoftware testing indispensable ensure modern application meet rigorous standard functionality reliability security however complexity pace contemporary software development often overwhelm traditional even aibased testing approach lead gap coverage delay feedback increase maintenance cost recent breakthrough generative particularly large language model llm offer new avenue automate optimize testing process model dynamically generate test case predict system vulnerability handle continuous software change reduce burden human tester paper explore generative complement advance establish aidriven testing framework outline associate challenge datum preparation governance propose future direction fully autonomous trustworthy testing solutionsjatsp,generative software testing harness large language model automated intelligent quality assurance jatspsoftware testing indispensable ensure modern application meet rigorous standard functionality reliability security however complexity pace contemporary software development often overwhelm traditional even aibased testing approach lead gap coverage delay feedback increase maintenance cost recent breakthrough generative particularly large language model llm offer new avenue automate optimize testing process model dynamically generate test case predict system vulnerability handle continuous software change reduce burden human tester paper explore generative complement advance establish aidriven testing framework outline associate challenge datum preparation governance propose future direction fully autonomous trustworthy testing solutionsjatsp,0.5977011494252874,0.13793103448275862,0.1839080459770115,0.06896551724137931,87.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Design and Development,Pattern‐based GUI testing: Bridging the gap between design and quality assurance,"<jats:title>Summary</jats:title><jats:p>Software systems with a graphical user interface (GUI) front end are typically designed using user interface (UI) Patterns, which describe generic solutions (with multiple possible implementations) for recurrent GUI design problems. However, existing testing techniques do not take advantage of this fact to test GUIs more efficiently. In this paper, we present a new pattern‐based GUI testing (PBGT) approach that formalizes the notion of UI Test Patterns, which are generic test strategies to test UI patterns over their different implementations. The PBGT approach is evaluated via 2 case studies. The first study involves 2 fielded Web application subjects; findings show that PBGT is both practical and useful, as testing teams were able to find real bugs in a reasonable time interval. The second study allows deeper analysis by studying software subjects seeded with artificial faults; the findings show that PBGT is more effective than a manual model‐based test case generation approach.</jats:p>",https://doi.org/10.1002/stvr.1629,CrossRef,gui testing bridge gap design quality assurance,jatstitlesummaryjatstitlejatspsoftware system graphical user interface gui front end typically design use user interface pattern describe generic solution multiple possible implementation recurrent gui design problem however exist testing technique take advantage fact test guis efficiently paper present new gui testing pbgt approach formalize notion test pattern generic test strategy test pattern different implementation pbgt approach evaluate via case study first study involve field web application subject finding show pbgt practical useful test team able find real bug reasonable time interval second study allow deep analysis study software subject seed artificial fault finding show pbgt effective manual test case generation approachjatsp,gui testing bridge gap design quality assurance jatstitlesummaryjatstitlejatspsoftware system graphical user interface gui front end typically design use user interface pattern describe generic solution multiple possible implementation recurrent gui design problem however exist testing technique take advantage fact test guis efficiently paper present new gui testing pbgt approach formalize notion test pattern generic test strategy test pattern different implementation pbgt approach evaluate via case study first study involve field web application subject finding show pbgt practical useful test team able find real bug reasonable time interval second study allow deep analysis study software subject seed artificial fault finding show pbgt effective manual test case generation approachjatsp,0.5757575757575758,0.10101010101010101,0.1717171717171717,0.030303030303030304,99.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Design and Development,"A Multimodal Approach to Software Quality Assurance: Integrating Static Analysis, Dynamic Testing, and AI-based Anomaly Detection","<jats:p>: The combination of software architecture evolutions and cloud computing and cyber-physical systems
creates advanced complexity when ensuring software reliability and security and efficiency. The once typical software
quality assurance (SQA) practices using manual reviews and isolated testing methods fail to provide acceptable modern
results anymore. This study develops a multimodal software quality assurance enhancement approach which combines
static analysis together with dynamic testing and AI anomaly detection techniques. Software quality examines both
potential defects alongside security vulnerabilities through code-level static analysis before running the program while
dynamic testing evaluates real-time functionalities and security features. AI-based anomaly detection systems develop
through machine learning models which help software testing teams by predicting failures as well as detecting security
threats and adjusting testing strategies in real-time. When these technologies work together it reduces undetected
defects while attaining higher software security and quality levels and decreasing testing requirements. The paper
explores implementation barriers together with ethical matters and evolving AI-powered software testing patterns while
discussing the future trajectory of automated predictive and adaptive SQA methods</jats:p>",https://doi.org/10.15680/ijircce.2024.1202003,CrossRef,multimodal approach software quality assurance integrate static analysis dynamic testing aibased anomaly detection,jatsp combination software architecture evolution cloud computing cyberphysical system create advanced complexity ensure software reliability security efficiency typical software quality assurance sqa practice use manual review isolate testing method fail provide acceptable modern result anymore study develop multimodal software quality assurance enhancement approach combine static analysis together dynamic testing anomaly detection technique software quality examine potential defect alongside security vulnerability codelevel static analysis run program dynamic testing evaluate realtime functionality security feature aibase anomaly detection system develop machine learning model help software testing team predict failure well detect security threat adjust testing strategy realtime technology work together reduce undetected defect attain high software security quality level decrease testing requirement paper explore implementation barrier together ethical matter evolve aipowere software testing pattern discuss future trajectory automate predictive adaptive sqa methodsjatsp,multimodal approach software quality assurance integrate static analysis dynamic testing aibased anomaly detection jatsp combination software architecture evolution cloud computing cyberphysical system create advanced complexity ensure software reliability security efficiency typical software quality assurance sqa practice use manual review isolate testing method fail provide acceptable modern result anymore study develop multimodal software quality assurance enhancement approach combine static analysis together dynamic testing anomaly detection technique software quality examine potential defect alongside security vulnerability codelevel static analysis run program dynamic testing evaluate realtime functionality security feature aibase anomaly detection system develop machine learning model help software testing team predict failure well detect security threat adjust testing strategy realtime technology work together reduce undetected defect attain high software security quality level decrease testing requirement paper explore implementation barrier together ethical matter evolve aipowere software testing pattern discuss future trajectory automate predictive adaptive sqa methodsjatsp,0.6124031007751938,0.14728682170542637,0.13953488372093023,0.031007751937984496,129.0,1.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Theoretical / Conceptual,"Adapting Quality Assurance to Adaptive Systems: The Scenario Coevolution
  Paradigm","From formal and practical analysis, we identify new challenges that
self-adaptive systems pose to the process of quality assurance. When tackling
these, the effort spent on various tasks in the process of software engineering
is naturally re-distributed. We claim that all steps related to testing need to
become self-adaptive to match the capabilities of the self-adaptive
system-under-test. Otherwise, the adaptive system's behavior might elude
traditional variants of quality assurance. We thus propose the paradigm of
scenario coevolution, which describes a pool of test cases and other
constraints on system behavior that evolves in parallel to the (in part
autonomous) development of behavior in the system-under-test. Scenario
coevolution offers a simple structure for the organization of adaptive testing
that allows for both human-controlled and autonomous intervention, supporting
software engineering for adaptive systems on a procedural as well as technical
level.",http://arxiv.org/abs/1902.04694v1,arXiv,adapt quality assurance adaptive system scenario coevolution paradigm,formal practical analysis identify new challenge selfadaptive system pose process quality assurance tackle effort spend various task process software engineering naturally redistribute claim step relate test need become selfadaptive match capability selfadaptive systemundert otherwise adaptive system behavior might elude traditional variant quality assurance thus propose paradigm scenario coevolution describe pool test case constraint system behavior evolve parallel part autonomous development behavior systemundert scenario coevolution offer simple structure organization adaptive testing allow humancontrolled autonomous intervention support software engineering adaptive system procedural well technical level,adapt quality assurance adaptive system scenario coevolution paradigm formal practical analysis identify new challenge selfadaptive system pose process quality assurance tackle effort spend various task process software engineering naturally redistribute claim step relate test need become selfadaptive match capability selfadaptive systemundert otherwise adaptive system behavior might elude traditional variant quality assurance thus propose paradigm scenario coevolution describe pool test case constraint system behavior evolve parallel part autonomous development behavior systemundert scenario coevolution offer simple structure organization adaptive testing allow humancontrolled autonomous intervention support software engineering adaptive system procedural well technical level,0.5542168674698795,0.14457831325301204,0.18072289156626506,0.04819277108433735,83.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Theoretical / Conceptual,"Quality Assurance Challenges for Machine Learning Software Applications
  During Software Development Life Cycle Phases","In the past decades, the revolutionary advances of Machine Learning (ML) have
shown a rapid adoption of ML models into software systems of diverse types.
Such Machine Learning Software Applications (MLSAs) are gaining importance in
our daily lives. As such, the Quality Assurance (QA) of MLSAs is of paramount
importance. Several research efforts are dedicated to determining the specific
challenges we can face while adopting ML models into software systems. However,
we are aware of no research that offered a holistic view of the distribution of
those ML quality assurance challenges across the various phases of software
development life cycles (SDLC). This paper conducts an in-depth literature
review of a large volume of research papers that focused on the quality
assurance of ML models. We developed a taxonomy of MLSA quality assurance
issues by mapping the various ML adoption challenges across different phases of
SDLC. We provide recommendations and research opportunities to improve SDLC
practices based on the taxonomy. This mapping can help prioritize quality
assurance efforts of MLSAs where the adoption of ML models can be considered
crucial.",http://arxiv.org/abs/2105.01195v2,arXiv,quality assurance challenge machine learn software application software development life cycle phase,past decade revolutionary advance machine learning show rapid adoption model software system diverse type machine learn software application mlsa gain importance daily life quality assurance mlsas paramount importance several research effort dedicate determine specific challenge face adopt model software system however aware research offer holistic view distribution quality assurance challenge across various phase software development life cycle sdlc paper conduct indepth literature review large volume research paper focus quality assurance model develop taxonomy mlsa quality assurance issue map various adoption challenge across different phase sdlc provide recommendation research opportunity improve sdlc practice base taxonomy mapping help prioritize quality assurance effort mlsas adoption model consider crucial,quality assurance challenge machine learn software application software development life cycle phase past decade revolutionary advance machine learning show rapid adoption model software system diverse type machine learn software application mlsa gain importance daily life quality assurance mlsas paramount importance several research effort dedicate determine specific challenge face adopt model software system however aware research offer holistic view distribution quality assurance challenge across various phase software development life cycle sdlc paper conduct indepth literature review large volume research paper focus quality assurance model develop taxonomy mlsa quality assurance issue map various adoption challenge across different phase sdlc provide recommendation research opportunity improve sdlc practice base taxonomy mapping help prioritize quality assurance effort mlsas adoption model consider crucial,0.6190476190476191,0.11428571428571428,0.13333333333333333,0.009523809523809525,105.0,0.0,0.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Theoretical / Conceptual,"A Roadmap for Software Testing in Open Collaborative Development
  Environments","Amidst the ever-expanding digital sphere, the evolution of the Internet has
not only fostered an atmosphere of information transparency and sharing but has
also sparked a revolution in software development practices. The distributed
nature of open collaborative development, along with its diverse contributors
and rapid iterations, presents new challenges for ensuring software quality.
This paper offers a comprehensive review and analysis of recent advancements in
software quality assurance within open collaborative development environments.
Our examination covers various aspects, including process management, personnel
dynamics, and technological advancements, providing valuable insights into
effective approaches for maintaining software quality in such collaborative
settings. Furthermore, we delve into the challenges and opportunities arising
from emerging technologies such as LLMs and the AI model-centric development
paradigm. By addressing these topics, our study contributes to a deeper
understanding of software quality assurance in open collaborative environments
and lays the groundwork for future exploration and innovation.",http://arxiv.org/abs/2406.05438v2,arXiv,roadmap software testing open collaborative development environment,amidst everexpande digital sphere evolution internet foster atmosphere information transparency sharing also spark revolution software development practice distribute nature open collaborative development along diverse contributor rapid iteration present new challenge ensure software quality paper offer comprehensive review analysis recent advancement software quality assurance within open collaborative development environment examination cover various aspect include process management personnel dynamic technological advancement provide valuable insight effective approach maintain software quality collaborative setting furthermore delve challenge opportunity arise emerge technology llm modelcentric development paradigm address topic study contribute deep understanding software quality assurance open collaborative environment lay groundwork future exploration innovation,roadmap software testing open collaborative development environment amidst everexpande digital sphere evolution internet foster atmosphere information transparency sharing also spark revolution software development practice distribute nature open collaborative development along diverse contributor rapid iteration present new challenge ensure software quality paper offer comprehensive review analysis recent advancement software quality assurance within open collaborative development environment examination cover various aspect include process management personnel dynamic technological advancement provide valuable insight effective approach maintain software quality collaborative setting furthermore delve challenge opportunity arise emerge technology llm modelcentric development paradigm address topic study contribute deep understanding software quality assurance open collaborative environment lay groundwork future exploration innovation,0.5463917525773195,0.1134020618556701,0.21649484536082475,0.020618556701030927,97.0,0.0,0.0,0.0,0.0
Software Engineering,Software Testing and Quality Assurance,Theoretical / Conceptual,Reframing the Test Pyramid for Digitally Transformed Organizations,"The test pyramid is a conceptual model that describes how quality checks can
be organized to ensure coverage of all components of a system, at all scales.
Originally conceived to help aerospace engineers plan tests to determine how
material changes impact system integrity, the concept was gradually introduced
into software engineering. Today, the test pyramid is typically used to
illustrate that the majority of tests should be performed at the lowest (unit
test) level, with fewer integration tests, and even fewer acceptance tests
(which are the most expensive to produce, and the slowest to execute). Although
the value of acceptance tests and integration tests increasingly depends on the
integrity of the underlying data, models, and pipelines, software development
and data management organizations have traditionally been siloed and quality
assurance practice is not as mature in data operations as it is for software.
Companies that close this gap by developing cross-organizational systems will
create new competitive advantage and differentiation. By taking a more holistic
view of testing that crosses these boundaries, practitioners can help their
organizations close the gap.",http://arxiv.org/abs/2011.00655v1,arXiv,reframe test pyramid digitally transform organization,test pyramid conceptual model describe quality check organize ensure coverage component system scale originally conceive help aerospace engineer plan test determine material change impact system integrity concept gradually introduce software engineering today test pyramid typically use illustrate majority test perform low unit test level integration test even acceptance test expensive produce slow execute although value acceptance test integration test increasingly depend integrity underlie data model pipeline software development datum management organization traditionally siloe quality assurance practice mature data operation software company close gap develop crossorganizational system create new competitive advantage differentiation take holistic view testing cross boundary practitioner help organization close gap,reframe test pyramid digitally transform organization test pyramid conceptual model describe quality check organize ensure coverage component system scale originally conceive help aerospace engineer plan test determine material change impact system integrity concept gradually introduce software engineering today test pyramid typically use illustrate majority test perform low unit test level integration test even acceptance test expensive produce slow execute although value acceptance test integration test increasingly depend integrity underlie data model pipeline software development datum management organization traditionally siloe quality assurance practice mature data operation software company close gap develop crossorganizational system create new competitive advantage differentiation take holistic view testing cross boundary practitioner help organization close gap,0.6274509803921569,0.12745098039215685,0.13725490196078433,0.058823529411764705,102.0,0.0,1.0,1.0,0.0
Software Engineering,Software Testing and Quality Assurance,Theoretical / Conceptual,Ontology Reuse: the Real Test of Ontological Design,"Reusing ontologies in practice is still very challenging, especially when
multiple ontologies are (jointly) involved. Moreover, despite recent advances,
the realization of systematic ontology quality assurance remains a difficult
problem. In this work, the quality of thirty biomedical ontologies, and the
Computer Science Ontology are investigated, from the perspective of a practical
use case. Special scrutiny is given to cross-ontology references, which are
vital for combining ontologies. Diverse methods to detect potential issues are
proposed, including natural language processing and network analysis. Moreover,
several suggestions for improving ontologies and their quality assurance
processes are presented. It is argued that while the advancing automatic tools
for ontology quality assurance are crucial for ontology improvement, they will
not solve the problem entirely. It is ontology reuse that is the ultimate
method for continuously verifying and improving ontology quality, as well as
for guiding its future development. Specifically, multiple issues can be found
and fixed primarily through practical and diverse ontology reuse scenarios.",http://arxiv.org/abs/2205.02892v2,arXiv,ontology reuse real test ontological design,reuse ontology practice still challenging especially multiple ontology jointly involve moreover despite recent advance realization systematic ontology quality assurance remain difficult problem work quality thirty biomedical ontology computer science ontology investigate perspective practical use case special scrutiny give crossontology reference vital combine ontology diverse method detect potential issue propose include natural language processing network analysis moreover several suggestion improve ontology quality assurance process present argue advance automatic tool ontology quality assurance crucial ontology improvement solve problem entirely ontology reuse ultimate method continuously verify improve ontology quality well guide future development specifically multiple issue find fix primarily practical diverse ontology reuse scenario,ontology reuse real test ontological design reuse ontology practice still challenging especially multiple ontology jointly involve moreover despite recent advance realization systematic ontology quality assurance remain difficult problem work quality thirty biomedical ontology computer science ontology investigate perspective practical use case special scrutiny give crossontology reference vital combine ontology diverse method detect potential issue propose include natural language processing network analysis moreover several suggestion improve ontology quality assurance process present argue advance automatic tool ontology quality assurance crucial ontology improvement solve problem entirely ontology reuse ultimate method continuously verify improve ontology quality well guide future development specifically multiple issue find fix primarily practical diverse ontology reuse scenario,0.5346534653465347,0.1485148514851485,0.19801980198019803,0.0891089108910891,101.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Quantitative,Analysing the Assumed Benefits of Software Requirements,"Often during the requirements engineering (RE) process, the value of a
requirement is assessed, e.g., in requirement prioritisation, release planning,
and trade-off analysis. In order to support these activities, this research
evaluates Goal Oriented Requirements Engineering (GORE) methods for the
description of a requirement's value. Specifically, we investigate the
goal-to-goal contribution relationship for its ability to demonstrate the value
of a requirement, and propose that it is enriched with concepts such as
correlation, confidence, and utility.",http://arxiv.org/abs/1305.3853v2,arXiv,analyse assumed benefit software requirement,often requirement engineering process value requirement assess requirement prioritisation release planning tradeoff analysis order support activity research evaluate goal orient requirement engineer gore method description requirement value specifically investigate goaltogoal contribution relationship ability demonstrate value requirement propose enrich concept correlation confidence utility,analyse assumed benefit software requirement often requirement engineering process value requirement assess requirement prioritisation release planning tradeoff analysis order support activity research evaluate goal orient requirement engineer gore method description requirement value specifically investigate goaltogoal contribution relationship ability demonstrate value requirement propose enrich concept correlation confidence utility,0.8095238095238095,0.047619047619047616,0.023809523809523808,0.047619047619047616,42.0,0.0,0.0,0.0,1.0
Software Engineering,Requirements Engineering,Quantitative,"A holistic look at requirements engineering practices in the gaming
  industry","In this work we present an account of the status of requirements engineering
in the gaming industry. Recent papers in the area were surveyed.
Characterizations of the gaming industry were deliberated upon by portraying
its relations with the market industry. Some research directions in the area of
requirements engineering in the gaming industry were also mentioned.",http://arxiv.org/abs/1811.03482v1,arXiv,holistic look requirement engineering practice gaming industry,work present account status requirement engineering gaming industry recent paper area survey characterization gaming industry deliberate upon portray relation market industry research direction area requirement engineer gaming industry also mention,holistic look requirement engineering practice gaming industry work present account status requirement engineering gaming industry recent paper area survey characterization gaming industry deliberate upon portray relation market industry research direction area requirement engineer gaming industry also mention,0.7333333333333333,0.06666666666666667,0.13333333333333333,0.03333333333333333,30.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Quantitative,Emotions in Requirements Engineering: A Systematic Mapping Study,"The purpose of requirements engineering (RE) is to make sure that the
expectations and needs of the stakeholders of a software system are met.
Emotional needs can be captured as emotional requirements that represent how
the end user should feel when using the system. Differently from functional and
quality (non-functional) requirements, emotional requirements have received
relatively less attention from the RE community. This study is motivated by the
need to explore and map the literature on emotional requirements. The study
applies the systematic mapping study technique for surveying and analyzing the
available literature to identify the most relevant publications on emotional
requirements. We identified 34 publications that address a wide spectrum of
practices concerned with engineering emotional requirements. The identified
publications were analyzed with respect to the application domains, instruments
used for eliciting and artefacts used for representing emotional requirements,
and the state of the practice in emotion-related requirements engineering. This
analysis serves to identify research gaps and research directions in
engineering emotional requirements. To the best of the knowledge by the
authors, no other similar study has been conducted on emotional requirements.",http://arxiv.org/abs/2305.16091v1,arXiv,emotion requirement engineer systematic mapping study,purpose requirement engineer make sure expectation need stakeholder software system meet emotional need capture emotional requirement represent end user feel use system differently functional quality nonfunctional requirement emotional requirement receive relatively less attention community study motivate need explore map literature emotional requirement study apply systematic mapping study technique survey analyze available literature identify relevant publication emotional requirement identify publication address wide spectrum practice concern engineer emotional requirement identify publication analyze respect application domain instrument use elicit artefact use represent emotional requirement state practice emotionrelate requirement engineer analysis serve identify research gap research direction engineering emotional requirement good knowledge author similar study conduct emotional requirement,emotion requirement engineer systematic mapping study purpose requirement engineer make sure expectation need stakeholder software system meet emotional need capture emotional requirement represent end user feel use system differently functional quality nonfunctional requirement emotional requirement receive relatively less attention community study motivate need explore map literature emotional requirement study apply systematic mapping study technique survey analyze available literature identify relevant publication emotional requirement identify publication address wide spectrum practice concern engineer emotional requirement identify publication analyze respect application domain instrument use elicit artefact use represent emotional requirement state practice emotionrelate requirement engineer analysis serve identify research gap research direction engineering emotional requirement good knowledge author similar study conduct emotional requirement,0.625,0.14423076923076922,0.20192307692307693,0.019230769230769232,104.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Quantitative,"Requirements engineering current practice and capability in small and
  medium software development enterprises in New Zealand","This paper presents research on current industry practices with respect to
requirements engineering as implemented within software development companies
in New Zealand. A survey instrument is designed and deployed. The results are
analysed and compared against what is internationally considered ""best
practice"" and previous New Zealand and Australian studies. An attempt is made
to assess the requirements engineering capability of New Zealand companies
using both formal and informal frameworks.",http://arxiv.org/abs/1407.6102v1,arXiv,requirement engineer current practice capability small medium software development enterprise new zealand,paper present research current industry practice respect requirement engineer implement within software development company new zealand survey instrument design deploy result analyse compare internationally consider good practice previous new zealand australian study attempt make assess requirement engineering capability new zealand company use formal informal framework,requirement engineer current practice capability small medium software development enterprise new zealand paper present research current industry practice respect requirement engineer implement within software development company new zealand survey instrument design deploy result analyse compare internationally consider good practice previous new zealand australian study attempt make assess requirement engineering capability new zealand company use formal informal framework,0.5333333333333333,0.06666666666666667,0.15555555555555556,0.022222222222222223,45.0,0.0,3.0,0.0,0.0
Software Engineering,Requirements Engineering,Quantitative,"Quality Requirements for Code: On the Untapped Potential in
  Maintainability Specifications","Quality requirements are critical for successful software engineering, with
maintainability being a key internal quality. Despite significant attention in
software metrics research, maintainability has attracted surprisingly little
focus in the Requirements Engineering (RE) community. This position paper
proposes a synergistic approach, combining code-oriented research with RE
expertise, to create meaningful industrial impact. We introduce six
illustrative use cases and propose three future research directions.
Preliminary findings indicate that the established QUPER model, designed for
setting quality targets, does not adequately address the unique aspects of
maintainability.",http://arxiv.org/abs/2401.10833v1,arXiv,quality requirement code untapped potential maintainability specification,quality requirement critical successful software engineering maintainability key internal quality despite significant attention software metric research maintainability attract surprisingly little focus requirement engineer community position paper propose synergistic approach combine codeoriented research expertise create meaningful industrial impact introduce six illustrative use case propose three future research direction preliminary finding indicate establish quper model design set quality target adequately address unique aspect maintainability,quality requirement code untapped potential maintainability specification quality requirement critical successful software engineering maintainability key internal quality despite significant attention software metric research maintainability attract surprisingly little focus requirement engineer community position paper propose synergistic approach combine codeoriented research expertise create meaningful industrial impact introduce six illustrative use case propose three future research direction preliminary finding indicate establish quper model design set quality target adequately address unique aspect maintainability,0.5,0.16129032258064516,0.25806451612903225,0.03225806451612903,62.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Qualitative,Theory of Regulatory Compliance for Requirements Engineering,"Regulatory compliance is increasingly being addressed in the practice of
requirements engineering as a main stream concern. This paper points out a gap
in the theoretical foundations of regulatory compliance, and presents a theory
that states (i) what it means for requirements to be compliant, (ii) the
compliance problem, i.e., the problem that the engineer should resolve in order
to verify whether requirements are compliant, and (iii) testable hypotheses
(predictions) about how compliance of requirements is verified. The theory is
instantiated by presenting a requirements engineering framework that implements
its principles, and is exemplified on a real-world case study.",http://arxiv.org/abs/1002.3711v1,arXiv,theory regulatory compliance requirement engineering,regulatory compliance increasingly address practice requirement engineer main stream concern paper point gap theoretical foundation regulatory compliance present theory state mean requirement compliant compliance problem problem engineer resolve order verify whether requirement compliant iii testable hypothesis prediction compliance requirement verify theory instantiate present requirement engineering framework implement principle exemplified realworld case study,theory regulatory compliance requirement engineering regulatory compliance increasingly address practice requirement engineer main stream concern paper point gap theoretical foundation regulatory compliance present theory state mean requirement compliant compliance problem problem engineer resolve order verify whether requirement compliant iii testable hypothesis prediction compliance requirement verify theory instantiate present requirement engineering framework implement principle exemplified realworld case study,0.5769230769230769,0.09615384615384616,0.2692307692307692,0.019230769230769232,52.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Qualitative,"Aspects of Modelling Requirements in Very-Large Agile Systems
  Engineering","Using models for requirements engineering (RE) is uncommon in systems
engineering, despite the widespread use of model-based engineering in general.
One reason for this lack of use is that formal models do not match well the
trend to move towards agile developing methods. While there exists work that
investigates challenges in the adoption of requirements modeling and agile
methods in systems engineering, there is a lack of work studying successful
approaches of using requirements modelling in agile systems engineering. To
address this gap, we conducted a case study investigating the application of
requirements models at Ericsson AB, a Swedish telecommunications company. We
studied a department using requirements models to bridge agile development and
plan-driven development aspects. We find that models are used to understand how
requirements relate to each other, and to keep track with the product's
evolution. To cope with the effort to maintain models over time, study
participants suggest to rely on text-based notations that bring the models
closer to developers and allow integration into existing software development
workflows. This results in tool trade-offs, e.g., losing the possibility to
control diagram layout.",http://arxiv.org/abs/2209.01993v1,arXiv,aspect modelling requirement verylarge agile system engineering,use model requirement engineer uncommon system engineering despite widespread use modelbase engineering general one reason lack use formal model match well trend move towards agile develop method exist work investigate challenge adoption requirement model agile method system engineering lack work study successful approach use requirement model agile system engineer address gap conduct case study investigate application requirement model ericsson swedish telecommunications company study department use requirement model bridge agile development plandriven development aspect find model use understand requirement relate keep track product evolution cope effort maintain model time study participant suggest rely textbase notation bring model close developer allow integration exist software development workflow result tool tradeoff lose possibility control diagram layout,aspect modelling requirement verylarge agile system engineering use model requirement engineer uncommon system engineering despite widespread use modelbase engineering general one reason lack use formal model match well trend move towards agile develop method exist work investigate challenge adoption requirement model agile method system engineering lack work study successful approach use requirement model agile system engineer address gap conduct case study investigate application requirement model ericsson swedish telecommunications company study department use requirement model bridge agile development plandriven development aspect find model use understand requirement relate keep track product evolution cope effort maintain model time study participant suggest rely textbase notation bring model close developer allow integration exist software development workflow result tool tradeoff lose possibility control diagram layout,0.5982142857142857,0.15178571428571427,0.08035714285714286,0.0,56.0,1.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Qualitative,ReXCL: A Tool for Requirement Document Extraction and Classification,"This paper presents the ReXCL tool, which automates the extraction and
classification processes in requirement engineering, enhancing the software
development lifecycle. The tool features two main modules: Extraction, which
processes raw requirement documents into a predefined schema using heuristics
and predictive modeling, and Classification, which assigns class labels to
requirements using adaptive fine-tuning of encoder-based models. The final
output can be exported to external requirement engineering tools. Performance
evaluations indicate that ReXCL significantly improves efficiency and accuracy
in managing requirements, marking a novel approach to automating the
schematization of semi-structured requirement documents.",http://arxiv.org/abs/2504.07562v1,arXiv,rexcl tool requirement document extraction classification,paper present rexcl tool automate extraction classification process requirement engineering enhance software development lifecycle tool feature two main module extraction process raw requirement document predefine schema use heuristic predictive modeling classification assign class label requirement use adaptive finetuning encoderbase model final output export external requirement engineering tool performance evaluation indicate rexcl significantly improve efficiency accuracy managing requirement mark novel approach automate schematization semistructure requirement document,rexcl tool requirement document extraction classification paper present rexcl tool automate extraction classification process requirement engineering enhance software development lifecycle tool feature two main module extraction process raw requirement document predefine schema use heuristic predictive modeling classification assign class label requirement use adaptive finetuning encoderbase model final output export external requirement engineering tool performance evaluation indicate rexcl significantly improve efficiency accuracy managing requirement mark novel approach automate schematization semistructure requirement document,0.7230769230769231,0.09230769230769231,0.13846153846153847,0.015384615384615385,65.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Qualitative,"Identifying relevant Factors of Requirements Quality: an industrial Case
  Study","[Context and Motivation]: The quality of requirements specifications impacts
subsequent, dependent software engineering activities. Requirements quality
defects like ambiguous statements can result in incomplete or wrong features
and even lead to budget overrun or project failure. [Problem]: Attempts at
measuring the impact of requirements quality have been held back by the vast
amount of interacting factors. Requirements quality research lacks an
understanding of which factors are relevant in practice. [Principal Ideas and
Results]: We conduct a case study considering data from both interview
transcripts and issue reports to identify relevant factors of requirements
quality. The results include 17 factors and 11 interaction effects relevant to
the case company. [Contribution]: The results contribute empirical evidence
that (1) strengthens existing requirements engineering theories and (2)
advances industry-relevant requirements quality research.",http://arxiv.org/abs/2402.00594v2,arXiv,identify relevant factor requirement quality industrial case study,context motivation quality requirement specification impact subsequent dependent software engineering activity requirement quality defect like ambiguous statement result incomplete wrong feature even lead budget overrun project failure problem attempt measure impact requirement quality hold back vast amount interact factor requirement quality research lack understanding factor relevant practice principal idea result conduct case study consider datum interview transcript issue report identify relevant factor requirement quality result include factor interaction effect relevant case company contribution result contribute empirical evidence strengthen exist requirement engineer theory advance industryrelevant requirement quality research,identify relevant factor requirement quality industrial case study context motivation quality requirement specification impact subsequent dependent software engineering activity requirement quality defect like ambiguous statement result incomplete wrong feature even lead budget overrun project failure problem attempt measure impact requirement quality hold back vast amount interact factor requirement quality research lack understanding factor relevant practice principal idea result conduct case study consider datum interview transcript issue report identify relevant factor requirement quality result include factor interaction effect relevant case company contribution result contribute empirical evidence strengthen exist requirement engineer theory advance industryrelevant requirement quality research,0.7011494252873564,0.11494252873563218,0.14942528735632185,0.011494252873563218,87.0,1.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Qualitative,"A multi-case study of agile requirements engineering and the use of test
  cases as requirements","Context: It is an enigma that agile projects can succeed 'without
requirements' when weak requirements engineering is a known cause for project
failures. While agile development projects often manage well without extensive
requirements test cases are commonly viewed as requirements and detailed
requirements are documented as test cases. Objective: We have investigated this
agile practice of using test cases as requirements to understand how test cases
can support the main requirements activities, and how this practice varies.
Method: We performed an iterative case study at three companies and collected
data through 14 interviews and two focus groups. Results: The use of test cases
as requirements poses both benefits and challenges when eliciting, validating,
verifying, and managing requirements, and when used as a documented agreement.
We have identified five variants of the test-cases-as-requirements practice,
namely de facto, behaviour-driven, story-test driven, stand-alone strict and
stand-alone manual for which the application of the practice varies concerning
the time frame of requirements documentation, the requirements format, the
extent to which the test cases are a machine executable specification and the
use of tools which provide specific support for the practice of using test
cases as requirements. Conclusions: The findings provide empirical insight into
how agile development projects manage and communicate requirements. The
identified variants of the practice of using test cases as requirements can be
used to perform in-depth investigations into agile requirements engineering.
Practitioners can use the provided recommendations as a guide in designing and
improving their agile requirements practices based on project characteristics
such as number of stakeholders and rate of change.",http://arxiv.org/abs/2308.11747v1,arXiv,multicase study agile requirement engineering use test case requirement,context enigma agile project succeed without requirement weak requirement engineering know cause project failure agile development project often manage well without extensive requirement test case commonly view requirement detailed requirement document test case objective investigate agile practice use test case requirement understand test case support main requirement activity practice vary method perform iterative case study three company collect datum interview two focus group result use test case requirement pose benefit challenge elicit validate verifying managing requirement use document agreement identify five variant testcasesasrequirement practice namely facto behaviourdriven storyt drive standalone strict standalone manual application practice vary concern time frame requirement documentation requirement format extent test case machine executable specification use tool provide specific support practice use test case requirement conclusion finding provide empirical insight agile development project manage communicate requirement identify variant practice use test case requirement use perform indepth investigation agile requirement engineering practitioner use provide recommendation guide design improve agile requirement practice base project characteristic number stakeholder rate change,multicase study agile requirement engineering use test case requirement context enigma agile project succeed without requirement weak requirement engineering know cause project failure agile development project often manage well without extensive requirement test case commonly view requirement detailed requirement document test case objective investigate agile practice use test case requirement understand test case support main requirement activity practice vary method perform iterative case study three company collect datum interview two focus group result use test case requirement pose benefit challenge elicit validate verifying managing requirement use document agreement identify five variant testcasesasrequirement practice namely facto behaviourdriven storyt drive standalone strict standalone manual application practice vary concern time frame requirement documentation requirement format extent test case machine executable specification use tool provide specific support practice use test case requirement conclusion finding provide empirical insight agile development project manage communicate requirement identify variant practice use test case requirement use perform indepth investigation agile requirement engineering practitioner use provide recommendation guide design improve agile requirement practice base project characteristic number stakeholder rate change,0.6335403726708074,0.13043478260869565,0.15527950310559005,0.031055900621118012,161.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Mixed Methods,Crowd-based requirements elicitation via pull feedback: method and case studies,"<jats:title>Abstract</jats:title><jats:p>Crowd-based Requirements Engineering (CrowdRE) promotes the active involvement of a large number of stakeholders in RE activities. A prominent strand of CrowdRE research concerns the creation and use of online platforms for a crowd of stakeholders to formulate ideas, which serve as an additional input for requirements elicitation. Most of the reported case studies are of small size, and they analyze the size of the crowd, rather than the quality of the collected ideas. By means of an iterative design that includes three case studies conducted at two organizations, we present the CREUS method for crowd-based elicitation via user stories. Besides reporting the details of these case studies and quantitative results on the number of participants, ideas, votes, etc., a key contribution of this paper is a qualitative analysis of the elicited ideas. To analyze the quality of the user stories, we apply criteria from the Quality User Story framework, we calculate automated text readability metrics, and we check for the presence of vague words. We also study whether the user stories can be linked to software qualities, and the specificity of the ideas. Based on the results, we distill six key findings regarding CREUS and, more generally, for CrowdRE via pull feedback.</jats:p>",https://doi.org/10.1007/s00766-022-00384-6,CrossRef,crowdbase requirement elicitation via pull feedback method case study,jatstitleabstractjatstitlejatspcrowdbase requirement engineering crowdre promote active involvement large number stakeholder activity prominent strand crowdre research concern creation use online platform crowd stakeholder formulate idea serve additional input requirement elicitation report case study small size analyze size crowd rather quality collect idea mean iterative design include three case study conduct two organization present creus method crowdbase elicitation via user story besides report detail case study quantitative result number participant idea vote etc key contribution paper qualitative analysis elicit idea analyze quality user story apply criterion quality user story framework calculate automate text readability metric check presence vague word also study whether user story link software quality specificity idea base result distill six key finding regard creus generally crowdre via pull feedbackjatsp,crowdbase requirement elicitation via pull feedback method case study jatstitleabstractjatstitlejatspcrowdbase requirement engineering crowdre promote active involvement large number stakeholder activity prominent strand crowdre research concern creation use online platform crowd stakeholder formulate idea serve additional input requirement elicitation report case study small size analyze size crowd rather quality collect idea mean iterative design include three case study conduct two organization present creus method crowdbase elicitation via user story besides report detail case study quantitative result number participant idea vote etc key contribution paper qualitative analysis elicit idea analyze quality user story apply criterion quality user story framework calculate automate text readability metric check presence vague word also study whether user story link software quality specificity idea base result distill six key finding regard creus generally crowdre via pull feedbackjatsp,0.6083333333333333,0.125,0.125,0.025,120.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Mixed Methods,"Causality in requirements artifacts: prevalence, detection, and impact","<jats:title>Abstract</jats:title><jats:p>Causal relations in natural language (NL) requirements convey strong, semantic information. Automatically extracting such causal information enables multiple use cases, such as test case generation, but it also requires to reliably detect causal relations in the first place. Currently, this is still a cumbersome task as causality in NL requirements is still barely understood and, thus, barely detectable. In our empirically informed research, we aim at better understanding the notion of causality and supporting the automatic extraction of causal relations in NL requirements. In a first case study, we investigate 14.983 sentences from 53 requirements documents to understand the extent and form in which causality occurs. Second, we present and evaluate a tool-supported approach, called CiRA, for causality detection. We conclude with a second case study where we demonstrate the applicability of our tool and investigate the impact of causality on NL requirements. The first case study shows that causality constitutes around 28 % of all NL requirements sentences. We then demonstrate that our detection tool achieves a macro-<jats:inline-formula><jats:alternatives><jats:tex-math>$$\hbox {F}_{1}$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:msub><mml:mtext>F</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:math></jats:alternatives></jats:inline-formula>score of 82 % on real-world data and that it outperforms related approaches with an average gain of 11.06 % in macro-Recall and 11.43 % in macro-Precision. Finally, our second case study corroborates the positive correlations of causality with features of NL requirements. The results strengthen our confidence in the eligibility of causal relations for downstream reuse, while our tool and publicly available data constitute a first step in the ongoing endeavors of utilizing causality in RE and beyond.</jats:p>",https://doi.org/10.1007/s00766-022-00371-x,CrossRef,causality requirement artifact prevalence detection impact,jatstitleabstractjatstitlejatspcausal relation natural language requirement convey strong semantic information automatically extract causal information enable multiple use case test case generation also require reliably detect causal relation first place currently still cumbersome task causality requirement still barely understand thus barely detectable empirically inform research aim well understand notion causality support automatic extraction causal relation requirement first case study investigate sentence requirement document understand extent form causality occur second present evaluate toolsupported approach call cira causality detection conclude second case study demonstrate applicability tool investigate impact causality requirement first case study show causality constitute around requirement sentence demonstrate detection tool achieve macrojatsinlineformulajatsalternativesjatstexmathhbox fjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmsubmmlmtextfmmlmtextmmlmnmmlmnmmlmsubmmlmathjatsalternativesjatsinlineformulascore realworld datum outperform related approach average gain macrorecall macroprecision finally second case study corroborate positive correlation causality feature requirement result strengthen confidence eligibility causal relation downstream reuse tool publicly available datum constitute first step ongoing endeavor utilize causality beyondjatsp,causality requirement artifact prevalence detection impact jatstitleabstractjatstitlejatspcausal relation natural language requirement convey strong semantic information automatically extract causal information enable multiple use case test case generation also require reliably detect causal relation first place currently still cumbersome task causality requirement still barely understand thus barely detectable empirically inform research aim well understand notion causality support automatic extraction causal relation requirement first case study investigate sentence requirement document understand extent form causality occur second present evaluate toolsupported approach call cira causality detection conclude second case study demonstrate applicability tool investigate impact causality requirement first case study show causality constitute around requirement sentence demonstrate detection tool achieve macrojatsinlineformulajatsalternativesjatstexmathhbox fjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmsubmmlmtextfmmlmtextmmlmnmmlmnmmlmsubmmlmathjatsalternativesjatsinlineformulascore realworld datum outperform related approach average gain macrorecall macroprecision finally second case study corroborate positive correlation causality feature requirement result strengthen confidence eligibility causal relation downstream reuse tool publicly available datum constitute first step ongoing endeavor utilize causality beyondjatsp,0.524822695035461,0.14184397163120568,0.1702127659574468,0.09219858156028368,141.0,0.0,0.0,0.0,1.0
Software Engineering,Requirements Engineering,Mixed Methods,Requirements and software engineering for automotive perception systems: an interview study,"<jats:title>Abstract</jats:title><jats:p>Driving automation systems, including autonomous driving and advanced driver assistance, are an important safety-critical domain. Such systems often incorporate perception systems that use machine learning to analyze the vehicle environment. We explore new or differing topics and challenges experienced by practitioners in this domain, which relate to requirements engineering (RE), quality, and systems and software engineering. We have conducted a semi-structured interview study with 19 participants across five companies and performed thematic analysis of the transcriptions. Practitioners have difficulty specifying upfront requirements and often rely on scenarios and operational design domains (ODDs) as RE artifacts. RE challenges relate to ODD detection and ODD exit detection, realistic scenarios, edge case specification, breaking down requirements, traceability, creating specifications for data and annotations, and quantifying quality requirements. Practitioners consider performance, reliability, robustness, user comfort, and—most importantly—safety as important quality attributes. Quality is assessed using statistical analysis of key metrics, and quality assurance is complicated by the addition of ML, simulation realism, and evolving standards. Systems are developed using a mix of methods, but these methods may not be sufficient for the needs of ML. Data quality methods must be a part of development methods. ML also requires a data-intensive verification and validation process, introducing data, analysis, and simulation challenges. Our findings contribute to understanding RE, safety engineering, and development methodologies for perception systems. This understanding and the collected challenges can drive future research for driving automation and other ML systems.</jats:p>",https://doi.org/10.1007/s00766-023-00410-1,CrossRef,requirement software engineering automotive perception system interview study,jatstitleabstractjatstitlejatspdrive automation system include autonomous driving advanced driver assistance important safetycritical domain system often incorporate perception system use machine learn analyze vehicle environment explore new differ topic challenge experience practitioner domain relate requirement engineering quality system software engineering conduct semistructure interview study participant across five company perform thematic analysis transcription practitioner difficulty specify upfront requirement often rely scenario operational design domain odd artifact challenge relate odd detection odd exit detection realistic scenario edge case specification break requirement traceability create specification datum annotation quantify quality requirement practitioner consider performance reliability robustness user comfort importantly safety important quality attribute quality assess use statistical analysis key metric quality assurance complicate addition simulation realism evolving standard system develop use mix method method may sufficient need datum quality method must part development method also require dataintensive verification validation process introduce datum analysis simulation challenge finding contribute understanding safety engineering development methodology perception system understanding collect challenge drive future research drive automation systemsjatsp,requirement software engineering automotive perception system interview study jatstitleabstractjatstitlejatspdrive automation system include autonomous driving advanced driver assistance important safetycritical domain system often incorporate perception system use machine learn analyze vehicle environment explore new differ topic challenge experience practitioner domain relate requirement engineering quality system software engineering conduct semistructure interview study participant across five company perform thematic analysis transcription practitioner difficulty specify upfront requirement often rely scenario operational design domain odd artifact challenge relate odd detection odd exit detection realistic scenario edge case specification break requirement traceability create specification datum annotation quantify quality requirement practitioner consider performance reliability robustness user comfort importantly safety important quality attribute quality assess use statistical analysis key metric quality assurance complicate addition simulation realism evolving standard system develop use mix method method may sufficient need datum quality method must part development method also require dataintensive verification validation process introduce datum analysis simulation challenge finding contribute understanding safety engineering development methodology perception system understanding collect challenge drive future research drive automation systemsjatsp,0.6178343949044586,0.16560509554140126,0.1337579617834395,0.025477707006369428,157.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Mixed Methods,Effects of common requirements engineering techniques on requirements engineering success in agile environments: A case study from Sri Lanka,"<jats:p>Requirements engineering is the process of exploring, analyzing, documenting and handling the needs to be facilitated through a computer-based system that is being developed. Though software solutions fail due to many reasons, Flawed Requirements Engineering (RE) is one of the main causes leading to failure of software projects especially in agile environments where requirements and solutions evolve through collaboration between self-organizing cross-functional teams. Therefore, succeeding in RE is an essential factor which influences success of the entire software project. In the light of achieving project success, various methods have been introduced to deal with RE. Main aim of this study is to explore the relationship between commonly used techniques and successful agile requirements engineering in agile environments with a special emphasis to Sri Lankan context. A secondary objective was to suggest innovative recommendations to software solution developers to achieve RE success. Five research questions were formulated to explore the relationship between mostly common techniques of requirements management and success of agile requirements engineering. Through key readings related to agile project development, authors have identified five key success factors as having an influence on successful project completion in an agile environment and are being tested in this research. Authors have designed the study taking an epistemological standpoint of positivism, using quantitative methods and case study strategy to derive conclusions. The entire population 130 employees of the case organization been considered for this study. The quantitative analysis of was conducted based on 105 valid responses gained through a five-point Likert scaled questionnaire from the case organization. It has been discovered that these common requirement engineering techniques are correlated with project success in agile environments. Further, scrutiny of each requirements engineering phase, led to finding a set of most effective techniques to be utilized in an agile environment contributing to software development project success.&#x0D;
Keywords: Requirements engineering, agile software development, project failures</jats:p>",https://doi.org/10.31357/icbm.v17.5193,CrossRef,effect common requirement engineer technique requirement engineer success agile environment case study sri lanka,jatsprequirement engineering process explore analyze documenting handle need facilitate computerbase system develop though software solution fail due many reason flaw requirement engineering one main cause lead failure software project especially agile environment requirement solution evolve collaboration selforganize crossfunctional team therefore succeed essential factor influence success entire software project light achieve project success various method introduce deal main aim study explore relationship commonly use technique successful agile requirement engineer agile environment special emphasis sri lankan context secondary objective suggest innovative recommendation software solution developer achieve success five research question formulate explore relationship mostly common technique requirement management success agile requirement engineer key reading relate agile project development author identify five key success factor influence successful project completion agile environment test research author design study take epistemological standpoint positivism use quantitative method case study strategy derive conclusion entire population employee case organization consider study quantitative analysis conduct base valid response gain fivepoint likert scale questionnaire case organization discover common requirement engineering technique correlate project success agile environment scrutiny requirement engineering phase lead find set effective technique utilize agile environment contribute software development project successxd keyword requirement engineer agile software development project failuresjatsp,effect common requirement engineer technique requirement engineer success agile environment case study sri lanka jatsprequirement engineering process explore analyze documenting handle need facilitate computerbase system develop though software solution fail due many reason flaw requirement engineering one main cause lead failure software project especially agile environment requirement solution evolve collaboration selforganize crossfunctional team therefore succeed essential factor influence success entire software project light achieve project success various method introduce deal main aim study explore relationship commonly use technique successful agile requirement engineer agile environment special emphasis sri lankan context secondary objective suggest innovative recommendation software solution developer achieve success five research question formulate explore relationship mostly common technique requirement management success agile requirement engineer key reading relate agile project development author identify five key success factor influence successful project completion agile environment test research author design study take epistemological standpoint positivism use quantitative method case study strategy derive conclusion entire population employee case organization consider study quantitative analysis conduct base valid response gain fivepoint likert scale questionnaire case organization discover common requirement engineering technique correlate project success agile environment scrutiny requirement engineering phase lead find set effective technique utilize agile environment contribute software development project successxd keyword requirement engineer agile software development project failuresjatsp,0.6526315789473685,0.11578947368421053,0.18421052631578946,0.021052631578947368,190.0,1.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Mixed Methods,Non-functional requirements for machine learning: understanding current use and challenges among practitioners,"<jats:title>Abstract</jats:title><jats:p>Systems that rely on Machine Learning (ML systems) have differing demands on quality—known as non-functional requirements (NFRs)—from traditional systems. NFRs for ML systems may differ in their definition, measurement, scope, and comparative importance. Despite the importance of NFRs in ensuring the quality ML systems, our understanding of all of these aspects is lacking compared to our understanding of NFRs in traditional domains. We have conducted interviews and a survey to understand how NFRs for ML systems are perceived among practitioners from both industry and academia. We have identified the degree of importance that practitioners place on different NFRs, including cases where practitioners are in agreement or have differences of opinion. We explore how NFRs are defined and measured over different aspects of a ML system (i.e., model, data, or whole system). We also identify challenges associated with NFR definition and measurement. Finally, we explore differences in perspective between practitioners in industry, academia, or a blended context. This knowledge illustrates how NFRs for ML systems are treated in current practice, and helps to guide future RE for ML efforts.</jats:p>",https://doi.org/10.1007/s00766-022-00395-3,CrossRef,nonfunctional requirement machine learn understand current use challenge among practitioner,jatstitleabstractjatstitlejatspsystem rely machine learning system differ demand quality know nonfunctional requirement nfrs traditional system nfrs system may differ definition measurement scope comparative importance despite importance nfrs ensure quality system understanding aspect lack compare understanding nfrs traditional domain conduct interview survey understand nfrs system perceive among practitioner industry academia identify degree importance practitioner place different nfrs include case practitioner agreement difference opinion explore nfrs define measure different aspect system model datum whole system also identify challenge associate nfr definition measurement finally explore difference perspective practitioner industry academia blended context knowledge illustrate nfrs system treat current practice help guide future effortsjatsp,nonfunctional requirement machine learn understand current use challenge among practitioner jatstitleabstractjatstitlejatspsystem rely machine learning system differ demand quality know nonfunctional requirement nfrs traditional system nfrs system may differ definition measurement scope comparative importance despite importance nfrs ensure quality system understanding aspect lack compare understanding nfrs traditional domain conduct interview survey understand nfrs system perceive among practitioner industry academia identify degree importance practitioner place different nfrs include case practitioner agreement difference opinion explore nfrs define measure different aspect system model datum whole system also identify challenge associate nfr definition measurement finally explore difference perspective practitioner industry academia blended context knowledge illustrate nfrs system treat current practice help guide future effortsjatsp,0.6262626262626263,0.16161616161616163,0.1414141414141414,0.020202020202020204,99.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Design and Development,"What If People Learn Requirements Over Time? A Rough Introduction to
  Requirements Economics","The overall objective of Requirements Engineering is to specify, in a
systematic way, a system that satisfies the expectations of its stakeholders.
Despite tremendous effort in the field, recent studies demonstrate this is
objective is not always achieved. In this paper, we discuss one particularly
challenging factor to Requirements Engineering projects, namely the change of
requirements. We proposes a rough discussion of how learning and time explain
requirements changes, how it can be introduced as a key variable in the
formulation of the Requirements Engineering Problem, and how this induces costs
for a requirements engineering project. This leads to a new discipline of
requirements economics.",http://arxiv.org/abs/1711.09092v1,arXiv,people learn requirement time rough introduction requirement economic,overall objective requirement engineering specify systematic way system satisfy expectation stakeholder despite tremendous effort field recent study demonstrate objective always achieve paper discuss one particularly challenge factor requirement engineering project namely change requirement propose rough discussion learning time explain requirement change introduce key variable formulation requirement engineering problem induce cost requirement engineering project lead new discipline requirement economic,people learn requirement time rough introduction requirement economic overall objective requirement engineering specify systematic way system satisfy expectation stakeholder despite tremendous effort field recent study demonstrate objective always achieve paper discuss one particularly challenge factor requirement engineering project namely change requirement propose rough discussion learning time explain requirement change introduce key variable formulation requirement engineering problem induce cost requirement engineering project lead new discipline requirement economic,0.5862068965517241,0.15517241379310345,0.1724137931034483,0.05172413793103448,58.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Design and Development,"Requirements Engineering Methods: A Classification Framework and
  Research Challenges","Requirements Engineering Methods (REMs) support Requirements Engineering (RE)
tasks, from elicitation, through modeling and analysis, to validation and
evolution of requirements. Despite the growing interest to design, validate and
teach REMs, it remains unclear what components REMs should have. A
classification framework for REMs is proposed. It distinguishes REMs based on
the domain-independent properties of their components. The classification
framework is intended to facilitate (i) analysis, teaching and extension of
existing REMs, (ii) engineering and validation of new REMs, and (iii)
identifying research challenges in REM design. The framework should help
clarify further the relations between REM and other concepts of interest in and
to RE, including Requirements Problem and Solution, Requirements Modeling
Language, and Formal Method.",http://arxiv.org/abs/1203.1717v1,arXiv,requirement engineering method classification framework research challenge,requirement engineering method rem support requirement engineer task elicitation modeling analysis validation evolution requirement despite grow interest design validate teach rem remain unclear component rem classification framework rem propose distinguish rem base domainindependent property component classification framework intend facilitate analysis teaching extension exist rem engineering validation new rem iii identify research challenge rem design framework help clarify far relation rem concept interest include requirement problem solution requirement model language formal method,requirement engineering method classification framework research challenge requirement engineering method rem support requirement engineer task elicitation modeling analysis validation evolution requirement despite grow interest design validate teach rem remain unclear component rem classification framework rem propose distinguish rem base domainindependent property component classification framework intend facilitate analysis teaching extension exist rem engineering validation new rem iii identify research challenge rem design framework help clarify far relation rem concept interest include requirement problem solution requirement model language formal method,0.8028169014084507,0.11267605633802817,0.04225352112676056,0.014084507042253521,71.0,0.0,0.0,0.0,1.0
Software Engineering,Requirements Engineering,Design and Development,Refinement-Based Specification: Requirements and Architecture,"This paper presents the methodology for the system requirements and
architecture w.r.t. their decomposition and refinement. It also introduces
ideas of refinement layers and of refinement-based verification.",http://arxiv.org/abs/1404.7260v1,arXiv,refinementbase specification requirement architecture,paper present methodology system requirement architecture wrt decomposition refinement also introduce idea refinement layer refinementbased verification,refinementbase specification requirement architecture paper present methodology system requirement architecture wrt decomposition refinement also introduce idea refinement layer refinementbased verification,0.6875,0.125,0.0625,0.0625,16.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Design and Development,A Framework for Aspectual Requirements Validation: An Experimental Study,"Requirements engineering is a discipline of software engineering that is
concerned with the identification and handling of user and system requirements.
Aspect-Oriented Requirements Engineering (AORE) extends the existing
requirements engineering approaches to cope with the issue of tangling and
scattering resulted from crosscutting concerns. Crosscutting concerns are
considered as potential aspects and can lead to the phenomena tyranny of the
dominant decomposition. Requirements-level aspects are responsible for
producing scattered and tangled descriptions of requirements in the
requirements document. Validation of requirements artefacts is an essential
task in software development. This task ensures that requirements are correct
and valid in terms of completeness and consistency, hence, reducing the
development cost, maintenance and establish an approximately correct estimate
of effort and completion time of the project. In this paper, we present a
validation framework to validate the aspectual requirements and the
crosscutting relationship of concerns that are resulted from the requirements
engineering phase. The proposed framework comprises a high-level and low-level
validation to implement on software requirements specification (SRS). The
high-level validation validates the concerns with stakeholders, whereas the
low-level validation validates the aspectual requirement by requirements
engineers and analysts using a checklist. The approach has been evaluated using
an experimental study on two AORE approaches. The approaches are
viewpoint-based called AORE with ArCaDe and lexical analysis based on Theme/Doc
approach. The results obtained from the study demonstrate that the proposed
framework is an effective validation model for AORE artefacts.",http://arxiv.org/abs/2110.03952v1,arXiv,framework aspectual requirement validation experimental study,requirement engineering discipline software engineering concerned identification handling user system requirement aspectoriente requirement engineering aore extend exist requirement engineering approach cope issue tangle scattering result crosscut concern crosscut concern consider potential aspect lead phenomena tyranny dominant decomposition requirementslevel aspect responsible produce scatter tangle description requirement requirement document validation requirement artefact essential task software development task ensure requirement correct valid term completeness consistency hence reduce development cost maintenance establish approximately correct estimate effort completion time project paper present validation framework validate aspectual requirement crosscut relationship concern result requirement engineering phase propose framework comprise highlevel lowlevel validation implement software requirement specification srs highlevel validation validate concern stakeholder whereas lowlevel validation validate aspectual requirement requirement engineer analyst use checklist approach evaluate use experimental study two aore approach approach viewpointbase call aore arcade lexical analysis base themedoc approach result obtain study demonstrate propose framework effective validation model aore artefact,framework aspectual requirement validation experimental study requirement engineering discipline software engineering concerned identification handling user system requirement aspectoriente requirement engineering aore extend exist requirement engineering approach cope issue tangle scattering result crosscut concern crosscut concern consider potential aspect lead phenomena tyranny dominant decomposition requirementslevel aspect responsible produce scatter tangle description requirement requirement document validation requirement artefact essential task software development task ensure requirement correct valid term completeness consistency hence reduce development cost maintenance establish approximately correct estimate effort completion time project paper present validation framework validate aspectual requirement crosscut relationship concern result requirement engineering phase propose framework comprise highlevel lowlevel validation implement software requirement specification srs highlevel validation validate concern stakeholder whereas lowlevel validation validate aspectual requirement requirement engineer analyst use checklist approach evaluate use experimental study two aore approach approach viewpointbase call aore arcade lexical analysis base themedoc approach result obtain study demonstrate propose framework effective validation model aore artefact,0.6689655172413793,0.1103448275862069,0.12413793103448276,0.027586206896551724,145.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Design and Development,"Applying Agile Requirements Engineering Approach for Re-engineering &
  Changes in existing Brownfield Adaptive Systems","Requirements Engineering (RE) is a key activity in the development of
software systems and is concerned with the identification of the goals of
stakeholders and their elaboration into precise statements of desired services
and behavior. The research describes an Agile Requirements Engineering approach
for re-engineering & changes in existing Brownfield adaptive system. The
approach has few modifications that can be used as a part of SCRUM development
process for re-engineering & changes. The approach illustrates the
re-engineering & changes requirements through introduction of GAP analysis &
requirements structuring & prioritization by creating AS-IS & TO-BE models with
80 / 20 rule. An attempt to close the gap between requirements engineering &
agile methods in form of this approach is provided for practical
implementation.",http://arxiv.org/abs/1410.6902v1,arXiv,apply agile requirement engineering approach reengineere change exist brownfield adaptive system,requirement engineer key activity development software system concern identification goal stakeholder elaboration precise statement desire service behavior research describe agile requirement engineering approach reengineere change exist brownfield adaptive system approach modification use part scrum development process reengineere change approach illustrate reengineere change requirement introduction gap analysis requirement structure prioritization create asis tobe model rule attempt close gap requirement engineer agile method form approach provide practical implementation,apply agile requirement engineering approach reengineere change exist brownfield adaptive system requirement engineer key activity development software system concern identification goal stakeholder elaboration precise statement desire service behavior research describe agile requirement engineering approach reengineere change exist brownfield adaptive system approach modification use part scrum development process reengineere change approach illustrate reengineere change requirement introduction gap analysis requirement structure prioritization create asis tobe model rule attempt close gap requirement engineer agile method form approach provide practical implementation,0.7424242424242424,0.10606060606060606,0.12121212121212122,0.0,66.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Theoretical / Conceptual,"Teaching Model-based Requirements Engineering to Industry Professionals:
  An Experience Report","The use of conceptual models to foster requirements engineering has been
proposed and evaluated as beneficial for several decades. For instance,
goal-oriented requirements engineering or the specification of scenarios are
commonly done using conceptual models. Bringing such model-based requirements
engineering approaches into industrial practice typically requires industrial
training. In this paper, we report lessons learned from a training program for
teaching industry professionals model-based requirements engineering.
Particularly, we as educators and learners report experiences from designing
the training program, conducting the actual training, and applying the
instructed material in our day-to-day work. From these findings we provide
guidelines for educators designing requirements engineering courses for
industry professionals.",http://arxiv.org/abs/2103.04433v1,arXiv,teach modelbase requirement engineer industry professional experience report,use conceptual model foster requirement engineering propose evaluate beneficial several decade instance goaloriente requirement engineer specification scenario commonly use conceptual model bring modelbase requirement engineering approach industrial practice typically require industrial training paper report lesson learn training program teach industry professional modelbase requirement engineering particularly educator learner report experience design training program conduct actual training apply instruct material daytoday work finding provide guideline educator design requirement engineer course industry professional,teach modelbase requirement engineer industry professional experience report use conceptual model foster requirement engineering propose evaluate beneficial several decade instance goaloriente requirement engineer specification scenario commonly use conceptual model bring modelbase requirement engineering approach industrial practice typically require industrial training paper report lesson learn training program teach industry professional modelbase requirement engineering particularly educator learner report experience design training program conduct actual training apply instruct material daytoday work finding provide guideline educator design requirement engineer course industry professional,0.6142857142857143,0.14285714285714285,0.15714285714285714,0.04285714285714286,70.0,0.0,0.0,1.0,0.0
Software Engineering,Requirements Engineering,Theoretical / Conceptual,"A Theoretical and Empirical Evaluation of Software Component Search
  Engines, Semantic Search Engines and Google Search Engine in the Context of
  COTS-Based Development","COTS-based development is a component reuse approach promising to reduce
costs and risks, and ensure higher quality. The growing availability of COTS
components on the Web has concretized the possibility of achieving these
objectives. In this multitude, a recurrent problem is the identification of the
COTS components that best satisfy the user requirements. Finding an adequate
COTS component implies searching among heterogeneous descriptions of the
components within a broad search space. Thus, the use of search engines is
required to make more efficient the COTS components identification. In this
paper, we investigate, theoretically and empirically, the COTS component search
performance of eight software component search engines, nine semantic search
engines and a conventional search engine (Google). Our empirical evaluation is
conducted with respect to precision and normalized recall. We defined ten
queries for the assessed search engines. These queries were carefully selected
to evaluate the capability of each search engine for handling COTS component
identification.",http://arxiv.org/abs/1204.2079v1,arXiv,theoretical empirical evaluation software component search engine semantic search engine google search engine context cotsbase development,cotsbase development component reuse approach promise reduce cost risk ensure high quality grow availability cot component web concretize possibility achieve objective multitude recurrent problem identification cot component well satisfy user requirement find adequate cot component imply search among heterogeneous description component within broad search space thus use search engine require make efficient cot component identification paper investigate theoretically empirically cot component search performance eight software component search engine nine semantic search engine conventional search engine google empirical evaluation conduct respect precision normalize recall define ten query assess search engine query carefully select evaluate capability search engine handle cot component identification,theoretical empirical evaluation software component search engine semantic search engine google search engine context cotsbase development cotsbase development component reuse approach promise reduce cost risk ensure high quality grow availability cot component web concretize possibility achieve objective multitude recurrent problem identification cot component well satisfy user requirement find adequate cot component imply search among heterogeneous description component within broad search space thus use search engine require make efficient cot component identification paper investigate theoretically empirically cot component search performance eight software component search engine nine semantic search engine conventional search engine google empirical evaluation conduct respect precision normalize recall define ten query assess search engine query carefully select evaluate capability search engine handle cot component identification,0.61,0.13,0.09,0.04,100.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Theoretical / Conceptual,"A Noble Methodology for Users Work Process Driven Software Requirements
  for Smart Handheld Devices","Requirement engineering is a key ingredient for software development to be
effective. Apart from the traditional software requirement which is not much
appropriate for new emerging software such as smart handheld device based
software. In many perspectives of requirement engineering, traditional and new
emerging software are not similar. Whereas requirement engineering of
traditional software needs more research, it is obvious that new emerging
software needs methodically and in-depth research for improved productivity,
quality, risk management and validity. In particular, the result of this paper
shows that how effective requirement engineering can improve in project
negotiation, project planning, managing feature creep, testing, defect, rework
and product quality. This paper also shows a new methodology which is focused
on users work process applicable for eliciting the requirement of traditional
software and any new type software of smart handheld device such as iPad. As an
example, the paper shows how the methodology will be applied as a software
requirement of iPad-based software for play-group students.",http://arxiv.org/abs/1408.2687v1,arXiv,noble methodology user work process drive software requirement smart handheld device,requirement engineering key ingredient software development effective apart traditional software requirement much appropriate new emerge software smart handheld device base software many perspective requirement engineering traditional new emerge software similar whereas requirement engineering traditional software need research obvious new emerge software need methodically indepth research improved productivity quality risk management validity particular result paper show effective requirement engineering improve project negotiation project planning manage feature creep testing defect rework product quality paper also show new methodology focus user work process applicable elicit requirement traditional software new type software smart handheld device ipad example paper show methodology apply software requirement ipadbased software playgroup student,noble methodology user work process drive software requirement smart handheld device requirement engineering key ingredient software development effective apart traditional software requirement much appropriate new emerge software smart handheld device base software many perspective requirement engineering traditional new emerge software similar whereas requirement engineering traditional software need research obvious new emerge software need methodically indepth research improved productivity quality risk management validity particular result paper show effective requirement engineering improve project negotiation project planning manage feature creep testing defect rework product quality paper also show new methodology focus user work process applicable elicit requirement traditional software new type software smart handheld device ipad example paper show methodology apply software requirement ipadbased software playgroup student,0.5922330097087378,0.06796116504854369,0.2815533980582524,0.02912621359223301,103.0,0.0,0.0,0.0,0.0
Software Engineering,Requirements Engineering,Theoretical / Conceptual,"Analysis of Software Engineering Practices in General Software and
  Machine Learning Startups","Context: On top of the inherent challenges startup software companies face
applying proper software engineering practices, the non-deterministic nature of
machine learning techniques makes it even more difficult for machine learning
(ML) startups.
  Objective: Therefore, the objective of our study is to understand the whole
picture of software engineering practices followed by ML startups and identify
additional needs.
  Method: To achieve our goal, we conducted a systematic literature review
study on 37 papers published in the last 21 years. We selected papers on both
general software startups and ML startups. We collected data to understand
software engineering (SE) practices in five phases of the software development
life-cycle: requirement engineering, design, development, quality assurance,
and deployment.
  Results: We find some interesting differences in software engineering
practices in ML startups and general software startups. The data management and
model learning phases are the most prominent among them.
  Conclusion: While ML startups face many similar challenges to general
software startups, the additional difficulties of using stochastic ML models
require different strategies in using software engineering practices to produce
high-quality products.",http://arxiv.org/abs/2304.01523v1,arXiv,analysis software engineering practice general software machine learn startup,context top inherent challenge startup software company face apply proper software engineering practice nondeterministic nature machine learn technique make even difficult machine learn startup objective therefore objective study understand whole picture software engineering practice follow startup identify additional need method achieve goal conduct systematic literature review study paper publish last year select paper general software startup startup collect datum understand software engineering practice five phase software development lifecycle requirement engineering design development quality assurance deployment result find interesting difference software engineering practice startup general software startup data management model learn phase prominent among conclusion startup face many similar challenge general software startup additional difficulty use stochastic model require different strategy use software engineering practice produce highquality product,analysis software engineering practice general software machine learn startup context top inherent challenge startup software company face apply proper software engineering practice nondeterministic nature machine learn technique make even difficult machine learn startup objective therefore objective study understand whole picture software engineering practice follow startup identify additional need method achieve goal conduct systematic literature review study paper publish last year select paper general software startup startup collect datum understand software engineering practice five phase software development lifecycle requirement engineering design development quality assurance deployment result find interesting difference software engineering practice startup general software startup data management model learn phase prominent among conclusion startup face many similar challenge general software startup additional difficulty use stochastic model require different strategy use software engineering practice produce highquality product,0.5726495726495726,0.18803418803418803,0.1794871794871795,0.017094017094017096,117.0,0.0,0.0,1.0,0.0
Software Engineering,Requirements Engineering,Theoretical / Conceptual,"Ontologies for Privacy Requirements Engineering: A Systematic Literature
  Review","Privacy has been frequently identified as a main concern for system
developers while dealing with/managing personal information. Despite this, most
existing work on privacy requirements deals with them as a special case of
security requirements. Therefore, key aspects of privacy are, usually,
overlooked. In this context, wrong design decisions might be made due to
insufficient understanding of privacy concerns. In this paper, we address this
problem with a systematic literature review whose main purpose is to identify
the main concepts/relations for capturing privacy requirements. In addition,
the identified concepts/relations are further analyzed to propose a novel
privacy ontology to be used by software engineers when dealing with privacy
requirements.",http://arxiv.org/abs/1611.10097v1,arXiv,ontology privacy requirement engineer systematic literature review,privacy frequently identify main concern system developer deal withmanage personal information despite exist work privacy requirement deal special case security requirement therefore key aspect privacy usually overlook context wrong design decision might make due insufficient understanding privacy concern paper address problem systematic literature review whose main purpose identify main conceptsrelation capture privacy requirement addition identify conceptsrelation far analyze propose novel privacy ontology use software engineer deal privacy requirement,ontology privacy requirement engineer systematic literature review privacy frequently identify main concern system developer deal withmanage personal information despite exist work privacy requirement deal special case security requirement therefore key aspect privacy usually overlook context wrong design decision might make due insufficient understanding privacy concern paper address problem systematic literature review whose main purpose identify main conceptsrelation capture privacy requirement addition identify conceptsrelation far analyze propose novel privacy ontology use software engineer deal privacy requirement,0.6029411764705882,0.11764705882352941,0.16176470588235295,0.058823529411764705,68.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Quantitative,Project Risk Management Model Based on PRINCE2 and Scrum Frameworks,"There is a lack of formal risk management techniques in agile software
development methods Scrum. The need to manage risks in agile project management
is also identified by various authors. Authors of this paper conducted a survey
to find out the current practices in agile project management. Furthermore
authors discuss the new integrated framework of Scrum and PRINCE2 with focus on
risk management. Enrichment of Scrum with selected practices from the
heavy-weight project management framework PRINCE2 promises better results in
delivering software products especially in global development projects.",http://arxiv.org/abs/1502.03595v1,arXiv,project risk management model base prince scrum framework,lack formal risk management technique agile software development method scrum need manage risk agile project management also identify various author author paper conduct survey find current practice agile project management furthermore author discuss new integrate framework scrum prince focus risk management enrichment scrum select practice heavyweight project management framework prince promise well result deliver software product especially global development project,project risk management model base prince scrum framework lack formal risk management technique agile software development method scrum need manage risk agile project management also identify various author author paper conduct survey find current practice agile project management furthermore author discuss new integrate framework scrum prince focus risk management enrichment scrum select practice heavyweight project management framework prince promise well result deliver software product especially global development project,0.5666666666666667,0.11666666666666667,0.18333333333333332,0.05,60.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Quantitative,Complexity in the Context of Systems Approach to Project Management,"Complexity is an inherent attribute of any project. The purpose of defining
and documenting complexity is to have an early warning tool allowing a project
team to focus on certain areas and aspects of the project in order to prevent
and alleviate future risks and issues caused by this complexity. The main
contribution of this paper is to present a systematic view of complexity in
project management by identifying its key attributes and classifying complexity
by these attributes. A ""complexity taxonomy"", based on a survey of the existing
complexity literature, is developed and discussed including the product,
project, and external environment dimensions. We show how complexity types are
described through simple real life examples and business cases. Then we develop
a framework (tool) for applying the notion of complexity as an early warning
tool for a project manager in order to timely foresee future risks and
problems. The paper is intended for researchers in complexity, project
management, information systems, technology solutions and business management,
and also for information specialists, project managers, program managers,
financial staff and technology directors.",http://arxiv.org/abs/1412.1027v1,arXiv,complexity context system approach project management,complexity inherent attribute project purpose define document complexity early warning tool allow project team focus certain area aspect project order prevent alleviate future risk issue cause complexity main contribution paper present systematic view complexity project management identify key attribute classify complexity attribute complexity taxonomy base survey exist complexity literature develop discuss include product project external environment dimension show complexity type describe simple real life example business case develop framework tool apply notion complexity early warning tool project manager order timely foresee future risk problem paper intend researcher complexity project management information system technology solution business management also information specialist project manager program manager financial staff technology director,complexity context system approach project management complexity inherent attribute project purpose define document complexity early warning tool allow project team focus certain area aspect project order prevent alleviate future risk issue cause complexity main contribution paper present systematic view complexity project management identify key attribute classify complexity attribute complexity taxonomy base survey exist complexity literature develop discuss include product project external environment dimension show complexity type describe simple real life example business case develop framework tool apply notion complexity early warning tool project manager order timely foresee future risk problem paper intend researcher complexity project management information system technology solution business management also information specialist project manager program manager financial staff technology director,0.7009345794392523,0.1308411214953271,0.11214953271028037,0.028037383177570093,107.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Quantitative,"Successful Management of Cloud Based Global Software Development
  Projects: A Multivocal Study","Context: Software industry is continuously exploring better ways to develop
applications. A new phenomenon to achieve this is Cloud based Global Software
Development (CGSD), which refers to the adoption of cloud computing services by
organizations to support global software development projects. The CGSD
approach affects the strategic and operational aspects of the way projects are
managed. Objective: The objective of the study is to identify the success
factors which contribute to management of CGSD projects. Methods: We carried
out a Multivocal Literature Review (MLR) to identify the success factors from
the state-of-the-art and the state-of-the-practice in project management of
CGSD projects. We identified 32 success factors that contribute to the
management of CGSD projects. Results: The findings of MLR indicate that time to
market, continuous development, financial restructuring, scalability Moreover,
the findings of the study show that there is a positive correlation between the
success factors reported in both formal literature and industry based grey
literature. Conclusion: The findings of this study can assist the practitioners
to develop the strategies needed for effective project management of CGSD
projects.",http://arxiv.org/abs/2208.08743v1,arXiv,successful management cloud base global software development project multivocal study,context software industry continuously explore well way develop application new phenomenon achieve cloud base global software development cgsd refer adoption cloud computing service organization support global software development project cgsd approach affect strategic operational aspect way project manage objective objective study identify success factor contribute management cgsd project method carry multivocal literature review mlr identify success factor stateoftheart stateofthepractice project management cgsd project identify success factor contribute management cgsd project result finding mlr indicate time market continuous development financial restructure scalability moreover finding study show positive correlation success factor report formal literature industry base grey literature conclusion finding study assist practitioner develop strategy need effective project management cgsd project,successful management cloud base global software development project multivocal study context software industry continuously explore well way develop application new phenomenon achieve cloud base global software development cgsd refer adoption cloud computing service organization support global software development project cgsd approach affect strategic operational aspect way project manage objective objective study identify success factor contribute management cgsd project method carry multivocal literature review mlr identify success factor stateoftheart stateofthepractice project management cgsd project identify success factor contribute management cgsd project result finding mlr indicate time market continuous development financial restructure scalability moreover finding study show positive correlation success factor report formal literature industry base grey literature conclusion finding study assist practitioner develop strategy need effective project management cgsd project,0.5596330275229358,0.1834862385321101,0.1651376146788991,0.027522935779816515,109.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Quantitative,"An Analytical Approach for Project Managers in Effective Defect
  Management in Software Process","Defect estimation and prediction are some of the main modulating factors for
the success of software projects in any software industry. Maturity and
competency of a project manager in efficient prediction and estimation of
resource capabilities are one of the strategic driving forces towards the
generation of high quality software. Currently, there are no estimation
techniques developed through empirical analysis to evaluate the decision
capability of a project manager towards resource allocation for effective
defect management. This paper brings out an empirical study carried out in a
product based software organization. Our deep investigation on several projects
throws light on the impact of decision capability of project manager towards
accomplishment of an aforementioned objective. The paper enables project
managers to gain further awareness towards the significance of predictive
positioning in resource allocation in order to develop high quality defect-free
software products. It also enhances the maturity level of the company and its
persistence in the competitive atmosphere.",http://arxiv.org/abs/1203.6439v1,arXiv,analytical approach project manager effective defect management software process,defect estimation prediction main modulating factor success software project software industry maturity competency project manager efficient prediction estimation resource capability one strategic drive force towards generation high quality software currently estimation technique develop empirical analysis evaluate decision capability project manager towards resource allocation effective defect management paper bring empirical study carry product base software organization deep investigation several project throw light impact decision capability project manager towards accomplishment aforementioned objective paper enable project manager gain awareness towards significance predictive positioning resource allocation order develop high quality defectfree software product also enhance maturity level company persistence competitive atmosphere,analytical approach project manager effective defect management software process defect estimation prediction main modulating factor success software project software industry maturity competency project manager efficient prediction estimation resource capability one strategic drive force towards generation high quality software currently estimation technique develop empirical analysis evaluate decision capability project manager towards resource allocation effective defect management paper bring empirical study carry product base software organization deep investigation several project throw light impact decision capability project manager towards accomplishment aforementioned objective paper enable project manager gain awareness towards significance predictive positioning resource allocation order develop high quality defectfree software product also enhance maturity level company persistence competitive atmosphere,0.6701030927835051,0.1134020618556701,0.14432989690721648,0.020618556701030927,97.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Quantitative,"An Study of The Role of Software Project Manger in the Outcome of the
  Project","This paper describes an in depth analysis of successful and unsuccessful
software Projects and the Role of Software Project Mangers in that success. One
of the main reason in software project success is manager. Software houses are
investing too much in this regard but the average ratio of software project
failure is on the high side. Project managers experience, technical knowledge,
and skills are not good enough for success in general. In this paper we have
conducted a survey related to the approached used by different project
managers, their methods and techniques, and the success ratio of their
projects, and the steps they took during their projects. We will explore the
core reasons of software project success and then will suggest key steps to be
taken by the software project managers to deliver a successful software
project.",http://arxiv.org/abs/2009.13869v1,arXiv,study role software project manger outcome project,paper describe depth analysis successful unsuccessful software project role software project manger success one main reason software project success manager software house invest much regard average ratio software project failure high side project manager experience technical knowledge skill good enough success general paper conduct survey relate approach use different project manager method technique success ratio project step take project explore core reason software project success suggest key step take software project manager deliver successful software project,study role software project manger outcome project paper describe depth analysis successful unsuccessful software project role software project manger success one main reason software project success manager software house invest much regard average ratio software project failure high side project manager experience technical knowledge skill good enough success general paper conduct survey relate approach use different project manager method technique success ratio project step take project explore core reason software project success suggest key step take software project manager deliver successful software project,0.6710526315789473,0.11842105263157894,0.17105263157894737,0.0,76.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Qualitative,Risk Analysis in the Selection of Project Managers Based on ANP and FMEA,"Project managers play a crucial role in the success of projects. The
selection of an appropriate project manager is a primary concern for senior
managers in firms. Typically, this process involves candidate interviews and
assessments of their abilities. There are various criteria for selecting a
project manager, and the importance of each criterion depends on the project
type, its conditions, and the risks associated with their absence in the chosen
candidate. Often, senior managers in engineering companies lack awareness of
the significance of these criteria and the potential risks linked to their
absence. This research aims to identify these risks in selecting project
managers for civil engineering projects, utilizing a combined ANP-FMEA
approach. Through a comprehensive literature review, five risk categories have
been identified: individual skills, power-related issues, knowledge and
expertise, experience, and personality traits. Subsequently, these risks, along
with their respective sub-criteria and internal relationships, were analysed
using the combined ANP-FMEA technique. The results highlighted that the lack of
political influence, absence of construction experience, and deficiency in
project management expertise represent the most substantial risks in selecting
a project manager. Moreover, upon comparison with the traditional FMEA
approach, this study demonstrates the superior ability of the ANP-FMEA model in
differentiating risks and pinpointing factors with elevated risk levels.",http://arxiv.org/abs/2311.03224v1,arXiv,risk analysis selection project manager base anp fmea,project manager play crucial role success project selection appropriate project manager primary concern senior manager firm typically process involve candidate interview assessment ability various criterion select project manager importance criterion depend project type condition risk associate absence choose candidate often senior manager engineering company lack awareness significance criterion potential risk link absence research aim identify risk select project manager civil engineering project utilize combine anpfmea approach comprehensive literature review five risk category identify individual skill powerrelate issue knowledge expertise experience personality trait subsequently risk along respective subcriteria internal relationship analyse use combine anpfmea technique result highlight lack political influence absence construction experience deficiency project management expertise represent substantial risk select project manager moreover upon comparison traditional fmea approach study demonstrate superior ability anpfmea model differentiate risk pinpointing factor elevated risk level,risk analysis selection project manager base anp fmea project manager play crucial role success project selection appropriate project manager primary concern senior manager firm typically process involve candidate interview assessment ability various criterion select project manager importance criterion depend project type condition risk associate absence choose candidate often senior manager engineering company lack awareness significance criterion potential risk link absence research aim identify risk select project manager civil engineering project utilize combine anpfmea approach comprehensive literature review five risk category identify individual skill powerrelate issue knowledge expertise experience personality trait subsequently risk along respective subcriteria internal relationship analyse use combine anpfmea technique result highlight lack political influence absence construction experience deficiency project management expertise represent substantial risk select project manager moreover upon comparison traditional fmea approach study demonstrate superior ability anpfmea model differentiate risk pinpointing factor elevated risk level,0.6030534351145038,0.11450381679389313,0.1297709923664122,0.030534351145038167,131.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Qualitative,"IT Project Governance in Project Delivery: Key Processes, Activities,
  Roles and Responsibilities","The general objective of this work was to contribute to the general body of
knowledge and research work in the area of managing IT projects successfully.
The office of Government commerce of the UK Government in conjunction with the
National Audit came out with a guideline in 2007 which list out eight causes of
project failures. Six out of the eight causes were attributed to governance
issues (Aon, 2011). This shows clearly that governance activities in project
management are really important, and failure to place premium on them can
result in failure of projects. The research work was therefore intended to come
out with IT governance frameworks that can help resolve the problem of failure
of IT projects resulting from governance issues. Four IT program managers and
eight IT project managers were talked to on a variety of IT project governance
issues. The frameworks were developed based on a combination of literature,
experts (IT project and program managers of the telecom industry in Ghana)
input, observation, and so on. The governance frameworks depicts project
management processes, project activities, project governance activities, roles
and responsibilities of key stakeholders, key milestones, approval bodies,
signatures, and so on, to ensure successful delivery of IT projects.",http://arxiv.org/abs/1912.13295v1,arXiv,project governance project delivery key process activity role responsibility,general objective work contribute general body knowledge research work area manage project successfully office government commerce government conjunction national audit come guideline list eight cause project failure six eight cause attribute governance issue aon show clearly governance activity project management really important failure place premium result failure project research work therefore intend come governance framework help resolve problem failure project result governance issue four program manager eight project manager talk variety project governance issue framework develop base combination literature expert project program manager telecom industry ghana input observation governance framework depict project management process project activity project governance activity role responsibility key stakeholder key milestone approval body signature ensure successful delivery project,project governance project delivery key process activity role responsibility general objective work contribute general body knowledge research work area manage project successfully office government commerce government conjunction national audit come guideline list eight cause project failure six eight cause attribute governance issue aon show clearly governance activity project management really important failure place premium result failure project research work therefore intend come governance framework help resolve problem failure project result governance issue four program manager eight project manager talk variety project governance issue framework develop base combination literature expert project program manager telecom industry ghana input observation governance framework depict project management process project activity project governance activity role responsibility key stakeholder key milestone approval body signature ensure successful delivery project,0.7232142857142857,0.08035714285714286,0.0625,0.03571428571428571,56.0,0.0,0.0,0.0,1.0
Software Engineering,Project Management,Qualitative,"Managing Security Issues in Software Containers: From Practitioners
  Perspective","Software development industries are increasingly adopting containers to
enhance the scalability and flexibility of software applications. Security in
containerized projects is a critical challenge that can lead to data breaches
and performance degradation, thereby directly affecting the reliability and
operations of the container services. Despite the ongoing effort to manage the
security issues in containerized projects in software engineering (SE)
research, more focused investigations are needed to explore the human
perspective of security management and the technical approaches to security
management in containerized projects. This research aims to explore security
management in containerized projects by exploring how SE practitioners perceive
the security issues in containerized software projects and their approach to
managing such issues. A clear understanding of security management in
containerized projects will enable industries to develop robust security
strategies that enhance software reliability and trust. To achieve this, we
conducted two separate semi-structured interview studies to examine how
practitioners approach security management. The first study focused on
practitioners perceptions of security challenges in containerized environments,
where we interviewed 15 participants between December 2022 and October 2023.
The second study explored how to enhance container security, with 20
participants interviewed between October 2024 and December 2024. Analyzing the
data from both studies reveals how SE practitioners address the various
security challenges in containerized projects. Our analysis also identified the
technical and non-technical enablers that can be utilized to enhance security.",http://arxiv.org/abs/2504.07707v1,arXiv,manage security issue software container practitioner perspective,software development industry increasingly adopt container enhance scalability flexibility software application security containerized project critical challenge lead datum breach performance degradation thereby directly affect reliability operation container service despite ongoing effort manage security issue containerized project software engineer research focused investigation need explore human perspective security management technical approach security management containerized project research aim explore security management containerized project explore practitioner perceive security issue containerize software project approach manage issue clear understanding security management containerized project enable industry develop robust security strategy enhance software reliability trust achieve conduct two separate semistructure interview study examine practitioner approach security management first study focus practitioner perception security challenge containerized environment interview participant december october second study explore enhance container security participant interview october december analyze datum study reveal practitioner address various security challenge containerized project analysis also identify technical nontechnical enabler utilize enhance security,manage security issue software container practitioner perspective software development industry increasingly adopt container enhance scalability flexibility software application security containerized project critical challenge lead datum breach performance degradation thereby directly affect reliability operation container service despite ongoing effort manage security issue containerized project software engineer research focused investigation need explore human perspective security management technical approach security management containerized project research aim explore security management containerized project explore practitioner perceive security issue containerize software project approach manage issue clear understanding security management containerized project enable industry develop robust security strategy enhance software reliability trust achieve conduct two separate semistructure interview study examine practitioner approach security management first study focus practitioner perception security challenge containerized environment interview participant december october second study explore enhance container security participant interview october december analyze datum study reveal practitioner address various security challenge containerized project analysis also identify technical nontechnical enabler utilize enhance security,0.6267605633802817,0.1619718309859155,0.08450704225352113,0.035211267605633804,71.0,0.0,0.0,2.0,0.0
Software Engineering,Project Management,Qualitative,"Automated Security Findings Management: A Case Study in Industrial
  DevOps","In recent years, DevOps, the unification of development and operation
workflows, has become a trend for the industrial software development
lifecycle. Security activities turned into an essential field of application
for DevOps principles as they are a fundamental part of secure software
development in the industry. A common practice arising from this trend is the
automation of security tests that analyze a software product from several
perspectives. To effectively improve the security of the analyzed product, the
identified security findings must be managed and looped back to the project
team for stakeholders to take action. This management must cope with several
challenges ranging from low data quality to a consistent prioritization of
findings while following DevOps aims. To manage security findings with the same
efficiency as other activities in DevOps projects, a methodology for the
management of industrial security findings minding DevOps principles is
essential.
  In this paper, we propose a methodology for the management of security
findings in industrial DevOps projects, summarizing our research in this domain
and presenting the resulting artifact. As an instance of the methodology, we
developed the Security Flama, a semantic knowledge base for the automated
management of security findings. To analyze the impact of our methodology on
industrial practice, we performed a case study on two DevOps projects of a
multinational industrial enterprise. The results emphasize the importance of
using such an automated methodology in industrial DevOps projects, confirm our
approach's usefulness and positive impact on the studied projects, and identify
the communication strategy as a crucial factor for usability in practice.",http://arxiv.org/abs/2401.06602v1,arXiv,automate security finding management case study industrial devop,recent year devop unification development operation workflow become trend industrial software development lifecycle security activity turn essential field application devop principle fundamental part secure software development industry common practice arise trend automation security test analyze software product several perspective effectively improve security analyzed product identify security finding must manage loop back project team stakeholder take action management must cope several challenge range low datum quality consistent prioritization finding follow devop aim manage security finding efficiency activity devop project methodology management industrial security finding mind devop principle essential paper propose methodology management security finding industrial devop project summarize research domain present result artifact instance methodology develop security flama semantic knowledge base automate management security finding analyze impact methodology industrial practice perform case study two devop project multinational industrial enterprise result emphasize importance use automated methodology industrial devop project confirm approach usefulness positive impact studied project identify communication strategy crucial factor usability practice,automate security finding management case study industrial devop recent year devop unification development operation workflow become trend industrial software development lifecycle security activity turn essential field application devop principle fundamental part secure software development industry common practice arise trend automation security test analyze software product several perspective effectively improve security analyzed product identify security finding must manage loop back project team stakeholder take action management must cope several challenge range low datum quality consistent prioritization finding follow devop aim manage security finding efficiency activity devop project methodology management industrial security finding mind devop principle essential paper propose methodology management security finding industrial devop project summarize research domain present result artifact instance methodology develop security flama semantic knowledge base automate management security finding analyze impact methodology industrial practice perform case study two devop project multinational industrial enterprise result emphasize importance use automated methodology industrial devop project confirm approach usefulness positive impact studied project identify communication strategy crucial factor usability practice,0.5894039735099338,0.2185430463576159,0.15894039735099338,0.006622516556291391,151.0,0.0,0.0,1.0,0.0
Software Engineering,Project Management,Qualitative,"Towards an Understanding of Why and How ICT Projects Are Initiated:
  Analysis via Repertory Grid","Contemporary business innovation relies increasingly on information and
communications technology (ICT) solutions. As ICT initiatives are generally
implemented via projects the management of ICT projects has come under
increasing scrutiny. ICT projects continue to fail; as a result, while research
in ICT project management has indeed increased, many challenges for research
and practice remain. Many studies have addressed the execution and management
of ICT projects and the many factors that might relate to project outcomes.
Very few, however, have considered ICT project initiation and the crucial
decisions made at that very early, pre-life cycle stage. The primary intent of
this research is therefore to investigate ICT projects with a particular focus
on their initiation. In doing so we wished to understand why ICT projects are
started, and how they are moved from idea or proposal to supported reality. A
combination of semi-structured interviews and the repertory grid data
collection and analysis method was employed to investigate and validate the
motivating factors that influence individual IT Managers' project initiation
decisions and the methods they use to transition from idea to enacted project.
Our results showed that there are indeed multiple underlying reasons for the
decisions made at this early stage and that there are some especially common
decision drivers. Some were expected, in the sense that they mapped to
recommended best practice. For instance, most projects are motivated by a
desire to achieve efficiencies or cost savings, and their potential tends to be
assessed using cost benefit analysis. Other results were more surprising -
competitor pressure was not a common driver for ICT project initiation in our
analysis. Unsurprisingly, formal evaluation methods are more frequently used to
assess project proposals when those projects are larger and higher profile.
(Abridged)",http://arxiv.org/abs/2103.10570v1,arXiv,towards understanding ict project initiate analysis via repertory grid,contemporary business innovation rely increasingly information communication technology ict solution ict initiative generally implement via project management ict project come increase scrutiny ict project continue fail result research ict project management indeed increase many challenge research practice remain many study address execution management ict project many factor might relate project outcome however consider ict project initiation crucial decision make early prelife cycle stage primary intent research therefore investigate ict project particular focus initiation wish understand ict project start move idea proposal support reality combination semistructure interview repertory grid datum collection analysis method employ investigate validate motivating factor influence individual manager project initiation decision method use transition idea enact project result show indeed multiple underlying reason decision make early stage especially common decision driver expect sense map recommend good practice instance project motivate desire achieve efficiency cost saving potential tend assess use cost benefit analysis result surprising competitor pressure common driver ict project initiation analysis unsurprisingly formal evaluation method frequently use assess project proposal project large high profile abridge,towards understanding ict project initiate analysis via repertory grid contemporary business innovation rely increasingly information communication technology ict solution ict initiative generally implement via project management ict project come increase scrutiny ict project continue fail result research ict project management indeed increase many challenge research practice remain many study address execution management ict project many factor might relate project outcome however consider ict project initiation crucial decision make early prelife cycle stage primary intent research therefore investigate ict project particular focus initiation wish understand ict project start move idea proposal support reality combination semistructure interview repertory grid datum collection analysis method employ investigate validate motivating factor influence individual manager project initiation decision method use transition idea enact project result show indeed multiple underlying reason decision make early stage especially common decision driver expect sense map recommend good practice instance project motivate desire achieve efficiency cost saving potential tend assess use cost benefit analysis result surprising competitor pressure common driver ict project initiation analysis unsurprisingly formal evaluation method frequently use assess project proposal project large high profile abridge,0.6488095238095238,0.14285714285714285,0.14285714285714285,0.05357142857142857,168.0,1.0,0.0,0.0,0.0
Software Engineering,Project Management,Mixed Methods,"Transient Information Adaptation of Artificial Intelligence: Towards
  Sustainable Data Processes in Complex Projects","Large scale projects increasingly operate in complicated settings whilst
drawing on an array of complex data-points, which require precise analysis for
accurate control and interventions to mitigate possible project failure.
Coupled with a growing tendency to rely on new information systems and
processes in change projects, 90% of megaprojects globally fail to achieve
their planned objectives. Renewed interest in the concept of Artificial
Intelligence (AI) against a backdrop of disruptive technological innovations,
seeks to enhance project managers cognitive capacity through the project
lifecycle and enhance project excellence. However, despite growing interest
there remains limited empirical insights on project managers ability to
leverage AI for cognitive load enhancement in complex settings. As such this
research adopts an exploratory sequential linear mixed methods approach to
address unresolved empirical issues on transient adaptations of AI in complex
projects, and the impact on cognitive load enhancement. Initial thematic
findings from semi-structured interviews with domain experts, suggest that in
order to leverage AI technologies and processes for sustainable cognitive load
enhancement with complex data over time, project managers require improved
knowledge and access to relevant technologies that mediate data processes in
complex projects, but equally reflect application across different project
phases. These initial findings support further hypothesis testing through a
larger quantitative study incorporating structural equation modelling to
examine the relationship between artificial intelligence and project managers
cognitive load with project data in complex contexts.",http://arxiv.org/abs/2104.04067v2,arXiv,transient information adaptation artificial intelligence towards sustainable datum process complex project,large scale project increasingly operate complicated setting whilst draw array complex datapoint require precise analysis accurate control intervention mitigate possible project failure couple grow tendency rely new information system process change project megaproject globally fail achieve plan objective renew interest concept artificial intelligence backdrop disruptive technological innovation seek enhance project manager cognitive capacity project lifecycle enhance project excellence however despite grow interest remain limited empirical insight project manager ability leverage cognitive load enhancement complex setting research adopt exploratory sequential linear mixed method approach address unresolved empirical issue transient adaptation complex project impact cognitive load enhancement initial thematic finding semistructure interview domain expert suggest order leverage technology process sustainable cognitive load enhancement complex datum time project manager require improve knowledge access relevant technology mediate data process complex project equally reflect application across different project phase initial finding support hypothesis testing large quantitative study incorporate structural equation model examine relationship artificial intelligence project manager cognitive load project datum complex contexts,transient information adaptation artificial intelligence towards sustainable datum process complex project large scale project increasingly operate complicated setting whilst draw array complex datapoint require precise analysis accurate control intervention mitigate possible project failure couple grow tendency rely new information system process change project megaproject globally fail achieve plan objective renew interest concept artificial intelligence backdrop disruptive technological innovation seek enhance project manager cognitive capacity project lifecycle enhance project excellence however despite grow interest remain limited empirical insight project manager ability leverage cognitive load enhancement complex setting research adopt exploratory sequential linear mixed method approach address unresolved empirical issue transient adaptation complex project impact cognitive load enhancement initial thematic finding semistructure interview domain expert suggest order leverage technology process sustainable cognitive load enhancement complex datum time project manager require improve knowledge access relevant technology mediate data process complex project equally reflect application across different project phase initial finding support hypothesis testing large quantitative study incorporate structural equation model examine relationship artificial intelligence project manager cognitive load project datum complex contexts,0.5949367088607594,0.12025316455696203,0.22784810126582278,0.02531645569620253,158.0,1.0,0.0,0.0,0.0
Software Engineering,Project Management,Mixed Methods,"Enhancing Project Performance Forecasting using Machine Learning
  Techniques","Accurate forecasting of project performance metrics is crucial for
successfully managing and delivering urban road reconstruction projects.
Traditional methods often rely on static baseline plans and fail to consider
the dynamic nature of project progress and external factors. This research
proposes a machine learning-based approach to forecast project performance
metrics, such as cost variance and earned value, for each Work Breakdown
Structure (WBS) category in an urban road reconstruction project. The proposed
model utilizes time series forecasting techniques, including Autoregressive
Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks,
to predict future performance based on historical data and project progress.
The model also incorporates external factors, such as weather patterns and
resource availability, as features to enhance the accuracy of forecasts. By
applying the predictive power of machine learning, the performance forecasting
model enables proactive identification of potential deviations from the
baseline plan, which allows project managers to take timely corrective actions.
The research aims to validate the effectiveness of the proposed approach using
a case study of an urban road reconstruction project, comparing the model's
forecasts with actual project performance data. The findings of this research
contribute to the advancement of project management practices in the
construction industry, offering a data-driven solution for improving project
performance monitoring and control.",http://arxiv.org/abs/2411.17914v1,arXiv,enhance project performance forecasting use machine learning technique,accurate forecasting project performance metric crucial successfully manage deliver urban road reconstruction project traditional method often rely static baseline plan fail consider dynamic nature project progress external factor research propose machine learningbase approach forecast project performance metric cost variance earn value work breakdown structure category urban road reconstruction project propose model utilize time series forecasting technique include autoregressive integrate moving average arima long shortterm memory lstm network predict future performance base historical datum project progress model also incorporate external factor weather pattern resource availability feature enhance accuracy forecast apply predictive power machine learn performance forecast model enable proactive identification potential deviation baseline plan allow project manager take timely corrective action research aim validate effectiveness propose approach use case study urban road reconstruction project compare model forecast actual project performance data finding research contribute advancement project management practice construction industry offer datadriven solution improve project performance monitoring control,enhance project performance forecasting use machine learning technique accurate forecasting project performance metric crucial successfully manage deliver urban road reconstruction project traditional method often rely static baseline plan fail consider dynamic nature project progress external factor research propose machine learningbase approach forecast project performance metric cost variance earn value work breakdown structure category urban road reconstruction project propose model utilize time series forecasting technique include autoregressive integrate moving average arima long shortterm memory lstm network predict future performance base historical datum project progress model also incorporate external factor weather pattern resource availability feature enhance accuracy forecast apply predictive power machine learn performance forecast model enable proactive identification potential deviation baseline plan allow project manager take timely corrective action research aim validate effectiveness propose approach use case study urban road reconstruction project compare model forecast actual project performance data finding research contribute advancement project management practice construction industry offer datadriven solution improve project performance monitoring control,0.6122448979591837,0.1564625850340136,0.14965986394557823,0.027210884353741496,147.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Mixed Methods,"Using statistical control charts to monitor duration-based performance
  of project","Monitoring of project performance is a crucial task of project managers that
significantly affect the project success or failure. Earned Value Management
(EVM) is a well-known tool to evaluate project performance and effective
technique for identifying delays and proposing appropriate corrective actions.
The original EVM analysis is a monetary-based method and it can be misleading
in the evaluation of the project schedule performance and estimation of the
project duration. Earned Duration Management (EDM) is a more recent method
which introduces metrics for the project schedule performance evaluation and
improves EVM analysis. In this paper, we apply statistical control charts on
EDM indices to better investigate the variations of project schedule
performance. Control charts are decision support tools to detect the out of
control performance. Usually project performance measurements are
auto-correlated and not following the normal distribution. Hence, in this
paper, a two-step adjustment framework is proposed to make the control charts
applicable to non-normal and auto-correlated measurements. The case study
project illustrates how the new method can be implemented in practice. The
numerical results conclude that that employing control chart method along with
analyzing the actual values of EDM indices increase the capability of project
management teams to detect cost and schedule problems on time",http://arxiv.org/abs/1902.02270v1,arXiv,use statistical control chart monitor durationbase performance project,monitoring project performance crucial task project manager significantly affect project success failure earn value management evm wellknown tool evaluate project performance effective technique identify delay propose appropriate corrective action original evm analysis monetarybased method misleading evaluation project schedule performance estimation project duration earn duration management edm recent method introduce metric project schedule performance evaluation improve evm analysis paper apply statistical control chart edm index well investigate variation project schedule performance control chart decision support tool detect control performance usually project performance measurement autocorrelated follow normal distribution hence paper twostep adjustment framework propose make control chart applicable nonnormal autocorrelated measurement case study project illustrate new method implement practice numerical result conclude employ control chart method along analyze actual value edm index increase capability project management team detect cost schedule problem time,use statistical control chart monitor durationbase performance project monitoring project performance crucial task project manager significantly affect project success failure earn value management evm wellknown tool evaluate project performance effective technique identify delay propose appropriate corrective action original evm analysis monetarybased method misleading evaluation project schedule performance estimation project duration earn duration management edm recent method introduce metric project schedule performance evaluation improve evm analysis paper apply statistical control chart edm index well investigate variation project schedule performance control chart decision support tool detect control performance usually project performance measurement autocorrelated follow normal distribution hence paper twostep adjustment framework propose make control chart applicable nonnormal autocorrelated measurement case study project illustrate new method implement practice numerical result conclude employ control chart method along analyze actual value edm index increase capability project management team detect cost schedule problem time,0.6230769230769231,0.15384615384615385,0.11538461538461539,0.038461538461538464,130.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Mixed Methods,"SLI, a New Metric to determine Success of a Software Project","Project Management process plays a critical role in managing factors such as
cost, time, technology and personnel towards achieving the success of a project
and henceforth the sustainability of the company in the industrial market. This
paper emphasizes empirical study of several projects developed over a period of
time in a product and service based CMMI Level 5 Software Company. The
investigation shows impact analysis of resources such as cost, time, and number
of developers towards the successful completion of the project as allocated by
the project manager during the developmental process. The analysis has further
led to the introduction of a new qualitative metric, Success Level Index Metric
(SLI) whose index value varies from 0 to 1. SLI acts as a maturity indicator
that indicates the degree of maturity of the company in terms of success of
their projects based on which the company can choose their desired level of
success for their projects.",http://arxiv.org/abs/1407.8377v1,arXiv,sli new metric determine success software project,project management process play critical role manage factor cost time technology personnel towards achieve success project henceforth sustainability company industrial market paper emphasize empirical study several project develop period time product service base cmmi level software company investigation show impact analysis resource cost time number developer towards successful completion project allocate project manager developmental process analysis far lead introduction new qualitative metric success level index metric sli whose index value vary sli act maturity indicator indicate degree maturity company term success project base company choose desire level success project,sli new metric determine success software project project management process play critical role manage factor cost time technology personnel towards achieve success project henceforth sustainability company industrial market paper emphasize empirical study several project develop period time product service base cmmi level software company investigation show impact analysis resource cost time number developer towards successful completion project allocate project manager developmental process analysis far lead introduction new qualitative metric success level index metric sli whose index value vary sli act maturity indicator indicate degree maturity company term success project base company choose desire level success project,0.7303370786516854,0.07865168539325842,0.12359550561797752,0.02247191011235955,89.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Mixed Methods,"ERP projects Internal Stakeholder network and how it influences the
  projects outcome","So far little effort has been put into researching the importance of internal
ERP project stakeholders mutual interactions,realizing the projects
complexity,influence on the whole organization, and high risk for a useful
final outcome. This research analyzes the stakeholders interactions and
positions in the project network, their criticality, potential bottlenecks and
conflicts. The main methods used are Social Network Analysis, and the
elicitation of drivers for the individual players. Information was collected
from several stakeholders from three large ERP projects all in global companies
headquartered in Finland, together with representatives from two different ERP
vendors, and with two experienced ERP consultants. The analysis gives
quantitative as well as qualitative characterization of stakeholder criticality
(mostly the Project Manager(s), the Business Owner(s) and the Process
Owner(s)), degree of centrality, closeness, mediating or bottleneck roles,
relational ties and conflicts (individual, besides those between business and
project organizations), and clique formations. A generic internal stakeholder
network model is established as well as the criticality of the project phases.
The results are summarized in the form of a list of recommendations for future
ERP projects to address the internal stakeholder impacts .Project management
should utilize the latest technology to provide tools to increase the
interaction between the stakeholders and to monitor the strength of these
relations. Social network analysis tools could be used in the projects to
visualize the stakeholder relations in order to better understand the possible
risks related to the relations (or lack of them).",http://arxiv.org/abs/1308.2938v1,arXiv,erp project internal stakeholder network influence project outcome,far little effort put research importance internal erp project stakeholder mutual interactionsrealize project complexityinfluence whole organization high risk useful final outcome research analyze stakeholder interaction position project network criticality potential bottleneck conflict main method use social network analysis elicitation driver individual player information collect several stakeholder three large erp project global company headquarter finland together representative two different erp vendor two experienced erp consultant analysis give quantitative well qualitative characterization stakeholder criticality mostly project manager business owner process owner degree centrality closeness mediating bottleneck role relational tie conflict individual besides business project organization clique formation generic internal stakeholder network model establish well criticality project phase result summarize form list recommendation future erp project address internal stakeholder impact project management utilize late technology provide tool increase interaction stakeholder monitor strength relation social network analysis tool could use project visualize stakeholder relation order well understand possible risk relate relation lack,erp project internal stakeholder network influence project outcome far little effort put research importance internal erp project stakeholder mutual interactionsrealize project complexityinfluence whole organization high risk useful final outcome research analyze stakeholder interaction position project network criticality potential bottleneck conflict main method use social network analysis elicitation driver individual player information collect several stakeholder three large erp project global company headquarter finland together representative two different erp vendor two experienced erp consultant analysis give quantitative well qualitative characterization stakeholder criticality mostly project manager business owner process owner degree centrality closeness mediating bottleneck role relational tie conflict individual besides business project organization clique formation generic internal stakeholder network model establish well criticality project phase result summarize form list recommendation future erp project address internal stakeholder impact project management utilize late technology provide tool increase interaction stakeholder monitor strength relation social network analysis tool could use project visualize stakeholder relation order well understand possible risk relate relation lack,0.6418918918918919,0.08783783783783784,0.19594594594594594,0.04054054054054054,148.0,0.0,1.0,0.0,0.0
Software Engineering,Project Management,Design and Development,"Embedding Sustainability in Complex Projects: A Pedagogic Practice
  Simulation Approach","Sustainability is focussed on avoiding the long-term depletion of natural
resources. Under the terms of a government plan to tackle climate change, a
driver for improved sustainability is the cut of greenhouse gas emissions in
the UK to almost zero by 2050. With this type of change, new themes are
continuously being developed which drive complex projects, such as the
development of new power generation methods, which encompass challenging lead
times and demanding requirements. Consideration of the implementation of
strategies and key concepts, which may engender sustainability within complex
projects therefore presents an opportunity for further critical debate, review,
and application through a project management lens. Sustainability incorporation
in project management has been documented in academic literature, with this
emerging field providing new challenges. For example, project management
education can provide a holistic base for the inculcation of sustainability
factors to a range of industries, including complex projects. Likewise,
practitioner interest and approaches to sustainability in project management
are being driven by the recently Chartered Association for Project Management
(APM). Whilst this body makes a significant contribution to the UK economy
across many sectors, it also addresses ongoing sustainability challenges.
Therefore, by drawing on research and practitioner developments, the authors
argue that by connecting with the next generation through practice simulation
approaches, and embedding sustainability issues within project management tools
and methods, improved focus on sustainability in complex project management may
be achieved.",http://arxiv.org/abs/2104.04068v2,arXiv,embed sustainability complex project pedagogic practice simulation approach,sustainability focusse avoid longterm depletion natural resource term government plan tackle climate change driver improve sustainability cut greenhouse gas emission almost zero type change new theme continuously develop drive complex project development new power generation method encompass challenge lead time demand requirement consideration implementation strategy key concept may engender sustainability within complex project therefore present opportunity far critical debate review application project management lens sustainability incorporation project management document academic literature emerge field provide new challenge example project management education provide holistic base inculcation sustainability factor range industry include complex project likewise practitioner interest approach sustainability project management drive recently charter association project management apm whilst body make significant contribution economy across many sector also address ongoing sustainability challenge therefore draw research practitioner development author argue connect next generation practice simulation approach embed sustainability issue within project management tool method improve focus sustainability complex project management may achieve,embed sustainability complex project pedagogic practice simulation approach sustainability focusse avoid longterm depletion natural resource term government plan tackle climate change driver improve sustainability cut greenhouse gas emission almost zero type change new theme continuously develop drive complex project development new power generation method encompass challenge lead time demand requirement consideration implementation strategy key concept may engender sustainability within complex project therefore present opportunity far critical debate review application project management lens sustainability incorporation project management document academic literature emerge field provide new challenge example project management education provide holistic base inculcation sustainability factor range industry include complex project likewise practitioner interest approach sustainability project management drive recently charter association project management apm whilst body make significant contribution economy across many sector also address ongoing sustainability challenge therefore draw research practitioner development author argue connect next generation practice simulation approach embed sustainability issue within project management tool method improve focus sustainability complex project management may achieve,0.6824324324324325,0.10135135135135136,0.11486486486486487,0.05405405405405406,148.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Design and Development,"Service Oriented Architecture A Revolution For Comprehensive Web Based
  Project Management Software","Service Oriented Architecture A Revolution for Project Management Software
has changed the way projects today are moving on the fly with the help of web
services booming the industry. Service oriented architecture improves
performance and the communication between the distributed and remote teams. Web
Services to Provide Project Management software the visibility and control of
the application development lifecycle-giving a better control over the entire
development process, from the management stage through development. The goal of
Service Oriented Architecture for Project Management Software is to produce a
product that is delivered on time, within the allocated budget, and with the
capabilities expected by the customer. Web Services in Project management
Project management software is basically a properly managed project and has a
clear, communicated, and managed set of goals and objectives, whose progress is
quantifiable and controlled. Resources are used effectively and efficiently to
produce the desired product. With the help of service oriented architecture we
can move into the future without abandoning the past. A project usually has a
communicated set of processes that cover the daily activities of the project,
forming the project framework. As a result, every team member understands their
roles, responsibilities and how they fit into the big picture thus promoting
the efficient use of resources.",http://arxiv.org/abs/1207.4966v1,arXiv,service orient architecture revolution comprehensive web base project management software,service orient architecture revolution project management software change way project today move fly help web service boom industry service orient architecture improve performance communication distribute remote team web service provide project management software visibility control application development lifecyclegive well control entire development process management stage development goal service orient architecture project management software produce product deliver time within allocate budget capability expect customer web service project management project management software basically properly manage project clear communicate manage set goal objective whose progress quantifiable control resource use effectively efficiently produce desire product help service orient architecture move future without abandon past project usually communicate set process cover daily activity project form project framework result every team member understand role responsibility fit big picture thus promote efficient use resource,service orient architecture revolution comprehensive web base project management software service orient architecture revolution project management software change way project today move fly help web service boom industry service orient architecture improve performance communication distribute remote team web service provide project management software visibility control application development lifecyclegive well control entire development process management stage development goal service orient architecture project management software produce product deliver time within allocate budget capability expect customer web service project management project management software basically properly manage project clear communicate manage set goal objective whose progress quantifiable control resource use effectively efficiently produce desire product help service orient architecture move future without abandon past project usually communicate set process cover daily activity project form project framework result every team member understand role responsibility fit big picture thus promote efficient use resource,0.6141732283464567,0.16535433070866143,0.11023622047244094,0.05511811023622047,127.0,0.0,0.0,2.0,0.0
Software Engineering,Project Management,Design and Development,"SoaDssPm: A new Service-Oriented Architecture of the decision support
  system for the Project Management","This paper presents an architecture for the Project Management, which is
defined using the concepts behind ServiceOriented and Decision Support System.
The framework described, denominated as SoaDssPm, represents the following: a
coherent solution to the problem of control Project Management the existing gap
between the real execution of Project Management by describing the business
process and relationships required by a SOA solution, and its objectives
representation, in which the decisional aspects determine the final shape of
the system, providing decision support to the identified business processes and
constraints.",http://arxiv.org/abs/1401.5433v1,arXiv,soadsspm new serviceoriente architecture decision support system project management,paper present architecture project management define use concept behind serviceoriented decision support system framework describe denominate soadsspm represent follow coherent solution problem control project management exist gap real execution project management describe business process relationship require soa solution objective representation decisional aspect determine final shape system provide decision support identify business process constraint,soadsspm new serviceoriente architecture decision support system project management paper present architecture project management define use concept behind serviceoriented decision support system framework describe denominate soadsspm represent follow coherent solution problem control project management exist gap real execution project management describe business process relationship require soa solution objective representation decisional aspect determine final shape system provide decision support identify business process constraint,0.660377358490566,0.16981132075471697,0.11320754716981132,0.0,53.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Design and Development,Towards effective AI-powered agile project management,"The rise of Artificial intelligence (AI) has the potential to significantly
transform the practice of project management. Project management has a large
socio-technical element with many uncertainties arising from variability in
human aspects e.g., customers' needs, developers' performance and team
dynamics. AI can assist project managers and team members by automating
repetitive, high-volume tasks to enable project analytics for estimation and
risk prediction, providing actionable recommendations, and even making
decisions. AI is potentially a game changer for project management in helping
to accelerate productivity and increase project success rates. In this paper,
we propose a framework where AI technologies can be leveraged to offer support
for managing agile projects, which have become increasingly popular in the
industry.",http://arxiv.org/abs/1812.10578v1,arXiv,towards effective aipowere agile project management,rise artificial intelligence potential significantly transform practice project management project management large sociotechnical element many uncertainty arise variability human aspect customer need developer performance team dynamic assist project manager team member automate repetitive highvolume task enable project analytic estimation risk prediction provide actionable recommendation even make decision potentially game changer project management help accelerate productivity increase project success rate paper propose framework technology leveraged offer support manage agile project become increasingly popular industry,towards effective aipowere agile project management rise artificial intelligence potential significantly transform practice project management project management large sociotechnical element many uncertainty arise variability human aspect customer need developer performance team dynamic assist project manager team member automate repetitive highvolume task enable project analytic estimation risk prediction provide actionable recommendation even make decision potentially game changer project management help accelerate productivity increase project success rate paper propose framework technology leveraged offer support manage agile project become increasingly popular industry,0.6301369863013698,0.1506849315068493,0.1643835616438356,0.0547945205479452,73.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Design and Development,Anywhere: A Web Crawler Automation Management Interface,"Web crawling projects or design is significant in the current information
age. Using the web spider or crawler can automatically search and collect a
huge amount of internet information. As one of the most popular web crawler
frameworks, Scrapy is robust in abundant functions but weak in easy operation.
In this paper, we provide a framework Anywhere, for optimising the usage
feeling and improving the use efficiency of the web crawling management of
Scrapy. We analyse the whole workflow of a web crawling project of Scrapy and
design two main functions in Anywhere, one is quickly generating a Scrapy
project with the preset temperatures, the other is repeatable configuration
function for the Scrapy project setting. Beside, with Anywhere, users can
easily directly manage multiple Scrapy projects with a file folders
architecture. Compared with normal Scrapy project interactive coding
development, we test Anywhere with enough experiments that show Anywhere can
improve the development efficiency of Scrapy projects to about 200\%. For the
multiple project management in code interaction level, the developing
efficiency is improved to about 300\%. We simplify the procedure to quickly
generate a simple spider project with Scrapy. Anywhere can assist the
development of Scrapy is useful for the design of large batch concurrent
projects at coding level.",http://arxiv.org/abs/2407.00025v1,arXiv,anywhere web crawler automation management interface,web crawl project design significant current information age use web spider crawler automatically search collect huge amount internet information one popular web crawler framework scrapy robust abundant function weak easy operation paper provide framework anywhere optimise usage feeling improve use efficiency web crawl management scrapy analyse whole workflow web crawl project scrapy design two main function anywhere one quickly generate scrapy project preset temperature repeatable configuration function scrapy project set beside anywhere user easily directly manage multiple scrapy project file folder architecture compare normal scrapy project interactive coding development test anywhere enough experiment show anywhere improve development efficiency scrapy project multiple project management code interaction level develop efficiency improve simplify procedure quickly generate simple spider project scrapy anywhere assist development scrapy useful design large batch concurrent project code level,anywhere web crawler automation management interface web crawl project design significant current information age use web spider crawler automatically search collect huge amount internet information one popular web crawler framework scrapy robust abundant function weak easy operation paper provide framework anywhere optimise usage feeling improve use efficiency web crawl management scrapy analyse whole workflow web crawl project scrapy design two main function anywhere one quickly generate scrapy project preset temperature repeatable configuration function scrapy project set beside anywhere user easily directly manage multiple scrapy project file folder architecture compare normal scrapy project interactive coding development test anywhere enough experiment show anywhere improve development efficiency scrapy project multiple project management code interaction level develop efficiency improve simplify procedure quickly generate simple spider project scrapy anywhere assist development scrapy useful design large batch concurrent project code level,0.5813953488372093,0.12403100775193798,0.16279069767441862,0.09302325581395349,129.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Theoretical / Conceptual,A Perspective-Based Understanding of Project Success,"Answering the call for alternative approaches to researching project
management, we explore the evaluation of project success from a subjectivist
perspective. An in-depth, longitudinal case study of information systems
development in a large manufacturing company was used to investigate how
various project stakeholders subjectively perceived the project outcome and
what evaluation criteria they drew on in doing so. A conceptual framework is
developed for understanding and analyzing evaluations of project success, both
formal and informal. The framework highlights how different stakeholder
perspectives influence the perceived outcome(s) of a project, and how project
evaluations may differ between stakeholders and across time.",http://arxiv.org/abs/2101.05425v1,arXiv,perspectivebased understanding project success,answer call alternative approach research project management explore evaluation project success subjectivist perspective indepth longitudinal case study information system development large manufacture company use investigate various project stakeholder subjectively perceive project outcome evaluation criterion draw conceptual framework develop understanding analyze evaluation project success formal informal framework highlight different stakeholder perspective influence perceive outcome project project evaluation may differ stakeholder across time,perspectivebased understanding project success answer call alternative approach research project management explore evaluation project success subjectivist perspective indepth longitudinal case study information system development large manufacture company use investigate various project stakeholder subjectively perceive project outcome evaluation criterion draw conceptual framework develop understanding analyze evaluation project success formal informal framework highlight different stakeholder perspective influence perceive outcome project project evaluation may differ stakeholder across time,0.6557377049180327,0.09836065573770492,0.16393442622950818,0.01639344262295082,61.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Theoretical / Conceptual,From Nobel Prize to Project Management: Getting Risks Right,"A major source of risk in project management is inaccurate forecasts of
project costs, demand, and other impacts. The paper presents a promising new
approach to mitigating such risk, based on theories of decision making under
uncertainty which won the 2002 Nobel prize in economics. First, the paper
documents inaccuracy and risk in project management. Second, it explains
inaccuracy in terms of optimism bias and strategic misrepresentation. Third,
the theoretical basis is presented for a promising new method called ""reference
class forecasting,"" which achieves accuracy by basing forecasts on actual
performance in a reference class of comparable projects and thereby bypassing
both optimism bias and strategic misrepresentation. Fourth, the paper presents
the first instance of practical reference class forecasting, which concerns
cost forecasts for large transportation infrastructure projects. Finally,
potentials for and barriers to reference class forecasting are assessed.",http://arxiv.org/abs/1302.3642v1,arXiv,nobel prize project management get risk right,major source risk project management inaccurate forecast project cost demand impact paper present promising new approach mitigate risk base theory decision make uncertainty win nobel prize economics first paper document inaccuracy risk project management second explain inaccuracy term optimism bias strategic misrepresentation third theoretical basis present promising new method call reference class forecasting achieve accuracy base forecast actual performance reference class comparable project thereby bypass optimism bias strategic misrepresentation fourth paper present first instance practical reference class forecasting concern cost forecast large transportation infrastructure project finally potential barrier reference class forecasting assess,nobel prize project management get risk right major source risk project management inaccurate forecast project cost demand impact paper present promising new approach mitigate risk base theory decision make uncertainty win nobel prize economics first paper document inaccuracy risk project management second explain inaccuracy term optimism bias strategic misrepresentation third theoretical basis present promising new method call reference class forecasting achieve accuracy base forecast actual performance reference class comparable project thereby bypass optimism bias strategic misrepresentation fourth paper present first instance practical reference class forecasting concern cost forecast large transportation infrastructure project finally potential barrier reference class forecasting assess,0.6630434782608695,0.09782608695652174,0.17391304347826086,0.021739130434782608,92.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Theoretical / Conceptual,"Quality Control and Due Diligence in Project Management: Getting
  Decisions Right by Taking the Outside View","This paper explores how theories of the planning fallacy and the outside view
may be used to conduct quality control and due diligence in project management.
First, a much-neglected issue in project management is identified, namely that
the front-end estimates of costs and benefits--used in the business cases,
cost-benefit analyses, and social and environmental impact assessments that
typically support decisions on projects--are typically significantly different
from actual ex post costs and benefits, and are therefore poor predictors of
the actual value and viability of projects. Second, it is discussed how
Kahneman and Tversky's theories of the planning fallacy and the outside view
may help explain and remedy this situation through quality control of
decisions. Third, it is described what quality control and due diligence are in
the context of project management, and an eight-step procedure is outlined for
due diligence based on the outside view. Fourth, the procedure is tested on a
real-life, multibillion-dollar project, organized as a public-private
partnership. Finally, Akerlof and Shiller's recent discussion in economics of
""firing the forecaster"" is discussed together with its relevance to project
management. In sum, the paper demonstrates the need, the theoretical basis, a
practical methodology, and a real-life example for how to de-bias project
management using quality control and due diligence based on the outside view.",http://arxiv.org/abs/1302.2544v1,arXiv,quality control due diligence project management getting decision right take outside view,paper explore theory planning fallacy outside view may use conduct quality control due diligence project management first muchneglected issue project management identify namely frontend estimate cost benefitsuse business case costbenefit analysis social environmental impact assessment typically support decision projectsare typically significantly different actual post cost benefit therefore poor predictor actual value viability project second discuss kahneman tverskys theory planning fallacy outside view may help explain remedy situation quality control decision third describe quality control due diligence context project management eightstep procedure outline due diligence base outside view fourth procedure test reallife multibilliondollar project organize publicprivate partnership finally akerlof shiller recent discussion economic fire forecaster discuss together relevance project management sum paper demonstrate need theoretical basis practical methodology reallife example debias project management use quality control due diligence base outside view,quality control due diligence project management getting decision right take outside view paper explore theory planning fallacy outside view may use conduct quality control due diligence project management first muchneglected issue project management identify namely frontend estimate cost benefitsuse business case costbenefit analysis social environmental impact assessment typically support decision projectsare typically significantly different actual post cost benefit therefore poor predictor actual value viability project second discuss kahneman tverskys theory planning fallacy outside view may help explain remedy situation quality control decision third describe quality control due diligence context project management eightstep procedure outline due diligence base outside view fourth procedure test reallife multibilliondollar project organize publicprivate partnership finally akerlof shiller recent discussion economic fire forecaster discuss together relevance project management sum paper demonstrate need theoretical basis practical methodology reallife example debias project management use quality control due diligence base outside view,0.6,0.11538461538461539,0.16923076923076924,0.06923076923076923,130.0,0.0,0.0,0.0,1.0
Software Engineering,Project Management,Theoretical / Conceptual,"OntoMaven: Maven-based Ontology Development and Management of
  Distributed Ontology Repositories","In collaborative agile ontology development projects support for modular
reuse of ontologies from large existing remote repositories, ontology project
life cycle management, and transitive dependency management are important
needs. The Apache Maven approach has proven its success in distributed
collaborative Software Engineering by its widespread adoption. The contribution
of this paper is a new design artifact called OntoMaven. OntoMaven adopts the
Maven-based development methodology and adapts its concepts to knowledge
engineering for Maven-based ontology development and management of ontology
artifacts in distributed ontology repositories.",http://arxiv.org/abs/1309.7341v1,arXiv,ontomaven mavenbase ontology development management distribute ontology repository,collaborative agile ontology development project support modular reuse ontology large exist remote repository ontology project life cycle management transitive dependency management important need apache maven approach prove success distribute collaborative software engineering widespread adoption contribution paper new design artifact call ontomaven ontomaven adopt mavenbase development methodology adapt concept knowledge engineering mavenbase ontology development management ontology artifact distribute ontology repository,ontomaven mavenbase ontology development management distribute ontology repository collaborative agile ontology development project support modular reuse ontology large exist remote repository ontology project life cycle management transitive dependency management important need apache maven approach prove success distribute collaborative software engineering widespread adoption contribution paper new design artifact call ontomaven ontomaven adopt mavenbase development methodology adapt concept knowledge engineering mavenbase ontology development management ontology artifact distribute ontology repository,0.576271186440678,0.15254237288135594,0.1694915254237288,0.01694915254237288,59.0,0.0,0.0,0.0,0.0
Software Engineering,Project Management,Theoretical / Conceptual,"Exploring Data Management Challenges and Solutions in Agile Software
  Development: A Literature Review and Practitioner Survey","Context: Managing data related to a software product and its development
poses significant challenges for software projects and agile development teams.
These include integrating data from diverse sources and ensuring data quality
amidst continuous change and adaptation. Objective: The paper systematically
explores data management challenges and potential solutions in agile projects,
aiming to provide insights into data management challenges and solutions for
both researchers and practitioners. Method: We employed a mixed-methods
approach, including a systematic literature review (SLR) to understand the
state-of-research followed by a survey with practitioners to reflect on the
state-of-practice. The SLR reviewed 45 studies, identifying and categorizing
data management aspects along with their associated challenges and solutions.
The practitioner survey captured practical experiences and solutions from 32
industry practitioners who were significantly involved in data management to
complement the findings from the SLR. Results: Our findings identified major
data management challenges in practice, such as managing data integration
processes, capturing diverse data, automating data collection, and meeting
real-time analysis requirements. To address the challenges, solutions such as
automation tools, decentralized data management practices, and ontology-based
approaches have been identified. The solutions enhance data integration,
improve data quality, and enable real-time decision-making by providing
flexible frameworks tailored to agile project needs. Conclusion: The study
pinpointed significant challenges and actionable solutions in data management
for agile software development. Our findings provide practical implications for
practitioners and researchers, emphasizing the development of effective data
management practices and tools to address those challenges and improve project
success.",http://arxiv.org/abs/2402.00462v4,arXiv,explore datum management challenge solution agile software development literature review practitioner survey,context manage datum relate software product development pose significant challenge software project agile development team include integrate datum diverse source ensure datum quality amidst continuous change adaptation objective paper systematically explore datum management challenge potential solution agile project aim provide insight data management challenge solution researcher practitioner method employ mixedmethod approach include systematic literature review slr understand stateofresearch follow survey practitioner reflect stateofpractice slr review study identify categorize datum management aspect along associate challenge solution practitioner survey capture practical experience solution industry practitioner significantly involve datum management complement finding slr result finding identify major data management challenge practice manage datum integration process capture diverse datum automate data collection meeting realtime analysis requirement address challenge solution automation tool decentralize data management practice ontologybase approach identify solution enhance datum integration improve data quality enable realtime decisionmake provide flexible framework tailor agile project need conclusion study pinpoint significant challenge actionable solution datum management agile software development finding provide practical implication practitioner researcher emphasize development effective datum management practice tool address challenge improve project success,explore datum management challenge solution agile software development literature review practitioner survey context manage datum relate software product development pose significant challenge software project agile development team include integrate datum diverse source ensure datum quality amidst continuous change adaptation objective paper systematically explore datum management challenge potential solution agile project aim provide insight data management challenge solution researcher practitioner method employ mixedmethod approach include systematic literature review slr understand stateofresearch follow survey practitioner reflect stateofpractice slr review study identify categorize datum management aspect along associate challenge solution practitioner survey capture practical experience solution industry practitioner significantly involve datum management complement finding slr result finding identify major data management challenge practice manage datum integration process capture diverse datum automate data collection meeting realtime analysis requirement address challenge solution automation tool decentralize data management practice ontologybase approach identify solution enhance datum integration improve data quality enable realtime decisionmake provide flexible framework tailor agile project need conclusion study pinpoint significant challenge actionable solution datum management agile software development finding provide practical implication practitioner researcher emphasize development effective datum management practice tool address challenge improve project success,0.6666666666666666,0.15204678362573099,0.1286549707602339,0.011695906432748537,171.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Quantitative,"Enterprise resource planning systems, strategic enterprise management systems and management accounting","<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>The purpose of this paper is to contribute to the body of knowledge about to what extent integrated information systems, such as ERP and SEM systems, affect the ability to solve different management accounting tasks.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>The relationship between IIS and management accounting practices was investigated quantitatively. A total of 349 responses were collected using a survey, and the data were analysed using linear regression models.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Analyses indicate that ERP systems support the data collection and the organisational breadth of management accounting better than SEM systems. SEM systems, on the other hand, seem to be better at supporting reporting and analysis. In addition, modern management accounting techniques involving the use of non‐financial data are better supported by an SEM system. This indicates that different management accounting tasks are supported by different parts of the IIS.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p>The study applies the methods of quantitative research. Thus, the internal validity is threatened. Conducting in‐depth studies might be able to reduce this possible shortcoming.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>On the basis of the findings, there is a need to consider the potential of closer integration of ERP and SEM systems in order to solve management accounting tasks.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>This paper adds to the limited body of knowledge about the relationship between IIS and management accounting practices.</jats:p></jats:sec>",https://doi.org/10.1108/17410390610636878,CrossRef,enterprise resource planning system strategic enterprise management system management accounting,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper contribute body knowledge extent integrate information system erp sem system affect ability solve different management accounting tasksjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe relationship iis management accounting practice investigate quantitatively total response collect use survey datum analyse use linear regression modelsjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspanalyse indicate erp system support data collection organisational breadth management accounting well sem system sem system hand seem well support reporting analysis addition modern management accounting technique involve use datum well support sem system indicate different management accounting task support different part iisjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe study apply method quantitative research thus internal validity threaten conduct study might able reduce possible shortcomingjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspon basis finding need consider potential close integration erp sem system order solve management accounting tasksjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis paper add limited body knowledge relationship iis management accounting practicesjatspjatssec,enterprise resource planning system strategic enterprise management system management accounting jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper contribute body knowledge extent integrate information system erp sem system affect ability solve different management accounting tasksjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe relationship iis management accounting practice investigate quantitatively total response collect use survey datum analyse use linear regression modelsjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspanalyse indicate erp system support data collection organisational breadth management accounting well sem system sem system hand seem well support reporting analysis addition modern management accounting technique involve use datum well support sem system indicate different management accounting task support different part iisjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe study apply method quantitative research thus internal validity threaten conduct study might able reduce possible shortcomingjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspon basis finding need consider potential close integration erp sem system order solve management accounting tasksjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis paper add limited body knowledge relationship iis management accounting practicesjatspjatssec,0.5658914728682171,0.13953488372093023,0.13178294573643412,0.046511627906976744,64.5,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Quantitative,Is it Really so 'Strategic'?,"<p>This paper presents empirical research on motivational factors for investing in Enterprise Systems (ES), based on the survey conducted among project leaders. The results show that enterprises make investments in ES mostly to increase operational efficiency, provide managers with more accurate information and, which is interesting, to be able to continue the operations on the current level. Almost one third of examined enterprises indicated the replacement of an inefficient IT infrastructure with a new one enabling smooth operation of current business processes as the most important motivational factor for investments. The results of the research presented in this paper may help to understand the productivity paradox as they prove that many enterprises treat IT as a commodity rather than a strategic asset that generates significant business gains.</p>",https://doi.org/10.4018/ijeis.2011100102,CrossRef,really strategic,pthis paper present empirical research motivational factor invest enterprise system base survey conduct among project leader result show enterprise make investment mostly increase operational efficiency provide manager accurate information interesting able continue operation current level almost one third examine enterprise indicate replacement inefficient infrastructure new one enable smooth operation current business process important motivational factor investment result research present paper may help understand productivity paradox prove many enterprise treat commodity rather strategic asset generate significant business gainsp,really strategic pthis paper present empirical research motivational factor invest enterprise system base survey conduct among project leader result show enterprise make investment mostly increase operational efficiency provide manager accurate information interesting able continue operation current level almost one third examine enterprise indicate replacement inefficient infrastructure new one enable smooth operation current business process important motivational factor investment result research present paper may help understand productivity paradox prove many enterprise treat commodity rather strategic asset generate significant business gainsp,0.5064935064935064,0.15584415584415584,0.23376623376623376,0.03896103896103896,77.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Quantitative,Modern problems of anomaly identification in Enterprise Systems,"<jats:p>The article addresses modern challenges in anomaly detection within enterprise systems us-ing memory dump analysis. As the complexity of enterprise systems grows, the number of potential issues affecting their stability and performance also increases. Anomalies, such as software failures or unexpected deviations from normal behavior, can lead to serious consequences, including data loss, reduced performance, or even complete system shutdown. Detecting and resolving these anomalies is a critical task for maintaining uninterrupted operation in enterprise environments. The primary method discussed in this article is memory dump analysis, which provides de-tailed information about the system's state at the time of an anomaly. This method is effective for identifying root causes of failures, such as memory leaks or other resource-intensive operations. However, due to the large volumes of data and the complexity of modern software systems, memory dump analysis faces several challenges, such as the need for precise data collection during inci-dents and the requirement for powerful computational resources to process such data. The article thoroughly analyzes algorithms and tools used for detecting problems in enter-prise systems. Specifically, statistical methods, machine learning algorithms, and tools for memory dump analysis are reviewed. Machine learning techniques enable the creation of models represent-ing normal system behavior and automatically detect deviations from these models, facilitating timely identification of potential issues. Additionally, optimization methods aimed at improving sys-tem performance, including techniques such as parallelization, caching, and code profiling, are ex-plored. One of the main challenges discussed in the article is the limitations of existing methods and tools for software analysis. High-load systems often face difficulties in real-time profiling and monitoring, complicating the identification of root causes. The article also examines limitations re-lated to the accuracy of data collection and the complexity of diagnosing issues in distributed sys-tems. Based on the analysis, the article suggests future prospects for improving modern methods of anomaly detection in enterprise systems. Key areas for further research include enhancing machine learning algorithms for memory dump analysis, developing more efficient optimization methods, and improving monitoring tools to increase the accuracy and speed of problem detection. The arti-cle also highlights the importance of integrating these technologies into real-world enterprise envi-ronments to ensure stability and reliability.</jats:p>",https://doi.org/10.34185/1562-9945-5-154-2024-15,CrossRef,modern problem anomaly identification enterprise system,jatspthe article address modern challenge anomaly detection within enterprise system use memory dump analysis complexity enterprise system grow number potential issue affect stability performance also increase anomaly software failure unexpected deviation normal behavior lead serious consequence include datum loss reduce performance even complete system shutdown detect resolve anomaly critical task maintain uninterrupted operation enterprise environment primary method discuss article memory dump analysis provide detailed information system state time anomaly method effective identify root cause failure memory leak resourceintensive operation however due large volume datum complexity modern software system memory dump analysis face several challenge need precise data collection incident requirement powerful computational resource process datum article thoroughly analyze algorithm tool use detect problem enterprise system specifically statistical method machine learn algorithm tool memory dump analysis review machine learn technique enable creation model represent normal system behavior automatically detect deviation model facilitate timely identification potential issue additionally optimization method aim improve system performance include technique parallelization cache code profiling explore one main challenge discuss article limitation exist method tool software analysis highload system often face difficulty realtime profiling monitoring complicate identification root cause article also examine limitation relate accuracy data collection complexity diagnose issue distribute system base analysis article suggest future prospect improve modern method anomaly detection enterprise system key area research include enhance machine learn algorithm memory dump analysis develop efficient optimization method improve monitoring tool increase accuracy speed problem detection article also highlight importance integrate technology realworld enterprise environment ensure stability reliabilityjatsp,modern problem anomaly identification enterprise system jatspthe article address modern challenge anomaly detection within enterprise system use memory dump analysis complexity enterprise system grow number potential issue affect stability performance also increase anomaly software failure unexpected deviation normal behavior lead serious consequence include datum loss reduce performance even complete system shutdown detect resolve anomaly critical task maintain uninterrupted operation enterprise environment primary method discuss article memory dump analysis provide detailed information system state time anomaly method effective identify root cause failure memory leak resourceintensive operation however due large volume datum complexity modern software system memory dump analysis face several challenge need precise data collection incident requirement powerful computational resource process datum article thoroughly analyze algorithm tool use detect problem enterprise system specifically statistical method machine learn algorithm tool memory dump analysis review machine learn technique enable creation model represent normal system behavior automatically detect deviation model facilitate timely identification potential issue additionally optimization method aim improve system performance include technique parallelization cache code profiling explore one main challenge discuss article limitation exist method tool software analysis highload system often face difficulty realtime profiling monitoring complicate identification root cause article also examine limitation relate accuracy data collection complexity diagnose issue distribute system base analysis article suggest future prospect improve modern method anomaly detection enterprise system key area research include enhance machine learn algorithm memory dump analysis develop efficient optimization method improve monitoring tool increase accuracy speed problem detection article also highlight importance integrate technology realworld enterprise environment ensure stability reliabilityjatsp,0.5925925925925926,0.18106995884773663,0.11934156378600823,0.0411522633744856,243.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Quantitative,Enterprise systems implementation and accounting benefits,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>The aim of this paper is to examine the accounting benefits involved in adopting enterprise systems, but also to comprehend the underlying causes that motivate their adoption.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>This paper presents evidence from a survey of 73 companies which implemented ES on the related benefits to their accounting information provision and practices.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Empirical evidence confirms a number of benefits derived from the application of ES that focus on the following dimensions: organisation, operations, management and IT infrastructure. These benefits are related both to the reasons leading to the implementation of ES and to the relevant selection of ES modules.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>The corresponding results from this survey can then be used as a basis for establishing the best approach in order to fully exploit the potential of future ES applications in accounting practice.</jats:p></jats:sec>",https://doi.org/10.1108/17410390610636887,CrossRef,enterprise system implementation accounting benefit,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe aim paper examine accounting benefit involve adopt enterprise system also comprehend underlie cause motivate adoptionjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthis paper present evidence survey company implement related benefit accounting information provision practicesjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspempirical evidence confirm number benefit derive application focus follow dimension organisation operation management infrastructure benefit relate reason lead implementation relevant selection modulesjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe correspond result survey use basis establish good approach order fully exploit potential future application accounting practicejatspjatssec,enterprise system implementation accounting benefit jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe aim paper examine accounting benefit involve adopt enterprise system also comprehend underlie cause motivate adoptionjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthis paper present evidence survey company implement related benefit accounting information provision practicesjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspempirical evidence confirm number benefit derive application focus follow dimension organisation operation management infrastructure benefit relate reason lead implementation relevant selection modulesjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe correspond result survey use basis establish good approach order fully exploit potential future application accounting practicejatspjatssec,0.5507246376811594,0.14492753623188406,0.14492753623188406,0.028985507246376812,34.5,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Quantitative,Improving Internal Supply Chain Collaboration by Increasing Information-Processing Capacity,"<p>This study examines the role of enterprise information systems in fostering collaboration between the Purchasing, Production, and Outbound Logistics functions of manufacturing facilities. These forms of integrative information technology are considered key facilitators of supply chain management. The research model embeds these systems within a broader model of facilitators of interfunctional integration. The model is tested by path analysis, using a survey sample of 120 manufacturing facilities located in the United States. The results suggest that integrative information technology has a significant effect on collaboration, and that the level of demand uncertainty moderates the effect on collaboration.</p>",https://doi.org/10.4018/jeis.2011100101,CrossRef,improve internal supply chain collaboration increase informationprocesse capacity,pthis study examine role enterprise information system foster collaboration purchase production outbound logistic function manufacture facility form integrative information technology consider key facilitator supply chain management research model embed system within broad model facilitator interfunctional integration model test path analysis use survey sample manufacture facility locate united states result suggest integrative information technology significant effect collaboration level demand uncertainty moderate effect collaborationp,improve internal supply chain collaboration increase informationprocesse capacity pthis study examine role enterprise information system foster collaboration purchase production outbound logistic function manufacture facility form integrative information technology consider key facilitator supply chain management research model embed system within broad model facilitator interfunctional integration model test path analysis use survey sample manufacture facility locate united states result suggest integrative information technology significant effect collaboration level demand uncertainty moderate effect collaborationp,0.6935483870967742,0.06451612903225806,0.14516129032258066,0.0,62.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Qualitative,"Exploring the Use of Enterprise 2.0 and Its Impact on Social Capital
  within a Large Organisation","Despite the rampant adoption of Enterprise 2.0, there is lack of empirical
evidence of how Enterprise 2.0 is aptly supporting the business objectives.
Social capital theory will be used as a theoretical lens to understand the
impact and implications of individual use of Enterprise 2.0. To ascertain the
impact from the use of Enterprise 2.0 on the various dimensions of social
capital, a single in-depth qualitative case study was conducted with a large
professional services organisation. The findings unfold the different areas of
impacts based on actual individual use and experience. The research concludes
with a framework delineating the intertwined relationship between each social
capital dimensions.",http://arxiv.org/abs/1606.02486v1,arXiv,explore use enterprise impact social capital within large organisation,despite rampant adoption enterprise lack empirical evidence enterprise aptly support business objective social capital theory use theoretical lens understand impact implication individual use enterprise ascertain impact use enterprise various dimension social capital single indepth qualitative case study conduct large professional service organisation finding unfold different area impact base actual individual use experience research conclude framework delineate intertwine relationship social capital dimension,explore use enterprise impact social capital within large organisation despite rampant adoption enterprise lack empirical evidence enterprise aptly support business objective social capital theory use theoretical lens understand impact implication individual use enterprise ascertain impact use enterprise various dimension social capital single indepth qualitative case study conduct large professional service organisation finding unfold different area impact base actual individual use experience research conclude framework delineate intertwine relationship social capital dimension,0.5737704918032787,0.13114754098360656,0.26229508196721313,0.01639344262295082,61.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Qualitative,"From Full-fledged ERP Systems Towards Process-centric Business Process
  Platforms","Enterprise Resource Planning (ERP) systems are critical to the success of
enterprises, facilitating business operations through standardized digital
processes. However, existing ERP systems are unsuitable for startups and small
and medium-sized enterprises that grow quickly and require adaptable solutions
with low barriers to entry. Drawing upon 15 explorative interviews with
industry experts, we examine the challenges of current ERP systems using the
task technology fit theory across companies of varying sizes. We describe high
entry barriers, high costs of implementing implicit processes, and insufficient
interoperability of already employed tools. We present a vision of a future
business process platform based on three enablers: Business processes as
first-class entities, semantic data and processes, and cloud-native elasticity
and high availability. We discuss how these enablers address current ERP
systems' challenges and how they may be used for research on the next
generation of business software for tomorrow's enterprises.",http://arxiv.org/abs/2306.02995v1,arXiv,fullfledged erp system towards processcentric business process platform,enterprise resource planning erp system critical success enterprise facilitate business operation standardized digital process however exist erp system unsuitable startup small mediumsize enterprise grow quickly require adaptable solution low barrier entry drawing upon explorative interview industry expert examine challenge current erp system use task technology fit theory across company vary size describe high entry barrier high cost implement implicit process insufficient interoperability already employ tool present vision future business process platform base three enabler business process firstclass entity semantic datum process cloudnative elasticity high availability discuss enabler address current erp system challenge may use research next generation business software tomorrow enterprise,fullfledged erp system towards processcentric business process platform enterprise resource planning erp system critical success enterprise facilitate business operation standardized digital process however exist erp system unsuitable startup small mediumsize enterprise grow quickly require adaptable solution low barrier entry drawing upon explorative interview industry expert examine challenge current erp system use task technology fit theory across company vary size describe high entry barrier high cost implement implicit process insufficient interoperability already employ tool present vision future business process platform base three enabler business process firstclass entity semantic datum process cloudnative elasticity high availability discuss enabler address current erp system challenge may use research next generation business software tomorrow enterprise,0.6039603960396039,0.0891089108910891,0.2376237623762376,0.0297029702970297,101.0,0.0,0.0,1.0,0.0
Information Systems,Enterprise Systems,Qualitative,"Towards Energy-Proportional Computing Using Subsystem-Level Power
  Management","Massive data centers housing thousands of computing nodes have become
commonplace in enterprise computing, and the power consumption of such data
centers is growing at an unprecedented rate. Adding to the problem is the
inability of the servers to exhibit energy proportionality, i.e., provide
energy-efficient execution under all levels of utilization, which diminishes
the overall energy efficiency of the data center. It is imperative that we
realize effective strategies to control the power consumption of the server and
improve the energy efficiency of data centers. With the advent of Intel Sandy
Bridge processors, we have the ability to specify a limit on power consumption
during runtime, which creates opportunities to design new power-management
techniques for enterprise workloads and make the systems that they run on more
energy-proportional.
  In this paper, we investigate whether it is possible to achieve energy
proportionality for enterprise-class server workloads, namely SPECpower_ssj2008
and SPECweb2009 benchmarks, by using Intel's Running Average Power Limit (RAPL)
interfaces. First, we analyze the average power consumption of the full system
as well as the subsystems and describe the energy proportionality of these
components. We then characterize the instantaneous power profile of these
benchmarks within different subsystems using the on-chip energy meters exposed
via the RAPL interfaces. Finally, we present the effects of power limiting on
the energy proportionality, performance, power and energy efficiency of
enterprise-class server workloads. Our observations and results shed light on
the efficacy of the RAPL interfaces and provide guidance for designing
power-management techniques for enterprise-class workloads.",http://arxiv.org/abs/1501.02724v1,arXiv,towards energyproportional computing use subsystemlevel power management,massive data center housing thousand computing node become commonplace enterprise computing power consumption datum center grow unprecedented rate add problem inability server exhibit energy proportionality provide energyefficient execution level utilization diminish overall energy efficiency data center imperative realize effective strategy control power consumption server improve energy efficiency data center advent intel sandy bridge processor ability specify limit power consumption runtime create opportunity design new powermanagement technique enterprise workload make system run energyproportional paper investigate whether possible achieve energy proportionality enterpriseclass server workload namely specpowerssj specweb benchmark use intel run average power limit rapl interface first analyze average power consumption full system well subsystem describe energy proportionality component characterize instantaneous power profile benchmark within different subsystem use onchip energy meter expose via rapl interface finally present effect power limit energy proportionality performance power energy efficiency enterpriseclass server workload observation result shed light efficacy rapl interface provide guidance designing powermanagement technique enterpriseclass workload,towards energyproportional computing use subsystemlevel power management massive data center housing thousand computing node become commonplace enterprise computing power consumption datum center grow unprecedented rate add problem inability server exhibit energy proportionality provide energyefficient execution level utilization diminish overall energy efficiency data center imperative realize effective strategy control power consumption server improve energy efficiency data center advent intel sandy bridge processor ability specify limit power consumption runtime create opportunity design new powermanagement technique enterprise workload make system run energyproportional paper investigate whether possible achieve energy proportionality enterpriseclass server workload namely specpowerssj specweb benchmark use intel run average power limit rapl interface first analyze average power consumption full system well subsystem describe energy proportionality component characterize instantaneous power profile benchmark within different subsystem use onchip energy meter expose via rapl interface finally present effect power limit energy proportionality performance power energy efficiency enterpriseclass server workload observation result shed light efficacy rapl interface provide guidance designing powermanagement technique enterpriseclass workload,0.6490066225165563,0.1456953642384106,0.10596026490066225,0.019867549668874173,151.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Qualitative,"Cloud Migration: A Case Study of Migrating an Enterprise IT System to
  IaaS","This case study illustrates the potential benefits and risks associated with
the migration of an IT system in the oil & gas industry from an in-house data
center to Amazon EC2 from a broad variety of stakeholder perspectives across
the enterprise, thus transcending the typical, yet narrow, financial and
technical analysis offered by providers. Our results show that the system
infrastructure in the case study would have cost 37% less over 5 years on EC2,
and using cloud computing could have potentially eliminated 21% of the support
calls for this system. These findings seem significant enough to call for a
migration of the system to the cloud but our stakeholder impact analysis
revealed that there are significant risks associated with this. Whilst the
benefits of using the cloud are attractive, we argue that it is important that
enterprise decision-makers consider the overall organizational implications of
the changes brought about with cloud computing to avoid implementing local
optimizations at the cost of organization-wide performance.",http://arxiv.org/abs/1002.3492v1,arXiv,cloud migration case study migrate enterprise system iaas,case study illustrate potential benefit risk associate migration system oil gas industry inhouse datum center amazon broad variety stakeholder perspective across enterprise thus transcend typical yet narrow financial technical analysis offer provider result show system infrastructure case study would cost less year use cloud computing could potentially eliminate support call system finding seem significant enough call migration system cloud stakeholder impact analysis reveal significant risk associate whilst benefit use cloud attractive argue important enterprise decisionmaker consider overall organizational implication change bring cloud computing avoid implement local optimization cost organizationwide performance,cloud migration case study migrate enterprise system iaas case study illustrate potential benefit risk associate migration system oil gas industry inhouse datum center amazon broad variety stakeholder perspective across enterprise thus transcend typical yet narrow financial technical analysis offer provider result show system infrastructure case study would cost less year use cloud computing could potentially eliminate support call system finding seem significant enough call migration system cloud stakeholder impact analysis reveal significant risk associate whilst benefit use cloud attractive argue important enterprise decisionmaker consider overall organizational implication change bring cloud computing avoid implement local optimization cost organizationwide performance,0.6,0.13333333333333333,0.17777777777777778,0.03333333333333333,90.0,0.0,0.0,1.0,0.0
Information Systems,Enterprise Systems,Qualitative,"Fostering Enterprise Conversations Around Data on Collaboration
  Platforms","In enterprise organizations, data-driven decision making processes include
the use of business intelligence dashboards and collaborative deliberation on
communication platforms such as Slack. However, apart from those in data
analyst roles, there is shallow engagement with dashboard content due to
insufficient context, poor representation choices, or a lack of access and
guidance. Data analysts often need to retarget their dashboard content for
those with limited engagement, and this retargeting process often involves
switching between different tools. To inform the design of systems that
streamline this work process, we conducted a co-design study with nine
enterprise professionals who use dashboard content to communicate with their
colleagues. We consolidate our findings from the co-design study into a
comprehensive demonstration scenario. Using this scenario as a design probe, we
interviewed 14 data workers to further develop our design recommendations.",http://arxiv.org/abs/2310.04315v3,arXiv,foster enterprise conversation around datum collaboration platform,enterprise organization datadriven decision making process include use business intelligence dashboard collaborative deliberation communication platform slack however apart datum analyst role shallow engagement dashboard content due insufficient context poor representation choice lack access guidance datum analyst often need retarget dashboard content limited engagement retargeting process often involve switching different tool inform design system streamline work process conduct codesign study nine enterprise professional use dashboard content communicate colleague consolidate finding codesign study comprehensive demonstration scenario use scenario design probe interview datum worker far develop design recommendation,foster enterprise conversation around datum collaboration platform enterprise organization datadriven decision making process include use business intelligence dashboard collaborative deliberation communication platform slack however apart datum analyst role shallow engagement dashboard content due insufficient context poor representation choice lack access guidance datum analyst often need retarget dashboard content limited engagement retargeting process often involve switching different tool inform design system streamline work process conduct codesign study nine enterprise professional use dashboard content communicate colleague consolidate finding codesign study comprehensive demonstration scenario use scenario design probe interview datum worker far develop design recommendation,0.6705882352941176,0.10588235294117647,0.09411764705882353,0.058823529411764705,85.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Mixed Methods,A Serverless Distributed Ledger for Enterprises,"Enterprises have been attracted by the capability of blockchains to provide a
single source of truth for workloads that span companies, geographies, and
clouds while retaining the independence of each party's IT operations. However,
so far production applications have remained rare, stymied by technical
limitations of existing blockchain technologies and challenges with their
integration into enterprises' IT systems. In this paper, we collect
enterprises' requirements on distributed ledgers for data sharing and
integration from a technical perspective, argue that they are not sufficiently
addressed by available blockchain frameworks, and propose a novel distributed
ledger design that is ""serverless"", i.e., built on cloud-native resources. We
evaluate its qualitative and quantitative properties and give evidence that
enterprises already heavily reliant on cloud service providers would consider
such an approach acceptable, particularly if it offers ease of deployment, low
transactional cost structure, and a combination of latency and scalability
aligned with real-time IT application needs.",http://arxiv.org/abs/2110.09221v1,arXiv,serverless distribute ledger enterprise,enterprise attract capability blockchain provide single source truth workload span company geography cloud retain independence party operation however far production application remain rare stymie technical limitation exist blockchain technology challenge integration enterprise system paper collect enterprise requirement distribute ledger datum sharing integration technical perspective argue sufficiently address available blockchain framework propose novel distribute ledger design serverless build cloudnative resource evaluate qualitative quantitative property give evidence enterprise already heavily reliant cloud service provider would consider approach acceptable particularly offer ease deployment low transactional cost structure combination latency scalability align realtime application need,serverless distribute ledger enterprise enterprise attract capability blockchain provide single source truth workload span company geography cloud retain independence party operation however far production application remain rare stymie technical limitation exist blockchain technology challenge integration enterprise system paper collect enterprise requirement distribute ledger datum sharing integration technical perspective argue sufficiently address available blockchain framework propose novel distribute ledger design serverless build cloudnative resource evaluate qualitative quantitative property give evidence enterprise already heavily reliant cloud service provider would consider approach acceptable particularly offer ease deployment low transactional cost structure combination latency scalability align realtime application need,0.5714285714285714,0.13186813186813187,0.17582417582417584,0.06593406593406594,91.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Mixed Methods,Multi-variable Adversarial Time-Series Forecast Model,"Short-term industrial enterprises power system forecasting is an important
issue for both load control and machine protection. Scientists focus on load
forecasting but ignore other valuable electric-meters which should provide
guidance of power system protection. We propose a new framework, multi-variable
adversarial time-series forecasting model, which regularizes Long Short-term
Memory (LSTM) models via an adversarial process. The novel model forecasts all
variables (may in different type, such as continue variables, category
variables, etc.) in power system at the same time and helps trade-off process
between forecasting accuracy of single variable and variable-variable
relations. Experiments demonstrate the potential of the framework through
qualitative and quantitative evaluation of the generated samples. The predict
results of electricity consumption of industrial enterprises by multi-variable
adversarial time-series forecasting model show that the proposed approach is
able to achieve better prediction accuracy. We also applied this model to real
industrial enterprises power system data we gathered from several large
industrial enterprises via advanced power monitors, and got impressed
forecasting results.",http://arxiv.org/abs/2406.00596v1,arXiv,multivariable adversarial timeserie forecast model,shortterm industrial enterprise power system forecasting important issue load control machine protection scientist focus load forecasting ignore valuable electricmeter provide guidance power system protection propose new framework multivariable adversarial timeserie forecasting model regularize long shortterm memory lstm model via adversarial process novel model forecast variable may different type continue variable category variable etc power system time help tradeoff process forecasting accuracy single variable variablevariable relation experiment demonstrate potential framework qualitative quantitative evaluation generate sample predict result electricity consumption industrial enterprise multivariable adversarial timeserie forecasting model show propose approach able achieve well prediction accuracy also apply model real industrial enterprise power system datum gather several large industrial enterprise via advanced power monitor get impress forecasting result,multivariable adversarial timeserie forecast model shortterm industrial enterprise power system forecasting important issue load control machine protection scientist focus load forecasting ignore valuable electricmeter provide guidance power system protection propose new framework multivariable adversarial timeserie forecasting model regularize long shortterm memory lstm model via adversarial process novel model forecast variable may different type continue variable category variable etc power system time help tradeoff process forecasting accuracy single variable variablevariable relation experiment demonstrate potential framework qualitative quantitative evaluation generate sample predict result electricity consumption industrial enterprise multivariable adversarial timeserie forecasting model show propose approach able achieve well prediction accuracy also apply model real industrial enterprise power system datum gather several large industrial enterprise via advanced power monitor get impress forecasting result,0.5739130434782609,0.1391304347826087,0.21739130434782608,0.017391304347826087,115.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Mixed Methods,Key Success Factors of Enterprise Risk Management Systems: Listed Polish Companies,"<jats:p>Purpose: The main purpose of the article is to determine the key success factors of enterprise risk management systems, understood as the characteristics of these systems that have the greatest impact on the effectiveness of their functioning.  Methodology: Bearing in mind the most accurate determination of key success factors of enterprise risk management systems, I used several research methods. The conducted research was divided into four stages: (1) literature review, (2) financial statements analysis, (3) individual in-depth interviews, and (4) anonymous surveys. The research embraced enterprises operating in Poland.  Findings: Based on the literature analysis, in-depth interviews, and conducted surveys, a list of risk management systems’ success factors was created and sorted in the order from the most important ones – that have the greatest impact on the success of risk management – to the least important ones.  Additional analysis of financial statements of all WSE-listed companies allowed me to discern that few of the surveyed companies use mature modern ERM systems, and it enabled me to identify a group of companies that qualified to participate in the survey. Moreover, a statistically significant positive correlation appeared between the degree of key success factors’ implementation and the overall ERM implementation’s impact on the organization, while a statistically significant negative correlation emerged between the overall impact of ERM implementation on the organization and the degree of ERM implementation goals’ achievement, but also between the degree of the implementation of key success factors and the degree of the ERM implementation objectives’ implementation. Moreover, I noted that the fact of using individual features has no significant impact on the assessment of a given feature by respondents.  Implications: All factors included in the study are success factors of risk management systems. However, the surveys’ results suggest a different level of individual factors’ significance, thus a different degree of these factors impact on risk management success.  Originality/Value: The article presents an original set of key success factors in risk management systems, created based on my own research. The obtained research results can be used by managers willing to implement or develop risk management systems in their organizations.</jats:p>",https://doi.org/10.7206/cemj.2658-0845.71,CrossRef,key success factor enterprise risk management system list polish company,jatsppurpose main purpose article determine key success factor enterprise risk management system understand characteristic system great impact effectiveness function methodology bearing mind accurate determination key success factor enterprise risk management system use several research method conduct research divide four stage literature review financial statement analysis individual indepth interview anonymous survey research embrace enterprise operate poland finding base literature analysis indepth interview conduct survey list risk management system success factor create sort order important one great impact success risk management least important one additional analysis financial statement wseliste company allow discern survey company use mature modern erm system enable identify group company qualify participate survey moreover statistically significant positive correlation appear degree key success factor implementation overall erm implementation impact organization statistically significant negative correlation emerge overall impact erm implementation organization degree erm implementation goal achievement also degree implementation key success factor degree erm implementation objective implementation moreover note fact use individual feature significant impact assessment give feature respondent implication factor include study success factor risk management system however survey result suggest different level individual factor significance thus different degree factor impact risk management success originalityvalue article present original set key success factor risk management system create base research obtain research result use manager willing implement develop risk management system organizationsjatsp,key success factor enterprise risk management system list polish company jatsppurpose main purpose article determine key success factor enterprise risk management system understand characteristic system great impact effectiveness function methodology bearing mind accurate determination key success factor enterprise risk management system use several research method conduct research divide four stage literature review financial statement analysis individual indepth interview anonymous survey research embrace enterprise operate poland finding base literature analysis indepth interview conduct survey list risk management system success factor create sort order important one great impact success risk management least important one additional analysis financial statement wseliste company allow discern survey company use mature modern erm system enable identify group company qualify participate survey moreover statistically significant positive correlation appear degree key success factor implementation overall erm implementation impact organization statistically significant negative correlation emerge overall impact erm implementation organization degree erm implementation goal achievement also degree implementation key success factor degree erm implementation objective implementation moreover note fact use individual feature significant impact assessment give feature respondent implication factor include study success factor risk management system however survey result suggest different level individual factor significance thus different degree factor impact risk management success originalityvalue article present original set key success factor risk management system create base research obtain research result use manager willing implement develop risk management system organizationsjatsp,0.6047619047619047,0.12857142857142856,0.16666666666666666,0.04285714285714286,210.0,0.0,1.0,0.0,1.0
Information Systems,Enterprise Systems,Mixed Methods,Enterprise Systems Outsourcing “Behind the Curtain”,"<p>Outsourcing is now a feasible means for enterprise systems (ES) cost savings, but does however increase the complexity of coordination substantially when many organizations are involved. We set out to study ES outsourcing in a large Scandinavian high-tech organization, SCANDI, a case setting with many inter-organizational partners, trying to answer the question: Why does SCANDI engage in these very complex outsourcing arrangements? To answer this question we have analyzed documents, observed meetings and gathered data from interviews in four parts of SCANDI. The first data analysis found just the rational front stage cost-saving explanation; but then, with a more careful analysis focusing on institutional factors, other backstage explanations “behind the curtain” were uncovered, such as management consultants with a “best practice” agenda, people promoting outsourcing, thereby being promoted themselves, and a belief in outsourcing as a “silver bullet”: a recipe to success, solving everything</p>",https://doi.org/10.4018/jeis.2011010101,CrossRef,enterprise system outsource behind curtain,poutsource feasible mean enterprise system cost saving however increase complexity coordination substantially many organization involve set study outsource large scandinavian hightech organization scandi case set many interorganizational partner try answer question scandi engage complex outsourcing arrangement answer question analyze document observe meeting gather datum interview four part scandi first data analysis find rational front stage costsave explanation careful analysis focus institutional factor backstage explanation behind curtain uncover management consultant good practice agenda people promote outsourcing thereby promote belief outsourcing silver bullet recipe success solve everythingp,enterprise system outsource behind curtain poutsource feasible mean enterprise system cost saving however increase complexity coordination substantially many organization involve set study outsource large scandinavian hightech organization scandi case set many interorganizational partner try answer question scandi engage complex outsourcing arrangement answer question analyze document observe meeting gather datum interview four part scandi first data analysis find rational front stage costsave explanation careful analysis focus institutional factor backstage explanation behind curtain uncover management consultant good practice agenda people promote outsourcing thereby promote belief outsourcing silver bullet recipe success solve everythingp,0.5764705882352941,0.16470588235294117,0.15294117647058825,0.03529411764705882,85.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Mixed Methods,"Assessing the Impact of System Quality, Information Quality, and Service Quality on Enterprise Resource Planning (ERP) Systems","<p>Globally, governments are taking steps to help them increase their income generation margin by implementing tax administrative ERP systems. However, the impacts on the internal system users of these ERP system quality features have not drawn the attention needed. This study, therefore, examines the relationship between the information systems' (IS) quality and individual impact using the theoretical foundation of the DeLone and McLean IS success model and, secondly, addresses the interrelationships between the quality constructs of information systems (IS). The authors also used the structural equation modeling technique of partial least squares to evaluate and analyze the data. The results show that system quality, the information quality, and the service quality characteristics of the tax administrative ERP system have a strong positive impact on the success of the IS at the individual level. There is also a positive relationship between the information systems' (IS) quality construction. The results provide additional empirical observations and consequences for management.</p>",https://doi.org/10.4018/ijeis.2021100104,CrossRef,assess impact system quality information quality service quality enterprise resource planning erp system,pglobally government take step help increase income generation margin implement tax administrative erp system however impact internal system user erp system quality feature draw attention need study therefore examine relationship information system quality individual impact use theoretical foundation delone mclean success model secondly address interrelationship quality construct information system author also use structural equation modeling technique partial least square evaluate analyze datum result show system quality information quality service quality characteristic tax administrative erp system strong positive impact success individual level also positive relationship information system quality construction result provide additional empirical observation consequence managementp,assess impact system quality information quality service quality enterprise resource planning erp system pglobally government take step help increase income generation margin implement tax administrative erp system however impact internal system user erp system quality feature draw attention need study therefore examine relationship information system quality individual impact use theoretical foundation delone mclean success model secondly address interrelationship quality construct information system author also use structural equation modeling technique partial least square evaluate analyze datum result show system quality information quality service quality characteristic tax administrative erp system strong positive impact success individual level also positive relationship information system quality construction result provide additional empirical observation consequence managementp,0.631578947368421,0.11578947368421053,0.16842105263157894,0.07368421052631578,95.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Design and Development,Comparative image filter-ing using monotonic morphological operators,"<jats:p>In a previous work, we proposed a Comparative Morphology (CM) construction scheme that generalized Pytyev's Morphological Image Analysis approach onto a wider range of practical image comparison applications. Within a Guided Contrasting framework, a filtering procedure and a related change detection algorithm were developed. In this work, we propose a class of CM filtering in which Mathematical Morphology operators introduced by Serra are used as smoothing operators that offer monotonically non-increasing (non-decreasing) filtering, in contrast to linear diffusion filtering and non-linear median filtering. The results of experiments on change detection based on the new CM filtering are discussed in comparison with other morphological procedures.</jats:p>",https://doi.org/10.18287/2412-6179-2018-42-2-306-311,CrossRef,comparative image filtering use monotonic morphological operator,jatspin previous work propose comparative morphology construction scheme generalize pytyevs morphological image analysis approach onto wide range practical image comparison application within guide contrast framework filter procedure relate change detection algorithm develop work propose class filter mathematical morphology operator introduce serra use smooth operator offer monotonically nonincrease nondecrease filter contrast linear diffusion filtering nonlinear median filter result experiment change detection base new filtering discuss comparison morphological proceduresjatsp,comparative image filtering use monotonic morphological operator jatspin previous work propose comparative morphology construction scheme generalize pytyevs morphological image analysis approach onto wide range practical image comparison application within guide contrast framework filter procedure relate change detection algorithm develop work propose class filter mathematical morphology operator introduce serra use smooth operator offer monotonically nonincrease nondecrease filter contrast linear diffusion filtering nonlinear median filter result experiment change detection base new filtering discuss comparison morphological proceduresjatsp,0.5970149253731343,0.13432835820895522,0.19402985074626866,0.014925373134328358,67.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Design and Development,"Enterprise Architecture, Enterprise Information Systems and Enterprise Integration: A Review Based on Systems Theory Perspective","<jats:p>Systems theory is one of the most important and well-used concept to explain the phenomenon in social sciences. Therefore, systems science plays an important role in explaining many of the phenomena in information systems research. Enterprise Systems (ES), Enterprise Information Systems (EIS) and Enterprise Architecture (EA) are three such emerging technologies in which systems’ perspective plays an important role in explaining the growth and development of these technologies. However, there is lack of literature that illustrates the development and the impact of systems science in these three technologies. This research carefully collects and studies 106 existing literature in the field of ES, EA and EIS, and a summary review of all the latest developments in the ways systems theory has been implemented to these three fields as well as different areas of these three technologies. In the conclusion, three future trends are concluded from the review.</jats:p>",https://doi.org/10.1142/s2424862219500015,CrossRef,enterprise architecture enterprise information system enterprise integration review base system theory perspective,jatspsystem theory one important welluse concept explain phenomenon social science therefore system science play important role explain many phenomenon information system research enterprise system enterprise information system eis enterprise architecture three emerge technology system perspective play important role explain growth development technology however lack literature illustrate development impact system science three technology research carefully collect study exist literature field eis summary review late development way system theory implement three field well different area three technology conclusion three future trend conclude reviewjatsp,enterprise architecture enterprise information system enterprise integration review base system theory perspective jatspsystem theory one important welluse concept explain phenomenon social science therefore system science play important role explain many phenomenon information system research enterprise system enterprise information system eis enterprise architecture three emerge technology system perspective play important role explain growth development technology however lack literature illustrate development impact system science three technology research carefully collect study exist literature field eis summary review late development way system theory implement three field well different area three technology conclusion three future trend conclude reviewjatsp,0.5679012345679012,0.09876543209876543,0.1111111111111111,0.04938271604938271,81.0,0.0,0.0,0.0,1.0
Information Systems,Enterprise Systems,Design and Development,Continuous Computing Technologies for Improving Performances of Enterprise Information Systems,"<p>Business computing has evolved into an organizational engine that drives business and provides a powerful source for competitive advantage. In order to achieve higher levels of competitiveness, business has to be continuous from a data availability perspective and agile with regard to data access. Simply put, system and application downtime are not an option in modern business since each hour, or even each minute, of downtime may generate negative financial effects. An enterprise information system (EIS) can be qualified as “high-quality” in terms of its architecture, application platform and information it can provide to users but if that information is unavailable when it is needed by customer, manager or any other end user, the value of that EIS simply becomes “zeroed” from end users’ point of view. The paper presents a framework for implementation of continuous computing technologies (CCT) for improving performances of enterprise information systems from business continuance perspective. It identifies high system availability and agile data access as two critical attributes (measures of performances) in evaluating performances of enterprise information systems. The framework is based on a MS/OR-based definition of a system given by Churchman (1968, 1971). In addition, it proposes a set of IT drivers for enhancing the performances of enterprise information systems from business continuity and business agility perspectives.</p>",https://doi.org/10.4018/jeis.2005100105,CrossRef,continuous computing technology improve performance enterprise information system,pbusiness computing evolve organizational engine drive business provide powerful source competitive advantage order achieve high level competitiveness business continuous data availability perspective agile regard data access simply put system application downtime option modern business since hour even minute downtime may generate negative financial effect enterprise information system eis qualified highquality term architecture application platform information provide user information unavailable need customer manager end user value eis simply become zero end user point view paper present framework implementation continuous computing technology cct improve performance enterprise information system business continuance perspective identify high system availability agile datum access two critical attribute measure performance evaluate performance enterprise information system framework base msorbased definition system give churchman addition propose set driver enhance performance enterprise information system business continuity business agility perspectivesp,continuous computing technology improve performance enterprise information system pbusiness computing evolve organizational engine drive business provide powerful source competitive advantage order achieve high level competitiveness business continuous data availability perspective agile regard data access simply put system application downtime option modern business since hour even minute downtime may generate negative financial effect enterprise information system eis qualified highquality term architecture application platform information provide user information unavailable need customer manager end user value eis simply become zero end user point view paper present framework implementation continuous computing technology cct improve performance enterprise information system business continuance perspective identify high system availability agile datum access two critical attribute measure performance evaluate performance enterprise information system framework base msorbased definition system give churchman addition propose set driver enhance performance enterprise information system business continuity business agility perspectivesp,0.6692913385826772,0.12598425196850394,0.11811023622047244,0.023622047244094488,127.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Design and Development,A Complex Adaptive Systems-Based Enterprise Knowledge Sharing Model,<p>This article describes a complex adaptive system (CAS)-based enterprise knowledge-sharing (KnS) model. The CAS-based enterprise KnS model consists of a CAS-based KnS framework and a multi-agent simulation model. Enterprise knowledge sharing is modeled as the emergent behavior of knowledge workers interacting with the KnS environment and other knowledge workers. The CAS-based enterprise KnS model is developed to aid knowledge management (KM) leadership and other KnS researchers in gaining an enhanced understanding of KnS behavior and its influences. A premise of this research is that a better understanding of KnS influences can result in enhanced decision-making of KnS interventions that can result in improvements in KnS behavior.</p>,https://doi.org/10.4018/jeis.2009040102,CrossRef,complex adaptive systemsbase enterprise knowledge sharing model,pthis article describe complex adaptive system casbase enterprise knowledgesharing kns model casbase enterprise kns model consist casbase kns framework multiagent simulation model enterprise knowledge sharing model emergent behavior knowledge worker interact kns environment knowledge worker casbase enterprise kns model develop aid knowledge management leadership kns researcher gain enhanced understanding kns behavior influence premise research well understanding kns influence result enhanced decisionmaking kns intervention result improvement kns behaviorp,complex adaptive systemsbase enterprise knowledge sharing model pthis article describe complex adaptive system casbase enterprise knowledgesharing kns model casbase enterprise kns model consist casbase kns framework multiagent simulation model enterprise knowledge sharing model emergent behavior knowledge worker interact kns environment knowledge worker casbase enterprise kns model develop aid knowledge management leadership kns researcher gain enhanced understanding kns behavior influence premise research well understanding kns influence result enhanced decisionmaking kns intervention result improvement kns behaviorp,0.5074626865671642,0.11940298507462686,0.029850746268656716,0.014925373134328358,67.0,1.0,0.0,0.0,8.0
Information Systems,Enterprise Systems,Design and Development,Detecting image differences based on reference EMD-filters,"<jats:p>In our previous works dealing with detecting differences in images in the case of substantial variations in brightness and geometry of an object, we proposed a morphological scheme for image analysis based on diffusion and reference mosaic filters. The filters were defined through the heat kernels of the similarity of image fragments. In this paper, we propose an implementation of this morphological scheme using original reference Earth mover's distance (EMD) filters, in which the optimal matrices of the mutual similarity of mosaic forms are calculated through a linear programming method.</jats:p>",https://doi.org/10.18287/2412-6179-2018-42-2-291-296,CrossRef,detect image difference base reference emdfilter,jatspin previous work deal detect difference image case substantial variation brightness geometry object propose morphological scheme image analysis base diffusion reference mosaic filter filter define heat kernel similarity image fragment paper propose implementation morphological scheme use original reference earth mover distance emd filter optimal matrix mutual similarity mosaic form calculate linear programming methodjatsp,detect image difference base reference emdfilter jatspin previous work deal detect difference image case substantial variation brightness geometry object propose morphological scheme image analysis base diffusion reference mosaic filter filter define heat kernel similarity image fragment paper propose implementation morphological scheme use original reference earth mover distance emd filter optimal matrix mutual similarity mosaic form calculate linear programming methodjatsp,0.5849056603773585,0.11320754716981132,0.18867924528301888,0.0,53.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Theoretical / Conceptual,People-Oriented Enterprise Information Systems,"<p>Current notations and languages do not emphasize the participation of users in business processes and consider them essentially as service providers. Moreover, they follow a centralized approach as all the interactions originate from or end in a business process; direct interactions between users cannot be represented. What is missing from this approach is that human work is cooperative and cooperation takes place through structured interactions called conversations; the notion of conversation is at the center of the language/action perspective. However, the problem of effectively integrating conversations and business processes is still open and this chapter proposes a notation called POBPN (People-Oriented Business Process Notation) and a perspective, referred to as conversation-oriented perspective, for its solution.</p>",https://doi.org/10.4018/jeis.2009090202,CrossRef,peopleoriente enterprise information system,pcurrent notation language emphasize participation user business process consider essentially service provider moreover follow centralized approach interaction originate end business process direct interaction user represent miss approach human work cooperative cooperation take place structured interaction call conversation notion conversation center languageaction perspective however problem effectively integrate conversation business process still open chapter propose notation call pobpn peopleoriente business process notation perspective refer conversationoriente perspective solutionp,peopleoriente enterprise information system pcurrent notation language emphasize participation user business process consider essentially service provider moreover follow centralized approach interaction originate end business process direct interaction user represent miss approach human work cooperative cooperation take place structured interaction call conversation notion conversation center languageaction perspective however problem effectively integrate conversation business process still open chapter propose notation call pobpn peopleoriente business process notation perspective refer conversationoriente perspective solutionp,0.6307692307692307,0.15384615384615385,0.07692307692307693,0.09230769230769231,65.0,0.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Theoretical / Conceptual,Authority and Its Implementation in Enterprise Information Systems,"<p>The concept of power is inherent in human organizations of any type. As power relations have important consequences for organizational viability and productivity, they should be explicitly represented in enterprise information systems (EISs). Although organization theory provides a rich and very diverse theoretical basis on organizational power, still most of the definitions for power-related concepts are too abstract, often vague and ambiguous to be directly implemented in EISs. To create a bridge between informal organization theories and automated EISs, this article proposes a formal logic-based specification language for representing power (in particular authority) relations. The use of the language is illustrated by considering authority structures of organizations of different types. Moreover, the article demonstrates how the formalized authority relations can be integrated into an EIS.</p>",https://doi.org/10.4018/jeis.2008070105,CrossRef,authority implementation enterprise information system,pthe concept power inherent human organization type power relation important consequence organizational viability productivity explicitly represent enterprise information system eiss although organization theory provide rich diverse theoretical basis organizational power still definition powerrelate concept abstract often vague ambiguous directly implement eiss create bridge informal organization theory automate eiss article propose formal logicbase specification language represent power particular authority relation use language illustrate consider authority structure organization different type moreover article demonstrate formalized authority relation integrate eisp,authority implementation enterprise information system pthe concept power inherent human organization type power relation important consequence organizational viability productivity explicitly represent enterprise information system eiss although organization theory provide rich diverse theoretical basis organizational power still definition powerrelate concept abstract often vague ambiguous directly implement eiss create bridge informal organization theory automate eiss article propose formal logicbase specification language represent power particular authority relation use language illustrate consider authority structure organization different type moreover article demonstrate formalized authority relation integrate eisp,0.5131578947368421,0.13157894736842105,0.2236842105263158,0.06578947368421052,76.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Theoretical / Conceptual,Ontology-Based Knowledge Management for Enterprise Systems,"<p>Companies face the challenges of expanding their markets, improving products, services and processes, and exploiting intellectual capital in a dynamic network. Therefore, more companies are turning to an Enterprise System (ES). Knowledge management (KM) has also received considerable attention and is continuously gaining the interest of industry, enterprises, and academia. For ES, KM can provide support across the entire lifecycle, from selection and implementation to use. In addition, it is also recognised that an ontology is an appropriate methodology to accomplish a common consensus of communication, as well as to support a diversity of KM activities, such as knowledge repository, retrieval, sharing, and dissemination. This paper examines the role of ontology-based KM for ES (OKES) and investigates the possible integration of ontology-based KM and ES. The authors develop a taxonomy as a framework for understanding OKES research. In order to achieve the objective of this study, a systematic review of existing research was conducted. Based on a theoretical framework of the ES lifecycle, KM, KM for ES, ontology, and ontology-based KM, guided by the framework of study, a taxonomy for OKES is established.</p>",https://doi.org/10.4018/jeis.2011100104,CrossRef,ontologybase knowledge management enterprise system,pcompanie face challenge expand market improve product service process exploit intellectual capital dynamic network therefore company turn enterprise system knowledge management also receive considerable attention continuously gain interest industry enterprise academia provide support across entire lifecycle selection implementation use addition also recognise ontology appropriate methodology accomplish common consensus communication well support diversity activity knowledge repository retrieval sharing dissemination paper examine role ontologybased oke investigate possible integration ontologybased author develop taxonomy framework understand oke research order achieve objective study systematic review exist research conduct base theoretical framework lifecycle ontology ontologybase guide framework study taxonomy oke establishedp,ontologybase knowledge management enterprise system pcompanie face challenge expand market improve product service process exploit intellectual capital dynamic network therefore company turn enterprise system knowledge management also receive considerable attention continuously gain interest industry enterprise academia provide support across entire lifecycle selection implementation use addition also recognise ontology appropriate methodology accomplish common consensus communication well support diversity activity knowledge repository retrieval sharing dissemination paper examine role ontologybased oke investigate possible integration ontologybased author develop taxonomy framework understand oke research order achieve objective study systematic review exist research conduct base theoretical framework lifecycle ontology ontologybase guide framework study taxonomy oke establishedp,0.6105263157894737,0.18947368421052632,0.11578947368421053,0.05263157894736842,95.0,0.0,0.0,0.0,1.0
Information Systems,Enterprise Systems,Theoretical / Conceptual,Using Institutional Theory in Enterprise Systems Research,"<p>This paper examines the use of institutional theory as a conceptually rich lens to study social issues of enterprise systems (ES) research. More precisely, the purpose is to categorize current ES research using institutional theory to develop a conceptual model that advances ES research. Key institutional features are presented such as isomorphism, rationalized myths, and bridging macro and micro structures, and institutional logics and their implications for ES research are discussed. Through a literature review of 181 articles, of which 18 papers are selected, the author’s built a conceptual model that advocates multi-level and multi-theory approaches and applies newer institutional aspects such as institutional logics. The findings show that institutional theory in ES research is in its infancy and adopts mainly traditional institutional aspects like isomorphism, with the organization as the level of analysis, and in several cases it is complemented by structuration theory and other theories.</p>",https://doi.org/10.4018/jeis.2013010101,CrossRef,use institutional theory enterprise system research,pthis paper examine use institutional theory conceptually rich lens study social issue enterprise system research precisely purpose categorize current research use institutional theory develop conceptual model advance research key institutional feature present isomorphism rationalize myth bridge macro micro structure institutional logic implication research discuss literature review article paper select author build conceptual model advocate multilevel multitheory approach apply new institutional aspect institutional logic finding show institutional theory research infancy adopt mainly traditional institutional aspect like isomorphism organization level analysis several case complement structuration theory theoriesp,use institutional theory enterprise system research pthis paper examine use institutional theory conceptually rich lens study social issue enterprise system research precisely purpose categorize current research use institutional theory develop conceptual model advance research key institutional feature present isomorphism rationalize myth bridge macro micro structure institutional logic implication research discuss literature review article paper select author build conceptual model advocate multilevel multitheory approach apply new institutional aspect institutional logic finding show institutional theory research infancy adopt mainly traditional institutional aspect like isomorphism organization level analysis several case complement structuration theory theoriesp,0.4823529411764706,0.07058823529411765,0.24705882352941178,0.03529411764705882,85.0,1.0,0.0,0.0,0.0
Information Systems,Enterprise Systems,Theoretical / Conceptual,The Impact of Enterprise Systems on Organizational Control and Drift,"<p>Enterprise systems (ES) are widespread in current organizations, and seen as integrating organizational procedures across functional divisions. An enterprise system (also known as enterprise resource planning – ERP system), once installed, seems to enable or constrain certain actions by managers and users, which have an impact on organizational operations. Those actions may result in increased organizational control, or may lead to organizational drift. The processes that give rise to such outcomes are investigated in this paper, which is based on a field study of five companies. By drawing on the theoretical concepts of human and machine agencies, as well as the embedding and disembedding of managerial and user actions in the system, this paper agues that control and drift arising from the use of an enterprise system are outcomes of the processes of embedding and disembedding human actions, which are afforded (enabled or constrained) by the enterprise system.</p>",https://doi.org/10.4018/jeis.2007070103,CrossRef,impact enterprise system organizational control drift,penterprise system widespread current organization see integrate organizational procedure across functional division enterprise system also know enterprise resource planning erp system instal seem enable constrain certain action manager user impact organizational operation action may result increase organizational control may lead organizational drift process give rise outcome investigate paper base field study five company draw theoretical concept human machine agency well embed disembedding managerial user action system paper ague control drift arise use enterprise system outcome process embed disembedde human action afford enable constrain enterprise systemp,impact enterprise system organizational control drift penterprise system widespread current organization see integrate organizational procedure across functional division enterprise system also know enterprise resource planning erp system instal seem enable constrain certain action manager user impact organizational operation action may result increase organizational control may lead organizational drift process give rise outcome investigate paper base field study five company draw theoretical concept human machine agency well embed disembedding managerial user action system paper ague control drift arise use enterprise system outcome process embed disembedde human action afford enable constrain enterprise systemp,0.5176470588235295,0.23529411764705882,0.1411764705882353,0.023529411764705882,85.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Quantitative,"Decision Support Systems in Fisheries and Aquaculture: A systematic
  review","Decision support systems help decision makers make better decisions in the
face of complex decision problems (e.g. investment or policy decisions).
Fisheries and Aquaculture is a domain where decision makers face such decisions
since they involve factors from many different scientific fields. No systematic
overview of literature describing decision support systems and their
application in fisheries and aquaculture has been conducted. This paper
summarizes scientific literature that describes decision support systems
applied to the domain of Fisheries and Aquaculture. We use an established
systematic mapping survey method to conduct our literature mapping. Our
research questions are: What decision support systems for fisheries and
aquaculture exists? What are the most investigated fishery and aquaculture
decision support systems topics and how have these changed over time? Do any
current DSS for fisheries provide real- time analytics? Do DSSes in Fisheries
and Aquaculture build their models using machine learning done on captured and
grounded data? The paper then detail how we employ the systematic mapping
method in answering these questions. This results in 27 papers being identified
as relevant and gives an exposition on the primary methods concluded in the
study for designing a decision support system. We provide an analysis of the
research done in the studies collected. We discovered that most literature does
not consider multiple aspects for multiple stakeholders in their work. In
addition we observed that little or no work has been done with real-time
analysis in these decision support systems.",http://arxiv.org/abs/1611.08374v1,arXiv,decision support system fishery aquaculture systematic review,decision support system help decision maker make well decision face complex decision problem investment policy decision fishery aquaculture domain decision maker face decision since involve factor many different scientific field systematic overview literature describe decision support system application fishery aquaculture conduct paper summarize scientific literature describe decision support system apply domain fishery aquaculture use establish systematic mapping survey method conduct literature map research question decision support system fishery aquaculture exist investigate fishery aquaculture decision support system topic change time current dss fishery provide real time analytic dsse fishery aquaculture build model use machine learning capture ground datum paper detail employ systematic mapping method answer question result paper identify relevant give exposition primary method conclude study design decision support system provide analysis research study collect discover literature consider multiple aspect multiple stakeholder work addition observe little work realtime analysis decision support system,decision support system fishery aquaculture systematic review decision support system help decision maker make well decision face complex decision problem investment policy decision fishery aquaculture domain decision maker face decision since involve factor many different scientific field systematic overview literature describe decision support system application fishery aquaculture conduct paper summarize scientific literature describe decision support system apply domain fishery aquaculture use establish systematic mapping survey method conduct literature map research question decision support system fishery aquaculture exist investigate fishery aquaculture decision support system topic change time current dss fishery provide real time analytic dsse fishery aquaculture build model use machine learning capture ground datum paper detail employ systematic mapping method answer question result paper identify relevant give exposition primary method conclude study design decision support system provide analysis research study collect discover literature consider multiple aspect multiple stakeholder work addition observe little work realtime analysis decision support system,0.723404255319149,0.1276595744680851,0.12056737588652482,0.0,141.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Quantitative,Towards Decision Support Technology Platform for Modular Systems,"The survey methodological paper addresses a glance to a general decision
support platform technology for modular systems (modular/composite
alterantives/solutions) in various applied domains. The decision support
platform consists of seven basic combinatorial engineering frameworks (system
synthesis, system modeling, evaluation, detection of bottleneck,
improvement/extension, multistage design, combinatorial evolution and
forecasting). The decision support platform is based on decision support
procedures (e.g., multicriteria selection/sorting, clustering), combinatorial
optimization problems (e.g., knapsack, multiple choice problem, clique,
assignment/allocation, covering, spanning trees), and their combinations. The
following is described: (1) general scheme of the decision support platform
technology; (2) brief descriptions of modular (composite) systems (or composite
alternatives); (3) trends in moving from chocie/selection of alternatives to
processing of composite alternatives which correspond to hierarchical modular
products/systems; (4) scheme of resource requirements (i.e., human,
information-computer); and (5) basic combinatorial engineering frameworks and
their applications in various domains.",http://arxiv.org/abs/1408.5492v1,arXiv,towards decision support technology platform modular system,survey methodological paper address glance general decision support platform technology modular system modularcomposite alterantivessolution various apply domain decision support platform consist seven basic combinatorial engineering framework system synthesis system modeling evaluation detection bottleneck improvementextension multistage design combinatorial evolution forecast decision support platform base decision support procedure multicriteria selectionsorte clustering combinatorial optimization problem knapsack multiple choice problem clique assignmentallocation covering span tree combination following describe general scheme decision support platform technology brief description modular composite system composite alternative trend move chocieselection alternative processing composite alternative correspond hierarchical modular productssystem scheme resource requirement human informationcomputer basic combinatorial engineering framework application various domain,towards decision support technology platform modular system survey methodological paper address glance general decision support platform technology modular system modularcomposite alterantivessolution various apply domain decision support platform consist seven basic combinatorial engineering framework system synthesis system modeling evaluation detection bottleneck improvementextension multistage design combinatorial evolution forecast decision support platform base decision support procedure multicriteria selectionsorte clustering combinatorial optimization problem knapsack multiple choice problem clique assignmentallocation covering span tree combination following describe general scheme decision support platform technology brief description modular composite system composite alternative trend move chocieselection alternative processing composite alternative correspond hierarchical modular productssystem scheme resource requirement human informationcomputer basic combinatorial engineering framework application various domain,0.63,0.11,0.23,0.0,100.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Quantitative,Revealing Sub-Optimality Conditions of Strategic Decisions,"Conceptual view of fitness and fitness measurement of strategic decisions on
information systems, technological systems and innovation are becoming more
important in recent years. This paper determines some dynamics of fitness
landscape which are lead to termination of decision makers' research before
reaching the global maximum in strategic decisions. These dynamics are
specified according to management decision making models and supported with
simulation results. This article determines simulation results by means of
""Fitness Value"" and ""Probability of Optimality"". Correlation between these two
concepts may be remarkable according to revealing optimal values in innovative
and research-based decision making approaches beside sub-optimal results of
traditional decision making approaches.",http://arxiv.org/abs/1107.0202v1,arXiv,reveal suboptimality condition strategic decision,conceptual view fitness fitness measurement strategic decision information system technological system innovation become important recent year paper determine dynamic fitness landscape lead termination decision maker research reach global maximum strategic decision dynamic specify accord management decision make model support simulation result article determine simulation result mean fitness value probability optimality correlation two concept may remarkable accord reveal optimal value innovative researchbase decision make approach beside suboptimal result traditional decision make approach,reveal suboptimality condition strategic decision conceptual view fitness fitness measurement strategic decision information system technological system innovation become important recent year paper determine dynamic fitness landscape lead termination decision maker research reach global maximum strategic decision dynamic specify accord management decision make model support simulation result article determine simulation result mean fitness value probability optimality correlation two concept may remarkable accord reveal optimal value innovative researchbase decision make approach beside suboptimal result traditional decision make approach,0.6056338028169014,0.14084507042253522,0.2112676056338028,0.0,71.0,0.0,0.0,1.0,0.0
Information Systems,Decision Support Systems,Quantitative,"An Example for BeSpaceD and its Use for Decision Support in Industrial
  Automation","We describe our formal methods-based spatial reasoning framework BeSpaceD and
its application in decision support for industrial automation. In particular we
are supporting analysis and decisions based on formal models for industrial
plant and mining operations. BeSpaceD is a framework for deciding geometric and
topological properties of spatio-temporal models. We present an example and
report on our ongoing experience with applications in different projects around
software and cyber-physical systems engineering. The example features
abstracted aspects of a production plant model. Using the example we motivate
the use of our framework in the context of an existing software platform
supporting monitoring, incident handling and maintenance of industrial
automation facilities in remote locations.",http://arxiv.org/abs/1512.04656v1,arXiv,example bespace use decision support industrial automation,describe formal methodsbase spatial reasoning framework bespace application decision support industrial automation particular support analysis decision base formal model industrial plant mining operation bespace framework decide geometric topological property spatiotemporal model present example report ongoing experience application different project around software cyberphysical system engineer example feature abstract aspect production plant model use example motivate use framework context exist software platform support monitor incident handling maintenance industrial automation facility remote location,example bespace use decision support industrial automation describe formal methodsbase spatial reasoning framework bespace application decision support industrial automation particular support analysis decision base formal model industrial plant mining operation bespace framework decide geometric topological property spatiotemporal model present example report ongoing experience application different project around software cyberphysical system engineer example feature abstract aspect production plant model use example motivate use framework context exist software platform support monitor incident handling maintenance industrial automation facility remote location,0.6714285714285714,0.04285714285714286,0.24285714285714285,0.0,70.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Quantitative,Note on Thompson sampling for large decision problems,"There is increasing interest in using streaming data to inform decision
making across a wide range of application domains including mobile health, food
safety, security, and resource management. A decision support system formalizes
online decision making as a map from up-to-date information to a recommended
decision. Online estimation of an optimal decision strategy from streaming data
requires simultaneous estimation of components of the underlying system
dynamics as well as the optimal decision strategy given these dynamics; thus,
there is an inherent trade-off between choosing decisions that lead to improved
estimates and choosing decisions that appear to be optimal based on current
estimates. Thompson (1933) was among the first to formalize this trade-off in
the context of choosing between two treatments for a stream of patients; he
proposed a simple heuristic wherein a treatment is selected randomly at each
time point with selection probability proportional to the posterior probability
that it is optimal. We consider a variant of Thompson sampling that is simple
to implement and can be applied to large and complex decision problems. We show
that the proposed Thompson sampling estimator is consistent for the optimal
decision support system and provide rates of convergence and finite sample
error bounds. The proposed algorithm is illustrated using an agent-based model
of the spread of influenza on a network and management of mallard populations
in the United States.",http://arxiv.org/abs/1905.04735v1,arXiv,note thompson sample large decision problem,increase interest use stream datum inform decision making across wide range application domain include mobile health food safety security resource management decision support system formalize online decision making map uptodate information recommend decision online estimation optimal decision strategy stream datum require simultaneous estimation component underlie system dynamic well optimal decision strategy give dynamic thus inherent tradeoff choose decision lead improved estimate choose decision appear optimal base current estimate thompson among first formalize tradeoff context choose two treatment stream patient propose simple heuristic wherein treatment select randomly time point selection probability proportional posterior probability optimal consider variant thompson sampling simple implement apply large complex decision problem show propose thompson sample estimator consistent optimal decision support system provide rate convergence finite sample error bound propose algorithm illustrate use agentbased model spread influenza network management mallard population united states,note thompson sample large decision problem increase interest use stream datum inform decision making across wide range application domain include mobile health food safety security resource management decision support system formalize online decision making map uptodate information recommend decision online estimation optimal decision strategy stream datum require simultaneous estimation component underlie system dynamic well optimal decision strategy give dynamic thus inherent tradeoff choose decision lead improved estimate choose decision appear optimal base current estimate thompson among first formalize tradeoff context choose two treatment stream patient propose simple heuristic wherein treatment select randomly time point selection probability proportional posterior probability optimal consider variant thompson sampling simple implement apply large complex decision problem show propose thompson sample estimator consistent optimal decision support system provide rate convergence finite sample error bound propose algorithm illustrate use agentbased model spread influenza network management mallard population united states,0.5147058823529411,0.14705882352941177,0.22058823529411764,0.007352941176470588,136.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Qualitative,"Beyond Recommendations: From Backward to Forward AI Support of Pilots'
  Decision-Making Process","AI is anticipated to enhance human decision-making in high-stakes domains
like aviation, but adoption is often hindered by challenges such as
inappropriate reliance and poor alignment with users' decision-making. Recent
research suggests that a core underlying issue is the recommendation-centric
design of many AI systems, i.e., they give end-to-end recommendations and
ignore the rest of the decision-making process. Alternative support paradigms
are rare, and it remains unclear how the few that do exist compare to
recommendation-centric support. In this work, we aimed to empirically compare
recommendation-centric support to an alternative paradigm, continuous support,
in the context of diversions in aviation. We conducted a mixed-methods study
with 32 professional pilots in a realistic setting. To ensure the quality of
our study scenarios, we conducted a focus group with four additional pilots
prior to the study. We found that continuous support can support pilots'
decision-making in a forward direction, allowing them to think more beyond the
limits of the system and make faster decisions when combined with
recommendations, though the forward support can be disrupted. Participants'
statements further suggest a shift in design goal away from providing
recommendations, to supporting quick information gathering. Our results show
ways to design more helpful and effective AI decision support that goes beyond
end-to-end recommendations.",http://arxiv.org/abs/2406.08959v3,arXiv,beyond recommendation backward forward support pilot decisionmake process,anticipate enhance human decisionmaking highstake domain like aviation adoption often hinder challenge inappropriate reliance poor alignment user decisionmake recent research suggest core underlie issue recommendationcentric design many system give endtoend recommendation ignore rest decisionmaking process alternative support paradigm rare remain unclear exist compare recommendationcentric support work aim empirically compare recommendationcentric support alternative paradigm continuous support context diversion aviation conduct mixedmethod study professional pilot realistic setting ensure quality study scenario conduct focus group four additional pilot prior study find continuous support support pilot decisionmake forward direction allow think beyond limit system make fast decision combine recommendation though forward support disrupt participant statement far suggest shift design goal away provide recommendation support quick information gather result show way design helpful effective decision support beyond endtoend recommendation,beyond recommendation backward forward support pilot decisionmake process anticipate enhance human decisionmaking highstake domain like aviation adoption often hinder challenge inappropriate reliance poor alignment user decisionmake recent research suggest core underlie issue recommendationcentric design many system give endtoend recommendation ignore rest decisionmaking process alternative support paradigm rare remain unclear exist compare recommendationcentric support work aim empirically compare recommendationcentric support alternative paradigm continuous support context diversion aviation conduct mixedmethod study professional pilot realistic setting ensure quality study scenario conduct focus group four additional pilot prior study find continuous support support pilot decisionmake forward direction allow think beyond limit system make fast decision combine recommendation though forward support disrupt participant statement far suggest shift design goal away provide recommendation support quick information gather result show way design helpful effective decision support beyond endtoend recommendation,0.5161290322580645,0.16129032258064516,0.1774193548387097,0.04032258064516129,124.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Qualitative,"Exploring the Requirements of Clinicians for Explainable AI Decision
  Support Systems in Intensive Care","There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.",http://arxiv.org/abs/2411.11774v1,arXiv,explore requirement clinician explainable decision support system intensive care,grow need understand digital system support clinical decisionmake particularly artificial intelligence model become increasingly complex less humaninterpretable complexity raise concern trustworthiness impact safe effective adoption technology improve understanding decisionmake process requirement explanation come decision support tool vital component provide effective explainable solution particularly relevant dataintensive fastpaced environment intensive care unit icus explore issue group interview conduct seven icu clinician represent various role experience level thematic analysis reveal three core theme icu decisionmake relie wide range factor complexity patient state challenge share decisionmaking requirement capability decision support system include design recommendation clinical input provide insight inform future system intensive care,explore requirement clinician explainable decision support system intensive care grow need understand digital system support clinical decisionmake particularly artificial intelligence model become increasingly complex less humaninterpretable complexity raise concern trustworthiness impact safe effective adoption technology improve understanding decisionmake process requirement explanation come decision support tool vital component provide effective explainable solution particularly relevant dataintensive fastpaced environment intensive care unit icus explore issue group interview conduct seven icu clinician represent various role experience level thematic analysis reveal three core theme icu decisionmake relie wide range factor complexity patient state challenge share decisionmaking requirement capability decision support system include design recommendation clinical input provide insight inform future system intensive care,0.5959595959595959,0.12121212121212122,0.20202020202020202,0.04040404040404041,99.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Qualitative,A Typology of Decision-Making Tasks for Visualization,"Despite decision-making being a vital goal of data visualization, little work
has been done to differentiate decision-making tasks within the field. While
visualization task taxonomies and typologies exist, they often focus on more
granular analytical tasks that are too low-level to describe large complex
decisions, which can make it difficult to reason about and design
decision-support tools. In this paper, we contribute a typology of
decision-making tasks that were iteratively refined from a list of design goals
distilled from a literature review. Our typology is concise and consists of
only three tasks: CHOOSE, ACTIVATE, and CREATE. Although decision types
originating in other disciplines exist, we provide definitions for these tasks
that are suitable for the visualization community. Our proposed typology offers
two benefits. First, the ability to compose and hierarchically organize the
tasks enables flexible and clear descriptions of decisions with varying levels
of complexities. Second, the typology encourages productive discourse between
visualization designers and domain experts by abstracting the intricacies of
data, thereby promoting clarity and rigorous analysis of decision-making
processes. We demonstrate the benefits of our typology through four case
studies, and present an evaluation of the typology from semi-structured
interviews with experienced members of the visualization community who have
contributed to developing or publishing decision support systems for domain
experts. Our interviewees used our typology to delineate the decision-making
processes supported by their systems, demonstrating its descriptive capacity
and effectiveness. Finally, we present preliminary findings on the usefulness
of our typology for visualization design.",http://arxiv.org/abs/2404.08812v3,arXiv,typology decisionmake task visualization,despite decisionmake vital goal datum visualization little work differentiate decisionmake task within field visualization task taxonomy typology exist often focus granular analytical task lowlevel describe large complex decision make difficult reason design decisionsupport tool paper contribute typology decisionmake task iteratively refine list design goal distil literature review typology concise consist three task choose activate create although decision type originate discipline exist provide definition task suitable visualization community propose typology offer two benefit first ability compose hierarchically organize task enable flexible clear description decision varying level complexity second typology encourage productive discourse visualization designer domain expert abstract intricacy datum thereby promote clarity rigorous analysis decisionmake process demonstrate benefit typology four case study present evaluation typology semistructured interview experienced member visualization community contribute develop publish decision support system domain expert interviewee use typology delineate decisionmake process support system demonstrate descriptive capacity effectiveness finally present preliminary finding usefulness typology visualization design,typology decisionmake task visualization despite decisionmake vital goal datum visualization little work differentiate decisionmake task within field visualization task taxonomy typology exist often focus granular analytical task lowlevel describe large complex decision make difficult reason design decisionsupport tool paper contribute typology decisionmake task iteratively refine list design goal distil literature review typology concise consist three task choose activate create although decision type originate discipline exist provide definition task suitable visualization community propose typology offer two benefit first ability compose hierarchically organize task enable flexible clear description decision varying level complexity second typology encourage productive discourse visualization designer domain expert abstract intricacy datum thereby promote clarity rigorous analysis decisionmake process demonstrate benefit typology four case study present evaluation typology semistructured interview experienced member visualization community contribute develop publish decision support system domain expert interviewee use typology delineate decisionmake process support system demonstrate descriptive capacity effectiveness finally present preliminary finding usefulness typology visualization design,0.5945945945945946,0.16216216216216217,0.14189189189189189,0.033783783783783786,148.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Qualitative,"""If I Had All the Time in the World"": Ophthalmologists' Perceptions of
  Anchoring Bias Mitigation in Clinical AI Support","Clinical needs and technological advances have resulted in increased use of
Artificial Intelligence (AI) in clinical decision support. However, such
support can introduce new and amplify existing cognitive biases. Through
contextual inquiry and interviews, we set out to understand the use of an
existing AI support system by ophthalmologists. We identified concerns
regarding anchoring bias and a misunderstanding of the AI's capabilities.
Following, we evaluated clinicians' perceptions of three bias mitigation
strategies as integrated into their existing decision support system. While
clinicians recognised the danger of anchoring bias, we identified a concern
around the impact of bias mitigation on procedure time. Our participants were
divided in their expectations of any positive impact on diagnostic accuracy,
stemming from varying reliance on the decision support. Our results provide
insights into the challenges of integrating bias mitigation into AI decision
support.",http://arxiv.org/abs/2303.03981v1,arXiv,time world ophthalmologist perception anchor bias mitigation clinical support,clinical need technological advance result increase use artificial intelligence clinical decision support however support introduce new amplify exist cognitive bias contextual inquiry interview set understand use exist support system ophthalmologist identify concern regard anchor bias misunderstanding ais capability follow evaluate clinician perception three bias mitigation strategy integrate exist decision support system clinician recognise danger anchor bias identify concern around impact bias mitigation procedure time participant divide expectation positive impact diagnostic accuracy stem vary reliance decision support result provide insight challenge integrate bias mitigation decision support,time world ophthalmologist perception anchor bias mitigation clinical support clinical need technological advance result increase use artificial intelligence clinical decision support however support introduce new amplify exist cognitive bias contextual inquiry interview set understand use exist support system ophthalmologist identify concern regard anchor bias misunderstanding ais capability follow evaluate clinician perception three bias mitigation strategy integrate exist decision support system clinician recognise danger anchor bias identify concern around impact bias mitigation procedure time participant divide expectation positive impact diagnostic accuracy stem vary reliance decision support result provide insight challenge integrate bias mitigation decision support,0.6588235294117647,0.1411764705882353,0.12941176470588237,0.011764705882352941,85.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Qualitative,"Fiduciary Responsibility: Facilitating Public Trust in Automated
  Decision Making","Automated decision-making systems are being increasingly deployed and affect
the public in a multitude of positive and negative ways. Governmental and
private institutions use these systems to process information according to
certain human-devised rules in order to address social problems or
organizational challenges. Both research and real-world experience indicate
that the public lacks trust in automated decision-making systems and the
institutions that deploy them. The recreancy theorem argues that the public is
more likely to trust and support decisions made or influenced by automated
decision-making systems if the institutions that administer them meet their
fiduciary responsibility. However, often the public is never informed of how
these systems operate and resultant institutional decisions are made. A ``black
box'' effect of automated decision-making systems reduces the public's
perceptions of integrity and trustworthiness. The result is that the public
loses the capacity to identify, challenge, and rectify unfairness or the costs
associated with the loss of public goods or benefits.
  The current position paper defines and explains the role of fiduciary
responsibility within an automated decision-making system. We formulate an
automated decision-making system as a data science lifecycle (DSL) and examine
the implications of fiduciary responsibility within the context of the DSL.
Fiduciary responsibility within DSLs provides a methodology for addressing the
public's lack of trust in automated decision-making systems and the
institutions that employ them to make decisions affecting the public. We posit
that fiduciary responsibility manifests in several contexts of a DSL, each of
which requires its own mitigation of sources of mistrust. To instantiate
fiduciary responsibility, a Los Angeles Police Department (LAPD) predictive
policing case study is examined.",http://arxiv.org/abs/2301.10001v1,arXiv,fiduciary responsibility facilitate public trust automate decision making,automate decisionmaking system increasingly deploy affect public multitude positive negative way governmental private institution use system process information accord certain humandevised rule order address social problem organizational challenge research realworld experience indicate public lack trust automate decisionmaking system institution deploy recreancy theorem argue public likely trust support decision make influence automate decisionmake system institution administer meet fiduciary responsibility however often public never inform system operate resultant institutional decision make black box effect automate decisionmaking system reduce public perception integrity trustworthiness result public lose capacity identify challenge rectify unfairness cost associate loss public good benefit current position paper define explain role fiduciary responsibility within automate decisionmaking system formulate automate decisionmaking system data science lifecycle dsl examine implication fiduciary responsibility within context dsl fiduciary responsibility within dsls provide methodology address public lack trust automate decisionmaking system institution employ make decision affect public posit fiduciary responsibility manifest several context dsl require mitigation source mistrust instantiate fiduciary responsibility los angeles police department lapd predictive policing case study examine,fiduciary responsibility facilitate public trust automate decision making automate decisionmaking system increasingly deploy affect public multitude positive negative way governmental private institution use system process information accord certain humandevised rule order address social problem organizational challenge research realworld experience indicate public lack trust automate decisionmaking system institution deploy recreancy theorem argue public likely trust support decision make influence automate decisionmake system institution administer meet fiduciary responsibility however often public never inform system operate resultant institutional decision make black box effect automate decisionmaking system reduce public perception integrity trustworthiness result public lose capacity identify challenge rectify unfairness cost associate loss public good benefit current position paper define explain role fiduciary responsibility within automate decisionmaking system formulate automate decisionmaking system data science lifecycle dsl examine implication fiduciary responsibility within context dsl fiduciary responsibility within dsls provide methodology address public lack trust automate decisionmaking system institution employ make decision affect public posit fiduciary responsibility manifest several context dsl require mitigation source mistrust instantiate fiduciary responsibility los angeles police department lapd predictive policing case study examine,0.5,0.18292682926829268,0.22560975609756098,0.03048780487804878,164.0,0.0,1.0,0.0,0.0
Information Systems,Decision Support Systems,Mixed Methods,"Adaptive questionnaires for facilitating patient data entry in clinical
  decision support systems: Methods and application to STOPP/START v2","Clinical decision support systems are software tools that help clinicians to
make medical decisions. However, their acceptance by clinicians is usually
rather low. A known problem is that they often require clinicians to manually
enter lots of patient data, which is long and tedious. Existing solutions, such
as the automatic data extraction from electronic health record, are not fully
satisfying, because of low data quality and availability. In practice, many
systems still include long questionnaire for data entry.
  In this paper, we propose an original solution to simplify patient data
entry, using an adaptive questionnaire, i.e. a questionnaire that evolves
during user interaction, showing or hiding questions dynamically. Considering a
rule-based decision support systems, we designed methods for translating the
system's clinical rules into display rules that determine the items to show in
the questionnaire, and methods for determining the optimal order of priority
among the items in the questionnaire. We applied this approach to a decision
support system implementing STOPP/START v2, a guideline for managing
polypharmacy. We show that it permits reducing by about two thirds the number
of clinical conditions displayed in the questionnaire. Presented to clinicians
during focus group sessions, the adaptive questionnaire was found ""pretty easy
to use"". In the future, this approach could be applied to other guidelines, and
adapted for data entry by patients.",http://arxiv.org/abs/2309.10398v1,arXiv,adaptive questionnaire facilitate patient data entry clinical decision support system method application stoppstart,clinical decision support system software tool help clinician make medical decision however acceptance clinician usually rather low know problem often require clinician manually enter lot patient datum long tedious exist solution automatic datum extraction electronic health record fully satisfying low datum quality availability practice many system still include long questionnaire datum entry paper propose original solution simplify patient data entry use adaptive questionnaire questionnaire evolve user interaction showing hiding question dynamically consider rulebase decision support system design method translate system clinical rule display rule determine item show questionnaire method determine optimal order priority among item questionnaire apply approach decision support system implement stoppstart guideline manage polypharmacy show permit reduce two third number clinical condition display questionnaire present clinician focus group session adaptive questionnaire find pretty easy use future approach could apply guideline adapt datum entry patient,adaptive questionnaire facilitate patient data entry clinical decision support system method application stoppstart clinical decision support system software tool help clinician make medical decision however acceptance clinician usually rather low know problem often require clinician manually enter lot patient datum long tedious exist solution automatic datum extraction electronic health record fully satisfying low datum quality availability practice many system still include long questionnaire datum entry paper propose original solution simplify patient data entry use adaptive questionnaire questionnaire evolve user interaction showing hiding question dynamically consider rulebase decision support system design method translate system clinical rule display rule determine item show questionnaire method determine optimal order priority among item questionnaire apply approach decision support system implement stoppstart guideline manage polypharmacy show permit reduce two third number clinical condition display questionnaire present clinician focus group session adaptive questionnaire find pretty easy use future approach could apply guideline adapt datum entry patient,0.6102941176470589,0.13970588235294118,0.15441176470588236,0.0661764705882353,136.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Mixed Methods,PERFEX: Classifier Performance Explanations for Trustworthy AI Systems,"Explainability of a classification model is crucial when deployed in
real-world decision support systems. Explanations make predictions actionable
to the user and should inform about the capabilities and limitations of the
system. Existing explanation methods, however, typically only provide
explanations for individual predictions. Information about conditions under
which the classifier is able to support the decision maker is not available,
while for instance information about when the system is not able to
differentiate classes can be very helpful. In the development phase it can
support the search for new features or combining models, and in the operational
phase it supports decision makers in deciding e.g. not to use the system. This
paper presents a method to explain the qualities of a trained base classifier,
called PERFormance EXplainer (PERFEX). Our method consists of a meta tree
learning algorithm that is able to predict and explain under which conditions
the base classifier has a high or low error or any other classification
performance metric. We evaluate PERFEX using several classifiers and datasets,
including a case study with urban mobility data. It turns out that PERFEX
typically has high meta prediction performance even if the base classifier is
hardly able to differentiate classes, while giving compact performance
explanations.",http://arxiv.org/abs/2212.06045v1,arXiv,perfex classifier performance explanation trustworthy system,explainability classification model crucial deploy realworld decision support system explanation make prediction actionable user inform capability limitation system exist explanation method however typically provide explanation individual prediction information condition classifier able support decision maker available instance information system able differentiate class helpful development phase support search new feature combine model operational phase support decision maker decide use system paper present method explain quality train base classifier call performance explainer perfex method consist meta tree learn algorithm able predict explain condition base classifier high low error classification performance metric evaluate perfex use several classifier dataset include case study urban mobility datum turn perfex typically high meta prediction performance even base classifier hardly able differentiate class give compact performance explanation,perfex classifier performance explanation trustworthy system explainability classification model crucial deploy realworld decision support system explanation make prediction actionable user inform capability limitation system exist explanation method however typically provide explanation individual prediction information condition classifier able support decision maker available instance information system able differentiate class helpful development phase support search new feature combine model operational phase support decision maker decide use system paper present method explain quality train base classifier call performance explainer perfex method consist meta tree learn algorithm able predict explain condition base classifier high low error classification performance metric evaluate perfex use several classifier dataset include case study urban mobility datum turn perfex typically high meta prediction performance even base classifier hardly able differentiate class give compact performance explanation,0.5847457627118644,0.11864406779661017,0.19491525423728814,0.0423728813559322,118.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Mixed Methods,"Towards Next-Generation Urban Decision Support Systems through
  AI-Powered Construction of Scientific Ontology using Large Language Models --
  A Case in Optimizing Intermodal Freight Transportation","The incorporation of Artificial Intelligence (AI) models into various
optimization systems is on the rise. Yet, addressing complex urban and
environmental management problems normally requires in-depth domain science and
informatics expertise. This expertise is essential for deriving data and
simulation-driven for informed decision support. In this context, we
investigate the potential of leveraging the pre-trained Large Language Models
(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated
workflow that encompasses natural language processing, methontology-based
prompt tuning, and transformers. This workflow automates the creation of
scenario-based ontology using existing research articles and technical manuals
of urban datasets and simulations. The outcomes of our methodology are
knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).
These facilitate the development of urban decision support systems by enhancing
the data and metadata modeling, the integration of complex datasets, the
coupling of multi-domain simulation models, and the formulation of
decision-making metrics and workflow. The feasibility of our methodology is
evaluated through a comparative analysis that juxtaposes our AI-generated
ontology with the well-known Pizza Ontology employed in tutorials for popular
ontology software (e.g., prot\'eg\'e). We close with a real-world case study of
optimizing the complex urban system of multi-modal freight transportation by
generating anthologies of various domain data and simulations to support
informed decision-making.",http://arxiv.org/abs/2405.19255v3,arXiv,towards nextgeneration urban decision support system aipowere construction scientific ontology use large language model case optimize intermodal freight transportation,incorporation artificial intelligence model various optimization system rise yet address complex urban environmental management problem normally require indepth domain science informatic expertise expertise essential derive datum simulationdriven informed decision support context investigate potential leverage pretraine large language model llm adopt chatgpt api reasoning core outline integrate workflow encompass natural language processing methontologybase prompt tuning transformer workflow automate creation scenariobase ontology use exist research article technical manual urban dataset simulation outcome methodology knowledge graph widely adopt ontology language owl rdf sparql facilitate development urban decision support system enhance datum metadata model integration complex dataset coupling multidomain simulation model formulation decisionmake metric workflow feasibility methodology evaluate comparative analysis juxtapose aigenerate ontology wellknown pizza ontology employ tutorial popular ontology software protege close realworld case study optimize complex urban system multimodal freight transportation generate anthology various domain datum simulation support inform decisionmake,towards nextgeneration urban decision support system aipowere construction scientific ontology use large language model case optimize intermodal freight transportation incorporation artificial intelligence model various optimization system rise yet address complex urban environmental management problem normally require indepth domain science informatic expertise expertise essential derive datum simulationdriven informed decision support context investigate potential leverage pretraine large language model llm adopt chatgpt api reasoning core outline integrate workflow encompass natural language processing methontologybase prompt tuning transformer workflow automate creation scenariobase ontology use exist research article technical manual urban dataset simulation outcome methodology knowledge graph widely adopt ontology language owl rdf sparql facilitate development urban decision support system enhance datum metadata model integration complex dataset coupling multidomain simulation model formulation decisionmake metric workflow feasibility methodology evaluate comparative analysis juxtapose aigenerate ontology wellknown pizza ontology employ tutorial popular ontology software protege close realworld case study optimize complex urban system multimodal freight transportation generate anthology various domain datum simulation support inform decisionmake,0.6014492753623188,0.08695652173913043,0.1956521739130435,0.028985507246376812,138.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Mixed Methods,"Do Expressions Change Decisions? Exploring the Impact of AI's
  Explanation Tone on Decision-Making","Explanatory information helps users to evaluate the suggestions offered by
AI-driven decision support systems. With large language models, adjusting
explanation expressions has become much easier. However, how these expressions
influence human decision-making remains largely unexplored. This study
investigated the effect of explanation tone (e.g., formal or humorous) on
decision-making, focusing on AI roles and user attributes. We conducted user
experiments across three scenarios depending on AI roles (assistant,
second-opinion provider, and expert) using datasets designed with varying
tones. The results revealed that tone significantly influenced decision-making
regardless of user attributes in the second-opinion scenario, whereas its
impact varied by user attributes in the assistant and expert scenarios. In
addition, older users were more influenced by tone, and highly extroverted
users exhibited discrepancies between their perceptions and decisions.
Furthermore, open-ended questionnaires highlighted that users expect tone
adjustments to enhance their experience while emphasizing the importance of
tone consistency and ethical considerations. Our findings provide crucial
insights into the design of explanation expressions.",http://arxiv.org/abs/2502.19730v1,arXiv,expression change decision explore impact ais explanation tone decisionmake,explanatory information help user evaluate suggestion offer aidriven decision support system large language model adjust explanation expression become much easy however expression influence human decisionmaking remain largely unexplored study investigate effect explanation tone formal humorous decisionmake focus role user attribute conduct user experiment across three scenario depend role assistant secondopinion provider expert use dataset design vary tone result reveal tone significantly influence decisionmake regardless user attribute secondopinion scenario whereas impact vary user attribute assistant expert scenario addition old user influence tone highly extroverte user exhibit discrepancy perception decision furthermore openende questionnaire highlight user expect tone adjustment enhance experience emphasize importance tone consistency ethical consideration finding provide crucial insight design explanation expression,expression change decision explore impact ais explanation tone decisionmake explanatory information help user evaluate suggestion offer aidriven decision support system large language model adjust explanation expression become much easy however expression influence human decisionmaking remain largely unexplored study investigate effect explanation tone formal humorous decisionmake focus role user attribute conduct user experiment across three scenario depend role assistant secondopinion provider expert use dataset design vary tone result reveal tone significantly influence decisionmake regardless user attribute secondopinion scenario whereas impact vary user attribute assistant expert scenario addition old user influence tone highly extroverte user exhibit discrepancy perception decision furthermore openende questionnaire highlight user expect tone adjustment enhance experience emphasize importance tone consistency ethical consideration finding provide crucial insight design explanation expression,0.6306306306306306,0.10810810810810811,0.11711711711711711,0.06306306306306306,111.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Mixed Methods,"OCEP: An Ontology-Based Complex Event Processing Framework for
  Healthcare Decision Support in Big Data Analytics","The exponential expansion of real-time data streams across multiple domains
needs the development of effective event detection, correlation, and
decision-making systems. However, classic Complex Event Processing (CEP)
systems struggle with semantic heterogeneity, data interoperability, and
knowledge driven event reasoning in Big Data environments. To solve these
challenges, this research work presents an Ontology based Complex Event
Processing (OCEP) framework, which utilizes semantic reasoning and Big Data
Analytics to improve event driven decision support. The proposed OCEP
architecture utilizes ontologies to support reasoning to event streams. It
ensures compatibility with different data sources and lets you find the events
based on the context. The Resource Description Framework (RDF) organizes event
data, and SPARQL query enables rapid event reasoning and retrieval. The
approach is implemented within the Hadoop environment, which consists of Hadoop
Distributed File System (HDFS) for scalable storage and Apache Kafka for
real-time CEP based event execution. We perform a real-time healthcare analysis
and case study to validate the model, utilizing IoT sensor data for illness
monitoring and emergency responses. This OCEP framework successfully integrates
several event streams, leading to improved early disease detection and aiding
doctors in decision-making. The result shows that OCEP predicts event detection
with an accuracy of 85%. This research work utilizes an OCEP to solve the
problems with semantic interoperability and correlation of complex events in
Big Data analytics. The proposed architecture presents an intelligent, scalable
and knowledge driven event processing framework for healthcare based decision
support.",http://arxiv.org/abs/2503.21453v1,arXiv,ocep ontologybase complex event processing framework healthcare decision support big datum analytic,exponential expansion realtime datum stream across multiple domain need development effective event detection correlation decisionmake system however classic complex event processing cep system struggle semantic heterogeneity datum interoperability knowledge drive event reasoning big datum environment solve challenge research work present ontology base complex event processing ocep framework utilize semantic reasoning big datum analytic improve event drive decision support propose ocep architecture utilize ontology support reasoning event stream ensure compatibility different data source let find event base context resource description framework rdf organize event datum sparql query enable rapid event reasoning retrieval approach implement within hadoop environment consist hadoop distribute file system hdfs scalable storage apache kafka realtime cep base event execution perform realtime healthcare analysis case study validate model utilize iot sensor datum illness monitoring emergency response ocep framework successfully integrate several event stream lead improve early disease detection aid doctor decisionmake result show ocep predict event detection accuracy research work utilize ocep solve problem semantic interoperability correlation complex event big data analytic propose architecture present intelligent scalable knowledge drive event processing framework healthcare base decision support,ocep ontologybase complex event processing framework healthcare decision support big datum analytic exponential expansion realtime datum stream across multiple domain need development effective event detection correlation decisionmake system however classic complex event processing cep system struggle semantic heterogeneity datum interoperability knowledge drive event reasoning big datum environment solve challenge research work present ontology base complex event processing ocep framework utilize semantic reasoning big datum analytic improve event drive decision support propose ocep architecture utilize ontology support reasoning event stream ensure compatibility different data source let find event base context resource description framework rdf organize event datum sparql query enable rapid event reasoning retrieval approach implement within hadoop environment consist hadoop distribute file system hdfs scalable storage apache kafka realtime cep base event execution perform realtime healthcare analysis case study validate model utilize iot sensor datum illness monitoring emergency response ocep framework successfully integrate several event stream lead improve early disease detection aid doctor decisionmake result show ocep predict event detection accuracy research work utilize ocep solve problem semantic interoperability correlation complex event big data analytic propose architecture present intelligent scalable knowledge drive event processing framework healthcare base decision support,0.6497175141242938,0.14689265536723164,0.14124293785310735,0.011299435028248588,177.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Design and Development,"Towards a Reliable Framework of Uncertainty-Based Group Decision Support
  System","This study proposes a framework of Uncertainty-based Group Decision Support
System (UGDSS). It provides a platform for multiple criteria decision analysis
in six aspects including (1) decision environment, (2) decision problem, (3)
decision group, (4) decision conflict, (5) decision schemes and (6) group
negotiation. Based on multiple artificial intelligent technologies, this
framework provides reliable support for the comprehensive manipulation of
applications and advanced decision approaches through the design of an
integrated multi-agents architecture.",http://arxiv.org/abs/1107.0089v1,arXiv,towards reliable framework uncertaintybased group decision support system,study propose framework uncertaintybased group decision support system ugdss provide platform multiple criterion decision analysis six aspect include decision environment decision problem decision group decision conflict decision scheme group negotiation base multiple artificial intelligent technology framework provide reliable support comprehensive manipulation application advanced decision approach design integrate multiagent architecture,towards reliable framework uncertaintybased group decision support system study propose framework uncertaintybased group decision support system ugdss provide platform multiple criterion decision analysis six aspect include decision environment decision problem decision group decision conflict decision scheme group negotiation base multiple artificial intelligent technology framework provide reliable support comprehensive manipulation application advanced decision approach design integrate multiagent architecture,0.673469387755102,0.10204081632653061,0.1836734693877551,0.02040816326530612,49.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Design and Development,"Stakeholder-in-the-Loop Fair Decisions: A Framework to Design Decision
  Support Systems in Public and Private Organizations","Due to the opacity of machine learning technology, there is a need for
explainability and fairness in the decision support systems used in public or
private organizations. Although the criteria for appropriate explanations and
fair decisions change depending on the values of those who are affected by the
decisions, there is a lack of discussion framework to consider the appropriate
outputs for each stakeholder. In this paper, we propose a discussion framework
that we call ""stakeholder-in-the-loop fair decisions."" This is proposed to
consider the requirements for appropriate explanations and fair decisions. We
identified four stakeholders that need to be considered to design accountable
decision support systems and discussed how to consider the appropriate outputs
for each stakeholder by referring to our works. By clarifying the
characteristics of specific stakeholders in each application domain and
integrating the stakeholders' values into outputs that all stakeholders agree
upon, decision support systems can be designed as systems that ensure
accountable decision makings.",http://arxiv.org/abs/2308.01163v1,arXiv,stakeholderintheloop fair decision framework design decision support system public private organization,due opacity machine learn technology need explainability fairness decision support system use public private organization although criterion appropriate explanation fair decision change depend value affect decision lack discussion framework consider appropriate output stakeholder paper propose discussion framework call stakeholderintheloop fair decision propose consider requirement appropriate explanation fair decision identify four stakeholder need consider design accountable decision support system discuss consider appropriate output stakeholder refer work clarify characteristic specific stakeholder application domain integrate stakeholder value output stakeholder agree upon decision support system design system ensure accountable decision making,stakeholderintheloop fair decision framework design decision support system public private organization due opacity machine learn technology need explainability fairness decision support system use public private organization although criterion appropriate explanation fair decision change depend value affect decision lack discussion framework consider appropriate output stakeholder paper propose discussion framework call stakeholderintheloop fair decision propose consider requirement appropriate explanation fair decision identify four stakeholder need consider design accountable decision support system discuss consider appropriate output stakeholder refer work clarify characteristic specific stakeholder application domain integrate stakeholder value output stakeholder agree upon decision support system design system ensure accountable decision making,0.6206896551724138,0.16091954022988506,0.1724137931034483,0.0,87.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Design and Development,An Ontology-driven Framework for Supporting Complex Decision Process,"The study proposes a framework of ONTOlogy-based Group Decision Support
System (ONTOGDSS) for decision process which exhibits the complex structure of
decision-problem and decision-group. It is capable of reducing the complexity
of problem structure and group relations. The system allows decision makers to
participate in group decision-making through the web environment, via the
ontology relation. It facilitates the management of decision process as a
whole, from criteria generation, alternative evaluation, and opinion
interaction to decision aggregation. The embedded ontology structure in
ONTOGDSS provides the important formal description features to facilitate
decision analysis and verification. It examines the software architecture, the
selection methods, the decision path, etc. Finally, the ontology application of
this system is illustrated with specific real case to demonstrate its
potentials towards decision-making development.",http://arxiv.org/abs/1107.2997v1,arXiv,ontologydriven framework support complex decision process,study propose framework ontologybase group decision support system ontogdss decision process exhibit complex structure decisionproblem decisiongroup capable reduce complexity problem structure group relation system allow decision maker participate group decisionmake web environment via ontology relation facilitate management decision process whole criterion generation alternative evaluation opinion interaction decision aggregation embed ontology structure ontogdss provide important formal description feature facilitate decision analysis verification examine software architecture selection method decision path etc finally ontology application system illustrate specific real case demonstrate potential towards decisionmake development,ontologydriven framework support complex decision process study propose framework ontologybase group decision support system ontogdss decision process exhibit complex structure decisionproblem decisiongroup capable reduce complexity problem structure group relation system allow decision maker participate group decisionmake web environment via ontology relation facilitate management decision process whole criterion generation alternative evaluation opinion interaction decision aggregation embed ontology structure ontogdss provide important formal description feature facilitate decision analysis verification examine software architecture selection method decision path etc finally ontology application system illustrate specific real case demonstrate potential towards decisionmake development,0.7560975609756098,0.08536585365853659,0.10975609756097561,0.012195121951219513,82.0,1.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Design and Development,Agile System Development Lifecycle for AI Systems: Decision Architecture,"Agile system development life cycle (SDLC) focuses on typical functional and
non-functional system requirements for developing traditional software systems.
However, Artificial Intelligent (AI) systems are different in nature and have
distinct attributes such as (1) autonomy, (2) adaptiveness, (3) content
generation, (4) decision-making, (5) predictability and (6) recommendation.
Agile SDLC needs to be enhanced to support the AI system development and
ongoing post-deployment adaptation. The challenge is: how can agile SDLC be
enhanced to support AI systems? The scope of this paper is limited to AI system
enabled decision automation. Thus, this paper proposes the use of decision
science to enhance the agile SDLC to support the AI system development.
Decision science is the study of decision-making, which seems useful to
identify, analyse and describe decisions and their architecture subject to
automation via AI systems. Specifically, this paper discusses the decision
architecture in detail within the overall context of agile SDLC for AI systems.
The application of the proposed approach is demonstrated with the help of an
example scenario of insurance claim processing. This initial work indicated the
usability of a decision science to enhancing the agile SDLC for designing and
implementing the AI systems for decision-automation. This work provides an
initial foundation for further work in this new area of decision architecture
and agile SDLC for AI systems.",http://arxiv.org/abs/2501.09434v2,arXiv,agile system development lifecycle system decision architecture,agile system development life cycle sdlc focus typical functional nonfunctional system requirement develop traditional software system however artificial intelligent system different nature distinct attribute autonomy adaptiveness content generation decisionmake predictability recommendation agile sdlc need enhance support system development ongoing postdeployment adaptation challenge agile sdlc enhance support system scope paper limit system enable decision automation thus paper propose use decision science enhance agile sdlc support system development decision science study decisionmake seem useful identify analyse describe decision architecture subject automation via system specifically paper discuss decision architecture detail within overall context agile sdlc system application propose approach demonstrate help example scenario insurance claim process initial work indicate usability decision science enhance agile sdlc design implement system decisionautomation work provide initial foundation work new area decision architecture agile sdlc system,agile system development lifecycle system decision architecture agile system development life cycle sdlc focus typical functional nonfunctional system requirement develop traditional software system however artificial intelligent system different nature distinct attribute autonomy adaptiveness content generation decisionmake predictability recommendation agile sdlc need enhance support system development ongoing postdeployment adaptation challenge agile sdlc enhance support system scope paper limit system enable decision automation thus paper propose use decision science enhance agile sdlc support system development decision science study decisionmake seem useful identify analyse describe decision architecture subject automation via system specifically paper discuss decision architecture detail within overall context agile sdlc system application propose approach demonstrate help example scenario insurance claim process initial work indicate usability decision science enhance agile sdlc design implement system decisionautomation work provide initial foundation work new area decision architecture agile sdlc system,0.65625,0.125,0.1640625,0.0234375,128.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Design and Development,A hybrid decision support system : application on healthcare,"Many systems based on knowledge, especially expert systems for medical
decision support have been developed. Only systems are based on production
rules, and cannot learn and evolve only by updating them. In addition, taking
into account several criteria induces an exorbitant number of rules to be
injected into the system. It becomes difficult to translate medical knowledge
or a support decision as a simple rule. Moreover, reasoning based on generic
cases became classic and can even reduce the range of possible solutions. To
remedy that, we propose an approach based on using a multi-criteria decision
guided by a case-based reasoning (CBR) approach.",http://arxiv.org/abs/1311.4086v1,arXiv,hybrid decision support system application healthcare,many system base knowledge especially expert system medical decision support develop system base production rule learn evolve update addition take account several criterion induce exorbitant number rule inject system become difficult translate medical knowledge support decision simple rule moreover reasoning base generic case become classic even reduce range possible solution remedy propose approach base use multicriteria decision guide casebase reasoning cbr approach,hybrid decision support system application healthcare many system base knowledge especially expert system medical decision support develop system base production rule learn evolve update addition take account several criterion induce exorbitant number rule inject system become difficult translate medical knowledge support decision simple rule moreover reasoning base generic case become classic even reduce range possible solution remedy propose approach base use multicriteria decision guide casebase reasoning cbr approach,0.6129032258064516,0.16129032258064516,0.16129032258064516,0.04838709677419355,62.0,1.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Theoretical / Conceptual,Introduction to Multi-Agent Simulation,"When designing systems that are complex, dynamic and stochastic in nature,
simulation is generally recognised as one of the best design support
technologies, and a valuable aid in the strategic and tactical decision making
process. A simulation model consists of a set of rules that define how a system
changes over time, given its current state. Unlike analytical models, a
simulation model is not solved but is run and the changes of system states can
be observed at any point in time. This provides an insight into system dynamics
rather than just predicting the output of a system based on specific inputs.
Simulation is not a decision making tool but a decision support tool, allowing
better informed decisions to be made. Due to the complexity of the real world,
a simulation model can only be an approximation of the target system. The
essence of the art of simulation modelling is abstraction and simplification.
Only those characteristics that are important for the study and analysis of the
target system should be included in the simulation model.",http://arxiv.org/abs/0803.3905v1,arXiv,introduction multiagent simulation,design system complex dynamic stochastic nature simulation generally recognise one good design support technology valuable aid strategic tactical decision making process simulation model consist set rule define system change time give current state unlike analytical model simulation model solve run change system state observe point time provide insight system dynamic rather predict output system base specific input simulation decision make tool decision support tool allow well inform decision make due complexity real world simulation model approximation target system essence art simulation modelling abstraction simplification characteristic important study analysis target system include simulation model,introduction multiagent simulation design system complex dynamic stochastic nature simulation generally recognise one good design support technology valuable aid strategic tactical decision making process simulation model consist set rule define system change time give current state unlike analytical model simulation model solve run change system state observe point time provide insight system dynamic rather predict output system base specific input simulation decision make tool decision support tool allow well inform decision make due complexity real world simulation model approximation target system essence art simulation modelling abstraction simplification characteristic important study analysis target system include simulation model,0.6451612903225806,0.13978494623655913,0.15053763440860216,0.021505376344086023,93.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Theoretical / Conceptual,Symbolic Decision Theory and Autonomous Systems,"The ability to reason under uncertainty and with incomplete information is a
fundamental requirement of decision support technology. In this paper we argue
that the concentration on theoretical techniques for the evaluation and
selection of decision options has distracted attention from many of the wider
issues in decision making. Although numerical methods of reasoning under
uncertainty have strong theoretical foundations, they are representationally
weak and only deal with a small part of the decision process. Knowledge based
systems, on the other hand, offer greater flexibility but have not been
accompanied by a clear decision theory. We describe here work which is under
way towards providing a theoretical framework for symbolic decision procedures.
A central proposal is an extended form of inference which we call
argumentation; reasoning for and against decision options from generalised
domain theories. The approach has been successfully used in several decision
support applications, but it is argued that a comprehensive decision theory
must cover autonomous decision making, where the agent can formulate questions
as well as take decisions. A major theoretical challenge for this theory is to
capture the idea of reflection to permit decision agents to reason about their
goals, what they believe and why, and what they need to know or do in order to
achieve their goals.",http://arxiv.org/abs/1303.5716v1,arXiv,symbolic decision theory autonomous system,ability reason uncertainty incomplete information fundamental requirement decision support technology paper argue concentration theoretical technique evaluation selection decision option distract attention many wide issue decision make although numerical method reasoning uncertainty strong theoretical foundation representationally weak deal small part decision process knowledge base system hand offer great flexibility accompany clear decision theory describe work way towards provide theoretical framework symbolic decision procedure central proposal extended form inference call argumentation reasoning decision option generalised domain theory approach successfully use several decision support application argue comprehensive decision theory must cover autonomous decision making agent formulate question well take decision major theoretical challenge theory capture idea reflection permit decision agent reason goal believe need know order achieve goal,symbolic decision theory autonomous system ability reason uncertainty incomplete information fundamental requirement decision support technology paper argue concentration theoretical technique evaluation selection decision option distract attention many wide issue decision make although numerical method reasoning uncertainty strong theoretical foundation representationally weak deal small part decision process knowledge base system hand offer great flexibility accompany clear decision theory describe work way towards provide theoretical framework symbolic decision procedure central proposal extended form inference call argumentation reasoning decision option generalised domain theory approach successfully use several decision support application argue comprehensive decision theory must cover autonomous decision making agent formulate question well take decision major theoretical challenge theory capture idea reflection permit decision agent reason goal believe need know order achieve goal,0.591304347826087,0.17391304347826086,0.1826086956521739,0.02608695652173913,115.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Theoretical / Conceptual,A Social Network for Societal-Scale Decision-Making Systems,"In societal-scale decision-making systems the collective is faced with the
problem of ensuring that the derived group decision is in accord with the
collective's intention. In modern systems, political institutions have
instatiated representative forms of decision-making to ensure that every
individual in the society has a participatory voice in the decision-making
behavior of the whole--even if only indirectly through representation. An
agent-based simulation demonstrates that in modern representative systems, as
the ratio of representatives increases, there exists an exponential decrease in
the ability for the group to behave in accord with the desires of the whole. To
remedy this issue, this paper provides a novel representative power structure
for decision-making that utilizes a social network and power distribution
algorithm to maintain the collective's perspective over varying degrees of
participation and/or ratios of representation. This work shows promise for the
future development of policy-making systems that are supported by the computer
and network infrastructure of our society.",http://arxiv.org/abs/cs/0412047v1,arXiv,social network societalscale decisionmaking system,societalscale decisionmaking system collective face problem ensure derive group decision accord collective intention modern system political institution instatiate representative form decisionmake ensure every individual society participatory voice decisionmake behavior wholeeven indirectly representation agentbase simulation demonstrate modern representative system ratio representative increase exist exponential decrease ability group behave accord desire whole remedy issue paper provide novel representative power structure decisionmake utilize social network power distribution algorithm maintain collective perspective vary degree participation andor ratio representation work show promise future development policymake system support computer network infrastructure society,social network societalscale decisionmaking system societalscale decisionmaking system collective face problem ensure derive group decision accord collective intention modern system political institution instatiate representative form decisionmake ensure every individual society participatory voice decisionmake behavior wholeeven indirectly representation agentbase simulation demonstrate modern representative system ratio representative increase exist exponential decrease ability group behave accord desire whole remedy issue paper provide novel representative power structure decisionmake utilize social network power distribution algorithm maintain collective perspective vary degree participation andor ratio representation work show promise future development policymake system support computer network infrastructure society,0.5697674418604651,0.12790697674418605,0.20930232558139536,0.023255813953488372,86.0,0.0,0.0,0.0,0.0
Information Systems,Decision Support Systems,Theoretical / Conceptual,"Extracting Process-Aware Decision Models from Object-Centric Process
  Data","Organizations execute decisions within business processes on a daily basis
whilst having to take into account multiple stakeholders who might require
multiple point of views of the same process. Moreover, the complexity of the
information systems running these business processes is generally high as they
are linked to databases storing all the relevant data and aspects of the
processes. Given the presence of multiple objects within an information system
which support the processes in their enactment, decisions are naturally
influenced by both these perspectives, logged in object-centric process logs.
However, the discovery of such decisions from object-centric process logs is
not straightforward as it requires to correctly link the involved objects
whilst considering the sequential constraints that business processes impose as
well as correctly discovering what a decision actually does. This paper
proposes the first object-centric decision-mining algorithm called Integrated
Object-centric Decision Discovery Algorithm (IODDA). IODDA is able to discover
how a decision is structured as well as how a decision is made. Moreover, IODDA
is able to discover which activities and object types are involved in the
decision-making process. Next, IODDA is demonstrated with the first artificial
knowledge-intensive process logs whose log generators are provided to the
research community.",http://arxiv.org/abs/2401.14847v1,arXiv,extract processaware decision model objectcentric process datum,organization execute decision within business process daily basis whilst take account multiple stakeholder might require multiple point view process moreover complexity information system run business process generally high link database store relevant datum aspect process give presence multiple object within information system support process enactment decision naturally influence perspective log objectcentric process log however discovery decision objectcentric process log straightforward require correctly link involved object whilst consider sequential constraint business process impose well correctly discover decision actually paper propose first objectcentric decisionmine algorithm call integrate objectcentric decision discovery algorithm iodda iodda able discover decision structure well decision make moreover iodda able discover activity object type involve decisionmaking process next iodda demonstrate first artificial knowledgeintensive process log whose log generator provide research community,extract processaware decision model objectcentric process datum organization execute decision within business process daily basis whilst take account multiple stakeholder might require multiple point view process moreover complexity information system run business process generally high link database store relevant datum aspect process give presence multiple object within information system support process enactment decision naturally influence perspective log objectcentric process log however discovery decision objectcentric process log straightforward require correctly link involved object whilst consider sequential constraint business process impose well correctly discover decision actually paper propose first objectcentric decisionmine algorithm call integrate objectcentric decision discovery algorithm iodda iodda able discover decision structure well decision make moreover iodda able discover activity object type involve decisionmaking process next iodda demonstrate first artificial knowledgeintensive process log whose log generator provide research community,0.5245901639344263,0.14754098360655737,0.14754098360655737,0.07377049180327869,122.0,0.0,0.0,1.0,0.0
Information Systems,Decision Support Systems,Theoretical / Conceptual,Explanation of Probabilistic Inference for Decision Support Systems,"An automated explanation facility for Bayesian conditioning aimed at
improving user acceptance of probability-based decision support systems has
been developed. The domain-independent facility is based on an information
processing perspective on reasoning about conditional evidence that accounts
both for biased and normative inferences. Experimental results indicate that
the facility is both acceptable to naive users and effective in improving
understanding.",http://arxiv.org/abs/1304.2756v1,arXiv,explanation probabilistic inference decision support system,automate explanation facility bayesian conditioning aim improve user acceptance probabilitybase decision support system develop domainindependent facility base information processing perspective reasoning conditional evidence account biased normative inference experimental result indicate facility acceptable naive user effective improve understanding,explanation probabilistic inference decision support system automate explanation facility bayesian conditioning aim improve user acceptance probabilitybase decision support system develop domainindependent facility base information processing perspective reasoning conditional evidence account biased normative inference experimental result indicate facility acceptable naive user effective improve understanding,0.5945945945945946,0.1891891891891892,0.21621621621621623,0.0,37.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Quantitative,Knowledge management in banking: A bibliometric literature review,"<jats:p>This bibliometric study examines publication trends, influential works, authorship networks, conceptual themes, and future directions in knowledge management research within the banking sector over the past three decades. Data were collected from a total of 443 scholarly publications written in English and indexed in Scopus. The data collection period spanned from 1994 to 2023. Quantitative bibliometric analysis techniques were employed, which involved the use of temporal visualization to examine publication and citation patterns, mapping co-authorship networks, and clustering high-frequency keywords. The results suggest a consistent rise in research interest and output as time progresses. Influential publications have proposed various models and frameworks for knowledge management, risk analysis, and organizational change. The majority of prolific authors were primarily of European descent, and it is worth noting that the Journal of Knowledge Management held the position as the most influential publication venue. The core research focus encompassed various areas such as knowledge for competitive advantage, intellectual capital measurement, knowledge-performance links, customer relationship management, and knowledge management technologies. The research has evolved to encompass digital transformation, sustainability, automation, and analytics. Proposed future directions include an examination of the role of knowledge management in ensuring continuity during crises, the facilitation of risk management through knowledge systems, and the development of decision support based on knowledge. This study offers valuable insights into the development of knowledge management research in the banking sector, although it is limited to English sources in Scopus.
Acknowledgment Expressing gratitude towards those who have contributed to the successful completion of a study has significant importance. In particular, it is crucial to extend appreciation to the individuals affiliated with the Ho Chi Minh University of Banking for their valuable support and assistance during the research endeavor.</jats:p>",https://doi.org/10.21511/kpm.08(1).2024.01,CrossRef,knowledge management bank bibliometric literature review,jatspthis bibliometric study examine publication trend influential work authorship network conceptual theme future direction knowledge management research within banking sector past three decade datum collect total scholarly publication write english index scopus data collection period span quantitative bibliometric analysis technique employ involve use temporal visualization examine publication citation pattern map coauthorship network clustering highfrequency keyword result suggest consistent rise research interest output time progress influential publication propose various model framework knowledge management risk analysis organizational change majority prolific author primarily european descent worth note journal knowledge management hold position influential publication venue core research focus encompass various area knowledge competitive advantage intellectual capital measurement knowledgeperformance link customer relationship management knowledge management technology research evolve encompass digital transformation sustainability automation analytic propose future direction include examination role knowledge management ensure continuity crisis facilitation risk management knowledge system development decision support base knowledge study offer valuable insight development knowledge management research banking sector although limit english source scopus acknowledgment express gratitude towards contribute successful completion study significant importance particular crucial extend appreciation individual affiliate chi minh university banking valuable support assistance research endeavorjatsp,knowledge management bank bibliometric literature review jatspthis bibliometric study examine publication trend influential work authorship network conceptual theme future direction knowledge management research within banking sector past three decade datum collect total scholarly publication write english index scopus data collection period span quantitative bibliometric analysis technique employ involve use temporal visualization examine publication citation pattern map coauthorship network clustering highfrequency keyword result suggest consistent rise research interest output time progress influential publication propose various model framework knowledge management risk analysis organizational change majority prolific author primarily european descent worth note journal knowledge management hold position influential publication venue core research focus encompass various area knowledge competitive advantage intellectual capital measurement knowledgeperformance link customer relationship management knowledge management technology research evolve encompass digital transformation sustainability automation analytic propose future direction include examination role knowledge management ensure continuity crisis facilitation risk management knowledge system development decision support base knowledge study offer valuable insight development knowledge management research banking sector although limit english source scopus acknowledgment express gratitude towards contribute successful completion study significant importance particular crucial extend appreciation individual affiliate chi minh university banking valuable support assistance research endeavorjatsp,0.6464088397790055,0.09392265193370165,0.15469613259668508,0.0055248618784530384,181.0,0.0,0.0,1.0,0.0
Information Systems,Knowledge Management,Quantitative,Knowledge‐enabled customer relationship management: integrating customer relationship management and knowledge management concepts[1],"<jats:p>The concepts of customer relationship management (CRM) and knowledge management (KM) both focus on allocating resources to supportive business activities in order to gain competitive advantages. CRM focuses on managing the relationship between a company and its current and prospective customer base as a key to success, while KM recognizes the knowledge available to a company as a major success factor. From a business process manager’s perspective both the CRM and KM approaches promise a positive impact on cost structures and revenue streams in return for the allocation of resources. However, investments in CRM and KM projects are not without risk, as demonstrated by many failed projects. In this paper we show that the benefit of using CRM and KM can be enhanced and the risk of failure reduced by integrating both approaches into a customer knowledge management (CKM) model. In this regard, managing relationships requires managing customer knowledge – knowledge about as well as from and for customers. In CKM, KM plays the role of a service provider, managing the four knowledge aspects: content, competence, collaboration and composition. Our findings are based on a literature analysis and six years of action research, supplemented by case studies and surveys.</jats:p>",https://doi.org/10.1108/13673270310505421,CrossRef,customer relationship management integrate customer relationship management knowledge management concept,jatspthe concept customer relationship management crm knowledge management focus allocate resource supportive business activity order gain competitive advantage crm focus manage relationship company current prospective customer base key success recognize knowledge available company major success factor business process manager perspective crm approach promise positive impact cost structure revenue stream return allocation resource however investment crm project without risk demonstrate many fail project paper show benefit use crm enhance risk failure reduce integrate approach customer knowledge management ckm model regard manage relationship require manage customer knowledge knowledge well customer ckm play role service provider manage four knowledge aspect content competence collaboration composition finding base literature analysis six year action research supplement case study surveysjatsp,customer relationship management integrate customer relationship management knowledge management concept jatspthe concept customer relationship management crm knowledge management focus allocate resource supportive business activity order gain competitive advantage crm focus manage relationship company current prospective customer base key success recognize knowledge available company major success factor business process manager perspective crm approach promise positive impact cost structure revenue stream return allocation resource however investment crm project without risk demonstrate many fail project paper show benefit use crm enhance risk failure reduce integrate approach customer knowledge management ckm model regard manage relationship require manage customer knowledge knowledge well customer ckm play role service provider manage four knowledge aspect content competence collaboration composition finding base literature analysis six year action research supplement case study surveysjatsp,0.6902654867256637,0.11504424778761062,0.09734513274336283,0.017699115044247787,113.0,0.0,0.0,1.0,0.0
Information Systems,Knowledge Management,Quantitative,Integrating knowledge management with smart technologies in public pharmaceutical organizations,"<jats:p>This study investigates the impact of Knowledge Management (KM) practices, enhanced by smart technologies, on organizational performance within public pharmaceutical organizations in Cairo Governorate, Egypt. Using a descriptive-analytical approach, the study targeted employees from five public pharmaceutical companies in Cairo Governorate, including Memphis Pharmaceuticals, Arab Pharmaceuticals, Cairo Pharmaceuticals, Nile Pharmaceuticals, and EIPICO. These companies were selected based on their public listing and accessible workforce data. Respondents included administrative and technical staff, ensuring a representative sample of the sector. The sample size of 372 was calculated using a 95% confidence level and a 5% margin of error, proportionally distributed across organizations and roles. The results of the study reveal that KM practices significantly enhance operational efficiency and foster innovation, with quantitative evidence showing that KM positively influences operational efficiency (β = 0.42, p &amp;amp;lt; 0.01) and innovation (β = 0.35, p &amp;amp;lt; 0.05). The analysis also indicates that strategic leadership plays a moderating role in the relationship between KM practices and organizational performance. Specifically, the moderation effect of leadership strengthens the impact of KM on operational efficiency (interaction term: β = 0.18, p &amp;amp;lt; 0.05) and innovation (interaction term: β = 0.21, p &amp;amp;lt; 0.05). These findings underscore the critical role of leadership in aligning KM practices with strategic goals, highlighting the potential for public pharmaceutical organizations to achieve higher efficiency and innovation. Organizations operating in highly regulated sectors can drive continuous improvement and achieve sustainable performance outcomes by integrating KM frameworks with advanced technologies and strategic leadership.
Acknowledgment  The authors are thankful to the Deanship of Graduate Studies and Scientific Research at the University of Bisha for supporting this work through the Fast-Track Research Support Program.</jats:p>",https://doi.org/10.21511/kpm.09(1).2025.03,CrossRef,integrate knowledge management smart technology public pharmaceutical organization,jatspthis study investigate impact knowledge management practice enhance smart technology organizational performance within public pharmaceutical organization cairo governorate egypt use descriptiveanalytical approach study target employee five public pharmaceutical company cairo governorate include memphis pharmaceutical arab pharmaceutical cairo pharmaceuticals nile pharmaceuticals eipico company select base public listing accessible workforce datum respondent include administrative technical staff ensure representative sample sector sample size calculate use confidence level margin error proportionally distribute across organization role result study reveal practice significantly enhance operational efficiency foster innovation quantitative evidence show positively influence operational efficiency ampamplt innovation ampamplt analysis also indicate strategic leadership play moderate role relationship practice organizational performance specifically moderation effect leadership strengthen impact operational efficiency interaction term ampamplt innovation interaction term ampamplt finding underscore critical role leadership align practice strategic goal highlight potential public pharmaceutical organization achieve high efficiency innovation organization operate highly regulate sector drive continuous improvement achieve sustainable performance outcome integrate framework advanced technology strategic leadership acknowledgment author thankful deanship graduate study scientific research university bisha support work fasttrack research support programjatsp,integrate knowledge management smart technology public pharmaceutical organization jatspthis study investigate impact knowledge management practice enhance smart technology organizational performance within public pharmaceutical organization cairo governorate egypt use descriptiveanalytical approach study target employee five public pharmaceutical company cairo governorate include memphis pharmaceutical arab pharmaceutical cairo pharmaceuticals nile pharmaceuticals eipico company select base public listing accessible workforce datum respondent include administrative technical staff ensure representative sample sector sample size calculate use confidence level margin error proportionally distribute across organization role result study reveal practice significantly enhance operational efficiency foster innovation quantitative evidence show positively influence operational efficiency ampamplt innovation ampamplt analysis also indicate strategic leadership play moderate role relationship practice organizational performance specifically moderation effect leadership strengthen impact operational efficiency interaction term ampamplt innovation interaction term ampamplt finding underscore critical role leadership align practice strategic goal highlight potential public pharmaceutical organization achieve high efficiency innovation organization operate highly regulate sector drive continuous improvement achieve sustainable performance outcome integrate framework advanced technology strategic leadership acknowledgment author thankful deanship graduate study scientific research university bisha support work fasttrack research support programjatsp,0.5,0.13529411764705881,0.21176470588235294,0.03529411764705882,170.0,0.0,4.0,0.0,0.0
Information Systems,Knowledge Management,Quantitative,Relationship between transformational leadership and knowledge management: The moderating effect of organizational culture,"<jats:p>In the context of Peruvian public universities, knowledge management is a key tool for academic advancement and social progress. This study investigates how transformational leadership impacts knowledge management, with a special focus on the moderating effect of organizational culture. Data were collected from 370 managerial staff members, both teaching and administrative, across various public universities in Peru, through online surveys. The methodology employed was the analysis of regression models with interaction terms. The results demonstrate that transformational leadership has a significant positive effect on knowledge management (β = 0.7092; p &amp;lt; 0.01), especially highlighting the influence of charisma (β = 0.5315; p &amp;lt; 0.01). Organizational culture proved to be a significant moderator in this relationship. This was reflected in the significance of the interaction terms between the dimensions of organizational culture and transformational leadership. Participation has a moderating effect (β = 0.4507; p &amp;lt; 0.01), consistency is a significant moderator (β = 0.5356; p &amp;lt; 0.01), adaptability has a moderating influence in the relationship between leadership and knowledge management (β = 0.4890; p &amp;lt; 0.01), as does mission (β = 0.3846; p &amp;lt; 0.01). This suggests that in contexts where organizational culture is robust and focused on learning and collaboration, transformational leadership effectively enhances knowledge management. These results provide a deeper understanding of the role of transformational leadership and organizational culture in knowledge management practices in the academic field, offering valuable insights for future research and administrative practices in the educational sector.</jats:p>",https://doi.org/10.21511/kpm.07(1).2023.11,CrossRef,relationship transformational leadership knowledge management moderate effect organizational culture,jatspin context peruvian public university knowledge management key tool academic advancement social progress study investigate transformational leadership impact knowledge management special focus moderate effect organizational culture datum collect managerial staff member teaching administrative across various public university peru online survey methodology employ analysis regression model interaction term result demonstrate transformational leadership significant positive effect knowledge management amplt especially highlight influence charisma amplt organizational culture prove significant moderator relationship reflect significance interaction term dimension organizational culture transformational leadership participation moderate effect amplt consistency significant moderator amplt adaptability moderate influence relationship leadership knowledge management amplt mission amplt suggest contexts organizational culture robust focus learn collaboration transformational leadership effectively enhance knowledge management result provide deep understanding role transformational leadership organizational culture knowledge management practice academic field offer valuable insight future research administrative practice educational sectorjatsp,relationship transformational leadership knowledge management moderate effect organizational culture jatspin context peruvian public university knowledge management key tool academic advancement social progress study investigate transformational leadership impact knowledge management special focus moderate effect organizational culture datum collect managerial staff member teaching administrative across various public university peru online survey methodology employ analysis regression model interaction term result demonstrate transformational leadership significant positive effect knowledge management amplt especially highlight influence charisma amplt organizational culture prove significant moderator relationship reflect significance interaction term dimension organizational culture transformational leadership participation moderate effect amplt consistency significant moderator amplt adaptability moderate influence relationship leadership knowledge management amplt mission amplt suggest contexts organizational culture robust focus learn collaboration transformational leadership effectively enhance knowledge management result provide deep understanding role transformational leadership organizational culture knowledge management practice academic field offer valuable insight future research administrative practice educational sectorjatsp,0.553030303030303,0.09848484848484848,0.24242424242424243,0.015151515151515152,132.0,0.0,0.0,0.0,1.0
Information Systems,Knowledge Management,Quantitative,"Does knowledge management really matter? Linking knowledge management practices, competitiveness and economic performance","<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p><jats:italic>While nowadays an extensive literature promoting knowledge management (KM) exists, there is a worrying shortage of empirical studies demonstrating an actual connection between KM activities and organizational outcomes. To bridge this gap, this paper aims to examine the link between KM practices, firm competitiveness and economic performance.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p><jats:italic>This paper proposes a framework of KM practices consisting of human resource management (HRM) and information communication technology (ICT). These both are hypothesized to impact competitiveness and economic performance of the firm. Hypotheses are then tested with structural equation modeling by using a survey dataset of 234 companies.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p><jats:italic>The results show that HRM and ICT practices for managing knowledge are quite strongly correlated and have a statistically significant influence on both financial performance and competitiveness of the firm. The findings also indicate that ICT practices improve financial performance only when they are coupled with HRM practices.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p><jats:italic>The data are limited to companies from Finland, Russia and China.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p><jats:italic>The paper contributes to managerial practice by pointing out the importance of utilizing a combination of both social and technical means for KM and illustrating that they do matter for the company bottom line.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p><jats:italic>This paper contributes to the literature on knowledge‐based organizing by empirically analyzing the performance impact of various areas of KM. It thereby tests the proposition put forth in many previous theoretical and case‐based studies that KM promotes high organizational performance. It also addresses the interaction of social and technical KM practices in producing organizational outcomes.</jats:italic></jats:p></jats:sec>",https://doi.org/10.1108/13673271211246185,CrossRef,knowledge management really matter link knowledge management practice competitiveness economic performance,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspjatsitalicwhile nowadays extensive literature promote knowledge management exist worrying shortage empirical study demonstrate actual connection activity organizational outcome bridge gap paper aim examine link practice firm competitiveness economic performancejatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspjatsitalicthis paper propose framework practice consist human resource management hrm information communication technology ict hypothesize impact competitiveness economic performance firm hypothesis test structural equation modeling use survey dataset companiesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspjatsitalicthe result show hrm ict practice manage knowledge quite strongly correlate statistically significant influence financial performance competitiveness firm finding also indicate ict practice improve financial performance couple hrm practicesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspjatsitalicthe datum limit company finland russia chinajatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspjatsitalicthe paper contribute managerial practice point importance utilize combination social technical mean illustrate matter company bottom linejatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspjatsitalicthis paper contribute literature organize empirically analyze performance impact various area thereby test proposition put forth many previous theoretical study promote high organizational performance also address interaction social technical practice produce organizational outcomesjatsitalicjatspjatssec,knowledge management really matter link knowledge management practice competitiveness economic performance jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspjatsitalicwhile nowadays extensive literature promote knowledge management exist worrying shortage empirical study demonstrate actual connection activity organizational outcome bridge gap paper aim examine link practice firm competitiveness economic performancejatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspjatsitalicthis paper propose framework practice consist human resource management hrm information communication technology ict hypothesize impact competitiveness economic performance firm hypothesis test structural equation modeling use survey dataset companiesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspjatsitalicthe result show hrm ict practice manage knowledge quite strongly correlate statistically significant influence financial performance competitiveness firm finding also indicate ict practice improve financial performance couple hrm practicesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspjatsitalicthe datum limit company finland russia chinajatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspjatsitalicthe paper contribute managerial practice point importance utilize combination social technical mean illustrate matter company bottom linejatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspjatsitalicthis paper contribute literature organize empirically analyze performance impact various area thereby test proposition put forth many previous theoretical study promote high organizational performance also address interaction social technical practice produce organizational outcomesjatsitalicjatspjatssec,0.4965986394557823,0.1564625850340136,0.1564625850340136,0.05442176870748299,73.5,0.0,1.0,0.0,0.0
Information Systems,Knowledge Management,Qualitative,An Introduction to Knowledge Management,"Knowledge has been lately recognized as one of the most important assets of
organizations. Managing knowledge has grown to be imperative for the success of
a company. This paper presents an overview of Knowledge Management and various
aspects of secure knowledge management. A case study of knowledge management
activities at Tata Steel is also discussed",http://arxiv.org/abs/0812.0438v1,arXiv,introduction knowledge management,knowledge lately recognize one important asset organization manage knowledge grow imperative success company paper present overview knowledge management various aspect secure knowledge management case study knowledge management activity tata steel also discuss,introduction knowledge management knowledge lately recognize one important asset organization manage knowledge grow imperative success company paper present overview knowledge management various aspect secure knowledge management case study knowledge management activity tata steel also discuss,0.59375,0.1875,0.125,0.0625,32.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Qualitative,"Pitfalls in Effective Knowledge Management: Insights from an
  International Information Technology Organization","Knowledge is considered an essential resource for organizations. For
organizations to benefit from their possessed knowledge, knowledge needs to be
managed effectively. Despite knowledge sharing and management being viewed as
important by practitioners, organizations fail to benefit from their knowledge,
leading to issues in cooperation and the loss of valuable knowledge with
departing employees. This study aims to identify hindering factors that prevent
individuals from effectively sharing and managing knowledge and understand how
to eliminate these factors. Empirical data were collected through
semi-structured group interviews from 50 individuals working in an
international large IT organization. This study confirms the existence of a gap
between the perceived importance of knowledge management and how little this
importance is reflected in practice. Several hindering factors were identified,
grouped into personal social topics, organizational social topics, technical
topics, environmental topics, and interrelated social and technical topics. The
presented recommendations for mitigating these hindering factors are focused on
improving employees' actions, such as offering training and guidelines to
follow. The findings of this study have implications for organizations in
knowledge-intensive fields, as they can use this knowledge to create knowledge
sharing and management strategies to improve their overall performance.",http://arxiv.org/abs/2304.07737v3,arXiv,pitfall effective knowledge management insight international information technology organization,knowledge consider essential resource organization organization benefit possess knowledge knowledge need manage effectively despite knowledge sharing management view important practitioner organization fail benefit knowledge lead issue cooperation loss valuable knowledge depart employee study aim identify hinder factor prevent individual effectively share manage knowledge understand eliminate factor empirical datum collect semistructure group interview individual work international large organization study confirm existence gap perceive importance knowledge management little importance reflect practice several hindering factor identify group personal social topic organizational social topic technical topic environmental topic interrelated social technical topic present recommendation mitigate hindering factor focus improve employee action offer training guideline follow finding study implication organization knowledgeintensive field use knowledge create knowledge sharing management strategy improve overall performance,pitfall effective knowledge management insight international information technology organization knowledge consider essential resource organization organization benefit possess knowledge knowledge need manage effectively despite knowledge sharing management view important practitioner organization fail benefit knowledge lead issue cooperation loss valuable knowledge depart employee study aim identify hinder factor prevent individual effectively share manage knowledge understand eliminate factor empirical datum collect semistructure group interview individual work international large organization study confirm existence gap perceive importance knowledge management little importance reflect practice several hindering factor identify group personal social topic organizational social topic technical topic environmental topic interrelated social technical topic present recommendation mitigate hindering factor focus improve employee action offer training guideline follow finding study implication organization knowledgeintensive field use knowledge create knowledge sharing management strategy improve overall performance,0.5897435897435898,0.1794871794871795,0.1794871794871795,0.017094017094017096,117.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Qualitative,Knowledge Engineering Technique for Cluster Development,"After the concept of industry cluster was tangibly applied in many countries,
SMEs trended to link to each other to maintain their competitiveness in the
market. The major key success factors of the cluster are knowledge sharing and
collaboration between partners. This knowledge is collected in form of tacit
and explicit knowledge from experts and institutions within the cluster. The
objective of this study is about enhancing the industry cluster with knowledge
management by using knowledge engineering which is one of the most important
method for managing knowledge. This work analyzed three well known knowledge
engineering methods, i.e. MOKA, SPEDE and CommonKADS, and compares the
capability to be implemented in the cluster context. Then, we selected one
method and proposed the adapted methodology. At the end of this paper, we
validated and demonstrated the proposed methodology with some primary result by
using case study of handicraft cluster in Thailand.",http://arxiv.org/abs/0712.1994v1,arXiv,knowledge engineering technique cluster development,concept industry cluster tangibly apply many country sme trend link maintain competitiveness market major key success factor cluster knowledge sharing collaboration partner knowledge collect form tacit explicit knowledge expert institution within cluster objective study enhance industry cluster knowledge management use knowledge engineering one important method manage knowledge work analyze three well know knowledge engineering method moka spede commonkad compare capability implement cluster context select one method propose adapt methodology end paper validate demonstrate propose methodology primary result use case study handicraft cluster thailand,knowledge engineering technique cluster development concept industry cluster tangibly apply many country sme trend link maintain competitiveness market major key success factor cluster knowledge sharing collaboration partner knowledge collect form tacit explicit knowledge expert institution within cluster objective study enhance industry cluster knowledge management use knowledge engineering one important method manage knowledge work analyze three well know knowledge engineering method moka spede commonkad compare capability implement cluster context select one method propose adapt methodology end paper validate demonstrate propose methodology primary result use case study handicraft cluster thailand,0.6144578313253012,0.10843373493975904,0.12048192771084337,0.024096385542168676,83.0,0.0,0.0,0.0,1.0
Information Systems,Knowledge Management,Qualitative,An Ontology-based Knowledge Management System for Industry Clusters,"Knowledge-based economy forces companies in the nation to group together as a
cluster in order to maintain their competitiveness in the world market. The
cluster development relies on two key success factors which are knowledge
sharing and collaboration between the actors in the cluster. Thus, our study
tries to propose knowledge management system to support knowledge management
activities within the cluster. To achieve the objectives of this study,
ontology takes a very important role in knowledge management process in various
ways; such as building reusable and faster knowledge-bases, better way for
representing the knowledge explicitly. However, creating and representing
ontology create difficulties to organization due to the ambiguity and
unstructured of source of knowledge. Therefore, the objectives of this paper
are to propose the methodology to create and represent ontology for the
organization development by using knowledge engineering approach. The
handicraft cluster in Thailand is used as a case study to illustrate our
proposed methodology.",http://arxiv.org/abs/0806.0526v1,arXiv,ontologybase knowledge management system industry cluster,knowledgebase economy force company nation group together cluster order maintain competitiveness world market cluster development rely two key success factor knowledge sharing collaboration actor cluster thus study try propose knowledge management system support knowledge management activity within cluster achieve objective study ontology take important role knowledge management process various way build reusable fast knowledgebase well way represent knowledge explicitly however create represent ontology create difficulty organization due ambiguity unstructured source knowledge therefore objective paper propose methodology create represent ontology organization development use knowledge engineering approach handicraft cluster thailand use case study illustrate propose methodology,ontologybase knowledge management system industry cluster knowledgebase economy force company nation group together cluster order maintain competitiveness world market cluster development rely two key success factor knowledge sharing collaboration actor cluster thus study try propose knowledge management system support knowledge management activity within cluster achieve objective study ontology take important role knowledge management process various way build reusable fast knowledgebase well way represent knowledge explicitly however create represent ontology create difficulty organization due ambiguity unstructured source knowledge therefore objective paper propose methodology create represent ontology organization development use knowledge engineering approach handicraft cluster thailand use case study illustrate propose methodology,0.6170212765957447,0.13829787234042554,0.1276595744680851,0.05319148936170213,94.0,1.0,0.0,0.0,1.0
Information Systems,Knowledge Management,Qualitative,Knowledge Management in the Companion Cognitive Architecture,"One of the fundamental aspects of cognitive architectures is their ability to
encode and manipulate knowledge. Without a consistent, well-designed, and
scalable knowledge management scheme, an architecture will be unable to move
past toy problems and tackle the broader problems of cognition. In this paper,
we document some of the challenges we have faced in developing the knowledge
stack for the Companion cognitive architecture and discuss the tools,
representations, and practices we have developed to overcome them. We also lay
out a series of potential next steps that will allow Companion agents to play a
greater role in managing their own knowledge. It is our hope that these
observations will prove useful to other cognitive architecture developers
facing similar challenges.",http://arxiv.org/abs/2407.06401v1,arXiv,knowledge management companion cognitive architecture,one fundamental aspect cognitive architecture ability encode manipulate knowledge without consistent welldesigned scalable knowledge management scheme architecture unable move past toy problem tackle broad problem cognition paper document challenge face develop knowledge stack companion cognitive architecture discuss tool representation practice develop overcome also lay series potential next step allow companion agent play great role manage knowledge hope observation prove useful cognitive architecture developer face similar challenge,knowledge management companion cognitive architecture one fundamental aspect cognitive architecture ability encode manipulate knowledge without consistent welldesigned scalable knowledge management scheme architecture unable move past toy problem tackle broad problem cognition paper document challenge face develop knowledge stack companion cognitive architecture discuss tool representation practice develop overcome also lay series potential next step allow companion agent play great role manage knowledge hope observation prove useful cognitive architecture developer face similar challenge,0.5454545454545454,0.16666666666666666,0.22727272727272727,0.015151515151515152,66.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Mixed Methods,"Impact of knowledge management, knowledge sharing, and mental accounting on farmer performance in Sasi culture in Maluku Islands, Indonesia","<jats:p>The welfare of farmers and agricultural productivity are significantly influenced by challenges in business and financial management. This study investigates how knowledge management, knowledge sharing, and mental accounting impact farmer performance within the unique context of Sasi culture in Maluku Islands, Indonesia. Knowledge management provides farmers with the tools to acquire, utilize, and apply agricultural insights, while mental accounting shapes their financial decision-making and resource allocation. Using a mixed-method approach that combines WarpPLS and ethnomethodology, data were gathered through questionnaires distributed to 65 respondents and in-depth interviews with selected participants. The analysis revealed that knowledge management significantly impacts farmer performance with a path coefficient of 0.717 (p &amp;lt; 0.001), while mental accounting also has a positive effect with a coefficient of 0.164 (p = 0.050). However, knowledge sharing did not significantly affect performance (coefficient = 0.372, p = 0.382). The results suggest that Sasi culture, deeply rooted in local wisdom, helps integrate knowledge management and mental accounting to improve farmer welfare and agricultural income. Despite the ineffectiveness of formal knowledge sharing, the cultural practice of Sasi inherently promotes the sharing of knowledge within the community, enhancing the overall management of agricultural practices. This study emphasizes the role of local wisdom in creating sustainable agricultural practices and highlights the potential of Sasi culture to synergize modern knowledge management with traditional financial behaviors.</jats:p>",https://doi.org/10.21511/kpm.09(1).2025.05,CrossRef,impact knowledge management knowledge sharing mental accounting farmer performance sasi culture maluku island indonesia,jatspthe welfare farmer agricultural productivity significantly influence challenge business financial management study investigate knowledge management knowledge sharing mental accounting impact farmer performance within unique context sasi culture maluku island indonesia knowledge management provide farmer tool acquire utilize apply agricultural insight mental accounting shape financial decisionmaking resource allocation use mixedmethod approach combine warppls ethnomethodology datum gather questionnaire distribute respondent indepth interview select participant analysis reveal knowledge management significantly impact farmer performance path coefficient amplt mental accounting also positive effect coefficient however knowledge sharing significantly affect performance coefficient result suggest sasi culture deeply root local wisdom help integrate knowledge management mental accounting improve farmer welfare agricultural income despite ineffectiveness formal knowledge share cultural practice sasi inherently promote sharing knowledge within community enhance overall management agricultural practice study emphasize role local wisdom create sustainable agricultural practice highlight potential sasi culture synergize modern knowledge management traditional financial behaviorsjatsp,impact knowledge management knowledge sharing mental accounting farmer performance sasi culture maluku island indonesia jatspthe welfare farmer agricultural productivity significantly influence challenge business financial management study investigate knowledge management knowledge sharing mental accounting impact farmer performance within unique context sasi culture maluku island indonesia knowledge management provide farmer tool acquire utilize apply agricultural insight mental accounting shape financial decisionmaking resource allocation use mixedmethod approach combine warppls ethnomethodology datum gather questionnaire distribute respondent indepth interview select participant analysis reveal knowledge management significantly impact farmer performance path coefficient amplt mental accounting also positive effect coefficient however knowledge sharing significantly affect performance coefficient result suggest sasi culture deeply root local wisdom help integrate knowledge management mental accounting improve farmer welfare agricultural income despite ineffectiveness formal knowledge share cultural practice sasi inherently promote sharing knowledge within community enhance overall management agricultural practice study emphasize role local wisdom create sustainable agricultural practice highlight potential sasi culture synergize modern knowledge management traditional financial behaviorsjatsp,0.5416666666666666,0.13194444444444445,0.1875,0.04861111111111111,144.0,0.0,1.0,0.0,0.0
Information Systems,Knowledge Management,Mixed Methods,"Knowledge management, adaptability and business process reengineering performance in microfinance institutions","<jats:p>The purpose of this paper is to provide theoretical explanation of business process reengineering performance using emerging themes of adaptability and knowledge management in the context of developing economies. The study used a narrative cross-sectional survey conducted using qualitative data collection technique, specifically the appreciative inquiry. The study used operations managers and senior executive managers to gather qualitative data from Uganda’s reengineered microfinance institutions to provide indepth explanation of business process reengineering performance. The authors find that adaptability, knowledge creation and knowledge sharing explain business process reengineering performance. The results suggest that business process reengineering be made mandatory to ensure sustainable competitiveness of the financial sector. The study provides novel insights of business process reengineering performance using a theory of change and a complexity theory. Methodological, theoretical, managerial and policy implications herein play pivotal role in bridging the knowledge gap that exists in Microfinance institutions of developing economies.</jats:p>",https://doi.org/10.21511/kpm.02(1).2018.06,CrossRef,knowledge management adaptability business process reengineere performance microfinance institution,jatspthe purpose paper provide theoretical explanation business process reengineere performance use emerge theme adaptability knowledge management context develop economy study use narrative crosssectional survey conduct use qualitative data collection technique specifically appreciative inquiry study use operation manager senior executive manager gather qualitative datum uganda reengineere microfinance institution provide indepth explanation business process reengineere performance author find adaptability knowledge creation knowledge sharing explain business process reengineere performance result suggest business process reengineering make mandatory ensure sustainable competitiveness financial sector study provide novel insight business process reengineere performance use theory change complexity theory methodological theoretical managerial policy implication herein play pivotal role bridge knowledge gap exist microfinance institution develop economiesjatsp,knowledge management adaptability business process reengineere performance microfinance institution jatspthe purpose paper provide theoretical explanation business process reengineere performance use emerge theme adaptability knowledge management context develop economy study use narrative crosssectional survey conduct use qualitative data collection technique specifically appreciative inquiry study use operation manager senior executive manager gather qualitative datum uganda reengineere microfinance institution provide indepth explanation business process reengineere performance author find adaptability knowledge creation knowledge sharing explain business process reengineere performance result suggest business process reengineering make mandatory ensure sustainable competitiveness financial sector study provide novel insight business process reengineere performance use theory change complexity theory methodological theoretical managerial policy implication herein play pivotal role bridge knowledge gap exist microfinance institution develop economiesjatsp,0.6388888888888888,0.14814814814814814,0.1574074074074074,0.009259259259259259,108.0,0.0,1.0,0.0,0.0
Information Systems,Knowledge Management,Mixed Methods,Knowledge Management Implementation Strategy for Knowledge Management Systems in Two Mobile Telecommunication Companies Namibia,"<jats:p>Rationale of Study – This article presents the findings of a study on the knowledge management (KM) implementation strategy for two mobile telecommunications (MT) companies in Namibia.Methodology – The case study used a mixed-methods approach via convergent parallel design. This permitted the concurrent gathering of quantitative and qualitative data for the study. The study used simple random sampling via probability sampling to identify 309 respondents. An online survey distributed 329 questionnaires, and 200 were received with a 60.79% response rate. A purposive sampling technique was employed for the qualitative phase; 11 participants were interviewed out of the planned 20.Findings – The study found that neither KM implementation strategies nor a department or section dedicated to organisational KM exist, necessitating a KM implementation strategy for KMS for effective KM practices in two MT companies in Namibia. The study also identified potential barriers to KMS, such as the complexity of employee attitudes, the dearth of use of specific KMS, and the organisational KM corporate work culture.Implications – This study's findings could expand academicians', KM researchers', and organisations' understanding of the importance of organisational KM implementation strategy for KMS to be effective and efficient in MT companies in Namibia.Originality – This study is the first on KM implementation strategies for KMS to influence knowledge management practices in Namibia.</jats:p>",https://doi.org/10.70759/zm1kk411,CrossRef,knowledge management implementation strategy knowledge management system two mobile telecommunication company namibia,jatsprationale study article present finding study knowledge management implementation strategy two mobile telecommunication company namibiamethodology case study use mixedmethod approach via convergent parallel design permit concurrent gathering quantitative qualitative datum study study use simple random sampling via probability sampling identify respondent online survey distribute questionnaire receive response rate purposive sampling technique employ qualitative phase participant interview plan finding study find neither implementation strategy department section dedicate organisational exist necessitate implementation strategy kms effective practice two company namibia study also identify potential barrier kms complexity employee attitude dearth use specific kms organisational corporate work cultureimplication studys finding could expand academician researcher organisation understanding importance organisational implementation strategy kms effective efficient company namibiaoriginality study first implementation strategy kms influence knowledge management practice namibiajatsp,knowledge management implementation strategy knowledge management system two mobile telecommunication company namibia jatsprationale study article present finding study knowledge management implementation strategy two mobile telecommunication company namibiamethodology case study use mixedmethod approach via convergent parallel design permit concurrent gathering quantitative qualitative datum study study use simple random sampling via probability sampling identify respondent online survey distribute questionnaire receive response rate purposive sampling technique employ qualitative phase participant interview plan finding study find neither implementation strategy department section dedicate organisational exist necessitate implementation strategy kms effective practice two company namibia study also identify potential barrier kms complexity employee attitude dearth use specific kms organisational corporate work cultureimplication studys finding could expand academician researcher organisation understanding importance organisational implementation strategy kms effective efficient company namibiaoriginality study first implementation strategy kms influence knowledge management practice namibiajatsp,0.5289256198347108,0.10743801652892562,0.18181818181818182,0.008264462809917356,121.0,1.0,1.0,0.0,0.0
Information Systems,Knowledge Management,Mixed Methods,The role of knowledge management in institutional strategy development and competitiveness at leading African universities,"<jats:p>The role of knowledge management as a strategic intervention in higher education in developing economies has not been studied extensively. Higher education plays a central role in a country’s economy through knowledge creation and dissemination to its stakeholders. The main purpose of this article was to examine the role and influence of knowledge management in decision-making and strategy formulation at leading universities in Africa and to establish if knowledge management was adding value and competitiveness to the institutions. A survey across 20 leading African universities was conducted in 2014. A mixed method of quantitative and qualitative approaches was adopted. The results show that knowledge management does have the potential to positively influence institutional strategy formulation, but should ideally be represented at executive level for its potential to be fully realized. More knowledge management practice is needed in the areas of academic teaching and learning, and research. There was a lack of sophisticated and powerful knowledge management Information Systems in most of Africa’s leading institutions. Those institutions that utilized KM more strategically, inclusive of specialized KM Information Systems were the higher ranked institutions. This suggests that knowledge management could play a crucial role in a University’s success and competitiveness.</jats:p>",https://doi.org/10.21511/kpm.03(1).2019.03,CrossRef,role knowledge management institutional strategy development competitiveness lead african university,jatspthe role knowledge management strategic intervention high education develop economy study extensively high education play central role country economy knowledge creation dissemination stakeholder main purpose article examine role influence knowledge management decisionmake strategy formulation lead university africa establish knowledge management add value competitiveness institution survey across lead african university conduct mixed method quantitative qualitative approach adopt result show knowledge management potential positively influence institutional strategy formulation ideally represent executive level potential fully realize knowledge management practice need area academic teaching learning research lack sophisticated powerful knowledge management information system africa lead institution institution utilize strategically inclusive specialized information system high rank institution suggest knowledge management could play crucial role university success competitivenessjatsp,role knowledge management institutional strategy development competitiveness lead african university jatspthe role knowledge management strategic intervention high education develop economy study extensively high education play central role country economy knowledge creation dissemination stakeholder main purpose article examine role influence knowledge management decisionmake strategy formulation lead university africa establish knowledge management add value competitiveness institution survey across lead african university conduct mixed method quantitative qualitative approach adopt result show knowledge management potential positively influence institutional strategy formulation ideally represent executive level potential fully realize knowledge management practice need area academic teaching learning research lack sophisticated powerful knowledge management information system africa lead institution institution utilize strategically inclusive specialized information system high rank institution suggest knowledge management could play crucial role university success competitivenessjatsp,0.5803571428571429,0.13392857142857142,0.14285714285714285,0.044642857142857144,112.0,2.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Mixed Methods,Strategic analysis of knowledge firms: the links between knowledge management and leadership,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p><jats:italic>The purpose of this paper is to explore and explain the links between knowledge management (KM) and leadership in knowledge‐intensive firms.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p><jats:italic>This study employs an instrumental case‐based study on four knowledge‐based firms to explore KM and leadership approaches, and the links between them. Data were primarily collected through qualitative interviews with firm managers and direct observations, as well as quantitative data by questionnaire from the firm employees.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p><jats:italic>The study identified two combinations of KM and leadership systems. These combinations are personalization‐distribution and codification‐centralization; which are explained within the theoretical framework of this paper. Other theoretically possible combinations were discussed and argued to be non‐viable or non‐economical.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p><jats:italic>As with most qualitative case‐based research papers, this research was focused on study of a small number of cases; a limitation that does not allow the authors to claim a statistical generalization but nevertheless allows analytical generalization to be made. Limitations of this paper include the fact that all cases were located in one country and all were more or less involved with the field of information technology.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p><jats:italic>Practical implications of this paper for managers and company strategists involve alignment of their KM strategy with a relevant leadership system.</jats:italic></jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p><jats:italic>There has been little research aimed at finding links between KM and leadership in firms, and how this link may lead to increased knowledge exploitation capability for the firm. The present study addresses this issue and presents an evidenced and theoretically supported explanation for this link.</jats:italic></jats:p></jats:sec>",https://doi.org/10.1108/13673271311300697,CrossRef,strategic analysis knowledge firm link knowledge management leadership,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspjatsitalicthe purpose paper explore explain link knowledge management leadership firmsjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspjatsitalicthis study employ instrumental study four firm explore leadership approach link datum primarily collect qualitative interview firm manager direct observation well quantitative datum questionnaire firm employeesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspjatsitalicthe study identify two combination leadership system combination explain within theoretical framework paper theoretically possible combination discuss argue contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspjatsitalicas qualitative research paper research focus study small number case limitation allow author claim statistical generalization nevertheless allow analytical generalization make limitation paper include fact case locate one country less involve field information technologyjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspjatsitalicpractical implication paper manager company strategist involve alignment strategy relevant leadership systemjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspjatsitalicthere little research aim find link leadership firm link may lead increase knowledge exploitation capability firm present study address issue present evidence theoretically support explanation linkjatsitalicjatspjatssec,strategic analysis knowledge firm link knowledge management leadership jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspjatsitalicthe purpose paper explore explain link knowledge management leadership firmsjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspjatsitalicthis study employ instrumental study four firm explore leadership approach link datum primarily collect qualitative interview firm manager direct observation well quantitative datum questionnaire firm employeesjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspjatsitalicthe study identify two combination leadership system combination explain within theoretical framework paper theoretically possible combination discuss argue contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspjatsitalicas qualitative research paper research focus study small number case limitation allow author claim statistical generalization nevertheless allow analytical generalization make limitation paper include fact case locate one country less involve field information technologyjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspjatsitalicpractical implication paper manager company strategist involve alignment strategy relevant leadership systemjatsitalicjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspjatsitalicthere little research aim find link leadership firm link may lead increase knowledge exploitation capability firm present study address issue present evidence theoretically support explanation linkjatsitalicjatspjatssec,0.5658914728682171,0.14728682170542637,0.12403100775193798,0.03875968992248062,129.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Design and Development,Knowledge Management,"This paper discusses the important process of knowledge and its management,
and differences between tacit and explicit knowledge and understanding the
culture as a key issue for the successful implementation of knowledge
management, in addition to, this paper is concerned with the four-stage model
for the evolution of information technology (IT) support for knowledge
management in law firms.",http://arxiv.org/abs/1003.1807v1,arXiv,knowledge management,paper discuss important process knowledge management difference tacit explicit knowledge understand culture key issue successful implementation knowledge management addition paper concern fourstage model evolution information technology support knowledge management law firm,knowledge management paper discuss important process knowledge management difference tacit explicit knowledge understand culture key issue successful implementation knowledge management addition paper concern fourstage model evolution information technology support knowledge management law firm,0.8064516129032258,0.06451612903225806,0.12903225806451613,0.0,31.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Design and Development,Review of Knowledge Management Systems As Socio-Technical System,"Knowledge Management Systems as socio-technical systemperspectives has
recognized for decades. Practitioners and scholars belief Knowledge Management
is best carried out throught the optimization both technological and
social-aspect.Lacking of understand and consider both aspects could lead
organizations in misinterpretation while developing andimplementing Knowledge
Management System. There is a need for practical guidance how Knowledge
Management System should implement in organizations. We propose a framework
that could use by practitioner and manager as guidance in developing and
implementing Knowledge Management System as Socio-Technical Systems. The
framework developed base on Pan and Scarborough view of Knowledge Management as
Socio-Technical system. Our framework consists of: Infrastructure(technology),
Info structure (organizational structure) and Info culture (organizational
culture). This concept would lead practitioners get clear understand aspect
contribute to Knowledge Management System success as Socio-Technical System.",http://arxiv.org/abs/1212.0387v1,arXiv,review knowledge management system sociotechnical system,knowledge management system sociotechnical systemperspective recognize decade practitioner scholar belief knowledge management well carry throught optimization technological socialaspectlacking understand consider aspect could lead organization misinterpretation develop andimplemente knowledge management system need practical guidance knowledge management system implement organization propose framework could use practitioner manager guidance develop implement knowledge management system sociotechnical system framework develop base pan scarborough view knowledge management sociotechnical system framework consist infrastructuretechnology info structure organizational structure info culture organizational culture concept would lead practitioner get clear understand aspect contribute knowledge management system success sociotechnical system,review knowledge management system sociotechnical system knowledge management system sociotechnical systemperspective recognize decade practitioner scholar belief knowledge management well carry throught optimization technological socialaspectlacking understand consider aspect could lead organization misinterpretation develop andimplemente knowledge management system need practical guidance knowledge management system implement organization propose framework could use practitioner manager guidance develop implement knowledge management system sociotechnical system framework develop base pan scarborough view knowledge management sociotechnical system framework consist infrastructuretechnology info structure organizational structure info culture organizational culture concept would lead practitioner get clear understand aspect contribute knowledge management system success sociotechnical system,0.5909090909090909,0.17045454545454544,0.1590909090909091,0.011363636363636364,88.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Design and Development,On the Convergence of Collaboration and Knowledge Management,"Collaboration technology typically focuses on collaboration and group
processes (cooperation, communication, coordination and coproduction).
Knowledge Management (KM) technology typically focuses on content (creation,
storage, sharing and use of data, information and knowledge). Yet, to achieve
their common goals, teams and organizations need both KM and collaboration
technology to make that more effective and efficient. This paper is interested
in knowledge management and collaboration regarding their convergence and their
integration. First, it contributes to a better understanding of the knowledge
management and collaboration concepts. Second, it focuses on KM and
collaboration convergence by presenting the different interpretation of this
convergence. Third, this paper proposes a generic framework of collaborative
knowledge management.",http://arxiv.org/abs/1202.6104v1,arXiv,convergence collaboration knowledge management,collaboration technology typically focus collaboration group process cooperation communication coordination coproduction knowledge management technology typically focus content creation storage sharing use datum information knowledge yet achieve common goal team organization need collaboration technology make effective efficient paper interested knowledge management collaboration regard convergence integration first contribute well understanding knowledge management collaboration concept second focus collaboration convergence present different interpretation convergence third paper propose generic framework collaborative knowledge management,convergence collaboration knowledge management collaboration technology typically focus collaboration group process cooperation communication coordination coproduction knowledge management technology typically focus content creation storage sharing use datum information knowledge yet achieve common goal team organization need collaboration technology make effective efficient paper interested knowledge management collaboration regard convergence integration first contribute well understanding knowledge management collaboration concept second focus collaboration convergence present different interpretation convergence third paper propose generic framework collaborative knowledge management,0.6617647058823529,0.1323529411764706,0.11764705882352941,0.07352941176470588,68.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Design and Development,"Penerapan Knowledge Management System Sales and Customer Care pada PT
  Satria Medikantara Palembang","PT Satria Medikantara Palembang has a great desire to apply knowledge
management system, therefore the documentation of knowledge and its utilization
needs to be well managed in the context of performance improvement. The
implementation of knowledge management in PT Satria Medikantara Palembang is
considered very good and can have a positive impact for the quality of
employees. Where every employee can store and document and share knowledge
owned, so that other employees can access, even learn and discuss with other
employees based on the knowledge posted. Then when needed a knowledge, it is
very easy to find in the database searching feature in the web based knowledge
management system at PT Satria Medikantara Palembang. The methodology used in
this study refers to the methodology of knowledge management system life cycle
developed by Awad and Ghaziri (2010), and this system will be based on web
using PHP programming language.",http://arxiv.org/abs/1911.01277v1,arXiv,penerapan knowledge management system sale customer care pada satria medikantara palembang,satria medikantara palembang great desire apply knowledge management system therefore documentation knowledge utilization need well manage context performance improvement implementation knowledge management satria medikantara palembang consider good positive impact quality employee every employee store document share knowledge employee access even learn discuss employee base knowledge post need knowledge easy find database search feature web base knowledge management system satria medikantara palembang methodology use study refer methodology knowledge management system life cycle develop awad ghaziri system base web use php programming language,penerapan knowledge management system sale customer care pada satria medikantara palembang satria medikantara palembang great desire apply knowledge management system therefore documentation knowledge utilization need well manage context performance improvement implementation knowledge management satria medikantara palembang consider good positive impact quality employee every employee store document share knowledge employee access even learn discuss employee base knowledge post need knowledge easy find database search feature web base knowledge management system satria medikantara palembang methodology use study refer methodology knowledge management system life cycle develop awad ghaziri system base web use php programming language,0.6049382716049383,0.12345679012345678,0.04938271604938271,0.037037037037037035,81.0,1.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Design and Development,"Dynamic Capitalization and Visualization Strategy in Collaborative
  Knowledge Management System for EI Process","Knowledge is attributed to human whose problem-solving behavior is subjective
and complex. In today's knowledge economy, the need to manage knowledge
produced by a community of actors cannot be overemphasized. This is due to the
fact that actors possess some level of tacit knowledge which is generally
difficult to articulate. Problem-solving requires searching and sharing of
knowledge among a group of actors in a particular context. Knowledge expressed
within the context of a problem resolution must be capitalized for future
reuse. In this paper, an approach that permits dynamic capitalization of
relevant and reliable actors' knowledge in solving decision problem following
Economic Intelligence process is proposed. Knowledge annotation method and
temporal attributes are used for handling the complexity in the communication
among actors and in contextualizing expressed knowledge. A prototype is built
to demonstrate the functionalities of a collaborative Knowledge Management
system based on this approach. It is tested with sample cases and the result
showed that dynamic capitalization leads to knowledge validation hence
increasing reliability of captured knowledge for reuse. The system can be
adapted to various domains",http://arxiv.org/abs/1012.3312v1,arXiv,dynamic capitalization visualization strategy collaborative knowledge management system process,knowledge attribute human whose problemsolve behavior subjective complex todays knowledge economy need manage knowledge produce community actor overemphasize due fact actor possess level tacit knowledge generally difficult articulate problemsolve require search sharing knowledge among group actor particular context knowledge express within context problem resolution must capitalize future reuse paper approach permit dynamic capitalization relevant reliable actor knowledge solve decision problem follow economic intelligence process propose knowledge annotation method temporal attribute use handle complexity communication among actor contextualizing express knowledge prototype build demonstrate functionality collaborative knowledge management system base approach test sample case result show dynamic capitalization lead knowledge validation hence increase reliability capture knowledge reuse system adapt various domain,dynamic capitalization visualization strategy collaborative knowledge management system process knowledge attribute human whose problemsolve behavior subjective complex todays knowledge economy need manage knowledge produce community actor overemphasize due fact actor possess level tacit knowledge generally difficult articulate problemsolve require search sharing knowledge among group actor particular context knowledge express within context problem resolution must capitalize future reuse paper approach permit dynamic capitalization relevant reliable actor knowledge solve decision problem follow economic intelligence process propose knowledge annotation method temporal attribute use handle complexity communication among actor contextualizing express knowledge prototype build demonstrate functionality collaborative knowledge management system base approach test sample case result show dynamic capitalization lead knowledge validation hence increase reliability capture knowledge reuse system adapt various domain,0.6422018348623854,0.11926605504587157,0.13761467889908258,0.01834862385321101,109.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Theoretical / Conceptual,Choosing a Knowledge Dissemination Approach,"Knowledge management has been described as getting the right knowledge to the
right people in the right place at the right time. Knowledge dissemination is a
crucial part of knowledge management because it ensures knowledge is available
to those who need it.
  This paper reviews four well-known knowledge dissemination techniques. Each
technique is classified according to a recently proposed classification scheme,
and advice is given regarding when it is appropriate to use each technique.",http://arxiv.org/abs/1809.05761v1,arXiv,choose knowledge dissemination approach,knowledge management describe get right knowledge right people right place right time knowledge dissemination crucial part knowledge management ensure knowledge available need paper review four wellknown knowledge dissemination technique technique classify accord recently propose classification scheme advice give regard appropriate use technique,choose knowledge dissemination approach knowledge management describe get right knowledge right people right place right time knowledge dissemination crucial part knowledge management ensure knowledge available need paper review four wellknown knowledge dissemination technique technique classify accord recently propose classification scheme advice give regard appropriate use technique,0.6428571428571429,0.14285714285714285,0.16666666666666666,0.023809523809523808,42.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Theoretical / Conceptual,"Knowledge Management Competence and ISD Vendor Innovativeness in
  Turbulent Markets","Continuous changes in the technology and the business landscape place high
strain on managing knowledge in organisations. Prior researchers highlight a
positive connotation with knowledge management competence and organisational
innovativeness in a turbulent environment. However, the rapid changes in the
market and technology landscape may exert an additional pressure on the
employees and such pressures may ultimately hinder organisational
innovativeness. Drawing on knowledge management and innovation literature, this
research conceptualises a model that investigates this tenacious relationship
between knowledge management competence and innovativeness specifically in
turbulent dynamic markets, considering information systems development
(ISD)-outsourcing as the context. Following a mixed method approach, this
research expects to provide guidance for ISD-outsourcing vendors to manage
innovation expectations, knowledge management process and performance of the
employees in dynamic market conditions.",http://arxiv.org/abs/2011.09840v1,arXiv,knowledge management competence isd vendor innovativeness turbulent market,continuous change technology business landscape place high strain manage knowledge organisation prior researcher highlight positive connotation knowledge management competence organisational innovativeness turbulent environment however rapid change market technology landscape may exert additional pressure employee pressure may ultimately hinder organisational innovativeness draw knowledge management innovation literature research conceptualise model investigate tenacious relationship knowledge management competence innovativeness specifically turbulent dynamic market consider information system development isdoutsourcing context follow mixed method approach research expect provide guidance isdoutsource vendor manage innovation expectation knowledge management process performance employee dynamic market condition,knowledge management competence isd vendor innovativeness turbulent market continuous change technology business landscape place high strain manage knowledge organisation prior researcher highlight positive connotation knowledge management competence organisational innovativeness turbulent environment however rapid change market technology landscape may exert additional pressure employee pressure may ultimately hinder organisational innovativeness draw knowledge management innovation literature research conceptualise model investigate tenacious relationship knowledge management competence innovativeness specifically turbulent dynamic market consider information system development isdoutsourcing context follow mixed method approach research expect provide guidance isdoutsource vendor manage innovation expectation knowledge management process performance employee dynamic market condition,0.5930232558139535,0.13953488372093023,0.1744186046511628,0.03488372093023256,86.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Theoretical / Conceptual,"Evident: a Development Methodology and a Knowledge Base Topology for
  Data Mining, Machine Learning and General Knowledge Management","Software has been developed for knowledge discovery, prediction and
management for over 30 years. However, there are still unresolved pain points
when using existing project development and artifact management methodologies.
Historically, there has been a lack of applicable methodologies. Further,
methodologies that have been applied, such as Agile, have several limitations
including scientific unfalsifiability that reduce their applicability. Evident,
a development methodology rooted in the philosophy of logical reasoning and
EKB, a knowledge base topology, are proposed. Many pain points in data mining,
machine learning and general knowledge management are alleviated conceptually.
Evident can be extended potentially to accelerate philosophical exploration,
science discovery, education as well as knowledge sharing & retention across
the globe. EKB offers one solution of storing information as knowledge, a
granular level above data. Related topics in computer history, software
engineering, database, sensor, philosophy, and project & organization &
military managements are also discussed.",http://arxiv.org/abs/2211.10291v1,arXiv,evident development methodology knowledge base topology datum mining machine learning general knowledge management,software develop knowledge discovery prediction management year however still unresolved pain point use exist project development artifact management methodology historically lack applicable methodology far methodology apply agile several limitation include scientific unfalsifiability reduce applicability evident development methodology root philosophy logical reasoning ekb knowledge base topology propose many pain point datum mining machine learning general knowledge management alleviate conceptually evident extend potentially accelerate philosophical exploration science discovery education well knowledge sharing retention across globe ekb offer one solution store information knowledge granular level datum relate topic computer history software engineering database sensor philosophy project organization military management also discuss,evident development methodology knowledge base topology datum mining machine learning general knowledge management software develop knowledge discovery prediction management year however still unresolved pain point use exist project development artifact management methodology historically lack applicable methodology far methodology apply agile several limitation include scientific unfalsifiability reduce applicability evident development methodology root philosophy logical reasoning ekb knowledge base topology propose many pain point datum mining machine learning general knowledge management alleviate conceptually evident extend potentially accelerate philosophical exploration science discovery education well knowledge sharing retention across globe ekb offer one solution store information knowledge granular level datum relate topic computer history software engineering database sensor philosophy project organization military management also discuss,0.6530612244897959,0.12244897959183673,0.12244897959183673,0.07142857142857142,98.0,0.0,0.0,1.0,0.0
Information Systems,Knowledge Management,Theoretical / Conceptual,"OntoMath Digital Ecosystem: Ontologies, Mathematical Knowledge Analytics
  and Management","In this article we consider the basic ideas, approaches and results of
developing of mathematical knowledge management technologies based on
ontologies. These solutions form the basis of a specialized digital ecosystem
OntoMath which consists of the ontology of the logical structure of
mathematical documents Mocassin and ontology of mathematical knowledge
OntoMathPRO, tools of text analysis, recommender system and other applications
to manage mathematical knowledge. The studies are in according to the ideas of
creating a distributed system of interconnected repositories of digitized
versions of mathematical documents and project to create a World Digital
Mathematical Library.",http://arxiv.org/abs/1702.05112v1,arXiv,ontomath digital ecosystem ontology mathematical knowledge analytic management,article consider basic idea approach result developing mathematical knowledge management technology base ontology solution form basis specialized digital ecosystem ontomath consist ontology logical structure mathematical document mocassin ontology mathematical knowledge ontomathpro tool text analysis recommender system application manage mathematical knowledge study accord idea create distribute system interconnect repository digitize version mathematical document project create world digital mathematical library,ontomath digital ecosystem ontology mathematical knowledge analytic management article consider basic idea approach result developing mathematical knowledge management technology base ontology solution form basis specialized digital ecosystem ontomath consist ontology logical structure mathematical document mocassin ontology mathematical knowledge ontomathpro tool text analysis recommender system application manage mathematical knowledge study accord idea create distribute system interconnect repository digitize version mathematical document project create world digital mathematical library,0.6379310344827587,0.1206896551724138,0.22413793103448276,0.0,58.0,0.0,0.0,0.0,0.0
Information Systems,Knowledge Management,Theoretical / Conceptual,"Imperfect Knowledge Management -- A Case Study in a Chilean
  Manufacturing Company","To conceptualize living systems based on the processes that create them,
rather than their interactions with the environment, as in systems theory.
Maturana and Varela (1969) at the University of Chile introduced the term
autopoiesis (from Greek self and production). This concept emphasizes autonomy
as the defining feature of living systems. It describes them as self-sustaining
entities that preserve their identity through continuous self-renewal to
preserve their unity. Furthermore, these systems can only be understood in
reference to themselves, as all internal activities are inherently
self-determined by self-production and self-referentiality. This thesis
introduces the Fuzzy Autopoietic Knowledge Management (FAKM) model, which
integrates the system theory of living systems, the cybernetic theory of viable
systems, and the autopoiesis theory of autopoietic systems. The goal is to move
beyond traditional knowledge management models that rely on Cartesian dualism
(cognition/action) where knowledge is treated as symbolic information
processing. Instead, the FAKM model adopts a dualism of organization/structure
to define an autopoietic system within a sociotechnical approach. The model is
experimentally applied to a manufacturing company in the Maule Region, south of
Santiago, Chile.",http://arxiv.org/abs/2502.01656v1,arXiv,imperfect knowledge management case study chilean manufacture company,conceptualize living system base process create rather interaction environment system theory maturana varela university chile introduce term autopoiesis greek self production concept emphasize autonomy define feature living system describe selfsustaine entity preserve identity continuous selfrenewal preserve unity furthermore system understand reference internal activity inherently selfdetermine selfproduction selfreferentiality thesis introduce fuzzy autopoietic knowledge management fakm model integrate system theory living system cybernetic theory viable system autopoiesis theory autopoietic system goal move beyond traditional knowledge management model rely cartesian dualism cognitionaction knowledge treat symbolic information processing instead fakm model adopt dualism organizationstructure define autopoietic system within sociotechnical approach model experimentally apply manufacture company maule region south santiago chile,imperfect knowledge management case study chilean manufacture company conceptualize living system base process create rather interaction environment system theory maturana varela university chile introduce term autopoiesis greek self production concept emphasize autonomy define feature living system describe selfsustaine entity preserve identity continuous selfrenewal preserve unity furthermore system understand reference internal activity inherently selfdetermine selfproduction selfreferentiality thesis introduce fuzzy autopoietic knowledge management fakm model integrate system theory living system cybernetic theory viable system autopoiesis theory autopoietic system goal move beyond traditional knowledge management model rely cartesian dualism cognitionaction knowledge treat symbolic information processing instead fakm model adopt dualism organizationstructure define autopoietic system within sociotechnical approach model experimentally apply manufacture company maule region south santiago chile,0.5283018867924528,0.1509433962264151,0.1320754716981132,0.04716981132075472,106.0,1.0,0.0,0.0,0.0
Information Systems,Information Security,Quantitative,Information Security Games: A Survey,"We introduce some preliminaries about game theory and information security.
Then surveying a subset of the literature, we identify opportunities for future
research.",http://arxiv.org/abs/2103.12520v1,arXiv,information security game survey,introduce preliminary game theory information security survey subset literature identify opportunity future research,information security game survey introduce preliminary game theory information security survey subset literature identify opportunity future research,0.6153846153846154,0.15384615384615385,0.15384615384615385,0.0,13.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Quantitative,"Quantitative Information Flow Control by Construction for
  Component-Based Systems","Secure software architecture is increasingly important in a data-driven
world. When security is neglected sensitive information might leak through
unauthorized access. To mitigate this software architects needs tools and
methods to quantify security risks in complex systems. This paper presents
doctoral research in its early stages concerned with creating constructive
methods for building secure component-based systems from a quantitative
information flow specification. This research aim at developing a method that
allows software architects to develop secure systems from a repository of
secure components. Planned contributions are refinement rules for secure
development of components from a specification and well-formedness rules for
secure composition of said components.",http://arxiv.org/abs/2401.07677v1,arXiv,quantitative information flow control construction componentbase system,secure software architecture increasingly important datadriven world security neglect sensitive information might leak unauthorized access mitigate software architect need tool method quantify security risk complex system paper present doctoral research early stage concern create constructive method build secure componentbase system quantitative information flow specification research aim develop method allow software architect develop secure system repository secure component plan contribution refinement rule secure development component specification wellformedness rule secure composition say component,quantitative information flow control construction componentbase system secure software architecture increasingly important datadriven world security neglect sensitive information might leak unauthorized access mitigate software architect need tool method quantify security risk complex system paper present doctoral research early stage concern create constructive method build secure componentbase system quantitative information flow specification research aim develop method allow software architect develop secure system repository secure component plan contribution refinement rule secure development component specification wellformedness rule secure composition say component,0.6338028169014085,0.1267605633802817,0.2112676056338028,0.014084507042253521,71.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Quantitative,On Converse Results for Secure Index Coding,"In this work, we study the secure index coding problem where there are
security constraints on both legitimate receivers and eavesdroppers. We develop
two performance bounds (i.e., converse results) on the symmetric secure
capacity. The first one is an extended version of the basic acyclic chain bound
(Liu and Sadeghi, 2019) that takes security constraints into account. The
second converse result is a novel information-theoretic lower bound on the
symmetric secure capacity, which is interesting as all the existing converse
results in the literature for secure index coding give upper bounds on the
capacity.",http://arxiv.org/abs/2105.07211v1,arXiv,converse result secure index coding,work study secure index code problem security constraint legitimate receiver eavesdropper develop two performance bound converse result symmetric secure capacity first one extended version basic acyclic chain bound liu sadeghi take security constraint account second converse result novel informationtheoretic lower bind symmetric secure capacity interesting exist converse result literature secure index coding give upper bound capacity,converse result secure index coding work study secure index code problem security constraint legitimate receiver eavesdropper develop two performance bound converse result symmetric secure capacity first one extended version basic acyclic chain bound liu sadeghi take security constraint account second converse result novel informationtheoretic lower bind symmetric secure capacity interesting exist converse result literature secure index coding give upper bound capacity,0.4642857142857143,0.16071428571428573,0.23214285714285715,0.03571428571428571,56.0,0.0,0.0,0.0,1.0
Information Systems,Information Security,Quantitative,"The need for effective information security awareness practices in Oman
  higher educational institutions","The revolution of internet technology and its usage have led a significant
increase in the number of online transactions and electronic data transfer,
parallely increased the number of cybercrime incidents around the world. Steady
economic growth in the Sultanate of Oman accelerated the volume of online
utilization for e-commerce, banking, communication, education and so forth.
Normally attackers target the users who ignore security practices due to the
lack of information security awareness. Unawareness of information security
practices, user negligence, lack of awareness programs and trainings are the
root cause for information security threats. Earlier studies reveal there is a
considerable and continuous cybercrime incident in Oman which compromises the
security policy of the organizations, affecting the business continuity and the
economic growth. In this study, a survey was performed among the educational
institutions in Oman to investigate the level of information security awareness
and based on the study, a security awareness model is proposed to enable
information security practices in the educational institutions.",http://arxiv.org/abs/1602.06510v1,arXiv,need effective information security awareness practice oman high educational institution,revolution internet technology usage lead significant increase number online transaction electronic datum transfer parallely increase number cybercrime incident around world steady economic growth sultanate oman accelerate volume online utilization ecommerce bank communication education forth normally attacker target user ignore security practice due lack information security awareness unawareness information security practice user negligence lack awareness program training root cause information security threat early study reveal considerable continuous cybercrime incident oman compromise security policy organization affect business continuity economic growth study survey perform among educational institution oman investigate level information security awareness base study security awareness model propose enable information security practice educational institution,need effective information security awareness practice oman high educational institution revolution internet technology usage lead significant increase number online transaction electronic datum transfer parallely increase number cybercrime incident around world steady economic growth sultanate oman accelerate volume online utilization ecommerce bank communication education forth normally attacker target user ignore security practice due lack information security awareness unawareness information security practice user negligence lack awareness program training root cause information security threat early study reveal considerable continuous cybercrime incident oman compromise security policy organization affect business continuity economic growth study survey perform among educational institution oman investigate level information security awareness base study security awareness model propose enable information security practice educational institution,0.6666666666666666,0.13725490196078433,0.12745098039215685,0.029411764705882353,102.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Quantitative,"Individual and Contextual Variables of Cyber Security Behaviour -- An
  empirical analysis of national culture, industry, organisation, and
  individual variables of (in)secure human behaviour","Cyber security incidents are increasing and humans play an important role in
reducing their likelihood and impact. We identify a skewed focus towards
technical aspects of cyber security in the literature, whereas factors
influencing the secure behaviour of individuals require additional research.
These factors span across both the individual level and the contextual level in
which the people are situated. We analyse two datasets of a total of 37,075
records from a) self-reported security behaviours across the EU, and b)
observed phishing-related behaviours from the industry security awareness
training programmes. We identify that national culture, industry type, and
organisational security culture play are influential Variables (antecedents) of
individuals' security behaviour at contextual level. Whereas, demographics
(age, gender, and level or urbanisation) and security-specific factors
(security awareness, security knowledge, and prior experience with security
incidents) are found to be influential variables of security behaviour at
individual level. Our findings have implications for both research and practice
as they fill a gap in the literature and provide concrete statistical evidence
on the variables which influence security behaviour. Moreover, findings
provides practical insights for organisations regarding the susceptibility of
groups of people to insecure behaviour. Consequently, organisations can tailor
their security training and awareness efforts (e.g., through behaviour change
interventions and/or appropriate employee group profiles), adapt their
communications (e.g., of information security policies), and customise their
interventions according to national culture characteristics to improve security
behaviour.",http://arxiv.org/abs/2405.16215v2,arXiv,individual contextual variable cyber security behaviour empirical analysis national culture industry organisation individual variable insecure human behaviour,cyber security incident increase human play important role reduce likelihood impact identify skewed focus towards technical aspect cyber security literature whereas factor influence secure behaviour individual require additional research factor span across individual level contextual level people situate analyse two dataset total record selfreporte security behaviour across observe phishingrelate behaviour industry security awareness training programme identify national culture industry type organisational security culture play influential variable antecedent individual security behaviour contextual level whereas demographic age gender level urbanisation securityspecific factor security awareness security knowledge prior experience security incident find influential variable security behaviour individual level finding implication research practice fill gap literature provide concrete statistical evidence variable influence security behaviour moreover finding provide practical insight organisation regard susceptibility group people insecure behaviour consequently organisation tailor security training awareness effort behaviour change intervention andor appropriate employee group profile adapt communication information security policy customise intervention accord national culture characteristic improve security behaviour,individual contextual variable cyber security behaviour empirical analysis national culture industry organisation individual variable insecure human behaviour cyber security incident increase human play important role reduce likelihood impact identify skewed focus towards technical aspect cyber security literature whereas factor influence secure behaviour individual require additional research factor span across individual level contextual level people situate analyse two dataset total record selfreporte security behaviour across observe phishingrelate behaviour industry security awareness training programme identify national culture industry type organisational security culture play influential variable antecedent individual security behaviour contextual level whereas demographic age gender level urbanisation securityspecific factor security awareness security knowledge prior experience security incident find influential variable security behaviour individual level finding implication research practice fill gap literature provide concrete statistical evidence variable influence security behaviour moreover finding provide practical insight organisation regard susceptibility group people insecure behaviour consequently organisation tailor security training awareness effort behaviour change intervention andor appropriate employee group profile adapt communication information security policy customise intervention accord national culture characteristic improve security behaviour,0.6158940397350994,0.09271523178807947,0.17218543046357615,0.013245033112582781,151.0,1.0,0.0,0.0,0.0
Information Systems,Information Security,Qualitative,"Secure Synthesis of Distributed Cryptographic Applications (Technical
  Report)","Developing secure distributed systems is difficult, and even harder when
advanced cryptography must be used to achieve security goals. Following prior
work, we advocate using secure program partitioning to synthesize cryptographic
applications: instead of implementing a system of communicating processes, the
programmer implements a centralized, sequential program, which is automatically
compiled into a secure distributed version that uses cryptography.
  While this approach is promising, formal results for the security of such
compilers are limited in scope. In particular, no security proof yet
simultaneously addresses subtleties essential for robust, efficient
applications: multiple cryptographic mechanisms, malicious corruption, and
asynchronous communication.
  In this work, we develop a compiler security proof that handles these
subtleties. Our proof relies on a novel unification of simulation-based
security, information-flow control, choreographic programming, and
sequentialization techniques for concurrent programs. While our proof targets
hybrid protocols, which abstract cryptographic mechanisms as idealized
functionalities, our approach offers a clear path toward leveraging Universal
Composability to obtain end-to-end, modular security results with fully
instantiated cryptographic mechanisms.
  Finally, following prior observations about simulation-based security, we
prove that our result guarantees robust hyperproperty preservation, an
important criterion for compiler correctness that preserves all source-level
security properties in target programs.",http://arxiv.org/abs/2401.04131v1,arXiv,secure synthesis distribute cryptographic application technical report,develop secure distribute system difficult even hard advanced cryptography must use achieve security goal follow prior work advocate use secure program partition synthesize cryptographic application instead implement system communicating process programmer implement centralized sequential program automatically compile secure distribute version use cryptography approach promise formal result security compiler limit scope particular security proof yet simultaneously address subtlety essential robust efficient application multiple cryptographic mechanism malicious corruption asynchronous communication work develop compiler security proof handle subtletie proof rely novel unification simulationbase security informationflow control choreographic programming sequentialization technique concurrent program proof target hybrid protocol abstract cryptographic mechanism idealize functionality approach offer clear path toward leverage universal composability obtain endtoend modular security result fully instantiate cryptographic mechanism finally follow prior observation simulationbase security prove result guarantee robust hyperproperty preservation important criterion compiler correctness preserve sourcelevel security property target program,secure synthesis distribute cryptographic application technical report develop secure distribute system difficult even hard advanced cryptography must use achieve security goal follow prior work advocate use secure program partition synthesize cryptographic application instead implement system communicating process programmer implement centralized sequential program automatically compile secure distribute version use cryptography approach promise formal result security compiler limit scope particular security proof yet simultaneously address subtlety essential robust efficient application multiple cryptographic mechanism malicious corruption asynchronous communication work develop compiler security proof handle subtletie proof rely novel unification simulationbase security informationflow control choreographic programming sequentialization technique concurrent program proof target hybrid protocol abstract cryptographic mechanism idealize functionality approach offer clear path toward leverage universal composability obtain endtoend modular security result fully instantiate cryptographic mechanism finally follow prior observation simulationbase security prove result guarantee robust hyperproperty preservation important criterion compiler correctness preserve sourcelevel security property target program,0.5036496350364964,0.145985401459854,0.25547445255474455,0.051094890510948905,68.5,0.0,0.0,0.0,0.0
Information Systems,Information Security,Qualitative,"Performance Measurement of Security Academic Information System using
  Maturity Level","This study aims to information security in academic information systems to
provide recommendations for improvements in information security management by
the expected maturity level based on ISO/IEC 27002:2013. By using a qualitative
descriptive approach, data collection and validation techniques with
triangulation techniques are interviews, observation, and documentation. The
data were analyzed by using gap analysis and to measure the maturity level
determined 15 objective control and 45 security controls scattered in 5
clauses, the result of the research found that the performance of academic
information system maturity level at level 2. That is, the current level of
maturity is below the expected maturity level, so it needs to be increased to
the expected level.",http://arxiv.org/abs/2204.09511v1,arXiv,performance measurement security academic information system use maturity level,study aim information security academic information system provide recommendation improvement information security management expected maturity level base isoiec use qualitative descriptive approach datum collection validation technique triangulation technique interview observation documentation datum analyze use gap analysis measure maturity level determined objective control security control scatter clause result research find performance academic information system maturity level level current level maturity expect maturity level need increase expect level,performance measurement security academic information system use maturity level study aim information security academic information system provide recommendation improvement information security management expected maturity level base isoiec use qualitative descriptive approach datum collection validation technique triangulation technique interview observation documentation datum analyze use gap analysis measure maturity level determined objective control security control scatter clause result research find performance academic information system maturity level level current level maturity expect maturity level need increase expect level,0.7575757575757576,0.10606060606060606,0.09090909090909091,0.0,66.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Qualitative,Security policies for distributed systems,"A security policy specifies a security property as the maximal information
flow. A distributed system composed of interacting processes implicitly defines
an intransitive security policy by repudiating direct information flow between
processes that do not exchange messages directly. We show that implicitly
defined security policies in distributed systems are enforced, provided that
processes run in separation, and possible process communication on a technical
platform is restricted to specified message paths of the system. Furthermore,
we propose to further restrict the allowable information flow by adding filter
functions for controlling which messages may be transmitted between processes,
and we prove that locally checking filter functions is sufficient for ensuring
global security policies. Altogether, global intransitive security policies are
established by means of local verification conditions for the (trusted)
processes of the distributed system. Moreover, security policies may be
implemented securely on distributed integration platforms which ensure
partitioning. We illustrate our results with a smart grid case study, where we
use CTL model checking for discharging local verification conditions for each
process under consideration.",http://arxiv.org/abs/1310.3723v1,arXiv,security policy distribute system,security policy specify security property maximal information flow distribute system compose interact process implicitly define intransitive security policy repudiate direct information flow process exchange message directly show implicitly define security policy distribute system enforce provide process run separation possible process communication technical platform restrict specify message path system furthermore propose far restrict allowable information flow add filter function control message may transmit process prove locally check filter function sufficient ensure global security policy altogether global intransitive security policy establish mean local verification condition trust process distribute system moreover security policy may implement securely distribute integration platform ensure partition illustrate result smart grid case study use ctl model check discharge local verification condition process consideration,security policy distribute system security policy specify security property maximal information flow distribute system compose interact process implicitly define intransitive security policy repudiate direct information flow process exchange message directly show implicitly define security policy distribute system enforce provide process run separation possible process communication technical platform restrict specify message path system furthermore propose far restrict allowable information flow add filter function control message may transmit process prove locally check filter function sufficient ensure global security policy altogether global intransitive security policy establish mean local verification condition trust process distribute system moreover security policy may implement securely distribute integration platform ensure partition illustrate result smart grid case study use ctl model check discharge local verification condition process consideration,0.5614035087719298,0.18421052631578946,0.14035087719298245,0.07894736842105263,114.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Qualitative,"Getting Users Smart Quick about Security: Results from 90 Minutes of
  Using a Persuasive Toolkit for Facilitating Information Security Problem
  Solving by Non-Professionals","There is a conflict between the need for security compliance by users and the
fact that commonly they cannot afford to dedicate much of their time and energy
to that security. A balanced level of user engagement in security is difficult
to achieve due to difference of priorities between the business perspective and
the security perspective. We sought to find a way to engage users minimally,
yet efficiently, so that they would both improve their security awareness and
provide necessary feedback for improvement purposes to security designers. We
have developed a persuasive software toolkit to engage users in structured
discussions about security vulnerabilities in their company and potential
interventions addressing these. In the toolkit we have adapted and integrated
an established framework from conventional crime prevention. In the research
reported here we examine how non-professionals perceived security problems
through a short-term use of the toolkit. We present perceptions from a pilot
lab study in which randomly recruited participants had to analyze a crafted
insider threat problem using the toolkit. Results demonstrate that study
participants were able to successfully identify causes, propose interventions
and engage in providing feedback on proposed interventions. Subsequent
interviews show that participants have developed greater awareness of
information security issues and the framework to address these, which in a real
setting would lead ultimately to significant benefits for the organization.
These results indicate that when well-structured such short-term engagement is
sufficient for users to meaningfully take part in complex security discussions
and develop in-depth understanding of theoretical principles of security.",http://arxiv.org/abs/2209.02420v1,arXiv,get user smart quick security result minute use persuasive toolkit facilitate information security problem solve nonprofessional,conflict need security compliance user fact commonly afford dedicate much time energy security balanced level user engagement security difficult achieve due difference priority business perspective security perspective seek find way engage user minimally yet efficiently would improve security awareness provide necessary feedback improvement purpose security designer develop persuasive software toolkit engage user structured discussion security vulnerability company potential intervention address toolkit adapt integrate establish framework conventional crime prevention research report examine nonprofessional perceive security problem shortterm use toolkit present perception pilot lab study randomly recruit participant analyze crafted insider threat problem use toolkit result demonstrate study participant able successfully identify cause propose intervention engage provide feedback propose intervention subsequent interview show participant develop great awareness information security issue framework address real setting would lead ultimately significant benefit organization result indicate wellstructure shortterm engagement sufficient user meaningfully take part complex security discussion develop indepth understanding theoretical principle security,get user smart quick security result minute use persuasive toolkit facilitate information security problem solve nonprofessional conflict need security compliance user fact commonly afford dedicate much time energy security balanced level user engagement security difficult achieve due difference priority business perspective security perspective seek find way engage user minimally yet efficiently would improve security awareness provide necessary feedback improvement purpose security designer develop persuasive software toolkit engage user structured discussion security vulnerability company potential intervention address toolkit adapt integrate establish framework conventional crime prevention research report examine nonprofessional perceive security problem shortterm use toolkit present perception pilot lab study randomly recruit participant analyze crafted insider threat problem use toolkit result demonstrate study participant able successfully identify cause propose intervention engage provide feedback propose intervention subsequent interview show participant develop great awareness information security issue framework address real setting would lead ultimately significant benefit organization result indicate wellstructure shortterm engagement sufficient user meaningfully take part complex security discussion develop indepth understanding theoretical principle security,0.5918367346938775,0.16326530612244897,0.1564625850340136,0.05442176870748299,147.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Qualitative,"Efficient Three-party Computation: An Information-theoretic Approach
  from Cut-and-Choose","As far as we know, the literature on secure computation from cut-and-choose
has focused on achieving computational security against malicious adversaries.
It is unclear whether the idea of cut-and-choose can be adapted to secure
computation with information-theoretic security. In this work we explore the
possibility of using cut-and-choose in information theoretic setting for secure
three-party computation (3PC). Previous work on 3PC has mainly focus on the
semi-honest case, and is motivated by the observation that real-word
deployments of multi-party computation (MPC) seem to involve few parties. We
propose a new protocol for information-theoretically secure 3PC tolerating one
malicious party with cheating probability $2^{-s}$ using $s$ runs of circuit
computation in the cut-and-choose paradigm. The computational cost of our
protocol is essentially only a small constant worse than that of
state-of-the-art 3PC protocols against a semi-honest corruption, while its
communication round is greatly reduced compared to other maliciously secure 3PC
protocols in information-theoretic setting.",http://arxiv.org/abs/1908.03718v1,arXiv,efficient threeparty computation informationtheoretic approach cutandchoose,far know literature secure computation cutandchoose focus achieve computational security malicious adversary unclear whether idea cutandchoose adapt secure computation informationtheoretic security work explore possibility use cutandchoose information theoretic setting secure threeparty computation previous work mainly focus semihon case motivate observation realword deployment multiparty computation mpc seem involve party propose new protocol informationtheoretically secure tolerate one malicious party cheating probability use run circuit computation cutandchoose paradigm computational cost protocol essentially small constant bad stateoftheart protocol semihon corruption communication round greatly reduce compare maliciously secure protocol informationtheoretic setting,efficient threeparty computation informationtheoretic approach cutandchoose far know literature secure computation cutandchoose focus achieve computational security malicious adversary unclear whether idea cutandchoose adapt secure computation informationtheoretic security work explore possibility use cutandchoose information theoretic setting secure threeparty computation previous work mainly focus semihon case motivate observation realword deployment multiparty computation mpc seem involve party propose new protocol informationtheoretically secure tolerate one malicious party cheating probability use run circuit computation cutandchoose paradigm computational cost protocol essentially small constant bad stateoftheart protocol semihon corruption communication round greatly reduce compare maliciously secure protocol informationtheoretic setting,0.5,0.13953488372093023,0.18604651162790697,0.06976744186046512,86.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Mixed Methods,"Chaotic iterations versus Spread-spectrum: topological-security and
  stego-security","A new framework for information hiding security, called topological-security,
has been proposed in a previous study. It is based on the evaluation of
unpredictability of the scheme, whereas existing notions of security, as
stego-security, are more linked to information leaks. It has been proven that
spread-spectrum techniques, a well-known stego-secure scheme, are
topologically-secure too. In this paper, the links between the two notions of
security is deepened and the usability of topological-security is clarified, by
presenting a novel data hiding scheme that is twice stego and
topological-secure. This last scheme has better scores than spread-spectrum
when evaluating qualitative and quantitative topological-security properties.
Incidentally, this result shows that the new framework for security tends to
improve the ability to compare data hiding scheme.",http://arxiv.org/abs/1112.3874v1,arXiv,chaotic iteration versus spreadspectrum topologicalsecurity stegosecurity,new framework information hiding security call topologicalsecurity propose previous study base evaluation unpredictability scheme whereas exist notion security stegosecurity link information leak prove spreadspectrum technique wellknown stegosecure scheme topologicallysecure paper link two notion security deepen usability topologicalsecurity clarify present novel datum hiding scheme twice stego topologicalsecure last scheme well score spreadspectrum evaluate qualitative quantitative topologicalsecurity property incidentally result show new framework security tend improve ability compare datum hiding scheme,chaotic iteration versus spreadspectrum topologicalsecurity stegosecurity new framework information hiding security call topologicalsecurity propose previous study base evaluation unpredictability scheme whereas exist notion security stegosecurity link information leak prove spreadspectrum technique wellknown stegosecure scheme topologicallysecure paper link two notion security deepen usability topologicalsecurity clarify present novel datum hiding scheme twice stego topologicalsecure last scheme well score spreadspectrum evaluate qualitative quantitative topologicalsecurity property incidentally result show new framework security tend improve ability compare datum hiding scheme,0.6666666666666666,0.15942028985507245,0.10144927536231885,0.028985507246376812,69.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Mixed Methods,Composite Metrics for Network Security Analysis,"Security metrics present the security level of a system or a network in both
qualitative and quantitative ways. In general, security metrics are used to
assess the security level of a system and to achieve security goals. There are
a lot of security metrics for security analysis, but there is no systematic
classification of security metrics that are based on network reachability
information. To address this, we propose a systematic classification of
existing security metrics based on network reachability information. Mainly, we
classify the security metrics into host-based and network-based metrics. The
host-based metrics are classified into metrics ``without probability"" and ""with
probability"", while the network-based metrics are classified into ""path-based""
and ""non-path based"". Finally, we present and describe an approach to develop
composite security metrics and it's calculations using a Hierarchical Attack
Representation Model (HARM) via an example network. Our novel classification of
security metrics provides a new methodology to assess the security of a system.",http://arxiv.org/abs/2007.03486v2,arXiv,composite metric network security analysis,security metric present security level system network qualitative quantitative way general security metric use assess security level system achieve security goal lot security metric security analysis systematic classification security metric base network reachability information address propose systematic classification exist security metric base network reachability information mainly classify security metric hostbased networkbased metric hostbase metric classify metric without probability probability networkbased metric classify pathbase nonpath base finally present describe approach develop composite security metric calculation use hierarchical attack representation model harm via example network novel classification security metric provide new methodology assess security system,composite metric network security analysis security metric present security level system network qualitative quantitative way general security metric use assess security level system achieve security goal lot security metric security analysis systematic classification security metric base network reachability information address propose systematic classification exist security metric base network reachability information mainly classify security metric hostbased networkbased metric hostbase metric classify metric without probability probability networkbased metric classify pathbase nonpath base finally present describe approach develop composite security metric calculation use hierarchical attack representation model harm via example network novel classification security metric provide new methodology assess security system,0.5913978494623656,0.16129032258064516,0.20430107526881722,0.021505376344086023,93.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Mixed Methods,Chaotic iterations versus Spread-spectrum: chaos and stego security,"A new framework for information hiding security, called chaos-security, has
been proposed in a previous study. It is based on the evaluation of
unpredictability of the scheme, whereas existing notions of security, as
stego-security, are more linked to information leaks. It has been proven that
spread-spectrum techniques, a well-known stego-secure scheme, are chaos-secure
too. In this paper, the links between the two notions of security is deepened
and the usability of chaos-security is clarified, by presenting a novel data
hiding scheme that is twice stego and chaos-secure. This last scheme has better
scores than spread-spectrum when evaluating qualitative and quantitative
chaos-security properties. Incidentally, this result shows that the new
framework for security tends to improve the ability to compare data hiding
scheme.",http://arxiv.org/abs/1005.0705v3,arXiv,chaotic iteration versus spreadspectrum chaos stego security,new framework information hiding security call chaossecurity propose previous study base evaluation unpredictability scheme whereas exist notion security stegosecurity link information leak prove spreadspectrum technique wellknown stegosecure scheme chaossecure paper link two notion security deepen usability chaossecurity clarify present novel datum hiding scheme twice stego chaossecure last scheme well score spreadspectrum evaluate qualitative quantitative chaossecurity property incidentally result show new framework security tend improve ability compare datum hiding scheme,chaotic iteration versus spreadspectrum chaos stego security new framework information hiding security call chaossecurity propose previous study base evaluation unpredictability scheme whereas exist notion security stegosecurity link information leak prove spreadspectrum technique wellknown stegosecure scheme chaossecure paper link two notion security deepen usability chaossecurity clarify present novel datum hiding scheme twice stego chaossecure last scheme well score spreadspectrum evaluate qualitative quantitative chaossecurity property incidentally result show new framework security tend improve ability compare datum hiding scheme,0.6521739130434783,0.15942028985507245,0.10144927536231885,0.028985507246376812,69.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Mixed Methods,SMEs' Confidentiality Concerns for Security Information Sharing,"Small and medium-sized enterprises are considered an essential part of the EU
economy, however, highly vulnerable to cyberattacks. SMEs have specific
characteristics which separate them from large companies and influence their
adoption of good cybersecurity practices. To mitigate the SMEs' cybersecurity
adoption issues and raise their awareness of cyber threats, we have designed a
self-paced security assessment and capability improvement method, CYSEC. CYSEC
is a security awareness and training method that utilises self-reporting
questionnaires to collect companies' information about cybersecurity awareness,
practices, and vulnerabilities to generate automated recommendations for
counselling. However, confidentiality concerns about cybersecurity information
have an impact on companies' willingness to share their information. Security
information sharing decreases the risk of incidents and increases users'
self-efficacy in security awareness programs. This paper presents the results
of semi-structured interviews with seven chief information security officers of
SMEs to evaluate the impact of online consent communication on motivation for
information sharing. The results were analysed in respect of the Self
Determination Theory. The findings demonstrate that online consent with
multiple options for indicating a suitable level of agreement improved
motivation for information sharing. This allows many SMEs to participate in
security information sharing activities and supports security experts to have a
better overview of common vulnerabilities. The final publication is available
at Springer via https://doi.org/10.1007/978-3-030-57404-8_22",http://arxiv.org/abs/2007.06308v2,arXiv,sme confidentiality concern security information sharing,small mediumsize enterprise consider essential part economy however highly vulnerable cyberattack sme specific characteristic separate large company influence adoption good cybersecurity practice mitigate sme cybersecurity adoption issue raise awareness cyber threat design selfpace security assessment capability improvement method cysec cysec security awareness training method utilise selfreporting questionnaire collect company information cybersecurity awareness practice vulnerability generate automate recommendation counselling however confidentiality concern cybersecurity information impact company willingness share information security information sharing decrease risk incident increase user selfefficacy security awareness program paper present result semistructure interview seven chief information security officer sme evaluate impact online consent communication motivation information share result analyse respect self determination theory finding demonstrate online consent multiple option indicate suitable level agreement improve motivation information share allow many sme participate security information sharing activity support security expert well overview common vulnerability final publication available springer via httpsdoiorg,sme confidentiality concern security information sharing small mediumsize enterprise consider essential part economy however highly vulnerable cyberattack sme specific characteristic separate large company influence adoption good cybersecurity practice mitigate sme cybersecurity adoption issue raise awareness cyber threat design selfpace security assessment capability improvement method cysec cysec security awareness training method utilise selfreporting questionnaire collect company information cybersecurity awareness practice vulnerability generate automate recommendation counselling however confidentiality concern cybersecurity information impact company willingness share information security information sharing decrease risk incident increase user selfefficacy security awareness program paper present result semistructure interview seven chief information security officer sme evaluate impact online consent communication motivation information share result analyse respect self determination theory finding demonstrate online consent multiple option indicate suitable level agreement improve motivation information share allow many sme participate security information sharing activity support security expert well overview common vulnerability final publication available springer via httpsdoiorg,0.65,0.12857142857142856,0.14285714285714285,0.02857142857142857,140.0,1.0,0.0,0.0,0.0
Information Systems,Information Security,Mixed Methods,strideSEA: A STRIDE-centric Security Evaluation Approach,"Microsoft's STRIDE methodology is at the forefront of threat modeling,
supporting the increasingly critical quality attribute of security in
software-intensive systems. However, in a comprehensive security evaluation
process, the general consensus is that the STRIDE classification is only useful
for threat elicitation, isolating threat modeling from the other security
evaluation activities involved in a secure software development life cycle
(SDLC). We present strideSEA, a STRIDE-centric Security Evaluation Approach
that integrates STRIDE as the central classification scheme into the security
activities of threat modeling, attack scenario analysis, risk analysis, and
countermeasure recommendation that are conducted alongside software engineering
activities in secure SDLCs. The application of strideSEA is demonstrated in a
real-world online immunization system case study. Using STRIDE as a single
unifying thread, we bind existing security evaluation approaches in the four
security activities of strideSEA to analyze (1) threats using Microsoft threat
modeling tool, (2) attack scenarios using attack trees, (3) systemic risk using
NASA's defect detection and prevention (DDP) technique, and (4) recommend
countermeasures based on their effectiveness in reducing the most critical
risks using DDP. The results include a detailed quantitative assessment of the
security of the online immunization system with a clear definition of the role
and advantages of integrating STRIDE in the evaluation process. Overall, the
unified approach in strideSEA enables a more structured security evaluation
process, allowing easier identification and recommendation of countermeasures,
thus supporting the security requirements and eliciting design considerations,
informing the software development life cycle of future software-based
information systems.",http://arxiv.org/abs/2503.19030v1,arXiv,stridesea stridecentric security evaluation approach,microsofts stride methodology forefront threat modeling support increasingly critical quality attribute security softwareintensive system however comprehensive security evaluation process general consensus stride classification useful threat elicitation isolate threat modeling security evaluation activity involve secure software development life cycle sdlc present stridesea stridecentric security evaluation approach integrate stride central classification scheme security activity threat modeling attack scenario analysis risk analysis countermeasure recommendation conduct alongside software engineering activity secure sdlcs application stridesea demonstrate realworld online immunization system case study use stride single unifying thread bind exist security evaluation approach four security activity stridesea analyze threat use microsoft threat modeling tool attack scenario use attack tree systemic risk use nasas defect detection prevention ddp technique recommend countermeasure base effectiveness reduce critical risk use ddp result include detailed quantitative assessment security online immunization system clear definition role advantage integrate stride evaluation process overall unified approach stridesea enable structured security evaluation process allow easy identification recommendation countermeasure thus support security requirement elicit design consideration inform software development life cycle future softwarebase information system,stridesea stridecentric security evaluation approach microsofts stride methodology forefront threat modeling support increasingly critical quality attribute security softwareintensive system however comprehensive security evaluation process general consensus stride classification useful threat elicitation isolate threat modeling security evaluation activity involve secure software development life cycle sdlc present stridesea stridecentric security evaluation approach integrate stride central classification scheme security activity threat modeling attack scenario analysis risk analysis countermeasure recommendation conduct alongside software engineering activity secure sdlcs application stridesea demonstrate realworld online immunization system case study use stride single unifying thread bind exist security evaluation approach four security activity stridesea analyze threat use microsoft threat modeling tool attack scenario use attack tree systemic risk use nasas defect detection prevention ddp technique recommend countermeasure base effectiveness reduce critical risk use ddp result include detailed quantitative assessment security online immunization system clear definition role advantage integrate stride evaluation process overall unified approach stridesea enable structured security evaluation process allow easy identification recommendation countermeasure thus support security requirement elicit design consideration inform software development life cycle future softwarebase information system,0.6964285714285714,0.09523809523809523,0.1130952380952381,0.017857142857142856,168.0,1.0,0.0,0.0,0.0
Information Systems,Information Security,Design and Development,"A Business Goal Driven Approach for Understanding and Specifying
  Information Security Requirements","In this paper we present an approach for specifying and prioritizing
information security requirements in organizations. It is important to
prioritize security requirements since hundred per cent security is not
achievable and the limited resources available should be directed to satisfy
the most important ones. We propose to link explicitly security requirements
with the organization's business vision, i.e. to provide business rationale for
security requirements. The rationale is then used as a basis for comparing the
importance of different security requirements. A conceptual framework is
presented, where the relationships between business vision, critical impact
factors and valuable assets (together with their security requirements) are
shown.",http://arxiv.org/abs/cs/0603129v1,arXiv,business goal drive approach understanding specify information security requirement,paper present approach specify prioritize information security requirement organization important prioritize security requirement since hundred per cent security achievable limited resource available direct satisfy important one propose link explicitly security requirement organization business vision provide business rationale security requirement rationale use basis compare importance different security requirement conceptual framework present relationship business vision critical impact factor valuable asset together security requirement show,business goal drive approach understanding specify information security requirement paper present approach specify prioritize information security requirement organization important prioritize security requirement since hundred per cent security achievable limited resource available direct satisfy important one propose link explicitly security requirement organization business vision provide business rationale security requirement rationale use basis compare importance different security requirement conceptual framework present relationship business vision critical impact factor valuable asset together security requirement show,0.6451612903225806,0.04838709677419355,0.20967741935483872,0.03225806451612903,62.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Design and Development,Secure physical layer network coding versus secure network coding,"Secure network coding realizes the secrecy of the message when the message is
transmitted via noiseless network and a part of edges or a part of intermediate
nodes are eavesdropped. In this framework, if the channels of the network has
noise, we apply the error correction to noisy channel before applying the
secure network coding. In contrast, secure physical layer network coding is a
method to securely transmit a message by a combination of coding operation on
nodes when the network is given as a set of noisy channels. In this paper, we
give several examples of network, in which, secure physical layer network
coding has advantage over secure network coding.",http://arxiv.org/abs/1812.00117v1,arXiv,secure physical layer network code versus secure network code,secure network coding realize secrecy message message transmit via noiseless network part edge part intermediate node eavesdrop framework channel network noise apply error correction noisy channel apply secure network code contrast secure physical layer network coding method securely transmit message combination code operation node network give set noisy channel paper give several example network secure physical layer network coding advantage secure network code,secure physical layer network code versus secure network code secure network coding realize secrecy message message transmit via noiseless network part edge part intermediate node eavesdrop framework channel network noise apply error correction noisy channel apply secure network code contrast secure physical layer network coding method securely transmit message combination code operation node network give set noisy channel paper give several example network secure physical layer network coding advantage secure network code,0.5555555555555556,0.20634920634920634,0.12698412698412698,0.015873015873015872,63.0,0.0,0.0,0.0,1.0
Information Systems,Information Security,Design and Development,A New Fuzzy MCDM Framework to Evaluate E-Government Security Strategy,"Ensuring security of e-government applications and infrastructures is crucial
to maintain trust among stakeholders to store, process and exchange information
over the e-government systems. Due to dynamic and continuous threats on
e-government information security, policy makers need to perform evaluation on
existing information security strategy as to deliver trusted e-government
services. This paper presents an information security evaluation framework
based on new fuzzy multi criteria decision making (MCDM) to help policy makers
conduct comprehensive assessment of e-government security strategy.",http://arxiv.org/abs/1011.3101v1,arXiv,new fuzzy mcdm framework evaluate egovernment security strategy,ensure security egovernment application infrastructure crucial maintain trust among stakeholder store process exchange information egovernment system due dynamic continuous threat egovernment information security policy maker need perform evaluation exist information security strategy deliver trusted egovernment service paper present information security evaluation framework base new fuzzy multi criterion decision make mcdm help policy maker conduct comprehensive assessment egovernment security strategy,new fuzzy mcdm framework evaluate egovernment security strategy ensure security egovernment application infrastructure crucial maintain trust among stakeholder store process exchange information egovernment system due dynamic continuous threat egovernment information security policy maker need perform evaluation exist information security strategy deliver trusted egovernment service paper present information security evaluation framework base new fuzzy multi criterion decision make mcdm help policy maker conduct comprehensive assessment egovernment security strategy,0.6271186440677966,0.13559322033898305,0.2033898305084746,0.0,59.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Design and Development,A Cross-Layer Security Analysis for Process-Aware Information Systems,"Information security in Process-aware Information System (PAIS) relies on
many factors, including security of business process and the underlying system
and technologies. Moreover, humans can be the weakest link that creates pathway
to vulnerabilities, or the worst enemy that compromises a well-defended system.
Since a system is as secure as its weakest link, information security can only
be achieved in PAIS if all factors are secure. In this paper, we address two
research questions: how to conduct a cross-layer security analysis that couple
security concerns at business process layer as well as at the technical layer;
and how to include human factor into the security analysis for the
identification of human-oriented vulnerabilities and threats. We propose a
methodology that supports the tracking of security interdependencies between
functional, technical, and human aspects which contribute to establish a
holistic approach to information security in PAIS. We demonstrate the
applicability with a scenario from the payment card industry.",http://arxiv.org/abs/1507.03415v1,arXiv,crosslayer security analysis processaware information system,information security processaware information system pais rely many factor include security business process underlie system technology moreover human weak link create pathway vulnerability bad enemy compromise welldefended system since system secure weak link information security achieve pais factor secure paper address two research question conduct crosslayer security analysis couple security concern business process layer well technical layer include human factor security analysis identification humanoriented vulnerability threat propose methodology support tracking security interdependency functional technical human aspect contribute establish holistic approach information security pais demonstrate applicability scenario payment card industry,crosslayer security analysis processaware information system information security processaware information system pais rely many factor include security business process underlie system technology moreover human weak link create pathway vulnerability bad enemy compromise welldefended system since system secure weak link information security achieve pais factor secure paper address two research question conduct crosslayer security analysis couple security concern business process layer well technical layer include human factor security analysis identification humanoriented vulnerability threat propose methodology support tracking security interdependency functional technical human aspect contribute establish holistic approach information security pais demonstrate applicability scenario payment card industry,0.6629213483146067,0.12359550561797752,0.15730337078651685,0.011235955056179775,89.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Design and Development,Secure Web-Based Student Information Management System,"The reliability and success of any organization such as academic institution
rely on its ability to provide secure, accurate and timely data about its
operations. Erstwhile managing student information in academic institution was
done through paper-based information system, where academic records are
documented in several files that are kept in shelves. Several problems are
associated with paper-based information system. Managing information through
the manual approach require physical exertion to retrieve, alter, and re-file
the paper records. These are nonvalue added services results in data
inconsistency and redundancy, currently institutions have migrated to web-based
student information management system without considering the security
architecture of the web portal. This project seeks to ameliorates and secure
how information is being managed in Nigeria Police Academy through the
development of a secured web-based student information management system, which
has a friendly user interface that provides an easy and secure way to manage
academic information such as students information, staff information, course
registration, course materials and results. This project was developed using
Laravel 5.5 PHP Framework to provide a robust secure web-based student
information system that is not vulnerable to 2018 OWASP TOP 10 web
vulnerabilities.",http://arxiv.org/abs/2211.00072v1,arXiv,secure webbase student information management system,reliability success organization academic institution rely ability provide secure accurate timely datum operation erstwhile manage student information academic institution paperbase information system academic record document several file keep shelf several problem associate paperbased information system manage information manual approach require physical exertion retrieve alter refile paper record nonvalue add service result datum inconsistency redundancy currently institution migrate webbase student information management system without consider security architecture web portal project seek ameliorate secure information manage nigeria police academy development secure webbase student information management system friendly user interface provide easy secure way manage academic information student information staff information course registration course material result project develop use laravel php framework provide robust secure webbase student information system vulnerable owasp top web vulnerability,secure webbase student information management system reliability success organization academic institution rely ability provide secure accurate timely datum operation erstwhile manage student information academic institution paperbase information system academic record document several file keep shelf several problem associate paperbased information system manage information manual approach require physical exertion retrieve alter refile paper record nonvalue add service result datum inconsistency redundancy currently institution migrate webbase student information management system without consider security architecture web portal project seek ameliorate secure information manage nigeria police academy development secure webbase student information management system friendly user interface provide easy secure way manage academic information student information staff information course registration course material result project develop use laravel php framework provide robust secure webbase student information system vulnerable owasp top web vulnerability,0.6446280991735537,0.14049586776859505,0.1487603305785124,0.01652892561983471,121.0,1.0,0.0,0.0,0.0
Information Systems,Information Security,Theoretical / Conceptual,"On the Equivalence of Two Security Notions for Hierarchical Key
  Assignment Schemes in the Unconditional Setting","The access control problem in a hierarchy can be solved by using a
hierarchical key assignment scheme, where each class is assigned an encryption
key and some private information. A formal security analysis for hierarchical
key assignment schemes has been traditionally considered in two different
settings, i.e., the unconditionally secure and the computationally secure
setting, and with respect to two different notions: security against key
recovery (KR-security) and security with respect to key indistinguishability
(KI-security), with the latter notion being cryptographically stronger.
Recently, Freire, Paterson and Poettering proposed strong key
indistinguishability (SKI-security) as a new security notion in the
computationally secure setting, arguing that SKI-security is strictly stronger
than KI-security in such a setting. In this paper we consider the
unconditionally secure setting for hierarchical key assignment schemes. In such
a setting the security of the schemes is not based on specific unproven
computational assumptions, i.e., it relies on the theoretical impossibility of
breaking them, despite the computational power of an adversary coalition. We
prove that, in this setting, SKI-security is not stronger than KI-security,
i.e., the two notions are fully equivalent from an information-theoretic point
of view.",http://arxiv.org/abs/1402.5371v2,arXiv,equivalence two security notion hierarchical key assignment scheme unconditional setting,access control problem hierarchy solve use hierarchical key assignment scheme class assign encryption key private information formal security analysis hierarchical key assignment scheme traditionally consider two different setting unconditionally secure computationally secure setting respect two different notion security key recovery krsecurity security respect key indistinguishability kisecurity latter notion cryptographically strong recently freire paterson poettering propose strong key indistinguishability skisecurity new security notion computationally secure setting argue skisecurity strictly strong kisecurity setting paper consider unconditionally secure setting hierarchical key assignment scheme set security scheme base specific unproven computational assumption rely theoretical impossibility break despite computational power adversary coalition prove set skisecurity strong kisecurity two notion fully equivalent informationtheoretic point view,equivalence two security notion hierarchical key assignment scheme unconditional setting access control problem hierarchy solve use hierarchical key assignment scheme class assign encryption key private information formal security analysis hierarchical key assignment scheme traditionally consider two different setting unconditionally secure computationally secure setting respect two different notion security key recovery krsecurity security respect key indistinguishability kisecurity latter notion cryptographically strong recently freire paterson poettering propose strong key indistinguishability skisecurity new security notion computationally secure setting argue skisecurity strictly strong kisecurity setting paper consider unconditionally secure setting hierarchical key assignment scheme set security scheme base specific unproven computational assumption rely theoretical impossibility break despite computational power adversary coalition prove set skisecurity strong kisecurity two notion fully equivalent informationtheoretic point view,0.45871559633027525,0.13761467889908258,0.28440366972477066,0.08256880733944955,109.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Theoretical / Conceptual,"Guardians of the Web: The Evolution and Future of Website Information
  Security","Website information security has become a critical concern in the digital
age. This article explores the evolution of website information security,
examining its historical development, current practices, and future directions.
The early beginnings from the 1960s to the 1980s laid the groundwork for modern
cybersecurity, with the development of ARPANET, TCP/IP, public-key
cryptography, and the first antivirus programs. The 1990s marked a
transformative era, driven by the commercialization of the Internet and the
emergence of web-based services. As the Internet grew, so did the range and
sophistication of cyber threats, leading to advancements in security
technologies such as the Secure Sockets Layer (SSL) protocol, password
protection, and firewalls. Current practices in website information security
involve a multi-layered approach, including encryption, secure coding
practices, regular security audits, and user education. The future of website
information security is expected to be shaped by emerging technologies such as
artificial intelligence, blockchain, and quantum computing, as well as the
increasing importance of international cooperation and standardization efforts.
As cyber threats continue to evolve, ongoing research and innovation in website
information security will be essential to protect sensitive information and
maintain trust in the digital world.",http://arxiv.org/abs/2505.04308v1,arXiv,guardian web evolution future website information security,website information security become critical concern digital age article explore evolution website information security examine historical development current practice future direction early beginning lay groundwork modern cybersecurity development arpanet tcpip publickey cryptography first antivirus program mark transformative era drive commercialization internet emergence webbase service internet grow range sophistication cyber threat lead advancement security technology secure socket layer ssl protocol password protection firewall current practice website information security involve multilayere approach include encryption secure coding practice regular security audits user education future website information security expect shape emerge technology artificial intelligence blockchain quantum computing well increase importance international cooperation standardization effort cyber threat continue evolve ongoing research innovation website information security essential protect sensitive information maintain trust digital world,guardian web evolution future website information security website information security become critical concern digital age article explore evolution website information security examine historical development current practice future direction early beginning lay groundwork modern cybersecurity development arpanet tcpip publickey cryptography first antivirus program mark transformative era drive commercialization internet emergence webbase service internet grow range sophistication cyber threat lead advancement security technology secure socket layer ssl protocol password protection firewall current practice website information security involve multilayere approach include encryption secure coding practice regular security audits user education future website information security expect shape emerge technology artificial intelligence blockchain quantum computing well increase importance international cooperation standardization effort cyber threat continue evolve ongoing research innovation website information security essential protect sensitive information maintain trust digital world,0.635593220338983,0.11016949152542373,0.15254237288135594,0.00847457627118644,118.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Theoretical / Conceptual,"On the Impact of Perceived Vulnerability in the Adoption of Information
  Systems Security Innovations","A number of determinants predict the adoption of Information Systems (IS)
security innovations. Amongst, perceived vulnerability of IS security threats
has been examined in a number of past explorations. In this research, we
examined the processes pursued in analysing the relationship between perceived
vulnerability of IS security threats and the adoption of IS security
innovations. The study uses Systematic Literature Review (SLR) method to
evaluate the practice involved in examining perceived vulnerability on IS
security innovation adoption. The SLR findings revealed the appropriateness of
the existing empirical investigations of the relationship between perceived
vulnerability of IS security threats on IS security innovation adoption.
Furthermore, the SLR results confirmed that individuals who perceives
vulnerable to an IS security threat are more likely to engage in the adoption
an IS security innovation. In addition, the study validates the past studies on
the relationship between perceived vulnerability and IS security innovation
adoption.",http://arxiv.org/abs/1904.08229v1,arXiv,impact perceive vulnerability adoption information system security innovation,number determinant predict adoption information system security innovation amongst perceive vulnerability security threat examine number past exploration research examine process pursue analyse relationship perceive vulnerability security threat adoption security innovation study use systematic literature review slr method evaluate practice involve examine perceive vulnerability security innovation adoption slr finding reveal appropriateness exist empirical investigation relationship perceive vulnerability security threat security innovation adoption furthermore slr result confirm individual perceive vulnerable security threat likely engage adoption security innovation addition study validate past study relationship perceive vulnerability security innovation adoption,impact perceive vulnerability adoption information system security innovation number determinant predict adoption information system security innovation amongst perceive vulnerability security threat examine number past exploration research examine process pursue analyse relationship perceive vulnerability security threat adoption security innovation study use systematic literature review slr method evaluate practice involve examine perceive vulnerability security innovation adoption slr finding reveal appropriateness exist empirical investigation relationship perceive vulnerability security threat security innovation adoption furthermore slr result confirm individual perceive vulnerable security threat likely engage adoption security innovation addition study validate past study relationship perceive vulnerability security innovation adoption,0.6395348837209303,0.11627906976744186,0.11627906976744186,0.023255813953488372,86.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Theoretical / Conceptual,"Blockchain-based Application Security Risks: A Systematic Literature
  Review","Although the blockchain-based applications are considered to be less
vulnerable due to the nature of the distributed ledger, they did not become the
silver bullet with respect to securing the information against different
security risks. In this paper, we present a literature review on the security
risks that can be mitigated by introducing the blockchain technology, and on
the security risks that are identified in the blockchain-based applications. In
addition, we highlight the application and technology domains where these
security risks are observed. The results of this study could be seen as a
preliminary checklist of security risks when implementing blockchain-based
applications.",http://arxiv.org/abs/1912.09556v1,arXiv,blockchainbase application security risk systematic literature review,although blockchainbased application consider less vulnerable due nature distribute ledger become silver bullet respect secure information different security risk paper present literature review security risk mitigate introduce blockchain technology security risk identify blockchainbased application addition highlight application technology domain security risk observe result study could see preliminary checklist security risk implement blockchainbase application,blockchainbase application security risk systematic literature review although blockchainbased application consider less vulnerable due nature distribute ledger become silver bullet respect secure information different security risk paper present literature review security risk mitigate introduce blockchain technology security risk identify blockchainbased application addition highlight application technology domain security risk observe result study could see preliminary checklist security risk implement blockchainbase application,0.5660377358490566,0.1320754716981132,0.18867924528301888,0.018867924528301886,53.0,0.0,0.0,0.0,0.0
Information Systems,Information Security,Theoretical / Conceptual,"Factors of people-centric security climate: conceptual model and
  exploratory study in Vietnam","There is an increasing focus on the persuasive approach to develop a
people-centric security climate where employees are aware of the priority of
security and perform conscious security behaviour proactively. Employees can
evaluate the priority of security as they observe and interact with the
security features that constitute the security climate of the workplace. We
examined the fundamental challenge that not every employee could recognise
those features. In this multi-stage research, we adopted the theoretical lens
of symbolic interactionism to advance a conceptual model which explains the
relationship between organisation's social networks and the formation of
information security climate. A descriptive case study in Vietnam was then
conducted to refine the proposed model. The findings validated and extended the
dimensions of information security climate, as well as identified the relevant
organisation's social networks (i.e. information, affect, and power) that lead
to its formation.",http://arxiv.org/abs/1606.00884v1,arXiv,factor peoplecentric security climate conceptual model exploratory study vietnam,increase focus persuasive approach develop peoplecentric security climate employee aware priority security perform conscious security behaviour proactively employee evaluate priority security observe interact security feature constitute security climate workplace examine fundamental challenge every employee could recognise feature multistage research adopt theoretical lens symbolic interactionism advance conceptual model explain relationship organisation social network formation information security climate descriptive case study vietnam conduct refine propose model finding validate extend dimension information security climate well identify relevant organisation social network information affect power lead formation,factor peoplecentric security climate conceptual model exploratory study vietnam increase focus persuasive approach develop peoplecentric security climate employee aware priority security perform conscious security behaviour proactively employee evaluate priority security observe interact security feature constitute security climate workplace examine fundamental challenge every employee could recognise feature multistage research adopt theoretical lens symbolic interactionism advance conceptual model explain relationship organisation social network formation information security climate descriptive case study vietnam conduct refine propose model finding validate extend dimension information security climate well identify relevant organisation social network information affect power lead formation,0.573170731707317,0.15853658536585366,0.15853658536585366,0.024390243902439025,82.0,0.0,1.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Quantitative,"The Effects of Website Quality on Adoption of E-Government Service:
  AnEmpirical Study Applying UTAUT Model Using SEM","In today global age, e-government services have become the main channel for
online communication between the government and its citizens. They aim to
provide citizens with more accessible, accurate, real-time and high quality
services. Therefore, the quality of government websites which provide
e-services is an essential factor in the successful adoption of e-government
services by the public. This paper discusses an investigation of the effect of
the Website Quality (WQ) factor on the acceptance of using e-government
services (G2C) in the Kingdom of Saudi Arabia (KSA) by adopting the Unified
Theory of Acceptance and Use of Technology (UTAUT) Model. Survey Data collected
from 400 respondents were examined using the structural equation modelling
(SEM) technique and utilising AMOS tools. This study found that the factors
that significantly influenced the Use Behaviour of e-government services in KSA
(USE) include Performance Expectancy (PE), Effort expectancy (EE), Facilitating
Conditions (FC) and Website Quality (WQ), while the construct known Social
Influence (SI) did not. Moreover, the results confirm the importance of quality
government websites and support systems as one of the main significant and
influential factors of e-government services adoption. The results of this
study can be helpful to Saudi governmental sectors to adjust their corporate
strategies and plans to advance successful adoption and diffusion of
e-government services (G2C) in KSA.",http://arxiv.org/abs/1211.2410v1,arXiv,effect website quality adoption egovernment service anempirical study apply utaut model use sem,today global age egovernment service become main channel online communication government citizen aim provide citizen accessible accurate realtime high quality service therefore quality government website provide eservice essential factor successful adoption egovernment service public paper discuss investigation effect website quality factor acceptance use egovernment service kingdom saudi arabia ksa adopt unified theory acceptance use technology utaut model survey datum collect respondent examine use structural equation modelling sem technique utilise amos tool study find factor significantly influence use behaviour egovernment service ksa use include performance expectancy effort expectancy facilitate condition website quality construct know social influence moreover result confirm importance quality government website support system one main significant influential factor egovernment service adoption result study helpful saudi governmental sector adjust corporate strategy plan advance successful adoption diffusion egovernment service ksa,effect website quality adoption egovernment service anempirical study apply utaut model use sem today global age egovernment service become main channel online communication government citizen aim provide citizen accessible accurate realtime high quality service therefore quality government website provide eservice essential factor successful adoption egovernment service public paper discuss investigation effect website quality factor acceptance use egovernment service kingdom saudi arabia ksa adopt unified theory acceptance use technology utaut model survey datum collect respondent examine use structural equation modelling sem technique utilise amos tool study find factor significantly influence use behaviour egovernment service ksa use include performance expectancy effort expectancy facilitate condition website quality construct know social influence moreover result confirm importance quality government website support system one main significant influential factor egovernment service adoption result study helpful saudi governmental sector adjust corporate strategy plan advance successful adoption diffusion egovernment service ksa,0.5813953488372093,0.11627906976744186,0.18604651162790697,0.023255813953488372,129.0,0.0,1.0,1.0,0.0
Information Systems,E-Government and E-Commerce,Quantitative,"Analysis of Citizens Acceptance for E-government Services: Applying the
  UTAUT Model","E-government services aims to provide citizens with more accessible,
accurate, real-time and high quality services and information. Although the
public sectors in Kingdom of Saudi Arabia (KSA) have promoted their
e-Government services for many years, its uses and achievements are few.
Therefore, this paper explores the key factors of Saudi citizens acceptance
through a research survey and by gathering empirical evidence based on the
Unified Theory of Acceptance and the Use of Technology (UTAUT). Survey Data
collected from 400 respondents was examined using structural equation modelling
(SEM) technique and utilized AMOS tools. The study results explored the factors
that affect the acceptance of e-government services in KSA based on UTAUT
model. Moreover, as a result of this study an amended UTAUT model was proposed.
Such a model contributes to the discussion and development of adoption models
for technology.",http://arxiv.org/abs/1304.3157v1,arXiv,analysis citizen acceptance egovernment service apply utaut model,egovernment service aim provide citizen accessible accurate realtime high quality service information although public sector kingdom saudi arabia ksa promote egovernment service many year use achievement therefore paper explore key factor saudi citizen acceptance research survey gather empirical evidence base unified theory acceptance use technology utaut survey data collect respondent examine use structural equation modelling sem technique utilize amos tool study result explore factor affect acceptance egovernment service ksa base utaut model moreover result study amend utaut model propose model contribute discussion development adoption model technology,analysis citizen acceptance egovernment service apply utaut model egovernment service aim provide citizen accessible accurate realtime high quality service information although public sector kingdom saudi arabia ksa promote egovernment service many year use achievement therefore paper explore key factor saudi citizen acceptance research survey gather empirical evidence base unified theory acceptance use technology utaut survey data collect respondent examine use structural equation modelling sem technique utilize amos tool study result explore factor affect acceptance egovernment service ksa base utaut model moreover result study amend utaut model propose model contribute discussion development adoption model technology,0.5116279069767442,0.10465116279069768,0.13953488372093023,0.011627906976744186,86.0,0.0,1.0,1.0,1.0
Information Systems,E-Government and E-Commerce,Quantitative,A Survey on Blockchain in E-Government Services: Status and Challenges,"Blockchain technology is referred to as a very secure decentralized,
distributed ledger that records the history of any digital asset. It is being
used in numerous governmental and private sector organizations across numerous
nations. Surveying the current state of blockchain applications and
difficulties in e-government services is the goal of this review. Held to the
account are use cases for current facilities that use blockchain. Finally, it
examines the research gap in blockchain deployment and makes suggestions for
future work for additional research.",http://arxiv.org/abs/2402.02483v1,arXiv,survey blockchain egovernment service status challenge,blockchain technology refer secure decentralize distribute ledger record history digital asset use numerous governmental private sector organization across numerous nation survey current state blockchain application difficulty egovernment service goal review hold account use case current facility use blockchain finally examine research gap blockchain deployment make suggestion future work additional research,survey blockchain egovernment service status challenge blockchain technology refer secure decentralize distribute ledger record history digital asset use numerous governmental private sector organization across numerous nation survey current state blockchain application difficulty egovernment service goal review hold account use case current facility use blockchain finally examine research gap blockchain deployment make suggestion future work additional research,0.6,0.14,0.22,0.02,50.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Quantitative,A Narrative Literature Review and E-Commerce Website Research,"In this study, a narrative literature review regarding culture and e-commerce
website design has been introduced. Cultural aspect and e-commerce website
design will play a significant role for successful global e-commerce sites in
the future. Future success of businesses will rely on e-commerce. To compete in
the global e-commerce marketplace, local businesses need to focus on designing
culturally friendly e-commerce websites. To the best of my knowledge, there has
been insignificant research conducted on correlations between culture and
e-commerce website design. The research shows that there are correlations
between e-commerce, culture, and website design. The result of the study
indicates that cultural aspects influence e-commerce website design. This study
aims to deliver a reference source for information systems and information
technology researchers interested in culture and e-commerce website design, and
will show lessfocused research areas in addition to future directions.",http://arxiv.org/abs/1806.07833v2,arXiv,narrative literature review ecommerce website research,study narrative literature review regard culture ecommerce website design introduce cultural aspect ecommerce website design play significant role successful global ecommerce site future future success business rely ecommerce compete global ecommerce marketplace local business need focus design culturally friendly ecommerce website good knowledge insignificant research conduct correlation culture ecommerce website design research show correlation ecommerce culture website design result study indicate cultural aspect influence ecommerce website design study aim deliver reference source information system information technology researcher interested culture ecommerce website design show lessfocuse research area addition future direction,narrative literature review ecommerce website research study narrative literature review regard culture ecommerce website design introduce cultural aspect ecommerce website design play significant role successful global ecommerce site future future success business rely ecommerce compete global ecommerce marketplace local business need focus design culturally friendly ecommerce website good knowledge insignificant research conduct correlation culture ecommerce website design research show correlation ecommerce culture website design result study indicate cultural aspect influence ecommerce website design study aim deliver reference source information system information technology researcher interested culture ecommerce website design show lessfocuse research area addition future direction,0.6629213483146067,0.11235955056179775,0.15730337078651685,0.011235955056179775,89.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Quantitative,Adoption of e-government in the Republic of Kazakhstan,"This paper identifies factors that influence Kazakhstan's e-Government portal
usage. It determines challenges encountered by citizens while using the portal.
Targeted respondents for the web-based questionnaire survey were the citizens
of Kazakhstan. The technology acceptance model was used as a methodology to
measure attitude towards portal usage. In addition, this paper discusses the
barriers which were experienced by the respondents and can prevent the
successful adoption of e-Government initiative. The results of the analysis
demonstrate that awareness among citizens is high, i.e. the majority of people
have visited it at least once and they perceive the portal to be useful, but
only a limited percentage of citizens' use it on the regular basis. Further,
paper can be used to help IT managers of the portal to improve management of
informational content and maintain a more effective adoption among citizens.",http://arxiv.org/abs/1802.06951v1,arXiv,adoption egovernment republic kazakhstan,paper identify factor influence kazakhstan egovernment portal usage determine challenge encounter citizen use portal target respondent webbased questionnaire survey citizen kazakhstan technology acceptance model use methodology measure attitude towards portal usage addition paper discuss barrier experience respondent prevent successful adoption egovernment initiative result analysis demonstrate awareness among citizen high majority people visit least perceive portal useful limited percentage citizen use regular basis far paper use help manager portal improve management informational content maintain effective adoption among citizen,adoption egovernment republic kazakhstan paper identify factor influence kazakhstan egovernment portal usage determine challenge encounter citizen use portal target respondent webbased questionnaire survey citizen kazakhstan technology acceptance model use methodology measure attitude towards portal usage addition paper discuss barrier experience respondent prevent successful adoption egovernment initiative result analysis demonstrate awareness among citizen high majority people visit least perceive portal useful limited percentage citizen use regular basis far paper use help manager portal improve management informational content maintain effective adoption among citizen,0.5454545454545454,0.14285714285714285,0.18181818181818182,0.025974025974025976,77.0,1.0,0.0,0.0,1.0
Information Systems,E-Government and E-Commerce,Qualitative,"Factors Enhancing E-Government Service Gaps in a Developing Country
  Context","Globally, the discourse of e-government has gathered momentum in public
service delivery. No country has been left untouched in the implementation of
e-government. Several government departments and agencies are now using
information and communication technology (ICTs) to deliver government services
and information to citizens, other government departments, and businesses.
However, most of the government departments have not provided all of their
services electronically or at least the most important ones. Thus, this creates
a phenomenon of e-government service gaps. The objective of this study was to
investigate the contextual factors enhancing e-government service gaps in a
developing country. To achieve this aim, the TOE framework was employed
together with a qualitative case study to guide data collection and analysis.
The data was collected through semi-structured interviews from government
employees who are involved in the implementation of e-government services in
Zimbabwe as well as from citizens and businesses. Eleven (11) factors were
identified and grouped under the TOE framework. This research contributes
significantly to the implementation and utilisation of e-government services in
Zimbabwe. The study also contributes to providing a strong theoretical
understanding of the factors that enhance e-government service gaps explored in
the research model.",http://arxiv.org/abs/2108.09803v1,arXiv,factor enhance egovernment service gap develop country context,globally discourse egovernment gather momentum public service delivery country leave untouched implementation egovernment several government department agency use information communication technology ict deliver government service information citizen government department business however government department provide service electronically least important one thus create phenomenon egovernment service gap objective study investigate contextual factor enhance egovernment service gap develop country achieve aim toe framework employ together qualitative case study guide data collection analysis datum collect semistructure interview government employee involve implementation egovernment service zimbabwe well citizen business eleven factor identify group toe framework research contribute significantly implementation utilisation egovernment service zimbabwe study also contribute provide strong theoretical understanding factor enhance egovernment service gap explore research model,factor enhance egovernment service gap develop country context globally discourse egovernment gather momentum public service delivery country leave untouched implementation egovernment several government department agency use information communication technology ict deliver government service information citizen government department business however government department provide service electronically least important one thus create phenomenon egovernment service gap objective study investigate contextual factor enhance egovernment service gap develop country achieve aim toe framework employ together qualitative case study guide data collection analysis datum collect semistructure interview government employee involve implementation egovernment service zimbabwe well citizen business eleven factor identify group toe framework research contribute significantly implementation utilisation egovernment service zimbabwe study also contribute provide strong theoretical understanding factor enhance egovernment service gap explore research model,0.5982142857142857,0.16071428571428573,0.15178571428571427,0.07142857142857142,112.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Qualitative,"Improving municipal responsiveness through AI-powered image analysis in
  E-Government","Integration of Machine Learning (ML) techniques into public administration
marks a new and transformative era for e-government systems. While
traditionally e-government studies were focusing on text-based interactions,
this one explores the innovative application of ML for image analysis, an
approach that enables governments to address citizen petitions more
efficiently. By using image classification and object detection algorithms, the
model proposed in this article supports public institutions in identifying and
fast responding to evidence submitted by citizens in picture format, such as
infrastructure issues, environmental concerns or other urban issues that
citizens might face. The research also highlights the Jevons Paradox as a
critical factor, wherein increased efficiency from the citizen side (especially
using mobile platforms and apps) may generate higher demand which should lead
to scalable and robust solutions. Using as a case study a Romanian municipality
who provided datasets of citizen-submitted images, the author analysed and
proved that ML can improve accuracy and responsiveness of public institutions.
The findings suggest that adopting ML for e-petition systems can not only
enhance citizen participation but also speeding up administrative processes,
paving the way for more transparent and effective governance. This study
contributes to the discourse on e-government 3.0 by showing the potential of
Artificial Intelligence (AI) to transform public service delivery, ensuring
sustainable (and scalable) solutions for the growing demands of modern urban
governance.",http://arxiv.org/abs/2504.08972v1,arXiv,improve municipal responsiveness aipowere image analysis egovernment,integration machine learning technique public administration mark new transformative era egovernment system traditionally egovernment study focus textbase interaction one explore innovative application image analysis approach enable government address citizen petition efficiently use image classification object detection algorithm model propose article support public institution identify fast respond evidence submit citizen picture format infrastructure issue environmental concern urban issue citizen might face research also highlight jevon paradox critical factor wherein increase efficiency citizen side especially use mobile platform app may generate high demand lead scalable robust solution use case study romanian municipality provide dataset citizensubmitte image author analyse prove improve accuracy responsiveness public institution finding suggest adopt epetition system enhance citizen participation also speed administrative process pave way transparent effective governance study contribute discourse egovernment show potential artificial intelligence transform public service delivery ensure sustainable scalable solution grow demand modern urban governance,improve municipal responsiveness aipowere image analysis egovernment integration machine learning technique public administration mark new transformative era egovernment system traditionally egovernment study focus textbase interaction one explore innovative application image analysis approach enable government address citizen petition efficiently use image classification object detection algorithm model propose article support public institution identify fast respond evidence submit citizen picture format infrastructure issue environmental concern urban issue citizen might face research also highlight jevon paradox critical factor wherein increase efficiency citizen side especially use mobile platform app may generate high demand lead scalable robust solution use case study romanian municipality provide dataset citizensubmitte image author analyse prove improve accuracy responsiveness public institution finding suggest adopt epetition system enhance citizen participation also speed administrative process pave way transparent effective governance study contribute discourse egovernment show potential artificial intelligence transform public service delivery ensure sustainable scalable solution grow demand modern urban governance,0.5142857142857142,0.18571428571428572,0.18571428571428572,0.03571428571428571,140.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Qualitative,"How Retailers at different Stages of E-Commerce Maturity Evaluate Their
  Entry to E-Commerce Activities?","This paper investigates how retailers at different stages of e-commerce
maturity evaluate their entry to e-commerce activities. The study was conducted
using qualitative approach interviewing 16 retailers in Saudi Arabia. It comes
up with 22 factors that are believed the most influencing factors for retailers
in Saudi Arabia. Interestingly, there seem to be differences between retailers
in companies at different maturity stages in terms of having different
attitudes regarding the issues of using e-commerce. The businesses that have
reached a high stage of e-commerce maturity provide practical evidence of
positive and optimistic attitudes and practices regarding use of e-commerce,
whereas the businesses that have not reached higher levels of maturity provide
practical evidence of more negative and pessimistic attitudes and practices.
The study, therefore, should contribute to efforts leading to greater
e-commerce development in Saudi Arabia and other countries with similar
context.",http://arxiv.org/abs/1503.05172v1,arXiv,retailer different stage ecommerce maturity evaluate entry ecommerce activity,paper investigate retailer different stage ecommerce maturity evaluate entry ecommerce activity study conduct use qualitative approach interview retailer saudi arabia come factor believe influence factor retailer saudi arabia interestingly seem difference retailer company different maturity stage term different attitude regard issue use ecommerce business reach high stage ecommerce maturity provide practical evidence positive optimistic attitude practice regard use ecommerce whereas business reach high level maturity provide practical evidence negative pessimistic attitude practice study therefore contribute effort lead great ecommerce development saudi arabia country similar context,retailer different stage ecommerce maturity evaluate entry ecommerce activity paper investigate retailer different stage ecommerce maturity evaluate entry ecommerce activity study conduct use qualitative approach interview retailer saudi arabia come factor believe influence factor retailer saudi arabia interestingly seem difference retailer company different maturity stage term different attitude regard issue use ecommerce business reach high stage ecommerce maturity provide practical evidence positive optimistic attitude practice regard use ecommerce whereas business reach high level maturity provide practical evidence negative pessimistic attitude practice study therefore contribute effort lead great ecommerce development saudi arabia country similar context,0.5529411764705883,0.1411764705882353,0.16470588235294117,0.023529411764705882,85.0,0.0,3.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Qualitative,"Achieving employees agile response in e-governance: Exploring the
  synergy of technology and group collaboration","The transformation of technology and collaboration methods driven by the
e-government system forces government employees to reconsider their daily
workflow and collaboration with colleagues. Despite the extensive existing
knowledge of technology usage and collaboration, there are limitations in
explaining the synergy between technology usage and group collaboration in
achieving agile response from the perspective of government employees,
particularly in the e-government setting. To address these challenges, this
study provides a holistic understanding of the successful pathway to agile
response in e-governance from the perspective of government employees. This
study explores a dual path to achieve agile response in e-governance through
qualitative analysis, involving 34 in-depth semi-structured interviews with
government employees in several government sectors in China. By employing three
rounds of coding processes and adopting Interpretative Structural Modeling
(ISM), this study identifies the five-layer mechanisms leading to agile
response in e-governance, considering both government employee technology usage
and group collaboration perspectives. Findings of this study provides
suggestions and implications for achieving agile response in e-governance.",http://arxiv.org/abs/2411.15875v1,arXiv,achieve employee agile response egovernance explore synergy technology group collaboration,transformation technology collaboration method drive egovernment system force government employee reconsider daily workflow collaboration colleague despite extensive exist knowledge technology usage collaboration limitation explain synergy technology usage group collaboration achieve agile response perspective government employee particularly egovernment setting address challenge study provide holistic understanding successful pathway agile response egovernance perspective government employee study explore dual path achieve agile response egovernance qualitative analysis involve indepth semistructure interview government employee several government sector china employ three round code process adopt interpretative structural modeling ism study identify fivelayer mechanism lead agile response egovernance consider government employee technology usage group collaboration perspective finding study provide suggestion implication achieve agile response egovernance,achieve employee agile response egovernance explore synergy technology group collaboration transformation technology collaboration method drive egovernment system force government employee reconsider daily workflow collaboration colleague despite extensive exist knowledge technology usage collaboration limitation explain synergy technology usage group collaboration achieve agile response perspective government employee particularly egovernment setting address challenge study provide holistic understanding successful pathway agile response egovernance perspective government employee study explore dual path achieve agile response egovernance qualitative analysis involve indepth semistructure interview government employee several government sector china employ three round code process adopt interpretative structural modeling ism study identify fivelayer mechanism lead agile response egovernance consider government employee technology usage group collaboration perspective finding study provide suggestion implication achieve agile response egovernance,0.6261682242990654,0.17757009345794392,0.14018691588785046,0.009345794392523364,107.0,0.0,1.0,1.0,0.0
Information Systems,E-Government and E-Commerce,Qualitative,"On the combination of static analysis for software security assessment
  -- a case study of an open-source e-government project","Static Application Security Testing (SAST) is a popular quality assurance
technique in software engineering. However, integrating SAST tools into
industry-level product development and security assessment poses various
technical and managerial challenges. In this work, we reported a longitudinal
case study of adopting SAST as a part of a human-driven security assessment for
an open-source e-government project. We described how SASTs are selected,
evaluated, and combined into a novel approach for software security assessment.
The approach was preliminarily evaluated using semi-structured interviews. Our
result shows that (1) while some SAST tools out-perform others, it is possible
to achieve better performance by combining more than one SAST tools and (2)
SAST tools should be used towards a practical performance and in the
combination with triangulated approaches for human-driven vulnerability
assessment in real-world projects.",http://arxiv.org/abs/2103.08010v2,arXiv,combination static analysis software security assessment case study opensource egovernment project,static application security testing sast popular quality assurance technique software engineering however integrate sast tool industrylevel product development security assessment pose various technical managerial challenge work report longitudinal case study adopt sast part humandriven security assessment opensource egovernment project describe sast select evaluate combine novel approach software security assessment approach preliminarily evaluate use semistructure interview result show sast tool outperform possible achieve well performance combine one sast tool sast tool use towards practical performance combination triangulate approach humandriven vulnerability assessment realworld project,combination static analysis software security assessment case study opensource egovernment project static application security testing sast popular quality assurance technique software engineering however integrate sast tool industrylevel product development security assessment pose various technical managerial challenge work report longitudinal case study adopt sast part humandriven security assessment opensource egovernment project describe sast select evaluate combine novel approach software security assessment approach preliminarily evaluate use semistructure interview result show sast tool outperform possible achieve well performance combine one sast tool sast tool use towards practical performance combination triangulate approach humandriven vulnerability assessment realworld project,0.6707317073170732,0.0975609756097561,0.14634146341463414,0.024390243902439025,82.0,1.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Mixed Methods,"Empirical Study of Sustaining the Actualized Value Propositions of
  Implemented E-Government Projects in Sub-Saharan Africa","Governments in sub-Saharan Africa have implemented e-Government projects.
Actualizing the value propositions and sustaining such values are becoming
problematic. Some scanty studies on the value propositions of implemented
e-Government projects did not consider actualization of the values. Besides,
such studies lack theoretical underpinnings, the identification, and measure of
what constitutes actualized values. Neither did they capture what mechanisms
could sustain the actualized values nor the contextual conditions enabling its
sustainability. Consequently, using a concept-centric systematic review, we
identified the value proposition of such implemented projects. By drawing from
theories of affordance actualization, realist evaluation (RE) theory,
self-determination theory, and sustainability framework for e-Government
success. We conducted a RE of the implemented e-Government projects in Rwanda
using RE as a methodology in three phases. In phase one, we developed the
initial program theory (IPT), in phase two, we used contingent valuation as a
quantitative approach and realist interview as qualitative method to validate
the IPT. Lastly, in the third phase, we synthesized the results of the two
investigative case studies to develop the actualized values sustainability
framework. Such framework encapsulates, the actualized value propositions,
mechanisms and enabling conditions in interactions to sustain the value
propositions discovered in the e-Government investigative contexts.",http://arxiv.org/abs/2108.09769v1,arXiv,empirical study sustain actualized value proposition implement egovernment project subsaharan africa,government subsaharan africa implement egovernment project actualize value proposition sustain value become problematic scanty study value proposition implement egovernment project consider actualization value besides study lack theoretical underpinning identification measure constitute actualized value neither capture mechanism could sustain actualized value contextual condition enable sustainability consequently use conceptcentric systematic review identify value proposition implement project draw theory affordance actualization realist evaluation theory selfdetermination theory sustainability framework egovernment success conduct implement egovernment project rwanda use methodology three phase phase one develop initial program theory ipt phase two use contingent valuation quantitative approach realist interview qualitative method validate ipt lastly third phase synthesize result two investigative case study develop actualized value sustainability framework framework encapsulate actualized value proposition mechanism enable condition interaction sustain value proposition discover egovernment investigative contexts,empirical study sustain actualized value proposition implement egovernment project subsaharan africa government subsaharan africa implement egovernment project actualize value proposition sustain value become problematic scanty study value proposition implement egovernment project consider actualization value besides study lack theoretical underpinning identification measure constitute actualized value neither capture mechanism could sustain actualized value contextual condition enable sustainability consequently use conceptcentric systematic review identify value proposition implement project draw theory affordance actualization realist evaluation theory selfdetermination theory sustainability framework egovernment success conduct implement egovernment project rwanda use methodology three phase phase one develop initial program theory ipt phase two use contingent valuation quantitative approach realist interview qualitative method validate ipt lastly third phase synthesize result two investigative case study develop actualized value sustainability framework framework encapsulate actualized value proposition mechanism enable condition interaction sustain value proposition discover egovernment investigative contexts,0.5873015873015873,0.1349206349206349,0.1746031746031746,0.015873015873015872,126.0,0.0,1.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Mixed Methods,"Barriers facing e-service adopting and implementation at local
  environment level in Nigeria","E-Government services offer a great deal of potential to improve government
activities and citizen support. However, there is a lack of research covering
E-Government services at the local government level, particularly in developing
countries. However, implementing successful E-Service technology in this part
of the world will not come without its barriers considering the unstable and
fragile economies in most developing countries. The research aim is to identify
the barriers facing E-Service adoption and implementation at a local
environment level, using Nigeria as a case example.
  This thesis adopts an interpretive paradigm and uses action research. It
consists of a large field study in Nigeria (interviews), an online survey of
government officials, online focus groups, and analyses government documents
and E-Service initiatives. A structured literature review method consisted of
sifting through 3,245 papers. The main theoretical tools used in this thesis
are the diffusion of innovation (DOI) theory and the theory of change.",http://arxiv.org/abs/2406.15375v1,arXiv,barrier face eservice adopt implementation local environment level nigeria,egovernment service offer great deal potential improve government activity citizen support however lack research cover egovernment service local government level particularly develop country however implement successful eservice technology part world come without barrier consider unstable fragile economy develop country research aim identify barrier face eservice adoption implementation local environment level use nigeria case example thesis adopt interpretive paradigm use action research consist large field study nigeria interview online survey government official online focus group analyse government document eservice initiative structured literature review method consist sift paper main theoretical tool use thesis diffusion innovation doi theory theory change,barrier face eservice adopt implementation local environment level nigeria egovernment service offer great deal potential improve government activity citizen support however lack research cover egovernment service local government level particularly develop country however implement successful eservice technology part world come without barrier consider unstable fragile economy develop country research aim identify barrier face eservice adoption implementation local environment level use nigeria case example thesis adopt interpretive paradigm use action research consist large field study nigeria interview online survey government official online focus group analyse government document eservice initiative structured literature review method consist sift paper main theoretical tool use thesis diffusion innovation doi theory theory change,0.5773195876288659,0.13402061855670103,0.15463917525773196,0.030927835051546393,97.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Mixed Methods,The Missing Link: Identifying Digital Intermediaries in E-Government,"The digitalization of public administration has advanced significantly on a
global scale. Many governments now view digital platforms as essential for
improving the delivery of public services and fostering direct communication
between citizens and public institutions. However, this view overlooks the role
played by digital intermediaries significantly shape the provision of
e-government services. Using Chile as a case study, we analyze these
intermediaries through a national survey on digitalization, we find five types
of intermediaries: family members, peers, political figures, bureaucrats, and
community leaders. The first two classes comprise close intermediaries, while
the latter three comprise hierarchical intermediaries. Our findings suggest
that all these intermediaries are a critical but underexplored element in the
digitalization of public administration.",http://arxiv.org/abs/2501.10846v1,arXiv,missing link identify digital intermediary egovernment,digitalization public administration advance significantly global scale many government view digital platform essential improve delivery public service foster direct communication citizen public institution however view overlook role play digital intermediary significantly shape provision egovernment service use chile case study analyze intermediary national survey digitalization find five type intermediary family member peer political figure bureaucrat community leader first two class comprise close intermediary latter three comprise hierarchical intermediary finding suggest intermediary critical underexplored element digitalization public administration,missing link identify digital intermediary egovernment digitalization public administration advance significantly global scale many government view digital platform essential improve delivery public service foster direct communication citizen public institution however view overlook role play digital intermediary significantly shape provision egovernment service use chile case study analyze intermediary national survey digitalization find five type intermediary family member peer political figure bureaucrat community leader first two class comprise close intermediary latter three comprise hierarchical intermediary finding suggest intermediary critical underexplored element digitalization public administration,0.4605263157894737,0.11842105263157894,0.27631578947368424,0.05263157894736842,76.0,0.0,1.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Mixed Methods,"Regional Pilot Study to Evaluate e-Readiness and Local e-Government
  Services","The concept of local e-Government has become a key factor for delivering
services in an efficient, cost effective, transparent and convenient way, in
circumstances where a) citizens do not have enough time available to
communicate with local authorities in order to perform their responsibilities
and needs, and b) information and communication technologies significantly
facilitate administrative procedures and citizens-government interaction. This
paper aims to identify e-services that local authorities provide, and to
investigate their readiness for delivering these services. A pilot research has
been conducted to identify the offer of e-services by local authorities, along
with e-readiness in municipalities of the Pelagonia region in the Republic of
Macedonia. The survey was carried out by means of structured interview
questions based on a modified model proposed by Partnership on Measuring ICT
for Development - web analysis of municipal websites in the region has been
conducted, as well. The study reveals uneven distribution according to the age
group of users, lack of reliability and confidence for processing the needs and
requests electronically by a large part of the population, and improperly
developed set of ICT tools by local governments for providing a variety of
services that can be fully processed electronically.",http://arxiv.org/abs/1406.7866v1,arXiv,regional pilot study evaluate ereadiness local egovernment service,concept local egovernment become key factor deliver service efficient cost effective transparent convenient way circumstance citizen enough time available communicate local authority order perform responsibility need information communication technology significantly facilitate administrative procedure citizensgovernment interaction paper aim identify eservice local authority provide investigate readiness deliver service pilot research conduct identify offer eservice local authority along ereadiness municipality pelagonia region republic macedonia survey carry mean structured interview question base modify model propose partnership measure ict development web analysis municipal website region conduct well study reveal uneven distribution accord age group user lack reliability confidence process need request electronically large part population improperly develop set ict tool local government provide variety service fully process electronically,regional pilot study evaluate ereadiness local egovernment service concept local egovernment become key factor deliver service efficient cost effective transparent convenient way circumstance citizen enough time available communicate local authority order perform responsibility need information communication technology significantly facilitate administrative procedure citizensgovernment interaction paper aim identify eservice local authority provide investigate readiness deliver service pilot research conduct identify offer eservice local authority along ereadiness municipality pelagonia region republic macedonia survey carry mean structured interview question base modify model propose partnership measure ict development web analysis municipal website region conduct well study reveal uneven distribution accord age group user lack reliability confidence process need request electronically large part population improperly develop set ict tool local government provide variety service fully process electronically,0.5398230088495575,0.1415929203539823,0.19469026548672566,0.05309734513274336,113.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Mixed Methods,Product Knowledge Graph Embedding for E-commerce,"In this paper, we propose a new product knowledge graph (PKG) embedding
approach for learning the intrinsic product relations as product knowledge for
e-commerce. We define the key entities and summarize the pivotal product
relations that are critical for general e-commerce applications including
marketing, advertisement, search ranking and recommendation. We first provide a
comprehensive comparison between PKG and ordinary knowledge graph (KG) and then
illustrate why KG embedding methods are not suitable for PKG learning. We
construct a self-attention-enhanced distributed representation learning model
for learning PKG embeddings from raw customer activity data in an end-to-end
fashion. We design an effective multi-task learning schema to fully leverage
the multi-modal e-commerce data. The Poincare embedding is also employed to
handle complex entity structures. We use a real-world dataset from
grocery.walmart.com to evaluate the performances on knowledge completion,
search ranking and recommendation. The proposed approach compares favourably to
baselines in knowledge completion and downstream tasks.",http://arxiv.org/abs/1911.12481v1,arXiv,product knowledge graph embed ecommerce,paper propose new product knowledge graph pkg embed approach learn intrinsic product relation product knowledge ecommerce define key entity summarize pivotal product relation critical general ecommerce application include marketing advertisement search ranking recommendation first provide comprehensive comparison pkg ordinary knowledge graph illustrate embedding method suitable pkg learn construct selfattentionenhance distribute representation learning model learn pkg embedding raw customer activity datum endtoend fashion design effective multitask learn schema fully leverage multimodal ecommerce data poincare embed also employ handle complex entity structure use realworld dataset grocerywalmartcom evaluate performance knowledge completion search rank recommendation propose approach compare favourably baseline knowledge completion downstream task,product knowledge graph embed ecommerce paper propose new product knowledge graph pkg embed approach learn intrinsic product relation product knowledge ecommerce define key entity summarize pivotal product relation critical general ecommerce application include marketing advertisement search ranking recommendation first provide comprehensive comparison pkg ordinary knowledge graph illustrate embedding method suitable pkg learn construct selfattentionenhance distribute representation learning model learn pkg embedding raw customer activity datum endtoend fashion design effective multitask learn schema fully leverage multimodal ecommerce data poincare embed also employ handle complex entity structure use realworld dataset grocerywalmartcom evaluate performance knowledge completion search rank recommendation propose approach compare favourably baseline knowledge completion downstream task,0.56,0.2,0.14,0.04,100.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Design and Development,A New Fuzzy MCDM Framework to Evaluate E-Government Security Strategy,"Ensuring security of e-government applications and infrastructures is crucial
to maintain trust among stakeholders to store, process and exchange information
over the e-government systems. Due to dynamic and continuous threats on
e-government information security, policy makers need to perform evaluation on
existing information security strategy as to deliver trusted e-government
services. This paper presents an information security evaluation framework
based on new fuzzy multi criteria decision making (MCDM) to help policy makers
conduct comprehensive assessment of e-government security strategy.",http://arxiv.org/abs/1011.3101v1,arXiv,new fuzzy mcdm framework evaluate egovernment security strategy,ensure security egovernment application infrastructure crucial maintain trust among stakeholder store process exchange information egovernment system due dynamic continuous threat egovernment information security policy maker need perform evaluation exist information security strategy deliver trusted egovernment service paper present information security evaluation framework base new fuzzy multi criterion decision make mcdm help policy maker conduct comprehensive assessment egovernment security strategy,new fuzzy mcdm framework evaluate egovernment security strategy ensure security egovernment application infrastructure crucial maintain trust among stakeholder store process exchange information egovernment system due dynamic continuous threat egovernment information security policy maker need perform evaluation exist information security strategy deliver trusted egovernment service paper present information security evaluation framework base new fuzzy multi criterion decision make mcdm help policy maker conduct comprehensive assessment egovernment security strategy,0.6271186440677966,0.13559322033898305,0.2033898305084746,0.0,59.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Design and Development,"Semantic-Driven e-Government: Application of Uschold and King Ontology
  Building Methodology for Semantic Ontology Models Development","Electronic government (e-government) has been one of the most active areas of
ontology development during the past six years. In e-government, ontologies are
being used to describe and specify e-government services (e-services) because
they enable easy composition, matching, mapping and merging of various
e-government services. More importantly, they also facilitate the semantic
integration and interoperability of e-government services. However, it is still
unclear in the current literature how an existing ontology building methodology
can be applied to develop semantic ontology models in a government service
domain. In this paper the Uschold and King ontology building methodology is
applied to develop semantic ontology models in a government service domain.
Firstly, the Uschold and King methodology is presented, discussed and applied
to build a government domain ontology. Secondly, the domain ontology is
evaluated for semantic consistency using its semi-formal representation in
Description Logic. Thirdly, an alignment of the domain ontology with the
Descriptive Ontology for Linguistic and Cognitive Engineering (DOLCE) upper
level ontology is drawn to allow its wider visibility and facilitate its
integration with existing metadata standard. Finally, the domain ontology is
formally written in Web Ontology Language (OWL) to enable its automatic
processing by computers. The study aims to provide direction for the
application of existing ontology building methodologies in the Semantic Web
development processes of e-government domain specific ontology models; which
would enable their repeatability in other e-government projects and strengthen
the adoption of semantic technologies in e-government.",http://arxiv.org/abs/1111.1941v1,arXiv,semanticdriven egovernment application uschold king ontology building methodology semantic ontology model development,electronic government egovernment one active area ontology development past six year egovernment ontology use describe specify egovernment service eservice enable easy composition matching mapping merging various egovernment service importantly also facilitate semantic integration interoperability egovernment service however still unclear current literature exist ontology building methodology apply develop semantic ontology model government service domain paper uschold king ontology building methodology apply develop semantic ontology model government service domain firstly uschold king methodology present discuss apply build government domain ontology secondly domain ontology evaluate semantic consistency use semiformal representation description logic thirdly alignment domain ontology descriptive ontology linguistic cognitive engineering dolce upper level ontology draw allow wide visibility facilitate integration exist metadata standard finally domain ontology formally write web ontology language owl enable automatic processing computer study aim provide direction application exist ontology building methodology semantic web development process egovernment domain specific ontology model would enable repeatability egovernment project strengthen adoption semantic technology egovernment,semanticdriven egovernment application uschold king ontology building methodology semantic ontology model development electronic government egovernment one active area ontology development past six year egovernment ontology use describe specify egovernment service eservice enable easy composition matching mapping merging various egovernment service importantly also facilitate semantic integration interoperability egovernment service however still unclear current literature exist ontology building methodology apply develop semantic ontology model government service domain paper uschold king ontology building methodology apply develop semantic ontology model government service domain firstly uschold king methodology present discuss apply build government domain ontology secondly domain ontology evaluate semantic consistency use semiformal representation description logic thirdly alignment domain ontology descriptive ontology linguistic cognitive engineering dolce upper level ontology draw allow wide visibility facilitate integration exist metadata standard finally domain ontology formally write web ontology language owl enable automatic processing computer study aim provide direction application exist ontology building methodology semantic web development process egovernment domain specific ontology model would enable repeatability egovernment project strengthen adoption semantic technology egovernment,0.5723684210526315,0.14473684210526316,0.16447368421052633,0.05921052631578947,152.0,0.0,0.0,1.0,1.0
Information Systems,E-Government and E-Commerce,Design and Development,An Innovative Approach for E-Government Transformation,"Despite the immeasurable investment in e-government initiatives throughout
the world, such initiatives have yet to succeed in fully meeting expectations
and desired outcomes. A key objective of this research article is to support
the government of the UAE in realizing its vision of e-government
transformation. It presents an innovative framework to support e-government
implementation, which was developed from a practitioner's perspective and based
on learnings from numerous e-government practices around the globe. The
framework presents an approach to guide governments worldwide, and UAE in
particular, to develop a top down strategy and leverage technology in order
realize its long term goal of e-government transformation. The study also
outlines the potential role of modern national identity schemes in enabling the
transformation of traditional identities into digital identities. The work
presented in this study is envisaged to help bridge the gap between policy
makers and implementers, by providing greater clarity and reducing misalignment
on key elements of e-government transformation. In the hands of leaders that
have a strong will to invest in e-government transformation, the work presented
in this study is envisaged to become a powerful tool to communicate and
coordinate initiatives, and provide a clear visualization of an integrated
approach to e-government transformation.",http://arxiv.org/abs/1105.6358v1,arXiv,innovative approach egovernment transformation,despite immeasurable investment egovernment initiative throughout world initiative yet succeed fully meet expectation desire outcome key objective research article support government uae realize vision egovernment transformation present innovative framework support egovernment implementation develop practitioner perspective base learning numerous egovernment practice around globe framework present approach guide government worldwide uae particular develop top strategy leverage technology order realize long term goal egovernment transformation study also outline potential role modern national identity scheme enable transformation traditional identity digital identity work present study envisage help bridge gap policy maker implementer provide great clarity reduce misalignment key element egovernment transformation hand leader strong invest egovernment transformation work present study envisage become powerful tool communicate coordinate initiative provide clear visualization integrate approach egovernment transformation,innovative approach egovernment transformation despite immeasurable investment egovernment initiative throughout world initiative yet succeed fully meet expectation desire outcome key objective research article support government uae realize vision egovernment transformation present innovative framework support egovernment implementation develop practitioner perspective base learning numerous egovernment practice around globe framework present approach guide government worldwide uae particular develop top strategy leverage technology order realize long term goal egovernment transformation study also outline potential role modern national identity scheme enable transformation traditional identity digital identity work present study envisage help bridge gap policy maker implementer provide great clarity reduce misalignment key element egovernment transformation hand leader strong invest egovernment transformation work present study envisage become powerful tool communicate coordinate initiative provide clear visualization integrate approach egovernment transformation,0.5546218487394958,0.14285714285714285,0.226890756302521,0.03361344537815126,119.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Design and Development,"Electronic-government in Saudi Arabia: A positive revolution in the
  peninsula","The informatization practice of countries all over the world has shown that
the level of a government's informatization is one main factor that can affect
its international competitive power. At present, e-government construction is
regarded as one of the most important tasks for the national economy and
society upliftment and informatization in Saudi Arabia. Unlike the traditional
governments, an e-government takes on a new look with its framework and
operation mode more suitable for the contemporary era. In fact, it is a basic
national strategy to promote Saudi Arabia's informatization by means of
e-government construction. This talk firstly introduces the basic concepts and
relevant viewpoints of egovernment, then reviews the development process of
e-government in Saudi Arabia, and describes the current states, development
strategies of e-government in Saudi Arabia. And also review e-government
maturity models and synthesize them e-government maturity models are
investigated, in which the authors have proposed the Delloite's six-stage
model, Layne and Lee four-stage model and Accenture five-stage model. So, the
main e-government maturity stages are: online presence, interaction,
transaction, transformation and digital democracy. After that, according to
many references, the main technologies which are used in each stage are
summarized.",http://arxiv.org/abs/1205.3986v1,arXiv,electronicgovernment saudi arabia positive revolution peninsula,informatization practice country world show level government informatization one main factor affect international competitive power present egovernment construction regard one important task national economy society upliftment informatization saudi arabia unlike traditional government egovernment take new look framework operation mode suitable contemporary era fact basic national strategy promote saudi arabias informatization mean egovernment construction talk firstly introduce basic concept relevant viewpoint egovernment review development process egovernment saudi arabia describe current state development strategy egovernment saudi arabia also review egovernment maturity model synthesize egovernment maturity model investigate author propose delloite sixstage model layne lee fourstage model accenture fivestage model main egovernment maturity stage online presence interaction transaction transformation digital democracy accord many reference main technology use stage summarize,electronicgovernment saudi arabia positive revolution peninsula informatization practice country world show level government informatization one main factor affect international competitive power present egovernment construction regard one important task national economy society upliftment informatization saudi arabia unlike traditional government egovernment take new look framework operation mode suitable contemporary era fact basic national strategy promote saudi arabias informatization mean egovernment construction talk firstly introduce basic concept relevant viewpoint egovernment review development process egovernment saudi arabia describe current state development strategy egovernment saudi arabia also review egovernment maturity model synthesize egovernment maturity model investigate author propose delloite sixstage model layne lee fourstage model accenture fivestage model main egovernment maturity stage online presence interaction transaction transformation digital democracy accord many reference main technology use stage summarize,0.49137931034482757,0.11206896551724138,0.22413793103448276,0.017241379310344827,116.0,0.0,3.0,0.0,1.0
Information Systems,E-Government and E-Commerce,Design and Development,"Belief-Rule-Based Expert Systems for Evaluation of E- Government: A Case
  Study","Little knowledge exists on the impact and results associated with
e-government projects in many specific use domains. Therefore it is necessary
to evaluate the efficiency and effectiveness of e-government systems. Since the
development of e-government is a continuous process of improvement, it requires
continuous evaluation of the overall e-government system as well as evaluation
of its various dimensions such as determinants, characteristics and results.
E-government development is often complex with multiple stakeholders, large
user bases and complex goals. Consequently, even experts have difficulties in
evaluating these systems, especially in an integrated and comprehensive way as
well as on an aggregate level. Expert systems are a candidate solution to
evaluate such complex e-government systems. However, it is difficult for expert
systems to cope with uncertain evaluation data that are vague, inconsistent,
highly subjective or in other ways challenging to formalize. This paper
presents an approach that can handle uncertainty in e-government evaluation:
The combination of Belief Rule Base (BRB) knowledge representation and
Evidential Reasoning (ES). This approach is illustrated with a concrete
prototype, known as Belief Rule Based Expert System (BRBES) and put to use in
the local e-government of Bangladesh. The results have been compared with a
recently developed method of evaluating e-Government, and it is shown that the
results of BRBES are more accurate and reliable. BRBES can be used to identify
the factors that need to be improved to achieve the overall aim of an
e-government project. In addition, various ""what if"" scenarios can be generated
and developers and managers can get a forecast of the outcomes. In this way,
the system can be used to facilitate decision making processes under
uncertainty.",http://arxiv.org/abs/1403.5618v2,arXiv,beliefrulebase expert system evaluation government case study,little knowledge exist impact result associate egovernment project many specific use domain therefore necessary evaluate efficiency effectiveness egovernment system since development egovernment continuous process improvement require continuous evaluation overall egovernment system well evaluation various dimension determinant characteristic result egovernment development often complex multiple stakeholder large user basis complex goal consequently even expert difficulty evaluate system especially integrated comprehensive way well aggregate level expert system candidate solution evaluate complex egovernment system however difficult expert system cope uncertain evaluation datum vague inconsistent highly subjective way challenge formalize paper present approach handle uncertainty egovernment evaluation combination belief rule base brb knowledge representation evidential reasoning approach illustrate concrete prototype know belief rule base expert system brbe put use local egovernment bangladesh result compare recently develop method evaluate egovernment show result brbe accurate reliable brbe use identify factor need improve achieve overall aim egovernment project addition various scenario generate developer manager get forecast outcome way system use facilitate decision make process uncertainty,beliefrulebase expert system evaluation government case study little knowledge exist impact result associate egovernment project many specific use domain therefore necessary evaluate efficiency effectiveness egovernment system since development egovernment continuous process improvement require continuous evaluation overall egovernment system well evaluation various dimension determinant characteristic result egovernment development often complex multiple stakeholder large user basis complex goal consequently even expert difficulty evaluate system especially integrated comprehensive way well aggregate level expert system candidate solution evaluate complex egovernment system however difficult expert system cope uncertain evaluation datum vague inconsistent highly subjective way challenge formalize paper present approach handle uncertainty egovernment evaluation combination belief rule base brb knowledge representation evidential reasoning approach illustrate concrete prototype know belief rule base expert system brbe put use local egovernment bangladesh result compare recently develop method evaluate egovernment show result brbe accurate reliable brbe use identify factor need improve achieve overall aim egovernment project addition various scenario generate developer manager get forecast outcome way system use facilitate decision make process uncertainty,0.5095541401273885,0.14012738853503184,0.2356687898089172,0.06369426751592357,157.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Theoretical / Conceptual,Towards an Understanding of Valence in E-Government Services,"The Australian government, to remind job seekers of appointments with
employment services providers in order to cut costs and free up human
resources, is using technologies such as Short Messaging Services (SMS).
However, the technologies in-use are but one side of this equation the
specifics of how these technologies are used is the other side, and these
specifics are highly under-theorized, particularly in regard to the views of
the people to which these technologies are directed. The purpose of this paper
is to provide a theoretical framing for this phenomenon as well as to introduce
an emerging methodological direction that may allow for a better understanding
of demographic-specific values and thereby better valence framing. The paper
also theorizes reactions to information that could be applicable elsewhere, not
just in e-government or with SMS, thereby contributing to discussions
surrounding the Big Data debate.",http://arxiv.org/abs/1606.01360v1,arXiv,towards understanding valence egovernment service,australian government remind job seeker appointment employment service provider order cut cost free human resource use technology short messaging service however technology inuse one side equation specific technology use side specific highly undertheorized particularly regard view people technology direct purpose paper provide theoretical framing phenomenon well introduce emerge methodological direction may allow well understanding demographicspecific value thereby well valence frame paper also theorize reaction information could applicable elsewhere egovernment sms thereby contribute discussion surround big data debate,towards understanding valence egovernment service australian government remind job seeker appointment employment service provider order cut cost free human resource use technology short messaging service however technology inuse one side equation specific technology use side specific highly undertheorized particularly regard view people technology direct purpose paper provide theoretical framing phenomenon well introduce emerge methodological direction may allow well understanding demographicspecific value thereby well valence frame paper also theorize reaction information could applicable elsewhere egovernment sms thereby contribute discussion surround big data debate,0.4935064935064935,0.15584415584415584,0.18181818181818182,0.11688311688311688,77.0,0.0,0.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Theoretical / Conceptual,"Towards an automated repository for indexing, analysis and
  characterization of municipal e-government websites in Mexico","This article addresses a problem in the electronic government discipline with
special interest in Mexico: the need for a concentrated and updated information
source about municipal e-government websites. One reason for this is the lack
of a complete and updated database containing the electronic addresses (web
domain names) of the municipal governments having a website. Due to diverse
causes, not all the Mexican municipalities have one, and a number of those
having it do not present information corresponding to the current governments
but, instead, to other previous ones. The scarce official lists of municipal
websites are not updated with the sufficient frequency, and manually
determining which municipalities have an operating and valid website in a given
moment is a time-consuming process. Besides, website contents do not always
comply with legal requirements and are considerably heterogeneous. In turn, the
evolution development level of municipal websites is valuable information that
can be harnessed for diverse theoretical and practical purposes in the public
administration field. Obtaining all these pieces of information requires
website content analysis. Therefore, this article investigates the need for and
the feasibility to automate implementation and updating of a digital repository
to perform diverse analyses of these websites. Its technological feasibility is
addressed by means of a literature review about web scraping and by proposing a
preliminary manual methodology. This takes into account known, proven,
techniques and software tools for web crawling and scraping. No new techniques
for crawling or scraping are proposed because the existing ones satisfy the
current needs. Finally, software requirements are specified in order to
automate the creation, updating, indexing, and analyses of the repository.",http://arxiv.org/abs/2006.14746v1,arXiv,towards automate repository indexing analysis characterization municipal egovernment website mexico,article address problem electronic government discipline special interest mexico need concentrated update information source municipal egovernment website one reason lack complete update database contain electronic address web domain name municipal government website due diverse cause mexican municipality one number present information correspond current government instead previous one scarce official list municipal website update sufficient frequency manually determine municipality operate valid website give moment timeconsuming process besides website content always comply legal requirement considerably heterogeneous turn evolution development level municipal website valuable information harness diverse theoretical practical purpose public administration field obtain piece information require website content analysis therefore article investigate need feasibility automate implementation updating digital repository perform diverse analysis website technological feasibility address mean literature review web scraping propose preliminary manual methodology take account know prove technique software tool web crawl scrape new technique crawl scrape propose exist one satisfy current need finally software requirement specify order automate creation update indexing analysis repository,towards automate repository indexing analysis characterization municipal egovernment website mexico article address problem electronic government discipline special interest mexico need concentrated update information source municipal egovernment website one reason lack complete update database contain electronic address web domain name municipal government website due diverse cause mexican municipality one number present information correspond current government instead previous one scarce official list municipal website update sufficient frequency manually determine municipality operate valid website give moment timeconsuming process besides website content always comply legal requirement considerably heterogeneous turn evolution development level municipal website valuable information harness diverse theoretical practical purpose public administration field obtain piece information require website content analysis therefore article investigate need feasibility automate implementation updating digital repository perform diverse analysis website technological feasibility address mean literature review web scraping propose preliminary manual methodology take account know prove technique software tool web crawl scrape new technique crawl scrape propose exist one satisfy current need finally software requirement specify order automate creation update indexing analysis repository,0.525974025974026,0.13636363636363635,0.24025974025974026,0.03896103896103896,154.0,0.0,1.0,0.0,0.0
Information Systems,E-Government and E-Commerce,Theoretical / Conceptual,"Intelligent Classification and Personalized Recommendation of E-commerce
  Products Based on Machine Learning","With the rapid evolution of the Internet and the exponential proliferation of
information, users encounter information overload and the conundrum of choice.
Personalized recommendation systems play a pivotal role in alleviating this
burden by aiding users in filtering and selecting information tailored to their
preferences and requirements. Such systems not only enhance user experience and
satisfaction but also furnish opportunities for businesses and platforms to
augment user engagement, sales, and advertising efficacy.This paper undertakes
a comparative analysis between the operational mechanisms of traditional
e-commerce commodity classification systems and personalized recommendation
systems. It delineates the significance and application of personalized
recommendation systems across e-commerce, content information, and media
domains. Furthermore, it delves into the challenges confronting personalized
recommendation systems in e-commerce, including data privacy, algorithmic bias,
scalability, and the cold start problem. Strategies to address these challenges
are elucidated.Subsequently, the paper outlines a personalized recommendation
system leveraging the BERT model and nearest neighbor algorithm, specifically
tailored to address the exigencies of the eBay e-commerce platform. The
efficacy of this recommendation system is substantiated through manual
evaluation, and a practical application operational guide and structured output
recommendation results are furnished to ensure the system's operability and
scalability.",http://arxiv.org/abs/2403.19345v1,arXiv,intelligent classification personalized recommendation ecommerce product base machine learning,rapid evolution internet exponential proliferation information user encounter information overload conundrum choice personalize recommendation system play pivotal role alleviate burden aid user filter select information tailor preference requirement system enhance user experience satisfaction also furnish opportunity business platform augment user engagement sale advertise efficacythis paper undertake comparative analysis operational mechanism traditional ecommerce commodity classification system personalize recommendation system delineate significance application personalize recommendation system across ecommerce content information medium domain furthermore delve challenge confront personalize recommendation system ecommerce include datum privacy algorithmic bias scalability cold start problem strategy address challenge elucidatedsubsequently paper outline personalize recommendation system leverage bert model near neighbor algorithm specifically tailor address exigency ebay ecommerce platform efficacy recommendation system substantiate manual evaluation practical application operational guide structured output recommendation result furnish ensure system operability scalability,intelligent classification personalized recommendation ecommerce product base machine learning rapid evolution internet exponential proliferation information user encounter information overload conundrum choice personalize recommendation system play pivotal role alleviate burden aid user filter select information tailor preference requirement system enhance user experience satisfaction also furnish opportunity business platform augment user engagement sale advertise efficacythis paper undertake comparative analysis operational mechanism traditional ecommerce commodity classification system personalize recommendation system delineate significance application personalize recommendation system across ecommerce content information medium domain furthermore delve challenge confront personalize recommendation system ecommerce include datum privacy algorithmic bias scalability cold start problem strategy address challenge elucidatedsubsequently paper outline personalize recommendation system leverage bert model near neighbor algorithm specifically tailor address exigency ebay ecommerce platform efficacy recommendation system substantiate manual evaluation practical application operational guide structured output recommendation result furnish ensure system operability scalability,0.71875,0.0859375,0.09375,0.03125,128.0,0.0,0.0,0.0,1.0
Information Systems,E-Government and E-Commerce,Theoretical / Conceptual,"Theoretical Understandings of Product Embedding for E-commerce Machine
  Learning","Product embeddings have been heavily investigated in the past few years,
serving as the cornerstone for a broad range of machine learning applications
in e-commerce. Despite the empirical success of product embeddings, little is
known on how and why they work from the theoretical standpoint. Analogous
results from the natural language processing (NLP) often rely on
domain-specific properties that are not transferable to the e-commerce setting,
and the downstream tasks often focus on different aspects of the embeddings. We
take an e-commerce-oriented view of the product embeddings and reveal a
complete theoretical view from both the representation learning and the
learning theory perspective. We prove that product embeddings trained by the
widely-adopted skip-gram negative sampling algorithm and its variants are
sufficient dimension reduction regarding a critical product relatedness
measure. The generalization performance in the downstream machine learning task
is controlled by the alignment between the embeddings and the product
relatedness measure. Following the theoretical discoveries, we conduct
exploratory experiments that supports our theoretical insights for the product
embeddings.",http://arxiv.org/abs/2102.12029v1,arXiv,theoretical understanding product embed ecommerce machine learning,product embedding heavily investigate past year serve cornerstone broad range machine learning application ecommerce despite empirical success product embedding little know work theoretical standpoint analogous result natural language processing nlp often rely domainspecific property transferable ecommerce set downstream task often focus different aspect embedding take ecommerceoriented view product embedding reveal complete theoretical view representation learning learning theory perspective prove product embedding train widelyadopte skipgram negative sampling algorithm variant sufficient dimension reduction regard critical product relatedness measure generalization performance downstream machine learning task control alignment embedding product relatedness measure follow theoretical discovery conduct exploratory experiment support theoretical insight product embedding,theoretical understanding product embed ecommerce machine learning product embedding heavily investigate past year serve cornerstone broad range machine learning application ecommerce despite empirical success product embedding little know work theoretical standpoint analogous result natural language processing nlp often rely domainspecific property transferable ecommerce set downstream task often focus different aspect embedding take ecommerceoriented view product embedding reveal complete theoretical view representation learning learning theory perspective prove product embedding train widelyadopte skipgram negative sampling algorithm variant sufficient dimension reduction regard critical product relatedness measure generalization performance downstream machine learning task control alignment embedding product relatedness measure follow theoretical discovery conduct exploratory experiment support theoretical insight product embedding,0.5050505050505051,0.1717171717171717,0.2222222222222222,0.04040404040404041,99.0,0.0,0.0,1.0,0.0
Information Systems,E-Government and E-Commerce,Theoretical / Conceptual,So What's the Plan? Mining Strategic Planning Documents,"In this paper we present a corpus of Russian strategic planning documents,
RuREBus. This project is grounded both from language technology and
e-government perspectives. Not only new language sources and tools are being
developed, but also their applications to e-goverment research. We demonstrate
the pipeline for creating a text corpus from scratch. First, the annotation
schema is designed. Next texts are marked up using human-in-the-loop strategy,
so that preliminary annotations are derived from a machine learning model and
are manually corrected. The amount of annotated texts is large enough to
showcase what insights can be gained from RuREBus.",http://arxiv.org/abs/2007.00257v2,arXiv,plan mine strategic planning document,paper present corpus russian strategic planning document rurebus project ground language technology egovernment perspective new language source tool develop also application egoverment research demonstrate pipeline create text corpus scratch first annotation schema design next text mark use humanintheloop strategy preliminary annotation derive machine learning model manually correct amount annotated text large enough showcase insight gain rurebus,plan mine strategic planning document paper present corpus russian strategic planning document rurebus project ground language technology egovernment perspective new language source tool develop also application egoverment research demonstrate pipeline create text corpus scratch first annotation schema design next text mark use humanintheloop strategy preliminary annotation derive machine learning model manually correct amount annotated text large enough showcase insight gain rurebus,0.5892857142857143,0.10714285714285714,0.16071428571428573,0.03571428571428571,56.0,1.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Quantitative,"InfraRisk: An Open-Source Simulation Platform for Asset-Level Resilience
  Analysis in Interconnected Infrastructure Networks","Integrated simulation models are emerging as an alternative for analyzing
large-scale interdependent infrastructure networks due to their modeling
advantages over traditional interdependency models. This paper presents an
open-source integrated simulation package for the asset-level analysis of
interdependent infrastructure systems. The simulation platform, named
'InfraRisk' and developed in Python, can simulate disaster-induced
infrastructure failures and subsequent post-disaster restoration in
interconnected water-, power-, and road networks. InfraRisk consists of an
infrastructure module, a hazard module, a recovery module, a simulation module,
and a resilience quantification module. The infrastructure module integrates
existing infrastructure network packages (wntr for water networks, pandapower
for power systems, and a static traffic assignment model for transportation
networks) through an interface that facilitates the network-level simulation of
interdependent failures. The hazard module generates infrastructure component
failure sequences based on various disaster characteristics. The recovery
module determines repair sequences and assigns repair crews based on predefined
heuristics-based recovery strategies or model predictive control (MPC) based
optimization. Based on the schedule, the simulation module implements the
network-wide simulation of the consequences of the disaster impacts and the
recovery actions. The resilience quantification module offers system-level and
consumer-level metrics to quantify both the risks and resilience of the
integrated infrastructure networks against disaster events. InfraRisk provides
a virtual platform for decision-makers to experiment and develop
region-specific pre-disaster and post-disaster policies to enhance the overall
resilience of interdependent urban infrastructure networks.",http://arxiv.org/abs/2205.04717v1,arXiv,infrarisk opensource simulation platform assetlevel resilience analysis interconnect infrastructure network,integrate simulation model emerge alternative analyze largescale interdependent infrastructure network due modeling advantage traditional interdependency model paper present opensource integrate simulation package assetlevel analysis interdependent infrastructure system simulation platform name infrarisk develop python simulate disasterinduced infrastructure failure subsequent postdisaster restoration interconnect water power road network infrarisk consist infrastructure module hazard module recovery module simulation module resilience quantification module infrastructure module integrate exist infrastructure network package wntr water network pandapower power system static traffic assignment model transportation network interface facilitate networklevel simulation interdependent failure hazard module generate infrastructure component failure sequence base various disaster characteristic recovery module determine repair sequence assign repair crew base predefine heuristicsbased recovery strategy model predictive control mpc base optimization base schedule simulation module implement networkwide simulation consequence disaster impact recovery action resilience quantification module offer systemlevel consumerlevel metric quantify risk resilience integrate infrastructure network disaster event infrarisk provide virtual platform decisionmaker experiment develop regionspecific predisaster postdisaster policy enhance overall resilience interdependent urban infrastructure network,infrarisk opensource simulation platform assetlevel resilience analysis interconnect infrastructure network integrate simulation model emerge alternative analyze largescale interdependent infrastructure network due modeling advantage traditional interdependency model paper present opensource integrate simulation package assetlevel analysis interdependent infrastructure system simulation platform name infrarisk develop python simulate disasterinduced infrastructure failure subsequent postdisaster restoration interconnect water power road network infrarisk consist infrastructure module hazard module recovery module simulation module resilience quantification module infrastructure module integrate exist infrastructure network package wntr water network pandapower power system static traffic assignment model transportation network interface facilitate networklevel simulation interdependent failure hazard module generate infrastructure component failure sequence base various disaster characteristic recovery module determine repair sequence assign repair crew base predefine heuristicsbased recovery strategy model predictive control mpc base optimization base schedule simulation module implement networkwide simulation consequence disaster impact recovery action resilience quantification module offer systemlevel consumerlevel metric quantify risk resilience integrate infrastructure network disaster event infrarisk provide virtual platform decisionmaker experiment develop regionspecific predisaster postdisaster policy enhance overall resilience interdependent urban infrastructure network,0.7341772151898734,0.06329113924050633,0.11392405063291139,0.0,158.0,0.0,0.0,0.0,1.0
Information Technology,Network and Infrastructure,Quantitative,"Network Properties for Robust Multilayer Infrastructure Systems: A
  Percolation Theory Review","Infrastructure systems, such as power, transportation, telecommunication, and
water systems, are composed of multiple components which are interconnected and
interdependent to produce and distribute essential goods and services. So, the
robustness of infrastructure systems to resist disturbances is crucial for the
durable performance of modern societies. Multilayer networks have been used to
model the multiplicity and interrelation of infrastructure systems and
percolation theory is the most common approach to quantify the robustness of
such networks. This survey systematically reviews literature published between
2010 and 2021, on applying percolation theory to assess the robustness of
infrastructure systems modeled as multilayer networks. We discussed all network
properties applied to build infrastructure models. Among all properties,
interdependency strength and communities were the most common network property
whilst very few studies considered realistic attributes of infrastructure
systems such as directed links and feedback conditions. The review highlights
that the properties produced approximately similar model outcomes, in terms of
detecting improvement or deterioration in the robustness of multilayer
infrastructure networks, with few exceptions. Most of the studies focused on
highly simpliffied synthetic models rather than models built by real datasets.
Thus, this review suggests analyzing multiple properties in a single model to
assess whether they boost or weaken the impact of each other. In addition, the
effect size of different properties on the robustness of infrastructure systems
should be quantiffied. It can support the design and planning of robust
infrastructure systems by arranging and prioritizing the most effective
properties.",http://arxiv.org/abs/2105.12701v2,arXiv,network property robust multilayer infrastructure system percolation theory review,infrastructure system power transportation telecommunication water system compose multiple component interconnect interdependent produce distribute essential good service robustness infrastructure system resist disturbance crucial durable performance modern society multilayer network use model multiplicity interrelation infrastructure system percolation theory common approach quantify robustness network survey systematically review literature publish apply percolation theory assess robustness infrastructure system model multilayer network discuss network property apply build infrastructure model among property interdependency strength community common network property whilst study consider realistic attribute infrastructure system direct link feedback condition review highlight property produce approximately similar model outcome term detect improvement deterioration robustness multilayer infrastructure network exception study focus highly simpliffied synthetic model rather model build real dataset thus review suggest analyze multiple property single model assess whether boost weaken impact addition effect size different property robustness infrastructure system quantiffie support design planning robust infrastructure system arrange prioritize effective property,network property robust multilayer infrastructure system percolation theory review infrastructure system power transportation telecommunication water system compose multiple component interconnect interdependent produce distribute essential good service robustness infrastructure system resist disturbance crucial durable performance modern society multilayer network use model multiplicity interrelation infrastructure system percolation theory common approach quantify robustness network survey systematically review literature publish apply percolation theory assess robustness infrastructure system model multilayer network discuss network property apply build infrastructure model among property interdependency strength community common network property whilst study consider realistic attribute infrastructure system direct link feedback condition review highlight property produce approximately similar model outcome term detect improvement deterioration robustness multilayer infrastructure network exception study focus highly simpliffied synthetic model rather model build real dataset thus review suggest analyze multiple property single model assess whether boost weaken impact addition effect size different property robustness infrastructure system quantiffie support design planning robust infrastructure system arrange prioritize effective property,0.5944055944055944,0.13986013986013987,0.16783216783216784,0.03496503496503497,143.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Quantitative,Safety Requirement Specifications for Connected Vehicles,"In the coming years, transportation system will be revamped in a manner that
there will be more intelligent and autonomous vehicle phenomenon around us such
as smart cars, auto driving system, etc. Some of automotive industries are
already producing smart cars. However, the main concern of this paper is on the
infrastructure for connected vehicles, which can support such intelligent
transportation. Current transportation system lacks proper infrastructure to
support connected vehicles. Hence, in this article, we have surveyed and
analyzed the current transportation system in developed and developing
countries. In contrast, we are going to introduce secure intelligent
transportation (roadside) infrastructure that is user centric (Driver,
Autonomous driver etc.) for connected vehicles. In this paper we present the
basic requirements of safety engineering infrastructure of roadside
infrastructure in ITS for connected vehicles. Connected vehicles has network
infrastructure to communicate with vehicle-to-vehicle (V-to-V),
vehicle-to-infrastructure (V-to-I), lane correction system, and traffic
information system etc. The connected vehicle is a good model for learning
demands of infrastructure for ITS process because the system having a lot of
use-cases and we must understand relationship between public institutions,
people, companies in order to proceed ITS System.",http://arxiv.org/abs/1707.08715v2,arXiv,safety requirement specification connected vehicle,come year transportation system revamp manner intelligent autonomous vehicle phenomenon around smart car auto driving system etc automotive industry already produce smart car however main concern paper infrastructure connected vehicle support intelligent transportation current transportation system lack proper infrastructure support connected vehicle hence article survey analyze current transportation system developed develop country contrast introduce secure intelligent transportation roadside infrastructure user centric driver autonomous driver etc connected vehicle paper present basic requirement safety engineering infrastructure roadside infrastructure connected vehicle connect vehicle network infrastructure communicate vehicletovehicle vtov vehicletoinfrastructure vtoi lane correction system traffic information system etc connected vehicle good model learn demand infrastructure process system lot usecase must understand relationship public institution people company order proceed system,safety requirement specification connected vehicle come year transportation system revamp manner intelligent autonomous vehicle phenomenon around smart car auto driving system etc automotive industry already produce smart car however main concern paper infrastructure connected vehicle support intelligent transportation current transportation system lack proper infrastructure support connected vehicle hence article survey analyze current transportation system developed develop country contrast introduce secure intelligent transportation roadside infrastructure user centric driver autonomous driver etc connected vehicle paper present basic requirement safety engineering infrastructure roadside infrastructure connected vehicle connect vehicle network infrastructure communicate vehicletovehicle vtov vehicletoinfrastructure vtoi lane correction system traffic information system etc connected vehicle good model learn demand infrastructure process system lot usecase must understand relationship public institution people company order proceed system,0.5826086956521739,0.1391304347826087,0.16521739130434782,0.02608695652173913,115.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Quantitative,Topological Convergence of Urban Infrastructure Networks,"Urban infrastructure networks play a major role in providing reliable flows
of multitude critical services demanded by citizens in modern cities. We
analyzed here a database of 125 infrastructure networks, roads (RN); urban
drainage networks (UDN); water distribution networks (WDN), in 52 global
cities, serving populations ranging from 1,000 to 9,000,000. For all
infrastructure networks, the node-degree distributions, p(k), derived using
undirected, dual-mapped graphs, fit Pareto distributions. Variance around mean
gamma reduces substantially as network size increases. Convergence of
functional topology of these urban infrastructure networks suggests that their
co-evolution results from similar generative mechanisms. Analysis of growing
UDNs over non-concurrent 40 year periods in three cities suggests the likely
generative process to be partial preferential attachment under geospatial
constraints. This finding is supported by high-variance node-degree
distributions as compared to that expected for a Poisson random graph. Directed
cascading failures, from UDNs to RNs, are investigated. Correlation of
node-degrees between spatially co-located networks are shown to be a major
factor influencing network fragmentation by node removal. Our results hold
major implications for the network design and maintenance, and for resilience
of urban communities relying on multiplex infrastructure networks for mobility
within the city, water supply, and wastewater collection and treatment.",http://arxiv.org/abs/1902.01266v1,arXiv,topological convergence urban infrastructure network,urban infrastructure network play major role provide reliable flow multitude critical service demand citizen modern city analyze database infrastructure network road urban drainage network udn water distribution network wdn global city serve population range infrastructure network nodedegree distribution derive use undirected dualmapped graph fit pareto distribution variance around mean gamma reduce substantially network size increase convergence functional topology urban infrastructure network suggest coevolution result similar generative mechanism analysis grow udns nonconcurrent year period three city suggest likely generative process partial preferential attachment geospatial constraint finding support highvariance nodedegree distribution compare expect poisson random graph direct cascade failure udns rns investigate correlation nodedegree spatially colocate network show major factor influence network fragmentation node removal result hold major implication network design maintenance resilience urban community rely multiplex infrastructure network mobility within city water supply wastewater collection treatment,topological convergence urban infrastructure network urban infrastructure network play major role provide reliable flow multitude critical service demand citizen modern city analyze database infrastructure network road urban drainage network udn water distribution network wdn global city serve population range infrastructure network nodedegree distribution derive use undirected dualmapped graph fit pareto distribution variance around mean gamma reduce substantially network size increase convergence functional topology urban infrastructure network suggest coevolution result similar generative mechanism analysis grow udns nonconcurrent year period three city suggest likely generative process partial preferential attachment geospatial constraint finding support highvariance nodedegree distribution compare expect poisson random graph direct cascade failure udns rns investigate correlation nodedegree spatially colocate network show major factor influence network fragmentation node removal result hold major implication network design maintenance resilience urban community rely multiplex infrastructure network mobility within city water supply wastewater collection treatment,0.6074074074074074,0.11851851851851852,0.21481481481481482,0.014814814814814815,135.0,0.0,0.0,1.0,0.0
Information Technology,Network and Infrastructure,Quantitative,"Integrating social capital with urban infrastructure networks for more
  resilient cities","More than half of the world's population now lives in urban environments,
which concentrate services and infrastructure to satisfy the material needs of
a growing number of inhabitants. The interdependencies between physical
infrastructure systems are required for cities to function efficiently, but
simultaneously expose cities to new hazards. Failures that emerge from one
infrastructure system and cascade through these interdependencies are becoming
larger and more frequent due to climate change and growing urban environments.
Because of the uneven distribution of resources and basic services, cascade
failures often exacerbate pre-existing socioeconomic inequalities. Human
communities rely on both social capital and infrastructure services to prepare
for, manage, and recover from these challenging scenarios, but the overlap
between social and physical infrastructure creates unpredictable feedback
dynamics. While prior research has focused on either social capital or physical
infrastructure in urban disaster management, an integrative view of these two
perspectives is seldom explored. In this paper, the feedback mechanisms between
the physical and social layers of different urban designs are identified and
analyzed to optimize relief response. Methodologically, we identify cities with
high accessibility that have undergone disasters. From these cities, we measure
their physical and social resilience indicators before and after disaster as a
means to evaluate the impact of accessibility on disaster relief and
preparedness. We will supplement this empirical analysis with a simulation that
captures a cascade failure/disaster through a multilayer infrastructure and
social network model.",http://arxiv.org/abs/2502.06328v1,arXiv,integrate social capital urban infrastructure network resilient city,half world population live urban environment concentrate service infrastructure satisfy material need grow number inhabitant interdependency physical infrastructure system require city function efficiently simultaneously expose city new hazard failure emerge one infrastructure system cascade interdependency become large frequent due climate change grow urban environment uneven distribution resource basic service cascade failure often exacerbate preexist socioeconomic inequality human community rely social capital infrastructure service prepare manage recover challenge scenario overlap social physical infrastructure create unpredictable feedback dynamic prior research focus either social capital physical infrastructure urban disaster management integrative view two perspective seldom explore paper feedback mechanism physical social layer different urban design identify analyze optimize relief response methodologically identify city high accessibility undergone disaster city measure physical social resilience indicator disaster mean evaluate impact accessibility disaster relief preparedness supplement empirical analysis simulation capture cascade failuredisaster multilayer infrastructure social network model,integrate social capital urban infrastructure network resilient city half world population live urban environment concentrate service infrastructure satisfy material need grow number inhabitant interdependency physical infrastructure system require city function efficiently simultaneously expose city new hazard failure emerge one infrastructure system cascade interdependency become large frequent due climate change grow urban environment uneven distribution resource basic service cascade failure often exacerbate preexist socioeconomic inequality human community rely social capital infrastructure service prepare manage recover challenge scenario overlap social physical infrastructure create unpredictable feedback dynamic prior research focus either social capital physical infrastructure urban disaster management integrative view two perspective seldom explore paper feedback mechanism physical social layer different urban design identify analyze optimize relief response methodologically identify city high accessibility undergone disaster city measure physical social resilience indicator disaster mean evaluate impact accessibility disaster relief preparedness supplement empirical analysis simulation capture cascade failuredisaster multilayer infrastructure social network model,0.5214285714285715,0.16428571428571428,0.19285714285714287,0.03571428571428571,140.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Qualitative,"Modelling interdependencies between the electricity and information
  infrastructures","The aim of this paper is to provide qualitative models characterizing
interdependencies related failures of two critical infrastructures: the
electricity infrastructure and the associated information infrastructure. The
interdependencies of these two infrastructures are increasing due to a growing
connection of the power grid networks to the global information infrastructure,
as a consequence of market deregulation and opening. These interdependencies
increase the risk of failures. We focus on cascading, escalating and
common-cause failures, which correspond to the main causes of failures due to
interdependencies. We address failures in the electricity infrastructure, in
combination with accidental failures in the information infrastructure, then we
show briefly how malicious attacks in the information infrastructure can be
addressed.",http://arxiv.org/abs/0809.4107v1,arXiv,model interdependency electricity information infrastructure,aim paper provide qualitative model characterize interdependency relate failure two critical infrastructure electricity infrastructure associate information infrastructure interdependency two infrastructure increase due grow connection power grid network global information infrastructure consequence market deregulation open interdependency increase risk failure focus cascade escalating commoncause failure correspond main cause failure due interdependency address failure electricity infrastructure combination accidental failure information infrastructure show briefly malicious attack information infrastructure address,model interdependency electricity information infrastructure aim paper provide qualitative model characterize interdependency relate failure two critical infrastructure electricity infrastructure associate information infrastructure interdependency two infrastructure increase due grow connection power grid network global information infrastructure consequence market deregulation open interdependency increase risk failure focus cascade escalating commoncause failure correspond main cause failure due interdependency address failure electricity infrastructure combination accidental failure information infrastructure show briefly malicious attack information infrastructure address,0.6923076923076923,0.09230769230769231,0.13846153846153847,0.015384615384615385,65.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Qualitative,"A Dynamic Game Analysis and Design of Infrastructure Network Protection
  and Recovery","Infrastructure networks are vulnerable to both cyber and physical attacks.
Building a secure and resilient networked system is essential for providing
reliable and dependable services. To this end, we establish a two-player
three-stage game framework to capture the dynamics in the infrastructure
protection and recovery phases. Specifically, the goal of the infrastructure
network designer is to keep the network connected before and after the attack,
while the adversary aims to disconnect the network by compromising a set of
links. With costs for creating and removing links, the two players aim to
maximize their utilities while minimizing the costs. In this paper, we use the
concept of subgame perfect equilibrium (SPE) to characterize the optimal
strategies of the network defender and attacker. We derive the SPE explicitly
in terms of system parameters. Finally, we use a case study of UAV-enabled
communication networks for disaster recovery to corroborate the obtained
analytical results.",http://arxiv.org/abs/1707.07054v1,arXiv,dynamic game analysis design infrastructure network protection recovery,infrastructure network vulnerable cyber physical attack build secure resilient networked system essential provide reliable dependable service end establish twoplayer threestage game framework capture dynamic infrastructure protection recovery phase specifically goal infrastructure network designer keep network connect attack adversary aim disconnect network compromise set link cost create remove link two player aim maximize utility minimize cost paper use concept subgame perfect equilibrium spe characterize optimal strategy network defender attacker derive spe explicitly term system parameter finally use case study uavenabled communication network disaster recovery corroborate obtain analytical result,dynamic game analysis design infrastructure network protection recovery infrastructure network vulnerable cyber physical attack build secure resilient networked system essential provide reliable dependable service end establish twoplayer threestage game framework capture dynamic infrastructure protection recovery phase specifically goal infrastructure network designer keep network connect attack adversary aim disconnect network compromise set link cost create remove link two player aim maximize utility minimize cost paper use concept subgame perfect equilibrium spe characterize optimal strategy network defender attacker derive spe explicitly term system parameter finally use case study uavenabled communication network disaster recovery corroborate obtain analytical result,0.5747126436781609,0.14942528735632185,0.1724137931034483,0.034482758620689655,87.0,0.0,0.0,0.0,1.0
Information Technology,Network and Infrastructure,Qualitative,On the resilience of cellular networks: how can national roaming help?,"Cellular networks have become one of the critical infrastructures, as many
services depend increasingly on wireless connectivity. Therefore, it is
important to quantify the resilience of existing cellular network
infrastructures against potential risks, ranging from natural disasters to
security attacks, that might occur with a low probability but can lead to
severe disruption of the services. In this paper, we combine models with public
data from national bodies on mobile network operator (MNO) infrastructures,
population distribution, and urbanity level to assess the coverage and capacity
of a cellular network at a country scale. Our analysis offers insights on the
potential weak points that need improvement to ensure a low fraction of
disconnected population (FDP) and high fraction of satisfied population (FSP).
As a resilience improvement approach, we investigate in which regions and to
what extent each MNO can benefit from infrastructure sharing or national
roaming, i.e., all MNOs act as a single national operator. As our case study,
we focus on Dutch cellular infrastructure and model risks as random failures,
correlated failures in a geographic region, and abrupt increase in the number
of users. Our analysis shows that there is a wide performance difference across
MNOs and geographic regions in terms of FDP and FSP. However, national roaming
consistently offers significant benefits, e.g., up to 13% improvement in FDP
and up to 55% in FSP when the networks function without any failures.",http://arxiv.org/abs/2301.03250v3,arXiv,resilience cellular network national roam help,cellular network become one critical infrastructure many service depend increasingly wireless connectivity therefore important quantify resilience exist cellular network infrastructure potential risk range natural disaster security attack might occur low probability lead severe disruption service paper combine model public datum national body mobile network operator mno infrastructure population distribution urbanity level assess coverage capacity cellular network country scale analysis offer insight potential weak point need improvement ensure low fraction disconnected population fdp high fraction satisfied population fsp resilience improvement approach investigate region extent mno benefit infrastructure sharing national roam mno act single national operator case study focus dutch cellular infrastructure model risk random failure correlate failure geographic region abrupt increase number user analysis show wide performance difference across mno geographic region term fdp fsp however national roaming consistently offer significant benefit improvement fdp fsp network function without failure,resilience cellular network national roam help cellular network become one critical infrastructure many service depend increasingly wireless connectivity therefore important quantify resilience exist cellular network infrastructure potential risk range natural disaster security attack might occur low probability lead severe disruption service paper combine model public datum national body mobile network operator mno infrastructure population distribution urbanity level assess coverage capacity cellular network country scale analysis offer insight potential weak point need improvement ensure low fraction disconnected population fdp high fraction satisfied population fsp resilience improvement approach investigate region extent mno benefit infrastructure sharing national roam mno act single national operator case study focus dutch cellular infrastructure model risk random failure correlate failure geographic region abrupt increase number user analysis show wide performance difference across mno geographic region term fdp fsp however national roaming consistently offer significant benefit improvement fdp fsp network function without failure,0.5072463768115942,0.13043478260869565,0.21014492753623187,0.028985507246376812,138.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Qualitative,A Road Segment Prioritization Approach for Cycling Infrastructure,"Understanding the motivators and deterrents to cycling is essential for
creating infrastructure that gets more people to adopt cycling as a mode of
transport. This paper demonstrates a new approach to support the prioritization
of cycling infrastructure and cycling network design, accounting for cyclist
preferences and the growing emphasis on 'filtered permeability' and 'Low
Traffic Neighborhood' interventions internationally. The approach combines
distance decay, route calculation, and network analysis methods to examine
where future cycling demand is most likely to arise, how such demand could be
accommodated within existing street networks, and how to ensure a fair
distribution of investment. Although each of these methods has been applied to
cycling infrastructure prioritization in previous research, this is the first
time that they have been combined, creating an integrated road segment
prioritization approach. The approach, which can be applied to other cities, as
shown in the Appendix, is demonstrated in a case study of Manchester, resulting
in cycling networks that balance directness against the need for safe and
stress-free routes under different investment scenarios. A key benefit of the
approach from a policy perspective is its ability to support egalitarian and
cost-effective strategic cycle network planning.",http://arxiv.org/abs/2105.03712v1,arXiv,road segment prioritization approach cycling infrastructure,understand motivator deterrent cycling essential create infrastructure get people adopt cycling mode transport paper demonstrate new approach support prioritization cycling infrastructure cycling network design accounting cyclist preference grow emphasis filter permeability low traffic neighborhood intervention internationally approach combine distance decay route calculation network analysis method examine future cycling demand likely arise demand could accommodate within exist street network ensure fair distribution investment although method apply cycling infrastructure prioritization previous research first time combine create integrated road segment prioritization approach approach apply city show appendix demonstrate case study manchester result cycling network balance directness need safe stressfree route different investment scenario key benefit approach policy perspective ability support egalitarian costeffective strategic cycle network planning,road segment prioritization approach cycling infrastructure understand motivator deterrent cycling essential create infrastructure get people adopt cycling mode transport paper demonstrate new approach support prioritization cycling infrastructure cycling network design accounting cyclist preference grow emphasis filter permeability low traffic neighborhood intervention internationally approach combine distance decay route calculation network analysis method examine future cycling demand likely arise demand could accommodate within exist street network ensure fair distribution investment although method apply cycling infrastructure prioritization previous research first time combine create integrated road segment prioritization approach approach apply city show appendix demonstrate case study manchester result cycling network balance directness need safe stressfree route different investment scenario key benefit approach policy perspective ability support egalitarian costeffective strategic cycle network planning,0.6460176991150443,0.1592920353982301,0.12389380530973451,0.017699115044247787,113.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Qualitative,OnionBots: Subverting Privacy Infrastructure for Cyber Attacks,"Over the last decade botnets survived by adopting a sequence of increasingly
sophisticated strategies to evade detection and take overs, and to monetize
their infrastructure. At the same time, the success of privacy infrastructures
such as Tor opened the door to illegal activities, including botnets,
ransomware, and a marketplace for drugs and contraband. We contend that the
next waves of botnets will extensively subvert privacy infrastructure and
cryptographic mechanisms. In this work we propose to preemptively investigate
the design and mitigation of such botnets. We first, introduce OnionBots, what
we believe will be the next generation of resilient, stealthy botnets.
OnionBots use privacy infrastructures for cyber attacks by completely
decoupling their operation from the infected host IP address and by carrying
traffic that does not leak information about its source, destination, and
nature. Such bots live symbiotically within the privacy infrastructures to
evade detection, measurement, scale estimation, observation, and in general all
IP-based current mitigation techniques. Furthermore, we show that with an
adequate self-healing network maintenance scheme, that is simple to implement,
OnionBots achieve a low diameter and a low degree and are robust to
partitioning under node deletions. We developed a mitigation technique, called
SOAP, that neutralizes the nodes of the basic OnionBots. We also outline and
discuss a set of techniques that can enable subsequent waves of Super
OnionBots. In light of the potential of such botnets, we believe that the
research community should proactively develop detection and mitigation methods
to thwart OnionBots, potentially making adjustments to privacy infrastructure.",http://arxiv.org/abs/1501.03378v1,arXiv,onionbot subvert privacy infrastructure cyber attack,last decade botnet survive adopt sequence increasingly sophisticated strategy evade detection take monetize infrastructure time success privacy infrastructure tor open door illegal activity include botnet ransomware marketplace drug contraband contend next wave botnet extensively subvert privacy infrastructure cryptographic mechanism work propose preemptively investigate design mitigation botnet first introduce onionbot believe next generation resilient stealthy botnet onionbot use privacy infrastructure cyber attack completely decouple operation infected host address carry traffic leak information source destination nature bot live symbiotically within privacy infrastructure evade detection measurement scale estimation observation general ipbase current mitigation technique furthermore show adequate selfheale network maintenance scheme simple implement onionbot achieve low diameter low degree robust partition node deletion develop mitigation technique call soap neutralize node basic onionbot also outline discuss set technique enable subsequent wave super onionbot light potential botnet believe research community proactively develop detection mitigation method thwart onionbot potentially make adjustment privacy infrastructure,onionbot subvert privacy infrastructure cyber attack last decade botnet survive adopt sequence increasingly sophisticated strategy evade detection take monetize infrastructure time success privacy infrastructure tor open door illegal activity include botnet ransomware marketplace drug contraband contend next wave botnet extensively subvert privacy infrastructure cryptographic mechanism work propose preemptively investigate design mitigation botnet first introduce onionbot believe next generation resilient stealthy botnet onionbot use privacy infrastructure cyber attack completely decouple operation infected host address carry traffic leak information source destination nature bot live symbiotically within privacy infrastructure evade detection measurement scale estimation observation general ipbase current mitigation technique furthermore show adequate selfheale network maintenance scheme simple implement onionbot achieve low diameter low degree robust partition node deletion develop mitigation technique call soap neutralize node basic onionbot also outline discuss set technique enable subsequent wave super onionbot light potential botnet believe research community proactively develop detection mitigation method thwart onionbot potentially make adjustment privacy infrastructure,0.5238095238095238,0.16326530612244897,0.1360544217687075,0.06802721088435375,147.0,1.0,1.0,1.0,0.0
Information Technology,Network and Infrastructure,Mixed Methods,"A Bayesian Approach to Reconstructing Interdependent Infrastructure
  Networks from Cascading Failures","Analyzing the behavior of complex interdependent networks requires complete
information about the network topology and the interdependent links across
networks. For many applications such as critical infrastructure systems,
understanding network interdependencies is crucial to anticipate cascading
failures and plan for disruptions. However, data on the topology of individual
networks are often publicly unavailable due to privacy and security concerns.
Additionally, interdependent links are often only revealed in the aftermath of
a disruption as a result of cascading failures. We propose a scalable
nonparametric Bayesian approach to reconstruct the topology of interdependent
infrastructure networks from observations of cascading failures.
Metropolis-Hastings algorithm coupled with the infrastructure-dependent
proposal are employed to increase the efficiency of sampling possible graphs.
Results of reconstructing a synthetic system of interdependent infrastructure
networks demonstrate that the proposed approach outperforms existing methods in
both accuracy and computational time. We further apply this approach to
reconstruct the topology of one synthetic and two real-world systems of
interdependent infrastructure networks, including gas-power-water networks in
Shelby County, TN, USA, and an interdependent system of power-water networks in
Italy, to demonstrate the general applicability of the approach.",http://arxiv.org/abs/2211.15590v1,arXiv,bayesian approach reconstruct interdependent infrastructure network cascade failure,analyze behavior complex interdependent network require complete information network topology interdependent link across network many application critical infrastructure system understand network interdependency crucial anticipate cascade failure plan disruption however datum topology individual network often publicly unavailable due privacy security concern additionally interdependent link often reveal aftermath disruption result cascade failure propose scalable nonparametric bayesian approach reconstruct topology interdependent infrastructure network observation cascade failure metropolishasting algorithm couple infrastructuredependent proposal employ increase efficiency sample possible graph result reconstruct synthetic system interdependent infrastructure network demonstrate propose approach outperform exist method accuracy computational time far apply approach reconstruct topology one synthetic two realworld system interdependent infrastructure network include gaspowerwater network shelby county usa interdependent system powerwater network italy demonstrate general applicability approach,bayesian approach reconstruct interdependent infrastructure network cascade failure analyze behavior complex interdependent network require complete information network topology interdependent link across network many application critical infrastructure system understand network interdependency crucial anticipate cascade failure plan disruption however datum topology individual network often publicly unavailable due privacy security concern additionally interdependent link often reveal aftermath disruption result cascade failure propose scalable nonparametric bayesian approach reconstruct topology interdependent infrastructure network observation cascade failure metropolishasting algorithm couple infrastructuredependent proposal employ increase efficiency sample possible graph result reconstruct synthetic system interdependent infrastructure network demonstrate propose approach outperform exist method accuracy computational time far apply approach reconstruct topology one synthetic two realworld system interdependent infrastructure network include gaspowerwater network shelby county usa interdependent system powerwater network italy demonstrate general applicability approach,0.5169491525423728,0.1271186440677966,0.17796610169491525,0.05084745762711865,118.0,0.0,1.0,0.0,0.0
Information Technology,Network and Infrastructure,Mixed Methods,Internet-human infrastructures: Lessons from Havana's StreetNet,"We propose a mixed-methods approach to understanding the human infrastructure
underlying StreetNet (SNET), a distributed, community-run intranet that serves
as the primary 'Internet' in Havana, Cuba. We bridge ethnographic studies and
the study of social networks and organizations to understand the way that power
is embedded in the structure of Havana's SNET. By quantitatively and
qualitatively unpacking the human infrastructure of SNET, this work reveals how
distributed infrastructure necessarily embeds the structural aspects of
inequality distributed within that infrastructure. While traditional technical
measurements of networks reflect the social, organizational, spatial, and
technical constraints that shape the resulting network, ethnographies can help
uncover the texture and role of these hidden supporting relationships. By
merging these perspectives, this work contributes to our understanding of
network roles in growing and maintaining distributed infrastructures, revealing
new approaches to understanding larger, more complex Internet-human
infrastructures---including the Internet and the WWW.",http://arxiv.org/abs/2004.12207v1,arXiv,internethuman infrastructure lesson havanas streetnet,propose mixedmethod approach understand human infrastructure underlying streetnet snet distribute communityrun intranet serve primary internet havana cuba bridge ethnographic study study social network organization understand way power embed structure havanas snet quantitatively qualitatively unpack human infrastructure snet work reveal distribute infrastructure necessarily embed structural aspect inequality distribute within infrastructure traditional technical measurement network reflect social organizational spatial technical constraint shape result network ethnography help uncover texture role hidden support relationship merge perspective work contribute understanding network role grow maintain distribute infrastructure reveal new approach understand large complex internethuman infrastructuresinclude internet www,internethuman infrastructure lesson havanas streetnet propose mixedmethod approach understand human infrastructure underlying streetnet snet distribute communityrun intranet serve primary internet havana cuba bridge ethnographic study study social network organization understand way power embed structure havanas snet quantitatively qualitatively unpack human infrastructure snet work reveal distribute infrastructure necessarily embed structural aspect inequality distribute within infrastructure traditional technical measurement network reflect social organizational spatial technical constraint shape result network ethnography help uncover texture role hidden support relationship merge perspective work contribute understanding network role grow maintain distribute infrastructure reveal new approach understand large complex internethuman infrastructuresinclude internet www,0.42857142857142855,0.1978021978021978,0.16483516483516483,0.03296703296703297,91.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Mixed Methods,Planning minimum regret $CO_2$ pipeline networks,"The transition to a low-carbon economy necessitates effective carbon capture
and storage (CCS) solutions, particularly for hard-to-abate sectors. Herein,
pipeline networks are indispensable for cost-efficient $CO_2$ transportation
over long distances. However, there is deep uncertainty regarding which
industrial sectors will participate in such systems. This poses a significant
challenge due to substantial investments as well as the lengthy planning and
development timelines required for $CO_2$ pipeline projects, which are further
constrained by limited upgrade options for already built infrastructure. The
economies of scale inherent in pipeline construction exacerbate these
challenges, leading to potential regret over earlier decisions. While numerous
models were developed to optimize the initial layout of pipeline infrastructure
based on known demand, a gap exists in addressing the incremental development
of infrastructure in conjunction with deep uncertainty. Hence, this paper
introduces a novel optimization model for $CO_2$ pipeline infrastructure
development, minimizing regret as its objective function and incorporating
various upgrade options, such as looping and pressure increases. The model's
effectiveness is also demonstrated by presenting a comprehensive case study of
Germany's cement and lime industries. The developed approach quantitatively
illustrates the trade-off between different options, which can help in deriving
effective strategies for $CO_2$ infrastructure development.",http://arxiv.org/abs/2502.12035v1,arXiv,plan minimum regret pipeline network,transition lowcarbon economy necessitate effective carbon capture storage ccs solution particularly hardtoabate sector herein pipeline network indispensable costefficient transportation long distance however deep uncertainty regard industrial sector participate system pose significant challenge due substantial investment well lengthy planning development timeline require pipeline project far constrain limited upgrade option already build infrastructure economy scale inherent pipeline construction exacerbate challenge lead potential regret early decision numerous model develop optimize initial layout pipeline infrastructure base know demand gap exist address incremental development infrastructure conjunction deep uncertainty hence paper introduce novel optimization model pipeline infrastructure development minimize regret objective function incorporate various upgrade option looping pressure increase model effectiveness also demonstrate present comprehensive case study germany cement lime industry developed approach quantitatively illustrate tradeoff different option help deriving effective strategy infrastructure development,plan minimum regret pipeline network transition lowcarbon economy necessitate effective carbon capture storage ccs solution particularly hardtoabate sector herein pipeline network indispensable costefficient transportation long distance however deep uncertainty regard industrial sector participate system pose significant challenge due substantial investment well lengthy planning development timeline require pipeline project far constrain limited upgrade option already build infrastructure economy scale inherent pipeline construction exacerbate challenge lead potential regret early decision numerous model develop optimize initial layout pipeline infrastructure base know demand gap exist address incremental development infrastructure conjunction deep uncertainty hence paper introduce novel optimization model pipeline infrastructure development minimize regret objective function incorporate various upgrade option looping pressure increase model effectiveness also demonstrate present comprehensive case study germany cement lime industry developed approach quantitatively illustrate tradeoff different option help deriving effective strategy infrastructure development,0.5390625,0.1328125,0.2109375,0.0625,128.0,0.0,1.0,0.0,0.0
Information Technology,Network and Infrastructure,Mixed Methods,"Modeling Infrastructure Sharing in mmWave Networks with Shared Spectrum
  Licenses","Competing cellular operators aggressively share infrastructure in many major
US markets. If operators also were to share spectrum in next-generation
millimeter-wave (mmWave) networks, intra-cellular interference will become
correlated with inter-cellular interference. We propose a mathematical
framework to model a multi-operator mmWave cellular network with co-located
base-stations (BSs). We then characterize the signal-to-interference-plus-noise
ratio (SINR) distribution for an arbitrary network and derive its coverage
probability. To understand how varying the spatial correlation between
different networks affects coverage probability, we derive special results for
the two-operator scenario, where we construct the operators' individual
networks from a single network via probabilistic coupling. For external
validation, we devise a method to quantify and estimate spatial correlation
from actual base-station deployments. We compare our two-operator model against
an actual macro-cell-dominated network and an actual network primarily
comprising distributed-antenna-system (DAS) nodes. Using the actual deployment
data to set the parameters of our model, we observe that coverage probabilities
for the model and actual deployments not only compare very well to each other,
but also match nearly perfectly for the case of the DAS-node-dominated
deployment. Another interesting observation is that a network that shares
spectrum and infrastructure has a lower rate coverage probability than a
network of the same number of BSs that shares neither spectrum nor
infrastructure, suggesting that the latter is more suitable for low-rate
applications.",http://arxiv.org/abs/1709.05741v2,arXiv,model infrastructure sharing mmwave network share spectrum license,compete cellular operator aggressively share infrastructure many major market operator also share spectrum nextgeneration millimeterwave mmwave network intracellular interference become correlate intercellular interference propose mathematical framework model multioperator mmwave cellular network colocate basestation bss characterize signaltointerferenceplusnoise ratio sinr distribution arbitrary network derive coverage probability understand vary spatial correlation different network affect coverage probability derive special result twooperator scenario construct operator individual network single network via probabilistic coupling external validation devise method quantify estimate spatial correlation actual basestation deployment compare twooperator model actual macrocelldominate network actual network primarily comprise distributedantennasystem das node use actual deployment datum set parameter model observe coverage probability model actual deployment compare well also match nearly perfectly case dasnodedominated deployment another interesting observation network share spectrum infrastructure low rate coverage probability network number bss share neither spectrum infrastructure suggest latter suitable lowrate application,model infrastructure sharing mmwave network share spectrum license compete cellular operator aggressively share infrastructure many major market operator also share spectrum nextgeneration millimeterwave mmwave network intracellular interference become correlate intercellular interference propose mathematical framework model multioperator mmwave cellular network colocate basestation bss characterize signaltointerferenceplusnoise ratio sinr distribution arbitrary network derive coverage probability understand vary spatial correlation different network affect coverage probability derive special result twooperator scenario construct operator individual network single network via probabilistic coupling external validation devise method quantify estimate spatial correlation actual basestation deployment compare twooperator model actual macrocelldominate network actual network primarily comprise distributedantennasystem das node use actual deployment datum set parameter model observe coverage probability model actual deployment compare well also match nearly perfectly case dasnodedominated deployment another interesting observation network share spectrum infrastructure low rate coverage probability network number bss share neither spectrum infrastructure suggest latter suitable lowrate application,0.4852941176470588,0.125,0.22794117647058823,0.058823529411764705,68.0,0.0,0.0,0.0,2.0
Information Technology,Network and Infrastructure,Mixed Methods,"The Sensitivity of Electric Power Infrastructure Resilience to the
  Spatial Distribution of Disaster Impacts","Credibly assessing the resilience of energy infrastructure in the face of
natural disasters is a salient concern facing researchers, government
officials, and community members. Here, we explore the influence of the spatial
distribution of disruptions due to hurricanes and other natural hazards on the
resilience of power distribution systems. We find that incorporating
information about the spatial distribution of disaster impacts has significant
implications for estimating infrastructure resilience. Specifically, the
uncertainty associated with estimated infrastructure resilience metrics to
spatially distributed disaster-induced disruptions is much higher than
determined by previous methods. We present a case study of an electric power
distribution grid impacted by a major landfalling hurricane. We show that
improved characterizations of disaster disruption drastically change the way in
which the grid recovers, including changes in emergent system properties such
as antifragility. Our work demonstrates that previous methods for estimating
critical infrastructure resilience may be overstating the confidence associated
with estimated network recoveries due to the lack of consideration of the
spatial structure of disruptions.",http://arxiv.org/abs/1902.02879v1,arXiv,sensitivity electric power infrastructure resilience spatial distribution disaster impact,credibly assess resilience energy infrastructure face natural disaster salient concern face researcher government official community member explore influence spatial distribution disruption due hurricane natural hazard resilience power distribution system find incorporate information spatial distribution disaster impact significant implication estimate infrastructure resilience specifically uncertainty associate estimate infrastructure resilience metric spatially distribute disasterinduced disruption much high determine previous method present case study electric power distribution grid impact major landfalle hurricane show improved characterization disaster disruption drastically change way grid recover include change emergent system property antifragility work demonstrate previous method estimate critical infrastructure resilience may overstate confidence associate estimate network recovery due lack consideration spatial structure disruption,sensitivity electric power infrastructure resilience spatial distribution disaster impact credibly assess resilience energy infrastructure face natural disaster salient concern face researcher government official community member explore influence spatial distribution disruption due hurricane natural hazard resilience power distribution system find incorporate information spatial distribution disaster impact significant implication estimate infrastructure resilience specifically uncertainty associate estimate infrastructure resilience metric spatially distribute disasterinduced disruption much high determine previous method present case study electric power distribution grid impact major landfalle hurricane show improved characterization disaster disruption drastically change way grid recover include change emergent system property antifragility work demonstrate previous method estimate critical infrastructure resilience may overstate confidence associate estimate network recovery due lack consideration spatial structure disruption,0.6190476190476191,0.11428571428571428,0.18095238095238095,0.047619047619047616,105.0,1.0,1.0,0.0,0.0
Information Technology,Network and Infrastructure,Design and Development,Cybersecurity Policies for Critical Infrastructure: Legal Mandates and Network Protection Requirements,"<jats:p>Securing crucial infrastructure, which incorporates ranges like vitality, transportation, healthcare, and finance, is exceptionally imperative since it plays an enormous portion in keeping the nation secure and secure. This paper study about how cybersecurity approaches and law necessities work together to ensure safeguard the critical resources from modern cyber threats. It gives an intensive approach toward the rules and directions that control hacking in critical areas, centring on the ones that must be taken after and universal guidelines of cybersecurity policies. The paper also discuss about the need for network security and centres on ways to form systems more versatile, such as through hazard evaluations, risk data, and occurrence reaction methods. Modern innovations like AI and blockchain are looked at to see how they could be able to form critical frameworks more secure. At the same time, the issues of lawful compliance, national issues, and information protection are carefully considered. This study considers supportive since it combines legitimate necessities and specialized security measures. It appears how to form solid cybersecurity plans that take after national and universal rules. These plans will ensure basic framework and keep operations running easily whereas moreover being legitimately mindful.</jats:p>",https://doi.org/10.70985/ns.v2024i8.51,CrossRef,cybersecurity policy critical infrastructure legal mandate network protection requirement,jatspsecure crucial infrastructure incorporate range like vitality transportation healthcare finance exceptionally imperative since play enormous portion keep nation secure secure paper study cybersecurity approach law necessity work together ensure safeguard critical resource modern cyber threat give intensive approach toward rule direction control hack critical area centre one must take universal guideline cybersecurity policy paper also discuss need network security centre way form system versatile hazard evaluation risk datum occurrence reaction method modern innovation like blockchain look see could able form critical framework secure time issue lawful compliance national issue information protection carefully consider study consider supportive since combine legitimate necessity specialized security measure appear form solid cybersecurity plan take national universal rule plan ensure basic framework keep operation run easily whereas moreover legitimately mindfuljatsp,cybersecurity policy critical infrastructure legal mandate network protection requirement jatspsecure crucial infrastructure incorporate range like vitality transportation healthcare finance exceptionally imperative since play enormous portion keep nation secure secure paper study cybersecurity approach law necessity work together ensure safeguard critical resource modern cyber threat give intensive approach toward rule direction control hack critical area centre one must take universal guideline cybersecurity policy paper also discuss need network security centre way form system versatile hazard evaluation risk datum occurrence reaction method modern innovation like blockchain look see could able form critical framework secure time issue lawful compliance national issue information protection carefully consider study consider supportive since combine legitimate necessity specialized security measure appear form solid cybersecurity plan take national universal rule plan ensure basic framework keep operation run easily whereas moreover legitimately mindfuljatsp,0.5161290322580645,0.16129032258064516,0.1935483870967742,0.056451612903225805,124.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Design and Development,Scheduling Algorithm in Infrastructure Less Network for SJF,"<jats:p>Some of recent researchers interested in the field of sensor network based wireless field (WSN) because of very difficult to communication via air medium due to lack of problems in using same carrier channel in all communication and easy to attack for security issues like malicious attacks or misbehaviour attacks, grey hole attacks, block hole attacks, etc. In truest based path not easy to fine this drawback overcome we proposed and implement one type of scheduling algorithm called shortest first job with help of infrastructure less network. This leading algorithm is overcome above issue of security issue in the wireless sensor networks problems, because of finding best cost and distance unbreakable path between sender to receiver simulated using NS2.</jats:p>",https://doi.org/10.48001/jocnv.2023.118-10,CrossRef,schedule algorithm infrastructure less network sjf,jatspsome recent researcher interested field sensor network base wireless field wsn difficult communication via air medium due lack problem use carrier channel communication easy attack security issue like malicious attack misbehaviour attack grey hole attack block hole attack etc truest base path easy fine drawback overcome propose implement one type scheduling algorithm call short first job help infrastructure less network lead algorithm overcome issue security issue wireless sensor network problem find good cost distance unbreakable path sender receiver simulated use nsjatsp,schedule algorithm infrastructure less network sjf jatspsome recent researcher interested field sensor network base wireless field wsn difficult communication via air medium due lack problem use carrier channel communication easy attack security issue like malicious attack misbehaviour attack grey hole attack block hole attack etc truest base path easy fine drawback overcome propose implement one type scheduling algorithm call short first job help infrastructure less network lead algorithm overcome issue security issue wireless sensor network problem find good cost distance unbreakable path sender receiver simulated use nsjatsp,0.5802469135802469,0.09876543209876543,0.2345679012345679,0.0,81.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Design and Development,Generating network representations of small‐scale infrastructure using generally available data,"<jats:title>Abstract</jats:title><jats:p>Risk analysis (including resilience analysis) of infrastructure requires models that describe the connection of components and subsequent flow dynamics. However, the detailed information needed to define these models may not be available, especially for small‐scale infrastructure that connect to every building. In this paper, we generate location‐specific small‐scale networks using detailed data that should always be available. We propose a general framework where we generate the network topology, we estimate the resource demand at each building, and we design the network components to meet the demands. This general framework is applicable to all types of infrastructure, but many procedures are specific to the type of network being generated. This paper develops the necessary procedures to generate sewer networks and illustrates the usage for an example network in a small study area in Seaside, Oregon. The proposed sewer network generator produces realistic sewer networks as compared to the real network of Seaside.</jats:p>",https://doi.org/10.1111/mice.13137,CrossRef,generate network representation infrastructure use generally available datum,jatstitleabstractjatstitlejatsprisk analysis include resilience analysis infrastructure require model describe connection component subsequent flow dynamic however detailed information need define model may available especially infrastructure connect every building paper generate network use detailed datum always available propose general framework generate network topology estimate resource demand building design network component meet demand general framework applicable type infrastructure many procedure specific type network generate paper develop necessary procedure generate sewer network illustrate usage example network small study area seaside oregon propose sewer network generator produce realistic sewer network compare real network seasidejatsp,generate network representation infrastructure use generally available datum jatstitleabstractjatstitlejatsprisk analysis include resilience analysis infrastructure require model describe connection component subsequent flow dynamic however detailed information need define model may available especially infrastructure connect every building paper generate network use detailed datum always available propose general framework generate network topology estimate resource demand building design network component meet demand general framework applicable type infrastructure many procedure specific type network generate paper develop necessary procedure generate sewer network illustrate usage example network small study area seaside oregon propose sewer network generator produce realistic sewer network compare real network seasidejatsp,0.6292134831460674,0.14606741573033707,0.15730337078651685,0.033707865168539325,89.0,0.0,1.0,0.0,1.0
Information Technology,Network and Infrastructure,Design and Development,Building Seamless Network Infrastructure for Scalable Service Integration in Smart Enterprises,"<jats:p>Building seamless network infrastructure with resilient QoS provisioning capabilities is important for integrating multiple virtualization technologies and scalable multiple service level agreement (SLA)-based services in an enterprise supporting large organizations and crowds. In this paper, a cloud network infrastructure for SLA-based networking as a service (NaaS) is introduced, which can evolve with SDN/NFV-based cloud networking innovations . Moreover, an intelligent agent-based reliable service provisioning framework is proposed that helps networking and cloud service integrating in a seamless manner in enterprises by investigating the cloud networking technologies and their interoperability challenges. Smart Enterprises are being formed and expanded by numerous organizations near and far owing to the fast advancement of information and communication technologies (ICTs). Their business process entails integration with numerous services of diverse service providers. Cloud service provisioning needs faster on-demand integration of possible service providers and their services in an enterprise. In such an enterprise with thousands of service providers, scalability, performance reliability, security, customer driven SLA assurance innovations and QoS monitoring are mainly important for meeting future service provisioning needs . Resilient QoS provisioning capabilities are critically important for large NeTs supporting enterprise-wide and city-wise resilient communications. Key innovations include new architectures for Wide Area, Access and Metro coalescence, SDN/NFV-based cloud networking innovations, cloud resource-rich network infrastructures and new QoS provisioning algorithms. Huge numbers of large Carrier NeTs are being massively deployed with numerous access technologies in many places, which is critical for the sustainable expansion and early realization of Smart Cities. Wi-Fi hotspots, Mobile Cellular communications and Optical Fiber access are a few add-on examples.</jats:p>",https://doi.org/10.53555/jrtdd.v6i10s(2).3609,CrossRef,build seamless network infrastructure scalable service integration smart enterprise,jatspbuilde seamless network infrastructure resilient qos provisioning capability important integrate multiple virtualization technology scalable multiple service level agreement slabase service enterprise support large organization crowd paper cloud network infrastructure slabased networking service naas introduce evolve sdnnfvbase cloud network innovation moreover intelligent agentbase reliable service provision framework propose help network cloud service integrate seamless manner enterprise investigate cloud network technology interoperability challenge smart enterprise form expand numerous organization near far owe fast advancement information communication technology ict business process entail integration numerous service diverse service provider cloud service provisioning need fast ondemand integration possible service provider service enterprise enterprise thousand service provider scalability performance reliability security customer drive sla assurance innovation qos monitoring mainly important meet future service provisioning need resilient qos provisioning capability critically important large net support enterprisewide citywise resilient communication key innovation include new architecture wide area access metro coalescence sdnnfvbase cloud network innovation cloud resourcerich network infrastructure new qos provisioning algorithm huge number large carrier net massively deploy numerous access technology many place critical sustainable expansion early realization smart city wifi hotspot mobile cellular communication optical fiber access addon examplesjatsp,build seamless network infrastructure scalable service integration smart enterprise jatspbuilde seamless network infrastructure resilient qos provisioning capability important integrate multiple virtualization technology scalable multiple service level agreement slabase service enterprise support large organization crowd paper cloud network infrastructure slabased networking service naas introduce evolve sdnnfvbase cloud network innovation moreover intelligent agentbase reliable service provision framework propose help network cloud service integrate seamless manner enterprise investigate cloud network technology interoperability challenge smart enterprise form expand numerous organization near far owe fast advancement information communication technology ict business process entail integration numerous service diverse service provider cloud service provisioning need fast ondemand integration possible service provider service enterprise enterprise thousand service provider scalability performance reliability security customer drive sla assurance innovation qos monitoring mainly important meet future service provisioning need resilient qos provisioning capability critically important large net support enterprisewide citywise resilient communication key innovation include new architecture wide area access metro coalescence sdnnfvbase cloud network innovation cloud resourcerich network infrastructure new qos provisioning algorithm huge number large carrier net massively deploy numerous access technology many place critical sustainable expansion early realization smart city wifi hotspot mobile cellular communication optical fiber access addon examplesjatsp,0.5573770491803278,0.08743169398907104,0.2185792349726776,0.02185792349726776,183.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Design and Development,Infrastructure as Code for Security Automation and Network Infrastructure Monitoring,"<jats:p>The Corona Virus (COVID-19) pandemic that has spread throughout the world has created a new work culture, namely working remotely by utilizing existing technology. This has the effect of increasing crime and cyber attacks as more and more devices are connected to the internet for work. Therefore, the priority on security and monitoring of network infrastructure should be increased. The security and monitoring of this infrastructure requires an administrator in its management and configuration. One administrator can manage multiple infrastructures, making the task more difficult and time-consuming. This research implements infrastructure as code for security automation and network infrastructure monitoring including IDS, honeypot, and SIEM. Automation is done using ansible tools to create virtual machines to security configuration and monitoring of network infrastructure automatically. The results obtained are automation processes and blackbox testing is carried out and validation is carried out using a User Acceptance Test to the computer apparatus of the IT Poltek SSN Unit to prove the ease of the automation carried out. Based on the results of the UAT, a score of 154 was obtained in the Agree area with an acceptance rate of 81.05% for the implementation of infrastructure as code for the automation carried out</jats:p>",https://doi.org/10.30812/matrik.v22i1.2471,CrossRef,infrastructure code security automation network infrastructure monitoring,jatspthe corona virus covid pandemic spread throughout world create new work culture namely work remotely utilize exist technology effect increase crime cyber attack device connect internet work therefore priority security monitoring network infrastructure increase security monitoring infrastructure require administrator management configuration one administrator manage multiple infrastructure make task difficult timeconsume research implement infrastructure code security automation network infrastructure monitoring include ids honeypot siem automation use ansible tool create virtual machine security configuration monitoring network infrastructure automatically result obtain automation process blackbox testing carry validation carry use user acceptance test computer apparatus poltek ssn unit prove ease automation carry base result uat score obtain agree area acceptance rate implementation infrastructure code automation carry outjatsp,infrastructure code security automation network infrastructure monitoring jatspthe corona virus covid pandemic spread throughout world create new work culture namely work remotely utilize exist technology effect increase crime cyber attack device connect internet work therefore priority security monitoring network infrastructure increase security monitoring infrastructure require administrator management configuration one administrator manage multiple infrastructure make task difficult timeconsume research implement infrastructure code security automation network infrastructure monitoring include ids honeypot siem automation use ansible tool create virtual machine security configuration monitoring network infrastructure automatically result obtain automation process blackbox testing carry validation carry use user acceptance test computer apparatus poltek ssn unit prove ease automation carry base result uat score obtain agree area acceptance rate implementation infrastructure code automation carry outjatsp,0.6194690265486725,0.18584070796460178,0.07079646017699115,0.035398230088495575,113.0,0.0,0.0,0.0,1.0
Information Technology,Network and Infrastructure,Theoretical / Conceptual,Reliability of Critical Infrastructure Networks: Challenges,"Critical infrastructures form a technological skeleton of our world by
providing us with water, food, electricity, gas, transportation, communication,
banking, and finance. Moreover, as urban population increases, the role of
infrastructures become more vital. In this paper, we adopt a network
perspective and discuss the ever growing need for fundamental interdisciplinary
study of critical infrastructure networks, efficient methods for estimating
their reliability, and cost-effective strategies for enhancing their
resiliency. We also highlight some of the main challenges arising on this way,
including cascading failures, feedback loops, and cross-sector
interdependencies.",http://arxiv.org/abs/1701.00594v1,arXiv,reliability critical infrastructure network challenge,critical infrastructure form technological skeleton world provide water food electricity gas transportation communication banking finance moreover urban population increase role infrastructure become vital paper adopt network perspective discuss ever grow need fundamental interdisciplinary study critical infrastructure network efficient method estimate reliability costeffective strategy enhance resiliency also highlight main challenge arise way include cascade failure feedback loop crosssector interdependency,reliability critical infrastructure network challenge critical infrastructure form technological skeleton world provide water food electricity gas transportation communication banking finance moreover urban population increase role infrastructure become vital paper adopt network perspective discuss ever grow need fundamental interdisciplinary study critical infrastructure network efficient method estimate reliability costeffective strategy enhance resiliency also highlight main challenge arise way include cascade failure feedback loop crosssector interdependency,0.6551724137931034,0.13793103448275862,0.15517241379310345,0.05172413793103448,58.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Theoretical / Conceptual,Uncertainty-Aware Resource Provisioning for Network Slicing,"Network slicing allows Mobile Network Operators to split the physical
infrastructure into isolated virtual networks (slices), managed by Service
Providers to accommodate customized services. The Service Function Chains
(SFCs) belonging to a slice are usually deployed on a best-effort premise:
nothing guarantees that network infrastructure resources will be sufficient to
support a varying number of users, each with uncertain requirements. Taking the
perspective of a network Infrastructure Provider (InP), this paper proposes a
resource provisioning approach for slices, robust to a partly unknown number of
users with random usage of the slice resources. The provisioning scheme aims to
maximize the total earnings of the InP, while providing a probabilistic
guarantee that the amount of provisioned network resources will meet the slice
requirements. Moreover, the proposed provisioning approach is performed so as
to limit its impact on low-priority background services, which may co-exist
with slices in the infrastructure network. A Mixed Integer Linear Programming
formulation of the slice resource provisioning problem is proposed. Optimal
joint and suboptimal sequential solutions are proposed. These solutions are
compared to a provisioning scheme that does not account for best-effort
services sharing the common infrastructure network.",http://arxiv.org/abs/2006.01104v1,arXiv,uncertaintyaware resource provisioning network slicing,network slicing allow mobile network operator split physical infrastructure isolated virtual network slice manage service provider accommodate customized service service function chain sfc belong slice usually deploy besteffort premise nothing guarantee network infrastructure resource sufficient support vary number user uncertain requirement take perspective network infrastructure provider inp paper propose resource provision approach slice robust partly unknown number user random usage slice resource provision scheme aim maximize total earning inp provide probabilistic guarantee amount provisioned network resource meet slice requirement moreover propose provision approach perform limit impact lowpriority background service may coexist slice infrastructure network mixed integer linear programming formulation slice resource provisioning problem propose optimal joint suboptimal sequential solution propose solution compare provision scheme account besteffort service share common infrastructure network,uncertaintyaware resource provisioning network slicing network slicing allow mobile network operator split physical infrastructure isolated virtual network slice manage service provider accommodate customized service service function chain sfc belong slice usually deploy besteffort premise nothing guarantee network infrastructure resource sufficient support vary number user uncertain requirement take perspective network infrastructure provider inp paper propose resource provision approach slice robust partly unknown number user random usage slice resource provision scheme aim maximize total earning inp provide probabilistic guarantee amount provisioned network resource meet slice requirement moreover propose provision approach perform limit impact lowpriority background service may coexist slice infrastructure network mixed integer linear programming formulation slice resource provisioning problem propose optimal joint suboptimal sequential solution propose solution compare provision scheme account besteffort service share common infrastructure network,0.5867768595041323,0.18181818181818182,0.12396694214876033,0.024793388429752067,121.0,1.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Theoretical / Conceptual,"ex uno pluria: The Service-Infrastructure Cycle, Ossification, and the
  Fragmentation of the Internet","In this article I will first argue that a Service-Infrastructure Cycle is
fundamental to networking evolution. Networks are built to accommodate certain
services at an expected scale. New applications and/or a significant increase
in scale require a rethinking of network mechanisms which results in new
deployments. Four decades-worth of iterations of this process have yielded the
Internet as we know it today, a common and shared global networking
infrastructure that delivers almost all services. I will further argue, using
brief historical case studies, that success of network mechanism deployments
often hinges on whether or not mechanism evolution follows the iterations of
this Cycle. Many have observed that this network, the Internet, has become
ossified and unable to change in response to new demands. In other words, after
decades of operation, the Service-Infrastructure Cycle has become stuck.
However, novel service requirements and scale increases continue to exert
significant pressure on this ossified infrastructure. The result, I will
conjecture, will be a fragmentation, the beginnings of which are evident today,
that will ultimately fundamentally change the character of the network
infrastructure. By ushering in a ManyNets world, this fragmentation will
lubricate the Service-Infrastructure Cycle so that it can continue to govern
the evolution of networking. I conclude this article with a brief discussion of
the possible implications of this emerging ManyNets world on networking
research.",http://arxiv.org/abs/1712.04379v1,arXiv,uno pluria serviceinfrastructure cycle ossification fragmentation internet,article first argue serviceinfrastructure cycle fundamental network evolution network build accommodate certain service expect scale new application andor significant increase scale require rethinking network mechanism result new deployment four decadesworth iteration process yield internet know today common shared global networking infrastructure deliver almost service far argue use brief historical case study success network mechanism deployment often hinge whether mechanism evolution follow iteration cycle many observe network internet become ossified unable change response new demand word decade operation serviceinfrastructure cycle become stuck however novel service requirement scale increase continue exert significant pressure ossified infrastructure result conjecture fragmentation beginning evident today ultimately fundamentally change character network infrastructure usher manynets world fragmentation lubricate serviceinfrastructure cycle continue govern evolution network conclude article brief discussion possible implication emerge manynet world network research,uno pluria serviceinfrastructure cycle ossification fragmentation internet article first argue serviceinfrastructure cycle fundamental network evolution network build accommodate certain service expect scale new application andor significant increase scale require rethinking network mechanism result new deployment four decadesworth iteration process yield internet know today common shared global networking infrastructure deliver almost service far argue use brief historical case study success network mechanism deployment often hinge whether mechanism evolution follow iteration cycle many observe network internet become ossified unable change response new demand word decade operation serviceinfrastructure cycle become stuck however novel service requirement scale increase continue exert significant pressure ossified infrastructure result conjecture fragmentation beginning evident today ultimately fundamentally change character network infrastructure usher manynets world fragmentation lubricate serviceinfrastructure cycle continue govern evolution network conclude article brief discussion possible implication emerge manynet world network research,0.5748031496062992,0.1732283464566929,0.14960629921259844,0.05511811023622047,127.0,0.0,0.0,2.0,0.0
Information Technology,Network and Infrastructure,Theoretical / Conceptual,"A Taxonomy for Blockchain-based Decentralized Physical Infrastructure
  Networks (DePIN)","As digitalization and technological advancements continue to shape the
infrastructure landscape, the emergence of blockchain-based decentralized
physical infrastructure networks (DePINs) has gained prominence. However, a
systematic categorization of DePIN components and their interrelationships is
still missing. To address this gap, we conduct a literature review and analysis
of existing frameworks and derived a taxonomy of DePIN systems from a
conceptual architecture. Our taxonomy encompasses three key dimensions:
distributed ledger technology, cryptoeconomic design and physicial
infrastructure network. Within each dimension, we identify and define relevant
components and attributes, establishing a clear hierarchical structure.
Moreover, we illustrate the relationships and dependencies among the identified
components, highlighting the interplay between governance models, hardware
architectures, networking protocols, token mechanisms, and distributed ledger
technologies. This taxonomy provides a foundation for understanding and
classifying diverse DePIN networks, serving as a basis for future research and
facilitating knowledge exchange, fostering collaboration and standardization
within the emerging field of decentralized physical infrastructure networks.",http://arxiv.org/abs/2309.16707v2,arXiv,taxonomy blockchainbase decentralize physical infrastructure network depin,digitalization technological advancement continue shape infrastructure landscape emergence blockchainbase decentralize physical infrastructure network depin gain prominence however systematic categorization depin component interrelationship still miss address gap conduct literature review analysis exist framework derive taxonomy depin system conceptual architecture taxonomy encompass three key dimension distribute ledger technology cryptoeconomic design physicial infrastructure network within dimension identify define relevant component attribute establish clear hierarchical structure moreover illustrate relationship dependency among identify component highlight interplay governance model hardware architecture network protocol token mechanism distribute ledger technology taxonomy provide foundation understanding classify diverse depin network serve basis future research facilitate knowledge exchange foster collaboration standardization within emerge field decentralized physical infrastructure network,taxonomy blockchainbase decentralize physical infrastructure network depin digitalization technological advancement continue shape infrastructure landscape emergence blockchainbase decentralize physical infrastructure network depin gain prominence however systematic categorization depin component interrelationship still miss address gap conduct literature review analysis exist framework derive taxonomy depin system conceptual architecture taxonomy encompass three key dimension distribute ledger technology cryptoeconomic design physicial infrastructure network within dimension identify define relevant component attribute establish clear hierarchical structure moreover illustrate relationship dependency among identify component highlight interplay governance model hardware architecture network protocol token mechanism distribute ledger technology taxonomy provide foundation understanding classify diverse depin network serve basis future research facilitate knowledge exchange foster collaboration standardization within emerge field decentralized physical infrastructure network,0.5794392523364486,0.14018691588785046,0.14953271028037382,0.028037383177570093,107.0,0.0,0.0,0.0,0.0
Information Technology,Network and Infrastructure,Theoretical / Conceptual,"Admission Control and Resource Reservation for Prioritized Slice
  Requests with Guaranteed SLA under Uncertainties","Network slicing has emerged as a key concept in 5G systems, allowing Mobile
Network Operators (MNOs) to build isolated logical networks (slices) on top of
shared infrastructure networks managed by Infrastructure Providers (InP).
Network slicing requires the assignment of infrastructure network resources to
virtual network components at slice activation time and the adjustment of
resources for slices under operation. Performing these operations just-in-time,
on a best-effort basis, comes with no guarantee on the availability of enough
infrastructure resources to meet slice requirements.
  This paper proposes a prioritized admission control mechanism for concurrent
slices based on an infrastructure resource reservation approach. The
reservation accounts for the dynamic nature of slice requests while being
robust to uncertainties in slice resource demands. Adopting the perspective of
an InP, reservation schemes are proposed that maximize the number of slices for
which infrastructure resources can be granted while minimizing the costs
charged to the MNOs. This requires the solution of a max-min optimization
problem with a non-linear cost function and non-linear constraints induced by
the robustness to uncertainties of demands and the limitation of the impact of
reservation on background services. The cost and the constraints are linearized
and several reduced-complexity strategies are proposed to solve the slice
admission control and resource reservation problem. Simulations show that the
proportion of admitted slices of different priority levels can be adjusted by a
differentiated selection of the delay between the reception and the processing
instants of a slice resource request.",http://arxiv.org/abs/2203.09367v1,arXiv,admission control resource reservation prioritize slice request guarantee sla uncertainty,network slicing emerge key concept system allow mobile network operator mno build isolated logical network slice top share infrastructure network manage infrastructure provider inp network slicing require assignment infrastructure network resource virtual network component slice activation time adjustment resource slice operation perform operation justintime besteffort basis come guarantee availability enough infrastructure resource meet slice requirement paper propose prioritize admission control mechanism concurrent slice base infrastructure resource reservation approach reservation account dynamic nature slice request robust uncertainty slice resource demand adopt perspective inp reservation scheme propose maximize number slice infrastructure resource grant minimize cost charge mno require solution maxmin optimization problem nonlinear cost function nonlinear constraint induce robustness uncertainty demand limitation impact reservation background service cost constraint linearize several reducedcomplexity strategy propose solve slice admission control resource reservation problem simulation show proportion admit slice different priority level adjust differentiate selection delay reception processing instant slice resource request,admission control resource reservation prioritize slice request guarantee sla uncertainty network slicing emerge key concept system allow mobile network operator mno build isolated logical network slice top share infrastructure network manage infrastructure provider inp network slicing require assignment infrastructure network resource virtual network component slice activation time adjustment resource slice operation perform operation justintime besteffort basis come guarantee availability enough infrastructure resource meet slice requirement paper propose prioritize admission control mechanism concurrent slice base infrastructure resource reservation approach reservation account dynamic nature slice request robust uncertainty slice resource demand adopt perspective inp reservation scheme propose maximize number slice infrastructure resource grant minimize cost charge mno require solution maxmin optimization problem nonlinear cost function nonlinear constraint induce robustness uncertainty demand limitation impact reservation background service cost constraint linearize several reducedcomplexity strategy propose solve slice admission control resource reservation problem simulation show proportion admit slice different priority level adjust differentiate selection delay reception processing instant slice resource request,0.7465753424657534,0.1095890410958904,0.10273972602739725,0.0,146.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Quantitative,OVERVIEW OF CYBERSECURITY METHODS AND STRATEGIES USING ARTIFICIAL INTELLIGENCE,"<jats:p>In today’s world, information technology is rapidly evolving, leading to an increase in both the number and complexity of cyber threats, including phishing, malware, and social engineering attacks. The growth in the quantity and sophistication of cyber threats creates an urgent need to improve methods for protecting information systems. Artificial Intelligence (AI), particularly machine learning and deep learning technologies, shows significant potential in enhancing cybersecurity. This article is dedicated to reviewing contemporary AI-based cybersecurity methods and strategies, as well as evaluating their effectiveness in detecting and countering cyber threats. The paper analyzes recent research by both domestic and international scientists, emphasizing AI’s ability to analyze large volumes of data, uncover hidden patterns, predict potential threats, and automate incident response processes. It highlights key research directions, including anomaly detection, threat modeling, incident response automation, and ensuring the interpretability of decisions made by AI systems. Special attention is given to the integration of AI into existing cybersecurity systems and its capacity to adapt to new threats. The article also discusses the main challenges and prospects of applying AI in cybersecurity, including ethical and legal aspects such as privacy issues, decision transparency, and accountability for actions taken based on AI system decisions. Recent statistical data indicate a rapid growth in the market for AI-based cybersecurity tools, underscoring the importance and relevance of this topic in contemporary conditions. The analysis results confirm that using AI allows for automating monitoring, threat detection, and response processes, reducing incident response time and enhancing the overall protection level of information systems. At the same time, implementing AI in cybersecurity faces several challenges, such as ensuring the transparency of AI decisions and protecting against potential threats created using the same technologies. Research in this field promotes strategic development and innovation in cybersecurity, providing researchers and professionals with new tools and methods for ensuring information system security. Thus, given the rapid growth and evolution of cyber threats, studying the role of AI in cybersecurity is extremely relevant and important. It not only enhances protection efficiency but also fosters the development of new strategies and technologies to counter threats in the digital age.</jats:p>",https://doi.org/10.28925/2663-4023.2024.25.379389,CrossRef,overview cybersecurity method strategy use artificial intelligence,jatspin today world information technology rapidly evolve lead increase number complexity cyber threat include phishe malware social engineering attack growth quantity sophistication cyber threat create urgent need improve method protect information system artificial intelligence particularly machine learning deep learning technology show significant potential enhance cybersecurity article dedicate review contemporary aibased cybersecurity method strategy well evaluate effectiveness detect counter cyber threat paper analyze recent research domestic international scientist emphasize ability analyze large volume datum uncover hide pattern predict potential threat automate incident response process highlight key research direction include anomaly detection threat modeling incident response automation ensure interpretability decision make system special attention give integration exist cybersecurity system capacity adapt new threat article also discuss main challenge prospect apply cybersecurity include ethical legal aspect privacy issue decision transparency accountability action take base system decision recent statistical datum indicate rapid growth market aibased cybersecurity tool underscore importance relevance topic contemporary condition analysis result confirm use allow automate monitor threat detection response process reduce incident response time enhance overall protection level information system time implement cybersecurity face several challenge ensure transparency decision protect potential threat create use technology research field promote strategic development innovation cybersecurity provide researcher professional new tool method ensure information system security thus give rapid growth evolution cyber threat study role cybersecurity extremely relevant important enhance protection efficiency also foster development new strategy technology counter threat digital agejatsp,overview cybersecurity method strategy use artificial intelligence jatspin today world information technology rapidly evolve lead increase number complexity cyber threat include phishe malware social engineering attack growth quantity sophistication cyber threat create urgent need improve method protect information system artificial intelligence particularly machine learning deep learning technology show significant potential enhance cybersecurity article dedicate review contemporary aibased cybersecurity method strategy well evaluate effectiveness detect counter cyber threat paper analyze recent research domestic international scientist emphasize ability analyze large volume datum uncover hide pattern predict potential threat automate incident response process highlight key research direction include anomaly detection threat modeling incident response automation ensure interpretability decision make system special attention give integration exist cybersecurity system capacity adapt new threat article also discuss main challenge prospect apply cybersecurity include ethical legal aspect privacy issue decision transparency accountability action take base system decision recent statistical datum indicate rapid growth market aibased cybersecurity tool underscore importance relevance topic contemporary condition analysis result confirm use allow automate monitor threat detection response process reduce incident response time enhance overall protection level information system time implement cybersecurity face several challenge ensure transparency decision protect potential threat create use technology research field promote strategic development innovation cybersecurity provide researcher professional new tool method ensure information system security thus give rapid growth evolution cyber threat study role cybersecurity extremely relevant important enhance protection efficiency also foster development new strategy technology counter threat digital agejatsp,0.6228070175438597,0.16666666666666666,0.16228070175438597,0.02631578947368421,228.0,0.0,0.0,1.0,0.0
Information Technology,Cybersecurity,Quantitative,The THE GENDER EQUALITY IN CYBERSECURITY,"<jats:p>The article examines gender aspects in the domestic cybersecurity sector. The insufficient level of representation of women in this field is caused by a small number of girls and women who chose this field of activity for training and professional realization due to insufficient awareness of it, various stereotypes and prejudices. However, the ongoing full-scale war in Ukraine, its hybrid nature, the spread of gender misinformation, the demographic crisis, and the shortage of labor in the labor market that are taking place in the country require the expansion of women's participation in combating cybercrime and strengthening the cyber resilience of the state. The study conducted by the authors is based on an analysis of current international and national legislation on gender equality in the country and, in particular, in the defense and security sector, as well as modern publications by foreign and Ukrainian scientists and researchers. Quantitative analysis of gender aspects in the field of cybersecurity, in particular, in matters of employment and education, was carried out based on data from the State Statistics Service of Ukraine.

The results of the study showed that it was the martial law in the country and the mobilization of men that forced women to replace them in a number of professions. The representation of women in the security and defense sector has increased significantly, which has a positive effect on the overall level of security in society. The number of women choosing professions in the field of cybersecurity is gradually increasing, which gives hope for their further employment there. In order to promote gender equality in cybersecurity, expand the professional realization of women in this field, the authors recommend that employers use the existing high educational potential of women and girls more diversely and inclusively, their ability to quickly learn and adapt to changes, the availability of digital skills and the level of access to the Internet. To overcome obstacles in future professional realization, form more skills that are practical in female students, hone the ability to think outside the box, and teach them to work with people.</jats:p>",https://doi.org/10.28925/2663-4023.2025.27.742,CrossRef,gender equality cybersecurity,jatspthe article examine gender aspect domestic cybersecurity sector insufficient level representation woman field cause small number girl woman choose field activity training professional realization due insufficient awareness various stereotype prejudice however ongoing fullscale war ukraine hybrid nature spread gender misinformation demographic crisis shortage labor labor market take place country require expansion women participation combat cybercrime strengthen cyber resilience state study conduct author base analysis current international national legislation gender equality country particular defense security sector well modern publication foreign ukrainian scientist researcher quantitative analysis gender aspect field cybersecurity particular matter employment education carry base datum state statistic service ukraine result study show martial law country mobilization man force woman replace number profession representation woman security defense sector increase significantly positive effect overall level security society number woman choose profession field cybersecurity gradually increase give hope employment order promote gender equality cybersecurity expand professional realization woman field author recommend employer use exist high educational potential woman girl diversely inclusively ability quickly learn adapt change availability digital skill level access internet overcome obstacle future professional realization form skill practical female student hone ability think outside box teach work peoplejatsp,gender equality cybersecurity jatspthe article examine gender aspect domestic cybersecurity sector insufficient level representation woman field cause small number girl woman choose field activity training professional realization due insufficient awareness various stereotype prejudice however ongoing fullscale war ukraine hybrid nature spread gender misinformation demographic crisis shortage labor labor market take place country require expansion women participation combat cybercrime strengthen cyber resilience state study conduct author base analysis current international national legislation gender equality country particular defense security sector well modern publication foreign ukrainian scientist researcher quantitative analysis gender aspect field cybersecurity particular matter employment education carry base datum state statistic service ukraine result study show martial law country mobilization man force woman replace number profession representation woman security defense sector increase significantly positive effect overall level security society number woman choose profession field cybersecurity gradually increase give hope employment order promote gender equality cybersecurity expand professional realization woman field author recommend employer use exist high educational potential woman girl diversely inclusively ability quickly learn adapt change availability digital skill level access internet overcome obstacle future professional realization form skill practical female student hone ability think outside box teach work peoplejatsp,0.6042780748663101,0.12834224598930483,0.1657754010695187,0.03208556149732621,187.0,0.0,1.0,0.0,1.0
Information Technology,Cybersecurity,Quantitative,Valet attack on privacy: a cybersecurity threat in automotive Bluetooth infotainment systems,"<jats:title>Abstract</jats:title><jats:p>Modern automobiles are equipped with connectivity features to enhance the user’s comfort. Bluetooth is one such communication technology that is used to pair a personal device with an automotive infotainment unit. Upon pairing, the user could access the personal information on the phone through the automotive head unit with minimum distraction while driving. However, such connectivity introduces a possibility for privacy attacks. Hence, performing an in-depth analysis of the system with privacy constraints is extremely important to prevent unauthorized access to personal information. In this work, we perform a systematic analysis of the Bluetooth network of an automotive infotainment unit to exploit security and privacy-related vulnerabilities. We model the identified threat with respect to privacy constraints of the system, emphasize the severity of attacks through a standardized rating metric and then provide potential countermeasures to prevent the attack. We perform System Theoretic Process Analysis for Privacy as a part of the systematic analysis and use the Common Vulnerability Scoring System to derive attack severity. The identified vulnerabilities are due to design flaws and assumptions on Bluetooth protocol implementation on automotive infotainment systems. We then elicit the vulnerability by performing a privacy attack on the Automotive system in an actual vehicle. We use Android Open-Source Project to report our findings and propose defense strategies.</jats:p>",https://doi.org/10.1186/s42400-022-00132-x,CrossRef,valet attack privacy cybersecurity threat automotive bluetooth infotainment system,jatstitleabstractjatstitlejatspmodern automobile equip connectivity feature enhance user comfort bluetooth one communication technology use pair personal device automotive infotainment unit upon pair user could access personal information phone automotive head unit minimum distraction drive however connectivity introduce possibility privacy attack hence perform indepth analysis system privacy constraint extremely important prevent unauthorized access personal information work perform systematic analysis bluetooth network automotive infotainment unit exploit security privacyrelate vulnerability model identify threat respect privacy constraint system emphasize severity attack standardized rating metric provide potential countermeasure prevent attack perform system theoretic process analysis privacy part systematic analysis use common vulnerability scoring system derive attack severity identify vulnerability due design flaw assumption bluetooth protocol implementation automotive infotainment system elicit vulnerability perform privacy attack automotive system actual vehicle use android opensource project report finding propose defense strategiesjatsp,valet attack privacy cybersecurity threat automotive bluetooth infotainment system jatstitleabstractjatstitlejatspmodern automobile equip connectivity feature enhance user comfort bluetooth one communication technology use pair personal device automotive infotainment unit upon pair user could access personal information phone automotive head unit minimum distraction drive however connectivity introduce possibility privacy attack hence perform indepth analysis system privacy constraint extremely important prevent unauthorized access personal information work perform systematic analysis bluetooth network automotive infotainment unit exploit security privacyrelate vulnerability model identify threat respect privacy constraint system emphasize severity attack standardized rating metric provide potential countermeasure prevent attack perform system theoretic process analysis privacy part systematic analysis use common vulnerability scoring system derive attack severity identify vulnerability due design flaw assumption bluetooth protocol implementation automotive infotainment system elicit vulnerability perform privacy attack automotive system actual vehicle use android opensource project report finding propose defense strategiesjatsp,0.6030534351145038,0.1297709923664122,0.15267175572519084,0.022900763358778626,131.0,1.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Quantitative,Cybersecurity Defence Mechanism Against DDoS Attack with Explainability,"<jats:p>Application-layer attacks (Layer 7 attacks), a form of distributed denial-of-service (DDoS) aimed at web servers, have become a significant concern in cybersecurity because of their ability to disrupt services by overwhelming server resources. This study focuses on addressing the challenges of detecting and mitigating the impact of such attacks, which are difficult to counter due to their sophisticated nature. The primary objective of this study is to develop an effective monitoring and defence model to detect, defend, and respond to these attacks efficiently. To achieve this, SHapley Additive exPlanations (SHAP) technology was used to understand the behaviour of the model and to increase the efficiency of the detection classifiers. The defence model is designed with three states: normal, observing, and suspicious. The observing mode, which represents the detection part, is triggered when the server load exceeds a predefined threshold. The detection system incorporates five machine learning (ML) algorithms: decision trees (DTs), support vector machines (SVMs), logistic regression (LR), naive Bayes (NB), and K-nearest neighbours (KNNs). A stacked classifier (SC) was then employed to combine these models to achieve optimal performance. The algorithms were evaluated in terms of accuracy (ACC), precision (PRC), recall (REC), F1 score (F1), and time (T). The SC demonstrates superior accuracy in distinguishing between legitimate traffic and malicious traffic. If the server continues to suffer from overload, the suspicious part of the defence model will be activated, and the mitigation algorithm will be called, which, in turn, bans users responsible for the attack and prevents illegitimate users from connecting to the server. The effects of the mitigation algorithm were noticeable in the server traffic rate, transmission rate, memory utilization, and CPU utilization, confirming its ability to defend against application-layer attacks.
 </jats:p>",https://doi.org/10.58496/mjcs/2024/027,CrossRef,cybersecurity defence mechanism ddo attack explainability,jatspapplicationlayer attack layer attack form distribute denialofservice ddo aim web server become significant concern cybersecurity ability disrupt service overwhelming server resource study focus address challenge detect mitigate impact attack difficult counter due sophisticated nature primary objective study develop effective monitoring defence model detect defend respond attack efficiently achieve shapley additive explanation shap technology use understand behaviour model increase efficiency detection classifier defence model design three state normal observe suspicious observe mode represent detection part trigger server load exceed predefine threshold detection system incorporate five machine learn algorithms decision tree dts support vector machine svms logistic regression naive baye knearest neighbour knns stack classifier employ combine model achieve optimal performance algorithm evaluate term accuracy acc precision prc recall rec score time demonstrate superior accuracy distinguish legitimate traffic malicious traffic server continue suffer overload suspicious part defence model activate mitigation algorithm call turn ban user responsible attack prevent illegitimate user connect server effect mitigation algorithm noticeable server traffic rate transmission rate memory utilization cpu utilization confirm ability defend applicationlayer attack jatsp,cybersecurity defence mechanism ddo attack explainability jatspapplicationlayer attack layer attack form distribute denialofservice ddo aim web server become significant concern cybersecurity ability disrupt service overwhelming server resource study focus address challenge detect mitigate impact attack difficult counter due sophisticated nature primary objective study develop effective monitoring defence model detect defend respond attack efficiently achieve shapley additive explanation shap technology use understand behaviour model increase efficiency detection classifier defence model design three state normal observe suspicious observe mode represent detection part trigger server load exceed predefine threshold detection system incorporate five machine learn algorithms decision tree dts support vector machine svms logistic regression naive baye knearest neighbour knns stack classifier employ combine model achieve optimal performance algorithm evaluate term accuracy acc precision prc recall rec score time demonstrate superior accuracy distinguish legitimate traffic malicious traffic server continue suffer overload suspicious part defence model activate mitigation algorithm call turn ban user responsible attack prevent illegitimate user connect server effect mitigation algorithm noticeable server traffic rate transmission rate memory utilization cpu utilization confirm ability defend applicationlayer attack jatsp,0.5502958579881657,0.14792899408284024,0.14792899408284024,0.005917159763313609,169.0,0.0,1.0,0.0,2.0
Information Technology,Cybersecurity,Quantitative,Enhanced detection of obfuscated malware in memory dumps: a machine learning approach for advanced cybersecurity,"<jats:title>Abstract</jats:title><jats:p>In the realm of cybersecurity, the detection and analysis of obfuscated malware remain a critical challenge, especially in the context of memory dumps. This research paper presents a novel machine learning-based framework designed to enhance the detection and analytical capabilities against such elusive threats for binary and multi type’s malware. Our approach leverages a comprehensive dataset comprising benign and malicious memory dumps, encompassing a wide array of obfuscated malware types including Spyware, Ransomware, and Trojan Horses with their sub-categories. We begin by employing rigorous data preprocessing methods, including the normalization of memory dumps and encoding of categorical data. To tackle the issue of class imbalance, a Synthetic Minority Over-sampling Technique is utilized, ensuring a balanced representation of various malware types. Feature selection is meticulously conducted through Chi-Square tests, mutual information, and correlation analyses, refining the model’s focus on the most indicative attributes of obfuscated malware. The heart of our framework lies in the deployment of an Ensemble-based Classifier, chosen for its robustness and effectiveness in handling complex data structures. The model’s performance is rigorously evaluated using a suite of metrics, including accuracy, precision, recall, F1-score, and the area under the ROC curve (AUC) with other evaluation metrics to assess the model’s efficiency. The proposed model demonstrates a detection accuracy exceeding 99% across all cases, surpassing the performance of all existing models in the realm of malware detection.</jats:p>",https://doi.org/10.1186/s42400-024-00205-z,CrossRef,enhance detection obfuscated malware memory dump machine learn approach advanced cybersecurity,jatstitleabstractjatstitlejatspin realm cybersecurity detection analysis obfuscate malware remain critical challenge especially context memory dump research paper present novel machine learningbase framework design enhance detection analytical capability elusive threat binary multi type malware approach leverage comprehensive dataset comprising benign malicious memory dump encompass wide array obfuscated malware type include spyware ransomware trojan horse subcategorie begin employ rigorous datum preprocessing method include normalization memory dump encoding categorical datum tackle issue class imbalance synthetic minority oversampling technique utilize ensure balanced representation various malware type feature selection meticulously conduct chisquare test mutual information correlation analysis refine model focus indicative attribute obfuscate malware heart framework lie deployment ensemblebase classifier choose robustness effectiveness handle complex data structure model performance rigorously evaluate use suite metric include accuracy precision recall fscore area roc curve auc evaluation metric assess model efficiency propose model demonstrate detection accuracy exceed across case surpass performance exist model realm malware detectionjatsp,enhance detection obfuscated malware memory dump machine learn approach advanced cybersecurity jatstitleabstractjatstitlejatspin realm cybersecurity detection analysis obfuscate malware remain critical challenge especially context memory dump research paper present novel machine learningbase framework design enhance detection analytical capability elusive threat binary multi type malware approach leverage comprehensive dataset comprising benign malicious memory dump encompass wide array obfuscated malware type include spyware ransomware trojan horse subcategorie begin employ rigorous datum preprocessing method include normalization memory dump encoding categorical datum tackle issue class imbalance synthetic minority oversampling technique utilize ensure balanced representation various malware type feature selection meticulously conduct chisquare test mutual information correlation analysis refine model focus indicative attribute obfuscate malware heart framework lie deployment ensemblebase classifier choose robustness effectiveness handle complex data structure model performance rigorously evaluate use suite metric include accuracy precision recall fscore area roc curve auc evaluation metric assess model efficiency propose model demonstrate detection accuracy exceed across case surpass performance exist model realm malware detectionjatsp,0.6598639455782312,0.12244897959183673,0.1564625850340136,0.02040816326530612,147.0,1.0,1.0,0.0,0.0
Information Technology,Cybersecurity,Qualitative,Exploiting Human Trust in Cybersecurity: Which Trust Development Process Is Predominant in Phishing Attacks?,"<jats:p>Humans live in an interconnected world that is increasingly featured with virtual interactions in cyberspace. That world has raised cybersecurity concerns, particularly regarding the exploitation of human trust through various means, such as phishing. Phishing remains one of the most prevalent forms of cybercrime. It exploits human trust to manipulate individuals into divulging sensitive information. This study investigates the trust development mechanisms most exploited by cybercriminals in phishing attacks. It focuses on two primary trust development processes: relationship history and future expectations. The study uses qualitative content analysis of 42 phishing messages collected from diverse secondary sources. The findings reveal that future expectations—such as promises of rewards, urgent requests, or threats of penalties—dominate phishing tactics. In contrast, relationship history mechanisms exploit existing or fabricated relationships to evoke trust and compliance. These findings provide critical insights into the psychological manipulations leveraged in phishing schemes and highlight the need to integrate behavioural and cognitive principles into cybersecurity education. Practical implications include tailored training programs for distinct user groups, such as seniors, employees, and students. The training should emphasise recognising urgency cues, emotional manipulation, and verification strategies.</jats:p>",https://doi.org/10.60097/acig/199452,CrossRef,exploit human trust cybersecurity trust development process predominant phishe attack,jatsphumans live interconnected world increasingly feature virtual interaction cyberspace world raise cybersecurity concern particularly regard exploitation human trust various mean phishe phishing remain one prevalent form cybercrime exploit human trust manipulate individual divulge sensitive information study investigate trust development mechanism exploit cybercriminal phishe attack focus two primary trust development process relationship history future expectation study use qualitative content analysis phishe message collect diverse secondary source finding reveal future expectation promise reward urgent request threat penalty dominate phishe tactic contrast relationship history mechanism exploit exist fabricate relationship evoke trust compliance finding provide critical insight psychological manipulation leverage phishe scheme highlight need integrate behavioural cognitive principle cybersecurity education practical implication include tailor training program distinct user group senior employee student training emphasise recognise urgency cue emotional manipulation verification strategiesjatsp,exploit human trust cybersecurity trust development process predominant phishe attack jatsphumans live interconnected world increasingly feature virtual interaction cyberspace world raise cybersecurity concern particularly regard exploitation human trust various mean phishe phishing remain one prevalent form cybercrime exploit human trust manipulate individual divulge sensitive information study investigate trust development mechanism exploit cybercriminal phishe attack focus two primary trust development process relationship history future expectation study use qualitative content analysis phishe message collect diverse secondary source finding reveal future expectation promise reward urgent request threat penalty dominate phishe tactic contrast relationship history mechanism exploit exist fabricate relationship evoke trust compliance finding provide critical insight psychological manipulation leverage phishe scheme highlight need integrate behavioural cognitive principle cybersecurity education practical implication include tailor training program distinct user group senior employee student training emphasise recognise urgency cue emotional manipulation verification strategiesjatsp,0.5826771653543307,0.14173228346456693,0.2047244094488189,0.015748031496062992,127.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Qualitative,Criminological Features of the Cybersecurity Threats,"<jats:p>[Purpose] Currently, novel tools have converted many traditional phenomena into cyber ones. The absence of a standardized terminology and classification of cybersecurity threats has raised significant concerns among researchers and lawmakers. Ignoring the emerging risks that necessitate appropriate responses is impracticable. Prior to devising countermeasures to combat cybercrime, it is imperative to accurately define the concept of cybersecurity threat and differentiate it from other related notions such as information security, computer security, cyberattack, cyberspace attack, cyber incident, cybersecurity incident, cyber threat, and cybersecurity event, whose definitions may be ascertained from the glossaries of various standardization institutes.
[Methodology/Approach/Design] This study presents a descriptive investigation of cybersecurity threats and their causes, utilizing genetic, systematic-functional, and systematization methods. Cyberattacks are identified as the primary threat, and data is represented through qualitative research and summarized in tables. The study also considers the historical background of concepts and cyber-criminality.
[Findings] The present study delves into a comprehensive analysis of distinct categories of cybersecurity threats, the trajectory of cybercrime, and the factors that underpin the emergence of new cybersecurity threats. The research scrutinizes both the general causes for cyber-criminality and the specific determinants for criminal activities that target the energy sector, a critical component of a state's infrastructure. The study reveals that the major sources of threats comprise terrorists, insiders (i.e., disgruntled employees), commercial spies, and black hackers or crackers, whose malicious acts are themselves considered threats to cybersecurity.</jats:p>",https://doi.org/10.26512/lstr.v15i2.45997,CrossRef,criminological feature cybersecurity threat,jatsppurpose currently novel tool convert many traditional phenomenon cyber one absence standardized terminology classification cybersecurity threat raise significant concern among researcher lawmaker ignore emerge risk necessitate appropriate response impracticable prior devise countermeasure combat cybercrime imperative accurately define concept cybersecurity threat differentiate relate notion information security computer security cyberattack cyberspace attack cyber incident cybersecurity incident cyber threat cybersecurity event whose definition may ascertain glossary various standardization institute methodologyapproachdesign study present descriptive investigation cybersecurity threat cause utilize genetic systematicfunctional systematization method cyberattack identify primary threat datum represent qualitative research summarize table study also consider historical background concept cybercriminality finding present study delf comprehensive analysis distinct category cybersecurity threat trajectory cybercrime factor underpin emergence new cybersecurity threat research scrutinize general cause cybercriminality specific determinant criminal activity target energy sector critical component state infrastructure study reveal major source threat comprise terrorist insider disgruntle employee commercial spy black hacker cracker whose malicious act consider threat cybersecurityjatsp,criminological feature cybersecurity threat jatsppurpose currently novel tool convert many traditional phenomenon cyber one absence standardized terminology classification cybersecurity threat raise significant concern among researcher lawmaker ignore emerge risk necessitate appropriate response impracticable prior devise countermeasure combat cybercrime imperative accurately define concept cybersecurity threat differentiate relate notion information security computer security cyberattack cyberspace attack cyber incident cybersecurity incident cyber threat cybersecurity event whose definition may ascertain glossary various standardization institute methodologyapproachdesign study present descriptive investigation cybersecurity threat cause utilize genetic systematicfunctional systematization method cyberattack identify primary threat datum represent qualitative research summarize table study also consider historical background concept cybercriminality finding present study delf comprehensive analysis distinct category cybersecurity threat trajectory cybercrime factor underpin emergence new cybersecurity threat research scrutinize general cause cybercriminality specific determinant criminal activity target energy sector critical component state infrastructure study reveal major source threat comprise terrorist insider disgruntle employee commercial spy black hacker cracker whose malicious act consider threat cybersecurityjatsp,0.5298013245033113,0.12582781456953643,0.2251655629139073,0.019867549668874173,151.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Qualitative,An Analysis of Cybersecurity Policy Compliance in Organisations,"<jats:p>In the contemporary digital landscape, cyber-attacks and incidents have placed cyber-security at the forefront of priorities in organisations. As organisations face cyber risks, it becomes imperative to implement and comply with various cyber-security policies. However, due to factors such as policy complexity and resistance from employees, compliance can be a challenging task. The study, which took a comprehensive approach, investigated the variables that affect an organisation's adherence to cyber-security policies. The findings of this study provide insights into the challenges and factors influencing compliance with cyber-security policies in organisations. A case study design was chosen as part of a qualitative approach to answer the research question. For data gathering, semi-structured interviews were performed, and existing documents were also considered when available to supplement interviews. The gathered data was meticulously organised, coded, and analysed using the Actor-Network Theory perspective, with a focus on its four moments of translation: problematisation, interessement, enrolment, and mobilisation. The analysis revealed that insider threats and phishing attempts are the two cyber threats that affect organisations; behavioural challenges and enforcement limitations are factors that influence and contribute to the non-compliance of cyber-security policy; phishing exercises and policy development processes are used to enforce cyber-security policies.</jats:p>",https://doi.org/10.60097/acig/191942,CrossRef,analysis cybersecurity policy compliance organisation,jatspin contemporary digital landscape cyberattack incident place cybersecurity forefront priority organisation organisation face cyber risk become imperative implement comply various cybersecurity policy however due factor policy complexity resistance employee compliance challenging task study take comprehensive approach investigate variable affect organisation adherence cybersecurity policy finding study provide insight challenge factor influence compliance cybersecurity policy organisation case study design choose part qualitative approach answer research question datum gathering semistructure interview perform exist document also consider available supplement interview gather datum meticulously organise code analyse use actornetwork theory perspective focus four moment translation problematisation interessement enrolment mobilisation analysis reveal insider threat phishe attempt two cyber threat affect organisation behavioural challenge enforcement limitation factor influence contribute noncompliance cybersecurity policy phishe exercise policy development process use enforce cybersecurity policiesjatsp,analysis cybersecurity policy compliance organisation jatspin contemporary digital landscape cyberattack incident place cybersecurity forefront priority organisation organisation face cyber risk become imperative implement comply various cybersecurity policy however due factor policy complexity resistance employee compliance challenging task study take comprehensive approach investigate variable affect organisation adherence cybersecurity policy finding study provide insight challenge factor influence compliance cybersecurity policy organisation case study design choose part qualitative approach answer research question datum gathering semistructure interview perform exist document also consider available supplement interview gather datum meticulously organise code analyse use actornetwork theory perspective focus four moment translation problematisation interessement enrolment mobilisation analysis reveal insider threat phishe attempt two cyber threat affect organisation behavioural challenge enforcement limitation factor influence contribute noncompliance cybersecurity policy phishe exercise policy development process use enforce cybersecurity policiesjatsp,0.6129032258064516,0.1532258064516129,0.08064516129032258,0.03225806451612903,124.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Qualitative,Digital Divide in Cybersecurity,"<jats:p>The digital gap actively determines how people obtain varying degrees of access to technological resources, educational opportunities, and job opportunities, specifically within cybersecurity. Research explores digital divide patterns in cybersecurity populations by analyzing unequal opportunities related to cybersecurity education, job opportunities, and security protection levels. This study combines demographic analytics and interview data to reveal how socioeconomic standing, racial background, gender identities, and regional locations simultaneously shape cybersecurity accessibility and workforce take-up. The data reveals systemic obstacles between low-income citizens and minority groups while closing access to awareness regarding entry into cybersecurity roles. The study ends by suggesting policy and educational outreach reforms that might eliminate digital inequalities.</jats:p>",https://doi.org/10.53889/citj.v3i1.622,CrossRef,digital divide cybersecurity,jatspthe digital gap actively determine people obtain vary degree access technological resource educational opportunity job opportunity specifically within cybersecurity research explore digital divide pattern cybersecurity population analyze unequal opportunity relate cybersecurity education job opportunity security protection level study combine demographic analytic interview datum reveal socioeconomic stand racial background gender identity regional location simultaneously shape cybersecurity accessibility workforce takeup data reveal systemic obstacle lowincome citizen minority group close access awareness regard entry cybersecurity role study end suggest policy educational outreach reform might eliminate digital inequalitiesjatsp,digital divide cybersecurity jatspthe digital gap actively determine people obtain vary degree access technological resource educational opportunity job opportunity specifically within cybersecurity research explore digital divide pattern cybersecurity population analyze unequal opportunity relate cybersecurity education job opportunity security protection level study combine demographic analytic interview datum reveal socioeconomic stand racial background gender identity regional location simultaneously shape cybersecurity accessibility workforce takeup data reveal systemic obstacle lowincome citizen minority group close access awareness regard entry cybersecurity role study end suggest policy educational outreach reform might eliminate digital inequalitiesjatsp,0.6071428571428571,0.14285714285714285,0.17857142857142858,0.03571428571428571,84.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Qualitative,Cybersecurity service level agreements: understanding government data confidentiality requirements,"<jats:title>Abstract</jats:title><jats:p>Cybersecurity requirements, such as data security, are often used as evidence for the Government's relationship with external service providers to process, store and transmit sensitive government data. However, cybersecurity researchers have not profoundly studied the practical application of government data security requirements (e.g. data confidentiality) in service level agreements (SLAs) in the context of an outsourced scenario. The relationships with external service providers are usually established through SLAs as trust-enhancing instruments. However, there is a concern that existing SLAs mainly focus on the system availability and performance aspects but overlook cybersecurity requirements (e.g. data security) in SLAs. Such an understanding is essential to develop government SLA data confidentiality requirements into the formulation of security-related SLAs. We seek to provide insights by developing and conducting a grounded adaptive Delphi method (GADM) with 35 government participants through group discussions and individual sessions. The work on the Indonesian Government's data confidentiality requirements was used as a case study. This paper provides insights into three understandings of the increasing considerations of the Government's data confidentiality requirements in SLA definitions. The three perceptions of security-related SLAs are the target of protection, the data confidentiality risks and the government SLA data confidentiality requirements. Our findings play important implications for a better understanding of how to incorporate data confidentiality requirements according to perceived threats for government data classification in security-SLAs. Based on these findings, we recommend that the Government and service providers improve existing security-related SLAs and future research lines.</jats:p>",https://doi.org/10.1093/cybsec/tyac004,CrossRef,cybersecurity service level agreement understand government datum confidentiality requirement,jatstitleabstractjatstitlejatspcybersecurity requirement datum security often use evidence government relationship external service provider process store transmit sensitive government datum however cybersecurity researcher profoundly study practical application government datum security requirement data confidentiality service level agreement sla context outsourced scenario relationship external service provider usually establish sla trustenhance instrument however concern exist sla mainly focus system availability performance aspect overlook cybersecurity requirement data security sla understanding essential develop government sla datum confidentiality requirement formulation securityrelate sla seek provide insight develop conduct ground adaptive delphi method gadm government participant group discussion individual session work indonesian government datum confidentiality requirement use case study paper provide insight three understanding increase consideration government datum confidentiality requirement sla definition three perception securityrelate sla target protection data confidentiality risk government sla datum confidentiality requirement finding play important implication well understanding incorporate datum confidentiality requirement accord perceive threat government datum classification securitysla base finding recommend government service provider improve exist securityrelate sla future research linesjatsp,cybersecurity service level agreement understand government datum confidentiality requirement jatstitleabstractjatstitlejatspcybersecurity requirement datum security often use evidence government relationship external service provider process store transmit sensitive government datum however cybersecurity researcher profoundly study practical application government datum security requirement data confidentiality service level agreement sla context outsourced scenario relationship external service provider usually establish sla trustenhance instrument however concern exist sla mainly focus system availability performance aspect overlook cybersecurity requirement data security sla understanding essential develop government sla datum confidentiality requirement formulation securityrelate sla seek provide insight develop conduct ground adaptive delphi method gadm government participant group discussion individual session work indonesian government datum confidentiality requirement use case study paper provide insight three understanding increase consideration government datum confidentiality requirement sla definition three perception securityrelate sla target protection data confidentiality risk government sla datum confidentiality requirement finding play important implication well understanding incorporate datum confidentiality requirement accord perceive threat government datum classification securitysla base finding recommend government service provider improve exist securityrelate sla future research linesjatsp,0.6858974358974359,0.1282051282051282,0.07692307692307693,0.04487179487179487,156.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Mixed Methods,"Strengthening Cybersecurity Resilience in Agriculture Through
  Educational Interventions: A Case Study of the Ponca Tribe of Nebraska","The increasing digitization of agricultural operations has introduced new
cybersecurity challenges for the farming community. This paper introduces an
educational intervention called Cybersecurity Improvement Initiative for
Agriculture (CIIA), which aims to strengthen cybersecurity awareness and
resilience among farmers and food producers. Using a case study that focuses on
farmers from the Ponca Tribe of Nebraska, the research evaluates pre- and post-
intervention survey data to assess participants' cybersecurity knowledge and
awareness before and after exposure to the CIIA. The findings reveal a
substantial baseline deficiency in cybersecurity education among participants,
however, post-intervention assessments demonstrate improvements in the
comprehension of cybersecurity concepts, such as password hygiene, multi-factor
authentication, and the necessity of routine data backups. These initial
findings highlight the need for a continued and sustained, community-specific
cybersecurity education effort to help mitigate emerging cyber threats in the
agricultural sector.",http://arxiv.org/abs/2505.23800v1,arXiv,strengthen cybersecurity resilience agriculture educational intervention case study ponca tribe nebraska,increase digitization agricultural operation introduce new cybersecurity challenge farming community paper introduce educational intervention call cybersecurity improvement initiative agriculture ciia aim strengthen cybersecurity awareness resilience among farmer food producer use case study focus farmer ponca tribe nebraska research evaluates pre post intervention survey datum assess participant cybersecurity knowledge awareness exposure ciia finding reveal substantial baseline deficiency cybersecurity education among participant however postintervention assessment demonstrate improvement comprehension cybersecurity concept password hygiene multifactor authentication necessity routine datum backup initial finding highlight need continued sustained communityspecific cybersecurity education effort help mitigate emerge cyber threat agricultural sector,strengthen cybersecurity resilience agriculture educational intervention case study ponca tribe nebraska increase digitization agricultural operation introduce new cybersecurity challenge farming community paper introduce educational intervention call cybersecurity improvement initiative agriculture ciia aim strengthen cybersecurity awareness resilience among farmer food producer use case study focus farmer ponca tribe nebraska research evaluates pre post intervention survey datum assess participant cybersecurity knowledge awareness exposure ciia finding reveal substantial baseline deficiency cybersecurity education among participant however postintervention assessment demonstrate improvement comprehension cybersecurity concept password hygiene multifactor authentication necessity routine datum backup initial finding highlight need continued sustained communityspecific cybersecurity education effort help mitigate emerge cyber threat agricultural sector,0.6989247311827957,0.11827956989247312,0.12903225806451613,0.010752688172043012,93.0,0.0,1.0,0.0,0.0
Information Technology,Cybersecurity,Mixed Methods,Cybersecurity Entity Alignment via Masked Graph Attention Networks,"Cybersecurity vulnerability information is often recorded by multiple
channels, including government vulnerability repositories,
individual-maintained vulnerability-gathering platforms, or
vulnerability-disclosure email lists and forums. Integrating vulnerability
information from different channels enables comprehensive threat assessment and
quick deployment to various security mechanisms. Efforts to automatically
gather such information, however, are impeded by the limitations of today's
entity alignment techniques. In our study, we annotate the first
cybersecurity-domain entity alignment dataset and reveal the unique
characteristics of security entities. Based on these observations, we propose
the first cybersecurity entity alignment model, CEAM, which equips GNN-based
entity alignment with two mechanisms: asymmetric masked aggregation and
partitioned attention. Experimental results on cybersecurity-domain entity
alignment datasets demonstrate that CEAM significantly outperforms
state-of-the-art entity alignment methods.",http://arxiv.org/abs/2207.01434v1,arXiv,cybersecurity entity alignment via mask graph attention network,cybersecurity vulnerability information often record multiple channel include government vulnerability repository individualmaintaine vulnerabilitygathere platform vulnerabilitydisclosure email list forum integrate vulnerability information different channel enable comprehensive threat assessment quick deployment various security mechanism effort automatically gather information however impede limitation today entity alignment technique study annotate first cybersecuritydomain entity alignment dataset reveal unique characteristic security entity base observation propose first cybersecurity entity alignment model ceam equip gnnbase entity alignment two mechanism asymmetric mask aggregation partition attention experimental result cybersecuritydomain entity alignment dataset demonstrate ceam significantly outperform stateoftheart entity alignment method,cybersecurity entity alignment via mask graph attention network cybersecurity vulnerability information often record multiple channel include government vulnerability repository individualmaintaine vulnerabilitygathere platform vulnerabilitydisclosure email list forum integrate vulnerability information different channel enable comprehensive threat assessment quick deployment various security mechanism effort automatically gather information however impede limitation today entity alignment technique study annotate first cybersecuritydomain entity alignment dataset reveal unique characteristic security entity base observation propose first cybersecurity entity alignment model ceam equip gnnbase entity alignment two mechanism asymmetric mask aggregation partition attention experimental result cybersecuritydomain entity alignment dataset demonstrate ceam significantly outperform stateoftheart entity alignment method,0.5730337078651685,0.0898876404494382,0.12359550561797752,0.0449438202247191,89.0,1.0,0.0,1.0,0.0
Information Technology,Cybersecurity,Mixed Methods,"Creating a Cybersecurity Concept Inventory: A Status Report on the CATS
  Project","We report on the status of our Cybersecurity Assessment Tools (CATS) project
that is creating and validating a concept inventory for cybersecurity, which
assesses the quality of instruction of any first course in cybersecurity. In
fall 2014, we carried out a Delphi process that identified core concepts of
cybersecurity. In spring 2016, we interviewed twenty-six students to uncover
their understandings and misconceptions about these concepts. In fall 2016, we
generated our first assessment tool--a draft Cybersecurity Concept Inventory
(CCI), comprising approximately thirty multiple-choice questions. Each question
targets a concept; incorrect answers are based on observed misconceptions from
the interviews. This year we are validating the draft CCI using cognitive
interviews, expert reviews, and psychometric testing. In this paper, we
highlight our progress to date in developing the CCI.
  The CATS project provides infrastructure for a rigorous evidence-based
improvement of cybersecurity education. The CCI permits comparisons of
different instructional methods by assessing how well students learned the core
concepts of the field (especially adversarial thinking), where instructional
methods refer to how material is taught (e.g., lab-based, case-studies,
collaborative, competitions, gaming). Specifically, the CCI is a tool that will
enable researchers to scientifically quantify and measure the effect of their
approaches to, and interventions in, cybersecurity education.",http://arxiv.org/abs/1706.05092v1,arXiv,create cybersecurity concept inventory status report cat project,report status cybersecurity assessment tool cat project create validate concept inventory cybersecurity assess quality instruction first course cybersecurity fall carry delphi process identify core concept cybersecurity spring interview twentysix student uncover understanding misconception concept fall generate first assessment toola draft cybersecurity concept inventory cci comprise approximately thirty multiplechoice question question target concept incorrect answer base observe misconception interview year validate draft cci use cognitive interview expert review psychometric testing paper highlight progress date develop cci cat project provide infrastructure rigorous evidencebase improvement cybersecurity education cci permit comparison different instructional method assess well student learn core concept field especially adversarial thinking instructional method refer material teach labbase casestudie collaborative competition game specifically cci tool enable researcher scientifically quantify measure effect approach intervention cybersecurity education,create cybersecurity concept inventory status report cat project report status cybersecurity assessment tool cat project create validate concept inventory cybersecurity assess quality instruction first course cybersecurity fall carry delphi process identify core concept cybersecurity spring interview twentysix student uncover understanding misconception concept fall generate first assessment toola draft cybersecurity concept inventory cci comprise approximately thirty multiplechoice question question target concept incorrect answer base observe misconception interview year validate draft cci use cognitive interview expert review psychometric testing paper highlight progress date develop cci cat project provide infrastructure rigorous evidencebase improvement cybersecurity education cci permit comparison different instructional method assess well student learn core concept field especially adversarial thinking instructional method refer material teach labbase casestudie collaborative competition game specifically cci tool enable researcher scientifically quantify measure effect approach intervention cybersecurity education,0.6829268292682927,0.15447154471544716,0.08943089430894309,0.032520325203252036,123.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Mixed Methods,"Development of a threat modelling framework and a web-based threat
  modelling tool for micro businesses","While there is a plethora of cybersecurity and risk management frameworks for
different target audiences and use cases, micro-businesses (MBs) are often
overlooked. As the smallest business entities, MBs represent a special case
with regard to cybersecurity for two reasons: (1) Having fewer than 10
employees, they tend to lack cybersecurity expertise. (2) Because of their low
turnover, they usually have a limited budget for cybersecurity. As a result,
MBs are often the victims of security breaches and cyber-attacks every year, as
demonstrated by various studies. This calls for a non-technical, simple
solution tailored specifically for MBs. To address this pressing need, the
SEANCE Cybersecurity Framework was developed through a 7-step methodology: (1)
A literature review was conducted to explore the current state of research and
available frameworks and methodologies, (2) followed by a qualitative survey to
identify the cybersecurity challenges faced by MBs. (3) After analyzing the
results of the literature review and the survey, (4) the relevant aspects of
existing frameworks and tools for MBs were identified and (5) a non-technical
framework was developed. (6) A web-based tool was developed to facilitate the
implementation of the framework and (7) another qualitative survey was
conducted to gather feedback. The SEANCE Framework suggests considering
possible vulnerabilities and cyber threats in six hierarchical layers: (1)
Self, (2) Employees, (3) Assets, (4) Network, (5) Customers and (6)
Environment, with the underlying idea of a vulnerability in an inner layer
propagates to the outer layers and therefore needs to be prioritized.",http://arxiv.org/abs/2411.14450v1,arXiv,development threat modelling framework webbase threat modelling tool micro business,plethora cybersecurity risk management framework different target audience use case microbusinesse mbs often overlook small business entity mbs represent special case regard cybersecurity two reason employee tend lack cybersecurity expertise low turnover usually limited budget cybersecurity result often victim security breach cyberattack every year demonstrate various study call nontechnical simple solution tailor specifically mbs address press need seance cybersecurity framework develop step methodology literature review conduct explore current state research available framework methodology follow qualitative survey identify cybersecurity challenge face mbs analyze result literature review survey relevant aspect exist framework tool mbs identify nontechnical framework develop webbase tool develop facilitate implementation framework another qualitative survey conduct gather feedback seance framework suggest consider possible vulnerability cyber threat six hierarchical layer self employee asset network customer environment underlie idea vulnerability inner layer propagate outer layer therefore need prioritize,development threat modelling framework webbase threat modelling tool micro business plethora cybersecurity risk management framework different target audience use case microbusinesse mbs often overlook small business entity mbs represent special case regard cybersecurity two reason employee tend lack cybersecurity expertise low turnover usually limited budget cybersecurity result often victim security breach cyberattack every year demonstrate various study call nontechnical simple solution tailor specifically mbs address press need seance cybersecurity framework develop step methodology literature review conduct explore current state research available framework methodology follow qualitative survey identify cybersecurity challenge face mbs analyze result literature review survey relevant aspect exist framework tool mbs identify nontechnical framework develop webbase tool develop facilitate implementation framework another qualitative survey conduct gather feedback seance framework suggest consider possible vulnerability cyber threat six hierarchical layer self employee asset network customer environment underlie idea vulnerability inner layer propagate outer layer therefore need prioritize,0.5808823529411765,0.15441176470588236,0.13970588235294118,0.03676470588235294,136.0,0.0,0.0,1.0,0.0
Information Technology,Cybersecurity,Mixed Methods,Frontier AI's Impact on the Cybersecurity Landscape,"As frontier AI advances rapidly, understanding its impact on cybersecurity
and inherent risks is essential to ensuring safe AI evolution (e.g., guiding
risk mitigation and informing policymakers). While some studies review AI
applications in cybersecurity, none of them comprehensively discuss AI's future
impacts or provide concrete recommendations for navigating its safe and secure
usage. This paper presents an in-depth analysis of frontier AI's impact on
cybersecurity and establishes a systematic framework for risk assessment and
mitigation. To this end, we first define and categorize the marginal risks of
frontier AI in cybersecurity and then systemically analyze the current and
future impacts of frontier AI in cybersecurity, qualitatively and
quantitatively. We also discuss why frontier AI likely benefits attackers more
than defenders in the short term from equivalence classes, asymmetry, and
economic impact. Next, we explore frontier AI's impact on future software
system development, including enabling complex hybrid systems while introducing
new risks. Based on our findings, we provide security recommendations,
including constructing fine-grained benchmarks for risk assessment, designing
AI agents for defenses, building security mechanisms and provable defenses for
hybrid systems, enhancing pre-deployment security testing and transparency, and
strengthening defenses for users. Finally, we present long-term research
questions essential for understanding AI's future impacts and unleashing its
defensive capabilities.",http://arxiv.org/abs/2504.05408v2,arXiv,frontier ais impact cybersecurity landscape,frontier advance rapidly understand impact cybersecurity inherent risk essential ensure safe evolution guide risk mitigation inform policymaker study review application cybersecurity none comprehensively discuss ais future impact provide concrete recommendation navigate safe secure usage paper present indepth analysis frontier ais impact cybersecurity establish systematic framework risk assessment mitigation end first define categorize marginal risk frontier cybersecurity systemically analyze current future impact frontier cybersecurity qualitatively quantitatively also discuss frontier likely benefit attacker defender short term equivalence class asymmetry economic impact next explore frontier ais impact future software system development include enable complex hybrid system introduce new risk base finding provide security recommendation include construct finegrained benchmark risk assessment design agent defense build security mechanism provable defense hybrid system enhance predeployment security testing transparency strengthen defense user finally present longterm research question essential understand ais future impact unleash defensive capability,frontier ais impact cybersecurity landscape frontier advance rapidly understand impact cybersecurity inherent risk essential ensure safe evolution guide risk mitigation inform policymaker study review application cybersecurity none comprehensively discuss ais future impact provide concrete recommendation navigate safe secure usage paper present indepth analysis frontier ais impact cybersecurity establish systematic framework risk assessment mitigation end first define categorize marginal risk frontier cybersecurity systemically analyze current future impact frontier cybersecurity qualitatively quantitatively also discuss frontier likely benefit attacker defender short term equivalence class asymmetry economic impact next explore frontier ais impact future software system development include enable complex hybrid system introduce new risk base finding provide security recommendation include construct finegrained benchmark risk assessment design agent defense build security mechanism provable defense hybrid system enhance predeployment security testing transparency strengthen defense user finally present longterm research question essential understand ais future impact unleash defensive capability,0.5434782608695652,0.15217391304347827,0.2028985507246377,0.06521739130434782,138.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Design and Development,OSINT TECHNOLOGIES AS A THREAT TO STATE CYBERSECURITY,"<jats:p>The article examines OSINT technologies as one of the key challenges for the national security of Ukraine. With the development of the digital space, methods of collecting, analyzing and using information from open sources have become widespread, in particular in the field of cybersecurity. The authors emphasize that, despite the legitimacy and general availability of OSINT technologies, they can be used by attackers to collect personal data, identify vulnerabilities in critical infrastructure and plan cyberattacks. The study is based on the analysis of open state registers, social networks, satellite images, mapping services and other sources containing potentially sensitive information. The main threats associated with OSINT are identified, including: theft of personal data, phishing, analysis of corporate information, unauthorized interference in state information systems. Special attention is paid to the analysis of real incidents of information leakage through OSINT technologies, including examples from international and Ukrainian practice. The authors have examined the legal and ethical aspects of the use of OSINT tools, in particular the conflict between the need for openness of state data and cybersecurity threats. The article provides an analysis of the legislative norms of Ukraine that regulate access to information, and also considers international experience in the field of countering OSINT threats. A separate section of the article is devoted to methods of countering threats that arise through the use of OSINT tools. Counter-OSINT methods are also studied, which involve minimizing the digital trace, disinformation, data anonymization, control over information leaks, and the use of means of countering OSINT analysis of images and videos. The role of state structures in the development and implementation of regulatory legal acts aimed at strengthening the protection of information in open sources is separately considered.</jats:p>",https://doi.org/10.28925/2663-4023.2025.27.749,CrossRef,osint technology threat state cybersecurity,jatspthe article examine osint technology one key challenge national security ukraine development digital space method collect analyze use information open source become widespread particular field cybersecurity author emphasize despite legitimacy general availability osint technology use attacker collect personal datum identify vulnerability critical infrastructure plan cyberattack study base analysis open state register social network satellite image mapping service source contain potentially sensitive information main threat associate osint identify include theft personal datum phishe analysis corporate information unauthorized interference state information system special attention pay analysis real incident information leakage osint technology include example international ukrainian practice author examine legal ethical aspect use osint tool particular conflict need openness state datum cybersecurity threat article provide analysis legislative norm ukraine regulate access information also consider international experience field counter osint threat separate section article devoted method counter threat arise use osint tool counterosint method also study involve minimize digital trace disinformation datum anonymization control information leak use mean counter osint analysis image video role state structure development implementation regulatory legal act aim strengthen protection information open source separately consideredjatsp,osint technology threat state cybersecurity jatspthe article examine osint technology one key challenge national security ukraine development digital space method collect analyze use information open source become widespread particular field cybersecurity author emphasize despite legitimacy general availability osint technology use attacker collect personal datum identify vulnerability critical infrastructure plan cyberattack study base analysis open state register social network satellite image mapping service source contain potentially sensitive information main threat associate osint identify include theft personal datum phishe analysis corporate information unauthorized interference state information system special attention pay analysis real incident information leakage osint technology include example international ukrainian practice author examine legal ethical aspect use osint tool particular conflict need openness state datum cybersecurity threat article provide analysis legislative norm ukraine regulate access information also consider international experience field counter osint threat separate section article devoted method counter threat arise use osint tool counterosint method also study involve minimize digital trace disinformation datum anonymization control information leak use mean counter osint analysis image video role state structure development implementation regulatory legal act aim strengthen protection information open source separately consideredjatsp,0.5909090909090909,0.16477272727272727,0.17613636363636365,0.022727272727272728,88.0,2.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Design and Development,CYBERSECURITY OF MQTT CONNECTIONS IN AN AUTOMATED GATE CONTROL SYSTEM,"<jats:p>With the development of the Internet of Things (IoT), the issue of data protection and the secure operation of IoT systems has become increasingly important. One of the major threats is unprotected MQTT connections, which are vulnerable to traffic interception (MitM attacks), command spoofing, unauthorized access, and DDoS attacks.This paper explores MQTT security methods using the example of an automated gate control system. It presents an analysis of recent research in IoT cybersecurity, identifies the main vulnerabilities of MQTT brokers and clients, and proposes measures to secure IoT infrastructure.Special attention is given to TLS/SSL encryption for traffic protection, MQTT client authentication, access restrictions using ACL (Access Control List), and the isolation of IoT devices in separate networks (VPN/VLAN).The research findings confirm that a comprehensive implementation of security measures significantly reduces attack risks and ensures the reliable and secure operation of IoT projects.</jats:p>",https://doi.org/10.28925/2663-4023.2025.27.727,CrossRef,cybersecurity mqtt connection automate gate control system,jatspwith development internet thing iot issue datum protection secure operation iot system become increasingly important one major threat unprotected mqtt connection vulnerable traffic interception mitm attack command spoof unauthorized access ddo attacksthis paper explore mqtt security method use example automate gate control system present analysis recent research iot cybersecurity identify main vulnerability mqtt broker client propose measure secure iot infrastructurespecial attention give tlsssl encryption traffic protection mqtt client authentication access restriction use acl access control list isolation iot device separate network vpnvlanthe research finding confirm comprehensive implementation security measure significantly reduce attack risk ensure reliable secure operation iot projectsjatsp,cybersecurity mqtt connection automate gate control system jatspwith development internet thing iot issue datum protection secure operation iot system become increasingly important one major threat unprotected mqtt connection vulnerable traffic interception mitm attack command spoof unauthorized access ddo attacksthis paper explore mqtt security method use example automate gate control system present analysis recent research iot cybersecurity identify main vulnerability mqtt broker client propose measure secure iot infrastructurespecial attention give tlsssl encryption traffic protection mqtt client authentication access restriction use acl access control list isolation iot device separate network vpnvlanthe research finding confirm comprehensive implementation security measure significantly reduce attack risk ensure reliable secure operation iot projectsjatsp,0.5454545454545454,0.1111111111111111,0.18181818181818182,0.020202020202020204,99.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Design and Development,METHOD OF COMPREHENSIVE CYBERSECURITY RISKS ASSESSMENT IN DISTRIBUTED INFORMATION SYSTEMS,"<jats:p>Cybersecurity risk assessment and analysis is an important element for building an effective information security management system.  The high complexity and scalability of the architecture of modern distributed systems, the heterogeneity of equipment and infrastructure, as well as constant changes in the configuration and scaling of the environment give rise to a number of problems related to the collection and analysis of information for risk assessment, the need for operational processing of large arrays of complex in structure and heterogeneous in nature data coming from differentiated security and monitoring systems, event logs, audit reports and other sources, as well as the lack of a single format for their presentation. The limitations of existing standards and methodologies in the dynamic conditions of modern DIS, their conceptual nature and the complexity of practical implementation and application require the development of flexible methodological and technological solutions for cyber risk analysis that would integrate the advantages of existing approaches, provide automation of calculations and take into account the dynamic aspects of distributed environment. The article presents a comprehensive adaptive method for quantitative assessment of cybersecurity risks in distributed information systems, which is relevant in dynamic conditions of complex multi-component and scalable DIS. The proposed method, integrating a metric-oriented approach based on the results of a complex of neural network models for assessing DIS infrastructure security indicators and compliance metrics for regulatory frameworks and leading standards, provides an opportunity to create a scalable and dynamic cyber risk management system that effectively responds to modern threats in DIS and open opportunities for the comprehensive implementation of intelligent information security management systems in risk management processes.</jats:p>",https://doi.org/10.28925/2663-4023.2024.26.731,CrossRef,method comprehensive cybersecurity risk assessment distribute information system,jatspcybersecurity risk assessment analysis important element build effective information security management system high complexity scalability architecture modern distribute system heterogeneity equipment infrastructure well constant change configuration scaling environment give rise number problem relate collection analysis information risk assessment need operational processing large array complex structure heterogeneous nature datum come differentiated security monitoring system event log audit report source well lack single format presentation limitation exist standard methodology dynamic condition modern dis conceptual nature complexity practical implementation application require development flexible methodological technological solution cyber risk analysis would integrate advantage exist approach provide automation calculation take account dynamic aspect distribute environment article present comprehensive adaptive method quantitative assessment cybersecurity risk distribute information system relevant dynamic condition complex multicomponent scalable dis propose method integrate metricoriente approach base result complex neural network model assess dis infrastructure security indicator compliance metric regulatory framework lead standard provide opportunity create scalable dynamic cyber risk management system effectively respond modern threat dis open opportunity comprehensive implementation intelligent information security management system risk management processesjatsp,method comprehensive cybersecurity risk assessment distribute information system jatspcybersecurity risk assessment analysis important element build effective information security management system high complexity scalability architecture modern distribute system heterogeneity equipment infrastructure well constant change configuration scaling environment give rise number problem relate collection analysis information risk assessment need operational processing large array complex structure heterogeneous nature datum come differentiated security monitoring system event log audit report source well lack single format presentation limitation exist standard methodology dynamic condition modern dis conceptual nature complexity practical implementation application require development flexible methodological technological solution cyber risk analysis would integrate advantage exist approach provide automation calculation take account dynamic aspect distribute environment article present comprehensive adaptive method quantitative assessment cybersecurity risk distribute information system relevant dynamic condition complex multicomponent scalable dis propose method integrate metricoriente approach base result complex neural network model assess dis infrastructure security indicator compliance metric regulatory framework lead standard provide opportunity create scalable dynamic cyber risk management system effectively respond modern threat dis open opportunity comprehensive implementation intelligent information security management system risk management processesjatsp,0.592814371257485,0.12574850299401197,0.2215568862275449,0.005988023952095809,167.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Design and Development,IPatch: a remote adversarial patch,"<jats:title>Abstract</jats:title><jats:p>Applications such as autonomous vehicles and medical screening use deep learning models to localize and identify hundreds of objects in a single frame. In the past, it has been shown how an attacker can fool these models by placing an adversarial patch within a scene. However, these patches must be placed in the target location and do not explicitly alter the semantics elsewhere in the image. In this paper, we introduce a new type of adversarial patch which alters a model’s perception of an image’s semantics. These patches can be placed anywhere within an image to change the classification or semantics of locations far from the patch. We call this new class of adversarial examples ‘remote adversarial patches’ (RAP). We implement our own RAP called IPatch and perform an in-depth analysis on without pixel clipping on image segmentation RAP attacks using five state-of-the-art architectures with eight different encoders on the CamVid street view dataset. Moreover, we demonstrate that the attack can be extended to object recognition models with preliminary results on the popular YOLOv3 model. We found that the patch can change the classification of a remote target region with a success rate of up to 93% on average.</jats:p>",https://doi.org/10.1186/s42400-023-00145-0,CrossRef,ipatch remote adversarial patch,jatstitleabstractjatstitlejatspapplication autonomous vehicle medical screening use deep learning model localize identify hundred object single frame past show attacker fool model place adversarial patch within scene however patch must place target location explicitly alter semantic elsewhere image paper introduce new type adversarial patch alter model perception image semantic patch place anywhere within image change classification semantic location far patch call new class adversarial example remote adversarial patch rap implement rap call ipatch perform indepth analysis without pixel clip image segmentation rap attack use five stateoftheart architecture eight different encoder camvid street view dataset moreover demonstrate attack extend object recognition model preliminary result popular yolov model find patch change classification remote target region success rate averagejatsp,ipatch remote adversarial patch jatstitleabstractjatstitlejatspapplication autonomous vehicle medical screening use deep learning model localize identify hundred object single frame past show attacker fool model place adversarial patch within scene however patch must place target location explicitly alter semantic elsewhere image paper introduce new type adversarial patch alter model perception image semantic patch place anywhere within image change classification semantic location far patch call new class adversarial example remote adversarial patch rap implement rap call ipatch perform indepth analysis without pixel clip image segmentation rap attack use five stateoftheart architecture eight different encoder camvid street view dataset moreover demonstrate attack extend object recognition model preliminary result popular yolov model find patch change classification remote target region success rate averagejatsp,0.5701754385964912,0.08771929824561403,0.19298245614035087,0.043859649122807015,114.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Design and Development,GRAPH-BASED ANALYSIS OF INFORMATION FLOWS IN TELEGRAM FOR CYBERSECURITY THREAT DETECTION,"<jats:p>This paper explores modern methods for analyzing information flows in messengers, emphasizing their role in cybersecurity. The study compares different approaches, including API-based data collection, the use of graph and relational databases, and the automation of open data gathering. Special attention is given to the theoretical foundations of information flow analysis, focusing on the social graph concept and its application in modeling the dissemination of information across networks. The advantages of graph databases for detecting, visualizing, and analyzing networks of information distribution are examined, highlighting their effectiveness in uncovering hidden connections between channels. A prototype system for automating open data collection has been developed, integrating methods for extracting, processing, and structuring information from messenger platforms. The proposed system employs a combination of graph-based and relational techniques to enhance the accuracy and efficiency of detecting interconnections between communication channels. A series of computational experiments has been conducted to validate the effectiveness of the developed algorithms and software prototypes. The results confirm that combining these methods significantly improves the ability to identify information threats, including disinformation campaigns, automated bot activity, and coordinated attacks within messenger ecosystems. Actionable recommendations for the practical implementation of these approaches in cybersecurity tasks are provided. Specifically, they outline strategies for improving the monitoring and detection of malicious information activities, optimizing data collection and analysis pipelines, and leveraging graph-based insights to enhance situational awareness in digital communication environments. These findings contribute to the ongoing development of advanced cybersecurity solutions aimed at mitigating risks associated with modern information warfare.</jats:p>",https://doi.org/10.28925/2663-4023.2025.27.746,CrossRef,graphbased analysis information flow telegram cybersecurity threat detection,jatspthis paper explore modern method analyze information flow messenger emphasize role cybersecurity study compare different approach include apibased datum collection use graph relational database automation open datum gather special attention give theoretical foundation information flow analysis focus social graph concept application model dissemination information across network advantage graph database detect visualize analyze network information distribution examine highlight effectiveness uncover hide connection channel prototype system automate open datum collection develop integrate method extract processing structure information messenger platform propose system employ combination graphbased relational technique enhance accuracy efficiency detect interconnection communication channel series computational experiment conduct validate effectiveness develop algorithm software prototype result confirm combine method significantly improve ability identify information threat include disinformation campaign automate bot activity coordinate attack within messenger ecosystem actionable recommendation practical implementation approach cybersecurity task provide specifically outline strategy improve monitoring detection malicious information activity optimize data collection analysis pipeline leverage graphbased insight enhance situational awareness digital communication environment finding contribute ongoing development advanced cybersecurity solution aim mitigate risk associate modern information warfarejatsp,graphbased analysis information flow telegram cybersecurity threat detection jatspthis paper explore modern method analyze information flow messenger emphasize role cybersecurity study compare different approach include apibased datum collection use graph relational database automation open datum gather special attention give theoretical foundation information flow analysis focus social graph concept application model dissemination information across network advantage graph database detect visualize analyze network information distribution examine highlight effectiveness uncover hide connection channel prototype system automate open datum collection develop integrate method extract processing structure information messenger platform propose system employ combination graphbased relational technique enhance accuracy efficiency detect interconnection communication channel series computational experiment conduct validate effectiveness develop algorithm software prototype result confirm combine method significantly improve ability identify information threat include disinformation campaign automate bot activity coordinate attack within messenger ecosystem actionable recommendation practical implementation approach cybersecurity task provide specifically outline strategy improve monitoring detection malicious information activity optimize data collection analysis pipeline leverage graphbased insight enhance situational awareness digital communication environment finding contribute ongoing development advanced cybersecurity solution aim mitigate risk associate modern information warfarejatsp,0.6287425149700598,0.17964071856287425,0.11976047904191617,0.011976047904191617,167.0,1.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Theoretical / Conceptual,CYBERSECURITY RISK ASSESSMENT FOR SELECTING A CLOUD SERVICE PROVIDER,"<jats:p>This paper presents the development of a cybersecurity risk assessment module for selecting a cloud service provider, enabling organizations to make informed decisions based on all aspects of security. The module is designed as part of an integrated decision support system (DSS) and utilizes a detailed taxonomy of cloud services, covering various models and deployment options (IaaS, PaaS, SaaS, public, private, and hybrid clouds). The system performs security assessments based on collected vulnerability data, including information from the National Vulnerability Database (NVD) and other sources.
One of the key stages of the assessment is determining the risks associated with each service, which allows for the accurate identification of potential threats and the selection of a provider with the best security performance. The module evaluates various factors, including the frequency and severity of vulnerabilities, the likelihood of exploitation by attackers, and the speed of vulnerability remediation. The collected data is used to form a weighted risk assessment matrix that aids decision-making based on specific criteria.
The results of the study show that the developed module can significantly improve the cloud service provider selection process, particularly for large organizations with high data security requirements. Future research will focus on integrating this module into automated decision support systems, which will allow the selection process to be adapted to the rapidly changing conditions of cloud technologies and emerging threats.</jats:p>",https://doi.org/10.28925/2663-4023.2025.27.773,CrossRef,cybersecurity risk assessment select cloud service provider,jatspthis paper present development cybersecurity risk assessment module select cloud service provider enable organization make informed decision base aspect security module design part integrate decision support system dss utilize detailed taxonomy cloud service cover various model deployment option iaas paas saas public private hybrid cloud system perform security assessment base collect vulnerability datum include information national vulnerability database nvd source one key stage assessment determine risk associate service allow accurate identification potential threat selection provider good security performance module evaluate various factor include frequency severity vulnerability likelihood exploitation attacker speed vulnerability remediation collect data use form weighted risk assessment matrix aid decisionmake base specific criterion result study show develop module significantly improve cloud service provider selection process particularly large organization high datum security requirement future research focus integrate module automate decision support system allow selection process adapt rapidly change condition cloud technology emerge threatsjatsp,cybersecurity risk assessment select cloud service provider jatspthis paper present development cybersecurity risk assessment module select cloud service provider enable organization make informed decision base aspect security module design part integrate decision support system dss utilize detailed taxonomy cloud service cover various model deployment option iaas paas saas public private hybrid cloud system perform security assessment base collect vulnerability datum include information national vulnerability database nvd source one key stage assessment determine risk associate service allow accurate identification potential threat selection provider good security performance module evaluate various factor include frequency severity vulnerability likelihood exploitation attacker speed vulnerability remediation collect data use form weighted risk assessment matrix aid decisionmake base specific criterion result study show develop module significantly improve cloud service provider selection process particularly large organization high datum security requirement future research focus integrate module automate decision support system allow selection process adapt rapidly change condition cloud technology emerge threatsjatsp,0.6736111111111112,0.13194444444444445,0.1597222222222222,0.020833333333333332,144.0,0.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Theoretical / Conceptual,"The (Il)legitimacy of
Cybersecurity. An Application
of Just Securitization Theory
to Cybersecurity based on
the Principle of Subsidiarity","<jats:p>This contribution applies Floyd’s just securitization theory (JST) to cybersecurity and develops an own version of JST focused on subsidiarity from the critical discussion of this application. Floyd’s JST pursues a subsidiary approach. It emphasizes that securitization is only legitimate if it has “a reasonable chance of success” to avert threats to the satisfaction of “basic human needs”. From this perspective, cyber-securitization would be only legitimate if it protects critical infrastructure, which is a too narrow scope. Whilst Floyd’s JST focuses exclusively on permissibility and needs instead of rights, I argue that there are cases in which states’ compliance with Human Rights requires the guarantee of cybersecurity, most importantly regarding the human right to privacy. Furthermore, my version of JST strengthens the principle of subsidiarity, in the sense that stakeholders directly affected by a threat should participate in securitization. In order to strengthen a kind of subsidiarity focused on the private sector, I argue for the legitimacy of private active self-defence in cyberspace and emphasize the importance of a ‘whole-of-society approach’ involving digital literacy and ‘everyday security practices’. In contrast to that, I argue that far-reaching securitization on the nation-state level can be connected to hyper-securitization. I argue that the securitization of the digital public sphere following unclear notions such as ‘digital sovereignty’ creates a ‘cybersecurity dilemma’ and a ‘societal security dilemma’. Furthermore, I argue that this kind of counterproductive hyper-securitization involves an ‘invisible handshake’ between Big Tech and governments that should be counteracted by structural desecuritization focused on subsidiarity.</jats:p>",https://doi.org/10.5604/01.3001.0016.1093,CrossRef,illegitimacy cybersecurity application securitization theory cybersecurity base principle subsidiarity,jatspthis contribution apply floyd securitization theory jst cybersecurity develop version jst focus subsidiarity critical discussion application floyd jst pursue subsidiary approach emphasize securitization legitimate reasonable chance success avert threat satisfaction basic human need perspective cybersecuritization would legitimate protect critical infrastructure narrow scope whilst floyd jst focus exclusively permissibility need instead right argue case state compliance human right require guarantee cybersecurity importantly regard human right privacy furthermore version jst strengthen principle subsidiarity sense stakeholder directly affect threat participate securitization order strengthen kind subsidiarity focus private sector argue legitimacy private active selfdefence cyberspace emphasize importance wholeofsociety approach involve digital literacy everyday security practice contrast argue farreache securitization nationstate level connect hypersecuritization argue securitization digital public sphere follow unclear notion digital sovereignty create cybersecurity dilemma societal security dilemma furthermore argue kind counterproductive hypersecuritization involve invisible handshake big tech government counteract structural desecuritization focus subsidiarityjatsp,illegitimacy cybersecurity application securitization theory cybersecurity base principle subsidiarity jatspthis contribution apply floyd securitization theory jst cybersecurity develop version jst focus subsidiarity critical discussion application floyd jst pursue subsidiary approach emphasize securitization legitimate reasonable chance success avert threat satisfaction basic human need perspective cybersecuritization would legitimate protect critical infrastructure narrow scope whilst floyd jst focus exclusively permissibility need instead right argue case state compliance human right require guarantee cybersecurity importantly regard human right privacy furthermore version jst strengthen principle subsidiarity sense stakeholder directly affect threat participate securitization order strengthen kind subsidiarity focus private sector argue legitimacy private active selfdefence cyberspace emphasize importance wholeofsociety approach involve digital literacy everyday security practice contrast argue farreache securitization nationstate level connect hypersecuritization argue securitization digital public sphere follow unclear notion digital sovereignty create cybersecurity dilemma societal security dilemma furthermore argue kind counterproductive hypersecuritization involve invisible handshake big tech government counteract structural desecuritization focus subsidiarityjatsp,0.5035460992907801,0.1347517730496454,0.18439716312056736,0.04964539007092199,141.0,0.0,0.0,0.0,2.0
Information Technology,Cybersecurity,Theoretical / Conceptual,FUNCTIONS OF THE INFORMATION SECURITY AND CYBERSECURITY SYSTEM OF CRITICAL INFORMATION INFRASTRUCTURE,"<jats:p>The subject of research in the scientific article is the system of Information Protection and cybersecurity of critical information infrastructure objects. An information security and cybersecurity system is a complex set of software, cryptographic, organizational, and other tools, methods, and measures designed to protect information and cybersecurity. Since the system of Information Protection and cybersecurity of critical information infrastructure facilities is relatively new, there is no single view on what functions this system should perform. As a result, the process of its formation and formation as a system continues. There was a need to define functions for further evaluation of the effectiveness of its functioning as a system. Evaluation is supposed to be carried out both in the process of creation, acceptance, and daily operation. Partial performance indicators are required to implement the procedure for evaluating the effectiveness of the information security system and cybersecurity of critical information infrastructure facilities. Using these indicators, it is possible to characterize the degree of achievement of the system's tasks assigned to it. The following performance indicators are proposed according to the functions: ID identification of cybersecurity risks; PR Cyber Defense; DE detection of cyber incidents; RS response to cyber incidents; RC restoration of the state of cybersecurity. The scientific novelty of the obtained result lies in the fact that Universal functions are proposed that the information security and cybersecurity system should implement at critical information infrastructure facilities. The presented study does not exhaust all aspects of this problem. The theoretical results obtained in the course of scientific research form the basis for further justification of indicators and criteria for evaluating the effectiveness of the information security and cybersecurity system.</jats:p>",https://doi.org/10.28925/2663-4023.2022.15.1241341,CrossRef,function information security cybersecurity system critical information infrastructure,jatspthe subject research scientific article system information protection cybersecurity critical information infrastructure object information security cybersecurity system complex set software cryptographic organizational tool method measure design protect information cybersecurity since system information protection cybersecurity critical information infrastructure facility relatively new single view function system perform result process formation formation system continue need define function evaluation effectiveness functioning system evaluation suppose carry process creation acceptance daily operation partial performance indicator require implement procedure evaluate effectiveness information security system cybersecurity critical information infrastructure facility use indicator possible characterize degree achievement system task assign follow performance indicator propose accord function identification cybersecurity risk cyber defense detection cyber incidents response cyber incidents restoration state cybersecurity scientific novelty obtain result lie fact universal function propose information security cybersecurity system implement critical information infrastructure facility present study exhaust aspect problem theoretical result obtain course scientific research form basis justification indicator criterion evaluate effectiveness information security cybersecurity systemjatsp,function information security cybersecurity system critical information infrastructure jatspthe subject research scientific article system information protection cybersecurity critical information infrastructure object information security cybersecurity system complex set software cryptographic organizational tool method measure design protect information cybersecurity since system information protection cybersecurity critical information infrastructure facility relatively new single view function system perform result process formation formation system continue need define function evaluation effectiveness functioning system evaluation suppose carry process creation acceptance daily operation partial performance indicator require implement procedure evaluate effectiveness information security system cybersecurity critical information infrastructure facility use indicator possible characterize degree achievement system task assign follow performance indicator propose accord function identification cybersecurity risk cyber defense detection cyber incidents response cyber incidents restoration state cybersecurity scientific novelty obtain result lie fact universal function propose information security cybersecurity system implement critical information infrastructure facility present study exhaust aspect problem theoretical result obtain course scientific research form basis justification indicator criterion evaluate effectiveness information security cybersecurity systemjatsp,0.7218543046357616,0.09271523178807947,0.12582781456953643,0.006622516556291391,151.0,1.0,0.0,1.0,0.0
Information Technology,Cybersecurity,Theoretical / Conceptual,BLOCKCHAIN AS A COMPONENT OF INFORMATION SECURITY,"<jats:p>The article describes the use of information and telecommunication systems in public and private institutions and disadvantages for the construction of information and telecommunication systems for decentralization. The analysis of recent researches and publications on the subject of the block is conducted. The paper describes the principle of the technology, the block and the ways in which a block protects itself from attempting to make unauthorized changes or deletion of data. The expediency and perspectives of using information security technologies from the point of view of the triad of information security services as confidentiality, integrity and accessibility are considered. The rapid development of information technology is expected to rapidly increase and increase, and also threatens the information and telecommunication systems that have most of these systems. A promising direction for the construction of information and telecommunication systems is the use of decentralization. Therefore, it is important to analyze the use of Blockchain technology for the construction of decentralized information and telecommunication systems in terms of information security.</jats:p>",https://doi.org/10.28925/2663-4023.2019.4.8589,CrossRef,blockchain component information security,jatspthe article describe use information telecommunication system public private institution disadvantage construction information telecommunication system decentralization analysis recent research publication subject block conduct paper describe principle technology block way block protect attempt make unauthorized change deletion datum expediency perspective use information security technology point view triad information security service confidentiality integrity accessibility consider rapid development information technology expect rapidly increase increase also threaten information telecommunication system system promising direction construction information telecommunication system use decentralization therefore important analyze use blockchain technology construction decentralized information telecommunication system term information securityjatsp,blockchain component information security jatspthe article describe use information telecommunication system public private institution disadvantage construction information telecommunication system decentralization analysis recent research publication subject block conduct paper describe principle technology block way block protect attempt make unauthorized change deletion datum expediency perspective use information security technology point view triad information security service confidentiality integrity accessibility consider rapid development information technology expect rapidly increase increase also threaten information telecommunication system system promising direction construction information telecommunication system use decentralization therefore important analyze use blockchain technology construction decentralized information telecommunication system term information securityjatsp,0.7303370786516854,0.1348314606741573,0.0898876404494382,0.033707865168539325,89.0,1.0,0.0,0.0,0.0
Information Technology,Cybersecurity,Theoretical / Conceptual,"Cybersecurity for Sustainable Smart Healthcare: State of the Art, Taxonomy, Mechanisms, and Essential Roles","<jats:p>Cutting-edge technologies have been widely employed in healthcare delivery, resulting in transformative advances and promising enhanced patient care, operational efficiency, and resource usage. However, the proliferation of networked devices and data-driven systems has created new cybersecurity threats that jeopardize the integrity, confidentiality, and availability of critical healthcare data. This review paper offers a comprehensive evaluation of the current state of cybersecurity in the context of smart healthcare, presenting a structured taxonomy of its existing cyber threats, mechanisms and essential roles. This study explored cybersecurity and smart healthcare systems (SHSs). It identified and discussed the most pressing cyber threats and attacks that SHSs face, including fake base stations, medjacking, and Sybil attacks. This study examined the security measures deployed to combat cyber threats and attacks in SHSs. These measures include cryptographic-based techniques, digital watermarking, digital steganography, and many others. Patient data protection, the prevention of data breaches, and the maintenance of SHS integrity and availability are some of the roles of cybersecurity in ensuring sustainable smart healthcare. The long-term viability of smart healthcare depends on the constant assessment of cyber risks that harm healthcare providers, patients, and professionals. This review aims to inform policymakers, healthcare practitioners, and technology stakeholders about the critical imperatives and best practices for fostering a secure and resilient smart healthcare ecosystem by synthesizing insights from multidisciplinary perspectives, such as cybersecurity, healthcare management, and sustainability research. Understanding the most recent cybersecurity measures is critical for controlling escalating cyber threats and attacks on SHSs and networks and encouraging intelligent healthcare delivery.</jats:p>",https://doi.org/10.58496/mjcs/2024/006,CrossRef,cybersecurity sustainable smart healthcare state art taxonomy mechanism essential role,jatspcuttingedge technology widely employ healthcare delivery result transformative advance promise enhance patient care operational efficiency resource usage however proliferation networked device datadriven system create new cybersecurity threat jeopardize integrity confidentiality availability critical healthcare datum review paper offer comprehensive evaluation current state cybersecurity context smart healthcare present structured taxonomy exist cyber threat mechanism essential role study explore cybersecurity smart healthcare system shss identify discuss pressing cyber threat attack shss face include fake base station medjacke sybil attack study examine security measure deploy combat cyber threat attack shss measure include cryptographicbase technique digital watermarke digital steganography many patient data protection prevention datum breach maintenance shs integrity availability role cybersecurity ensure sustainable smart healthcare longterm viability smart healthcare depend constant assessment cyber risk harm healthcare provider patient professional review aim inform policymaker healthcare practitioner technology stakeholder critical imperative good practice foster secure resilient smart healthcare ecosystem synthesize insight multidisciplinary perspective cybersecurity healthcare management sustainability research understand recent cybersecurity measure critical control escalate cyber threat attack shss network encourage intelligent healthcare deliveryjatsp,cybersecurity sustainable smart healthcare state art taxonomy mechanism essential role jatspcuttingedge technology widely employ healthcare delivery result transformative advance promise enhance patient care operational efficiency resource usage however proliferation networked device datadriven system create new cybersecurity threat jeopardize integrity confidentiality availability critical healthcare datum review paper offer comprehensive evaluation current state cybersecurity context smart healthcare present structured taxonomy exist cyber threat mechanism essential role study explore cybersecurity smart healthcare system shss identify discuss pressing cyber threat attack shss face include fake base station medjacke sybil attack study examine security measure deploy combat cyber threat attack shss measure include cryptographicbase technique digital watermarke digital steganography many patient data protection prevention datum breach maintenance shs integrity availability role cybersecurity ensure sustainable smart healthcare longterm viability smart healthcare depend constant assessment cyber risk harm healthcare provider patient professional review aim inform policymaker healthcare practitioner technology stakeholder critical imperative good practice foster secure resilient smart healthcare ecosystem synthesize insight multidisciplinary perspective cybersecurity healthcare management sustainability research understand recent cybersecurity measure critical control escalate cyber threat attack shss network encourage intelligent healthcare deliveryjatsp,0.5595238095238095,0.13690476190476192,0.19047619047619047,0.023809523809523808,84.0,3.0,0.0,0.0,0.0
Information Technology,IT Service Management,Quantitative,"Resource Management and Quality of Service Provisioning in 5G Cellular
  Networks","With the commercial launch of 5G technologies and fast pace of expansion of
cellular network infrastructure, it is expected that cellular and mobile
networks traffic will exponentially increase. In addition, new services are
expected to spread widely, such as the Internet of Things connected to mobile
networks. This will add additional burden in terms of traffic load. As a
result, some studies suggest that mobile traffic may increase more than 1000
times compared to the amount of traffic that is generated nowadays. This means
that network resources for mobile services must be managed and controlled in a
smart way, because resources are always limited, but the demand for services
and the need for keeping user equipment always connected to mobile networks can
be considered unlimited, leaving gap between huge service demands and available
resources. In order to narrow this gap, major consideration should be given to
the management of network resources to avoid network congestion and performance
degradation during peak hour/s and traffic spikes, and allow access to network
services to more customers when demand is high. On the other hand, guaranteeing
quality of service requirements for the wide range of new services is another
challenge that must be met in 5G networks. In this paper we will review 5G
networks characteristics and specifications, then carry out a survey on
resource management and QoS provisioning to improve and manage resource
utilization in 5G networks.",http://arxiv.org/abs/2008.09601v1,arXiv,resource management quality service provisioning cellular network,commercial launch technology fast pace expansion cellular network infrastructure expect cellular mobile network traffic exponentially increase addition new service expect spread widely internet thing connect mobile network add additional burden term traffic load result study suggest mobile traffic may increase time compare amount traffic generate nowadays mean network resource mobile service must manage control smart way resource always limited demand service need keep user equipment always connect mobile network consider unlimited leaving gap huge service demand available resource order narrow gap major consideration give management network resource avoid network congestion performance degradation peak hour traffic spike allow access network service customer demand high hand guarantee quality service requirement wide range new service another challenge must meet network paper review network characteristic specification carry survey resource management qos provisioning improve manage resource utilization network,resource management quality service provisioning cellular network commercial launch technology fast pace expansion cellular network infrastructure expect cellular mobile network traffic exponentially increase addition new service expect spread widely internet thing connect mobile network add additional burden term traffic load result study suggest mobile traffic may increase time compare amount traffic generate nowadays mean network resource mobile service must manage control smart way resource always limited demand service need keep user equipment always connect mobile network consider unlimited leaving gap huge service demand available resource order narrow gap major consideration give management network resource avoid network congestion performance degradation peak hour traffic spike allow access network service customer demand high hand guarantee quality service requirement wide range new service another challenge must meet network paper review network characteristic specification carry survey resource management qos provisioning improve manage resource utilization network,0.5864661654135338,0.15037593984962405,0.15789473684210525,0.03759398496240601,133.0,1.0,0.0,0.0,0.0
Information Technology,IT Service Management,Quantitative,"Mining Target-Oriented Fuzzy Correlation Rules to Optimize Telecom
  Service Management","To optimize telecom service management, it is necessary that information
about telecom services is highly related to the most popular telecom service.
To this end, we propose an algorithm for mining target-oriented fuzzy
correlation rules. In this paper, we show that by using the fuzzy statistics
analysis and the data mining technology, the target-oriented fuzzy correlation
rules can be obtained from a given database. We conduct an experiment by using
a sample database from a telecom service provider in Taiwan. Our work can be
used to assist the telecom service provider in providing the appropriate
services to the customers for better customer relationship management.",http://arxiv.org/abs/1103.0083v1,arXiv,mining targetoriente fuzzy correlation rule optimize telecom service management,optimize telecom service management necessary information telecom service highly related popular telecom service end propose algorithm mining targetoriente fuzzy correlation rule paper show use fuzzy statistic analysis data mining technology targetoriente fuzzy correlation rule obtain give database conduct experiment use sample database telecom service provider taiwan work use assist telecom service provider provide appropriate service customer well customer relationship management,mining targetoriente fuzzy correlation rule optimize telecom service management optimize telecom service management necessary information telecom service highly related popular telecom service end propose algorithm mining targetoriente fuzzy correlation rule paper show use fuzzy statistic analysis data mining technology targetoriente fuzzy correlation rule obtain give database conduct experiment use sample database telecom service provider taiwan work use assist telecom service provider provide appropriate service customer well customer relationship management,0.5166666666666667,0.15,0.11666666666666667,0.016666666666666666,60.0,0.0,1.0,0.0,0.0
Information Technology,IT Service Management,Quantitative,Change Impact Analysis Based Regression Testing of Web Services,"Reducing the effort required to make changes in web services is one of the
primary goals in web service projects maintenance and evolution. Normally,
functional and non-functional testing of a web service is performed by testing
the operations specified in its WSDL. The regression testing is performed by
identifying the changes made thereafter to the web service code and the WSDL.
In this thesis, we present a tool-supported approach to perform efficient
regression testing of web services. By representing a web service as a directed
graph of WSDL elements, we identify and gathers the changed portions of the
graph and use this information to reduce regression testing efforts.
Specifically, we identify, categorize, and capture the web service testing
needs in two different ways, namely, Operationalized Regression Testing of Web
Service (ORTWS) and Parameterized Regression Testing of Web Service (PRTWS).
Both of the approach can be combined to reduce the regression testing efforts
in the web service project. The proposed approach is prototyped as a tool,
named as Automatic Web Service Change Management (AWSCM), which helps in
selecting the relevant test cases to construct reduced test suite from the old
test suite. We present few case studies on different web service projects to
demonstrate the applicability of the proposed tool. The reduction in the effort
for regression testing of web service is also estimated.",http://arxiv.org/abs/1408.1600v1,arXiv,change impact analysis base regression testing web service,reduce effort require make change web service one primary goal web service project maintenance evolution normally functional nonfunctional testing web service perform test operation specify wsdl regression testing perform identify change make thereafter web service code wsdl thesis present toolsupported approach perform efficient regression testing web service represent web service direct graph wsdl element identify gather change portion graph use information reduce regression testing effort specifically identify categorize capture web service testing need two different way namely operationalize regression testing web service ortws parameterized regression testing web service prtws approach combine reduce regression test effort web service project propose approach prototype tool name automatic web service change management awscm help select relevant test case construct reduced test suite old test suite present case study different web service project demonstrate applicability propose tool reduction effort regression testing web service also estimate,change impact analysis base regression testing web service reduce effort require make change web service one primary goal web service project maintenance evolution normally functional nonfunctional testing web service perform test operation specify wsdl regression testing perform identify change make thereafter web service code wsdl thesis present toolsupported approach perform efficient regression testing web service represent web service direct graph wsdl element identify gather change portion graph use information reduce regression testing effort specifically identify categorize capture web service testing need two different way namely operationalize regression testing web service ortws parameterized regression testing web service prtws approach combine reduce regression test effort web service project propose approach prototype tool name automatic web service change management awscm help select relevant test case construct reduced test suite old test suite present case study different web service project demonstrate applicability propose tool reduction effort regression testing web service also estimate,0.6428571428571429,0.17857142857142858,0.10714285714285714,0.02857142857142857,140.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Quantitative,Efficient Resource Management in Cloud Environment,"In cloud computing resource management plays a significant role in data
centres and it is directly dependent on the application workload. Various
services such as Infrastructure as a Service (IaaS), Platform as a Service
(PaaS), and Software as a Service (SaaS) are offered by cloud computing to
provide compute, network, and storage capabilities to the cloud users utilizing
the pay-per-usage approach. Resource allocation is a prior solution to address
various demanding situations like the under/overload handling, resource
wastage, load balancing, Quality-of-Services (QoS) violations, VM migration and
many more. The primary aim of Virtual Machine Placement (VMP) is mapping of
Virtual Machines (VMs) to physical machines (PMs), such that the PMs may be
utilized to their maximum efficiency, where the already active VMs are not to
be interrupted. It provides a list of live VM migrations that must be
accomplished to get the optimum solution and reduces energy consumption to a
larger extent. The inefficient VMP leads to wastage of resources, excessive
energy consumption and also increase overall operational cost of the data
center. On this context, this article provides an extensive survey of resource
management schemes in cloud environment. A conceptual scheme for resource
management, grouping of current machine learning based resource allocation
strategies, and fundamental problems of ineffective distribution of physical
resources are analyzed. Thereafter, a complete survey of existing techniques in
machine learning based mechanisms in the field of cloud resource management are
explained. Ultimately, the paper explores and concludes distinct approaching
challenges and future research guidelines associated to resource management in
cloud environment.",http://arxiv.org/abs/2207.12085v1,arXiv,efficient resource management cloud environment,cloud compute resource management play significant role datum centre directly dependent application workload various service infrastructure service iaas platform service paas software service saas offer cloud computing provide compute network storage capability cloud user utilize payperusage approach resource allocation prior solution address various demand situation like underoverload handle resource wastage load balancing qualityofservice qos violation migration many primary aim virtual machine placement vmp mapping virtual machine vms physical machine may utilize maximum efficiency already active interrupt provide list live migration must accomplish get optimum solution reduce energy consumption large extent inefficient vmp lead wastage resource excessive energy consumption also increase overall operational cost datum center context article provide extensive survey resource management scheme cloud environment conceptual scheme resource management grouping current machine learn base resource allocation strategy fundamental problem ineffective distribution physical resource analyze thereafter complete survey exist technique machine learn base mechanism field cloud resource management explain ultimately paper explore conclude distinct approach challenge future research guideline associate resource management cloud environment,efficient resource management cloud environment cloud compute resource management play significant role datum centre directly dependent application workload various service infrastructure service iaas platform service paas software service saas offer cloud computing provide compute network storage capability cloud user utilize payperusage approach resource allocation prior solution address various demand situation like underoverload handle resource wastage load balancing qualityofservice qos violation migration many primary aim virtual machine placement vmp mapping virtual machine vms physical machine may utilize maximum efficiency already active interrupt provide list live migration must accomplish get optimum solution reduce energy consumption large extent inefficient vmp lead wastage resource excessive energy consumption also increase overall operational cost datum center context article provide extensive survey resource management scheme cloud environment conceptual scheme resource management grouping current machine learn base resource allocation strategy fundamental problem ineffective distribution physical resource analyze thereafter complete survey exist technique machine learn base mechanism field cloud resource management explain ultimately paper explore conclude distinct approach challenge future research guideline associate resource management cloud environment,0.5705521472392638,0.12269938650306748,0.1901840490797546,0.03067484662576687,163.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Quantitative,Managing Word-of-Mouth through Capacity Allocation and Advertisement,"Advancements in service sector and growing online platforms are intensifying
the information exchange between customers through (electronic) word-of-mouth
(WoM). The information obtained by WoM has shown to be a dominant factor in
customers' purchase decisions creating an endogenous demand structure. Service
providers can monitor how their service is perceived by consumers through
different methods, for example surveys. Although this requires an additional
effort, the understanding and integration of endogenous demand into operational
decisions offer great benefits. In this paper, we study a service system where
customers are sensitive to the on-demand access to the service. Customers form
a perception based on the information obtained by WoM communication and the
advertisement. Depending on the type of the service environment, service
capacity can be flexible or constant. We consider two types of service
providers: aware firm that has complete information on endogenous demand
structure, and na\""ive firm that has partial information. Our focus is to
understand the optimal advertisement and capacity decisions, and the value of
information on the underlying demand. For firms that have flexible service
capacity, we show that it is optimal to employ aggressive advertisement
strategies in the early stages. Myopic naive firms often misinterpret the
market conditions and cease operating, where they could in fact realize profit.
For the cases where the capacity is not flexible, it may not be possible to
avoid negative WoM. Therefore, the service provider is forced to keep the level
of advertisements more compatible with the actual quality of the service. This
prevents the firm from overcrowding the system through advertisement without
considering the service quality.",http://arxiv.org/abs/2201.04779v1,arXiv,manage wordofmouth capacity allocation advertisement,advancement service sector grow online platform intensify information exchange customer electronic wordofmouth wom information obtain wom show dominant factor customer purchase decision create endogenous demand structure service provider monitor service perceive consumer different method example survey although require additional effort understanding integration endogenous demand operational decision offer great benefit paper study service system customer sensitive ondemand access service customer form perception base information obtain wom communication advertisement depend type service environment service capacity flexible constant consider two type service provider aware firm complete information endogenous demand structure naive firm partial information focus understand optimal advertisement capacity decision value information underlie demand firm flexible service capacity show optimal employ aggressive advertisement strategy early stage myopic naive firm often misinterpret market condition cease operate could fact realize profit case capacity flexible may possible avoid negative wom therefore service provider force keep level advertisement compatible actual quality service prevent firm overcrowd system advertisement without consider service quality,manage wordofmouth capacity allocation advertisement advancement service sector grow online platform intensify information exchange customer electronic wordofmouth wom information obtain wom show dominant factor customer purchase decision create endogenous demand structure service provider monitor service perceive consumer different method example survey although require additional effort understanding integration endogenous demand operational decision offer great benefit paper study service system customer sensitive ondemand access service customer form perception base information obtain wom communication advertisement depend type service environment service capacity flexible constant consider two type service provider aware firm complete information endogenous demand structure naive firm partial information focus understand optimal advertisement capacity decision value information underlie demand firm flexible service capacity show optimal employ aggressive advertisement strategy early stage myopic naive firm often misinterpret market condition cease operate could fact realize profit case capacity flexible may possible avoid negative wom therefore service provider force keep level advertisement compatible actual quality service prevent firm overcrowd system advertisement without consider service quality,0.6103896103896104,0.12987012987012986,0.21428571428571427,0.012987012987012988,154.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Qualitative,"Assessing the maturity of software testing services using CMMI-SVC: An
  industrial case study","Context: While many companies conduct their software testing activities
in-house, many other companies outsource their software testing needs to other
firms who act as software testing service providers. As a result, Testing as a
Service (TaaS) has emerged as a strong service industry in the last several
decades. In the context of software testing services, there could be various
challenges (e.g., during the planning and service delivery phases) and, as a
result, the quality of testing services is not always as expected. Objective:
It is important, for both providers and also customers of testing services, to
assess the quality and maturity of test services and subsequently improve them.
Method: Motivated by a real industrial need in the context of several testing
service providers, to assess the maturity of their software testing services,
we chose the existing CMMI for Services maturity model (CMMI-SVC), and
conducted a case study using it in the context of two Turkish testing service
providers. Results: The case-study results show that maturity appraisal of
testing services using CMMI-SVC was helpful for both companies and their test
management teams by enabling them objectively assess the maturity of their
testing services and also by pinpointing potential improvement areas.
Conclusion: We empirically observed that, after some minor customization,
CMMI-SVC is indeed a suitable model for maturity appraisal of testing services.",http://arxiv.org/abs/2005.12570v2,arXiv,assess maturity software testing service use cmmisvc industrial case study,context many company conduct software testing activity inhouse many company outsource software testing need firm act software testing service provider result testing service taas emerge strong service industry last several decade context software testing service could various challenge planning service delivery phase result quality testing service always expect objective important provider also customer test service assess quality maturity test service subsequently improve method motivate real industrial need context several testing service provider assess maturity software testing service choose exist cmmi service maturity model cmmisvc conduct case study use context two turkish testing service provider result casestudy result show maturity appraisal testing service use cmmisvc helpful company test management team enable objectively assess maturity testing service also pinpoint potential improvement area conclusion empirically observe minor customization cmmisvc indeed suitable model maturity appraisal test service,assess maturity software testing service use cmmisvc industrial case study context many company conduct software testing activity inhouse many company outsource software testing need firm act software testing service provider result testing service taas emerge strong service industry last several decade context software testing service could various challenge planning service delivery phase result quality testing service always expect objective important provider also customer test service assess quality maturity test service subsequently improve method motivate real industrial need context several testing service provider assess maturity software testing service choose exist cmmi service maturity model cmmisvc conduct case study use context two turkish testing service provider result casestudy result show maturity appraisal testing service use cmmisvc helpful company test management team enable objectively assess maturity testing service also pinpoint potential improvement area conclusion empirically observe minor customization cmmisvc indeed suitable model maturity appraisal test service,0.631578947368421,0.12781954887218044,0.13533834586466165,0.05263157894736842,133.0,0.0,0.0,1.0,0.0
Information Technology,IT Service Management,Qualitative,Slicing-Based AI Service Provisioning on Network Edge,"Edge intelligence leverages computing resources on network edge to provide
artificial intelligence (AI) services close to network users. As it enables
fast inference and distributed learning, edge intelligence is envisioned to be
an important component of 6G networks. In this article, we investigate AI
service provisioning for supporting edge intelligence. First, we present the
features and requirements of AI services. Then, we introduce AI service data
management, and customize network slicing for AI services. Specifically, we
propose a novel resource pooling method to jointly manage service data and
network resources for AI services. A trace-driven case study demonstrates the
effectiveness of the proposed resource pooling method. Through this study, we
illustrate the necessity, challenge, and potential of AI service provisioning
on network edge.",http://arxiv.org/abs/2105.07052v1,arXiv,slicingbase service provision network edge,edge intelligence leverage compute resource network edge provide artificial intelligence service close network user enable fast inference distribute learn edge intelligence envision important component network article investigate service provisioning support edge intelligence first present feature requirement service introduce service datum management customize network slicing service specifically propose novel resource pool method jointly manage service datum network resource service tracedriven case study demonstrate effectiveness propose resource pool method study illustrate necessity challenge potential service provisioning network edge,slicingbase service provision network edge edge intelligence leverage compute resource network edge provide artificial intelligence service close network user enable fast inference distribute learn edge intelligence envision important component network article investigate service provisioning support edge intelligence first present feature requirement service introduce service datum management customize network slicing service specifically propose novel resource pool method jointly manage service datum network resource service tracedriven case study demonstrate effectiveness propose resource pool method study illustrate necessity challenge potential service provisioning network edge,0.6842105263157895,0.14473684210526316,0.10526315789473684,0.039473684210526314,76.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Qualitative,"An Approach for Selecting Cloud Service Adequate to Big Data Case Study:
  E-health Context","The expanding Cloud computing's services offers great opportunities for
consumers to find the best service and best cost. It offers a computing power
and a storage space adapted especially for Big Data processing. However, it
raises new challenges on how to select the best service out of the huge pool.
It is time-consuming for consumers to collect the necessary information and
analyze all service providers to make the right decision. Moreover, it'is a
highly demanding task from a computational perspective, because the same
computations may be conducted repeatedly by multiple consumers who have similar
requirements. Therefore, in this paper, we propose an approach based on
Analytic Hierarchy Process (AHP) method, which manages the selection of the
Cloud Service adequate to Big Data based on its parameters and criteria. We
applied this approach on a case study in order to validate its efficity. The
studied case is about the selection of the adequate Cloud Service for Big Data
in the context of National Health Service (NHS) of United Kingdom (UK).",http://arxiv.org/abs/2004.01640v1,arXiv,approach select cloud service adequate big datum case study ehealth context,expand cloud computing service offer great opportunity consumer find good service good cost offer computing power storage space adapt especially big datum processing however raise new challenge select good service huge pool timeconsuming consumer collect necessary information analyze service provider make right decision moreover itis highly demanding task computational perspective computation may conduct repeatedly multiple consumer similar requirement therefore paper propose approach base analytic hierarchy process ahp method manage selection cloud service adequate big datum base parameter criterion apply approach case study order validate efficity study case selection adequate cloud service big datum context national health service nhs united kingdom,approach select cloud service adequate big datum case study ehealth context expand cloud computing service offer great opportunity consumer find good service good cost offer computing power storage space adapt especially big datum processing however raise new challenge select good service huge pool timeconsuming consumer collect necessary information analyze service provider make right decision moreover itis highly demanding task computational perspective computation may conduct repeatedly multiple consumer similar requirement therefore paper propose approach base analytic hierarchy process ahp method manage selection cloud service adequate big datum base parameter criterion apply approach case study order validate efficity study case selection adequate cloud service big datum context national health service nhs united kingdom,0.54,0.12,0.2,0.06,100.0,0.0,1.0,0.0,0.0
Information Technology,IT Service Management,Qualitative,"Semantic web based Sensor Planning Services (SPS) for Sensor Web
  Enablement (SWE)","The Sensor Planning Service (SPS) is service model to define the web service
interface for requesting user driven acquisitions and observation. It's defined
by the Open Geospatial Consortium (OGC) Sensor Web Enablement (SWE) group to
provide standardized interface for tasking sensors to allow to defining,
checking, modifying and cancelling tasks of sensor and sensor data. The goal of
Sensor Planning Service (SPS) of OGC - SWE is standardize the interoperability
between a client and a server collection management environment. The Sensor
Planning Service (SPS) is need to automate complex data flow in a large
enterprises that are depend on live & stored data from sensors and multimedia
equipment. The obstacle are faced in Sensor Planning Service (SPS) are (I)
Observation from sensor at the right time and right place will be problem, (II)
acquisition information(data) that are collected at a specific time and
specific place will be problem. The above two obstacle are accomplished and
obtained by the web based semantic technology in order to provide & apply the
ontology based semantic rule to user driven a acquisitions and observation of
Sensor Planning Service (SPS). The novelty of our approach is by adding the
semantic rule to Sensor Planning Service model in SWE and we implemented Sensor
Planning Service (SPS) with semantic knowledge based to achieve high
standardized service model for Sensor Planning Service (SPS) of OGC - SWE.",http://arxiv.org/abs/1207.5310v1,arXiv,semantic web base sensor planning service sps sensor web enablement swe,sensor planning service sps service model define web service interface request user drive acquisition observation define open geospatial consortium ogc sensor web enablement swe group provide standardized interface task sensor allow define checking modifying cancel task sensor sensor data goal sensor planning service sps ogc swe standardize interoperability client server collection management environment sensor planning service sps need automate complex datum flow large enterprise depend live store datum sensor multimedia equipment obstacle face sensor planning service sps observation sensor right time right place problem acquisition informationdata collect specific time specific place problem two obstacle accomplish obtain web base semantic technology order provide apply ontology base semantic rule user drive acquisition observation sensor planning service sps novelty approach add semantic rule sensor planning service model swe implement sensor planning service sps semantic knowledge base achieve high standardized service model sensor planning service sps ogc swe,semantic web base sensor planning service sps sensor web enablement swe sensor planning service sps service model define web service interface request user drive acquisition observation define open geospatial consortium ogc sensor web enablement swe group provide standardized interface task sensor allow define checking modifying cancel task sensor sensor data goal sensor planning service sps ogc swe standardize interoperability client server collection management environment sensor planning service sps need automate complex datum flow large enterprise depend live store datum sensor multimedia equipment obstacle face sensor planning service sps observation sensor right time right place problem acquisition informationdata collect specific time specific place problem two obstacle accomplish obtain web base semantic technology order provide apply ontology base semantic rule user drive acquisition observation sensor planning service sps novelty approach add semantic rule sensor planning service model swe implement sensor planning service sps semantic knowledge base achieve high standardized service model sensor planning service sps ogc swe,0.7013888888888888,0.10416666666666667,0.1388888888888889,0.0,144.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Qualitative,"Defining the optimal level of business benefits within IS/IT projects:
  Insights from benefit identification practices adopted in an IT Service
  Management (ITSM) project","The popularity of benefit realization management (BRM) in today's IT-enabled
world is fast gaining traction within IT organisations around the world.
However, there appears to be limited attention paid to the intra-organisational
practice by which benefits are identified. The purpose of this paper is
twofold: firstly, to describe and define a practice approach to the
identification of benefits that exploits a number of benefit identification
methods in an effort to more comprehensively identify IS/IT related benefits
that reflect the ongoing organisational investment. Secondly, to underline the
importance of this benefit identification process in the context of IT service
management (ITSM). This is achieved through a case study of an information
technology infrastructure library (ITIL) implementation in a multi-national
organization. The case study exposes a pragmatic practice approach of
customising such implementations in an effort to achieve a cost effective
implementation of IT services that reflects the context and requirements of
that specific organisation.",http://arxiv.org/abs/1606.03537v1,arXiv,define optimal level business benefit within isit project insight benefit identification practice adopt service management itsm project,popularity benefit realization management brm today itenable world fast gain traction within organisation around world however appear limited attention pay intraorganisational practice benefit identify purpose paper twofold firstly describe define practice approach identification benefit exploit number benefit identification method effort comprehensively identify isit related benefit reflect ongoing organisational investment secondly underline importance benefit identification process context service management itsm achieve case study information technology infrastructure library itil implementation multinational organization case study expose pragmatic practice approach customise implementation effort achieve cost effective implementation service reflect context requirement specific organisation,define optimal level business benefit within isit project insight benefit identification practice adopt service management itsm project popularity benefit realization management brm today itenable world fast gain traction within organisation around world however appear limited attention pay intraorganisational practice benefit identify purpose paper twofold firstly describe define practice approach identification benefit exploit number benefit identification method effort comprehensively identify isit related benefit reflect ongoing organisational investment secondly underline importance benefit identification process context service management itsm achieve case study information technology infrastructure library itil implementation multinational organization case study expose pragmatic practice approach customise implementation effort achieve cost effective implementation service reflect context requirement specific organisation,0.6404494382022472,0.1348314606741573,0.11235955056179775,0.056179775280898875,89.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Mixed Methods,PECULIARITIES OF THE UNIVERSITIES' MANAGEMENT LOCATED ON FRONTLINE TERRITORIES,"<jats:p>The article analyzes the peculiarities of the management of universities (including displaced ones) located on the frontline territories, in the conditions of the war between Russia and Ukraine. It has been found that universities in these regions face unique challenges that require adaptation and the development of new management strategies, such as ensuring physical security, psychological support, infrastructure restoration, providing access to communications, quality educational services, hybrid learning models, scientific activities, financing and adaptation to new conditions. It is justified that the research is determined by the need for prompt response to security threats, ensuring the continuity of the educational process, infrastructure restoration, personnel support, international cooperation, development of innovative solutions, and socio-economic stability of the regions. The analysis and systematization of specific aspects of the management of higher education institutions operating in the frontline territories aimed at identifying key challenges and developing effective strategies for overcoming them was carried out. It has been proven that university management includes normative-procedural, structural-functional, and strategic-organizational processes. Peculiarities of the processes of implementation of innovative educational activities and conducting scientific research in universities located in the frontline territories were studied. Synergistic, systemic, statistical, comparative, and functional methods were used for the research. It is found that the synergistic method integrates various management components such as organizational, financial, personnel, and infrastructure management to create a holistic picture of wartime management. The system method allows you to consider the university as a whole system interacting with the environment, using interviews, discussions, surveys, and statistical analysis to collect data. The statistical method evaluates the impact of various factors on university management through quantitative data using means, medians, variances, regression models, and statistical tests. The comparative method analyzes and compares management practices, identifying the best of them to improve efficiency. The functional method assesses the effectiveness of key management functions such as planning, organization, resource allocation, communication, and control. It was found that the methodology for researching the peculiarities of the management of universities in the frontline territories involves a comprehensive approach, which includes the collection of primary and secondary data, qualitative and quantitative analysis, the development of recommendations and their validation, which provides a deep understanding of the problem and the development of effective strategies for the support and development of universities in war conditions.</jats:p>",https://doi.org/10.31891/dsim-2024-6(20),CrossRef,peculiarity university management locate frontline territory,jatspthe article analyze peculiarity management university include displace one locate frontline territory condition war russia ukraine find university region face unique challenge require adaptation development new management strategy ensure physical security psychological support infrastructure restoration provide access communication quality educational service hybrid learning model scientific activity financing adaptation new condition justify research determine need prompt response security threat ensure continuity educational process infrastructure restoration personnel support international cooperation development innovative solution socioeconomic stability region analysis systematization specific aspect management high education institution operate frontline territory aim identify key challenge develop effective strategy overcome carry prove university management include normativeprocedural structuralfunctional strategicorganizational process peculiarity process implementation innovative educational activity conduct scientific research university locate frontline territory study synergistic systemic statistical comparative functional method use research find synergistic method integrate various management component organizational financial personnel infrastructure management create holistic picture wartime management system method allow consider university whole system interact environment use interview discussion survey statistical analysis collect datum statistical method evaluate impact various factor university management quantitative datum use mean medians variance regression model statistical test comparative method analyze compare management practice identify good improve efficiency functional method assess effectiveness key management function planning organization resource allocation communication control find methodology research peculiarity management university frontline territory involve comprehensive approach include collection primary secondary datum qualitative quantitative analysis development recommendation validation provide deep understanding problem development effective strategy support development university war conditionsjatsp,peculiarity university management locate frontline territory jatspthe article analyze peculiarity management university include displace one locate frontline territory condition war russia ukraine find university region face unique challenge require adaptation development new management strategy ensure physical security psychological support infrastructure restoration provide access communication quality educational service hybrid learning model scientific activity financing adaptation new condition justify research determine need prompt response security threat ensure continuity educational process infrastructure restoration personnel support international cooperation development innovative solution socioeconomic stability region analysis systematization specific aspect management high education institution operate frontline territory aim identify key challenge develop effective strategy overcome carry prove university management include normativeprocedural structuralfunctional strategicorganizational process peculiarity process implementation innovative educational activity conduct scientific research university locate frontline territory study synergistic systemic statistical comparative functional method use research find synergistic method integrate various management component organizational financial personnel infrastructure management create holistic picture wartime management system method allow consider university whole system interact environment use interview discussion survey statistical analysis collect datum statistical method evaluate impact various factor university management quantitative datum use mean medians variance regression model statistical test comparative method analyze compare management practice identify good improve efficiency functional method assess effectiveness key management function planning organization resource allocation communication control find methodology research peculiarity management university frontline territory involve comprehensive approach include collection primary secondary datum qualitative quantitative analysis development recommendation validation provide deep understanding problem development effective strategy support development university war conditionsjatsp,0.592274678111588,0.1459227467811159,0.21030042918454936,0.0,233.0,1.0,1.0,0.0,0.0
Information Technology,IT Service Management,Mixed Methods,Service Quality Management: A Process‐control Approach,"<jats:p>The world is moving into a services industry environment which is
evidencing many of the same productivity and quality issues associated
with manufacturing during the past two decades. Quick fixes using
qualitative approaches have not been universally successful and some
have advocated a more quantitative direction. Proposes a middle ground
incorporating both ideas. Reports the development of a process model
based on current service sector paradigms and more traditional
statistical quality‐control techniques from manufacturing management.
Details a test of the proposed model in the travel agency industry with
results generally confirming the potential for transporting
quality‐control concepts from manufacturing into services on a selected
basis. While the heterogeneity of services may constrain and even
preclude direct application of the process‐control approach in all
cases, the five‐step plan proposed may prove to be a useful tool for
service management across diverse businesses.</jats:p>",https://doi.org/10.1108/eum0000000002808,CrossRef,service quality management approach,jatspthe world move service industry environment evidence many productivity quality issue associate manufacturing past two decade quick fix use qualitative approach universally successful advocate quantitative direction propose middle ground incorporate idea report development process model base current service sector paradigm traditional statistical technique manufacture management detail test propose model travel agency industry result generally confirm potential transport concept manufacture service select basis heterogeneity service may constrain even preclude direct application approach case plan propose may prove useful tool service management across diverse businessesjatsp,service quality management approach jatspthe world move service industry environment evidence many productivity quality issue associate manufacturing past two decade quick fix use qualitative approach universally successful advocate quantitative direction propose middle ground incorporate idea report development process model base current service sector paradigm traditional statistical technique manufacture management detail test propose model travel agency industry result generally confirm potential transport concept manufacture service select basis heterogeneity service may constrain even preclude direct application approach case plan propose may prove useful tool service management across diverse businessesjatsp,0.6024096385542169,0.08433734939759036,0.1686746987951807,0.03614457831325301,83.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Mixed Methods,Knowledge management in public service provision: the Child Support Agency,"<jats:p>The paper addresses the issue of knowledge management in public service organisations where the concept of provider competitiveness is of limited significance but other priorities prevail. The broad aim is to understand how the concept of “competitive advantage through knowledge management”, as practised in the broader business community, might translate to the modern Civil Service? This issue is explored through the medium of a study within the UK's Child Support Agency (CSA) based on the results of interviews with, and questionnaire responses from, the senior management group. The central question thereby investigated was: “To what extent can the conditions required for successful knowledge management be observed and evaluated?” A “conditions framework” and associated analysis is then used to assess broader implications and the possibility of wider application within other such public service organisations.</jats:p>",https://doi.org/10.1108/09564230310478828,CrossRef,knowledge management public service provision child support agency,jatspthe paper address issue knowledge management public service organisation concept provider competitiveness limited significance priority prevail broad aim understand concept competitive advantage knowledge management practise broad business community might translate modern civil service issue explore medium study within uks child support agency csa base result interview questionnaire response senior management group central question thereby investigate extent condition require successful knowledge management observe evaluate condition framework associate analysis use assess broad implication possibility wide application within public service organisationsjatsp,knowledge management public service provision child support agency jatspthe paper address issue knowledge management public service organisation concept provider competitiveness limited significance priority prevail broad aim understand concept competitive advantage knowledge management practise broad business community might translate modern civil service issue explore medium study within uks child support agency csa base result interview questionnaire response senior management group central question thereby investigate extent condition require successful knowledge management observe evaluate condition framework associate analysis use assess broad implication possibility wide application within public service organisationsjatsp,0.5769230769230769,0.11538461538461539,0.1794871794871795,0.01282051282051282,78.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Mixed Methods,Exploring the alignment between service strategy and service innovation,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>Literature is relatively sparse on describing how companies should align their determinants for service innovations with their different types of service strategies. This study seeks to explore the alignment between three types of service strategies and determinants for service innovations.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>A qualitative, multi‐case research design on 12 Western European capital goods manufacturers including 24 service innovation projects was employed. The study is based on multiple sources of evidence: internal documentation of service innovation and development projects and, most importantly, interview data and participation in internal innovation workshops. Traditional inductive research methods were used to analyze the case studies.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>These indicate that aligning service strategies with determinants for service innovations is very complex. The configurations of the determinants are associated with the innovation success. Alternative configurations of determinants can create counterproductive effects and can limit the success of service innovation projects as well as implementation of service strategies.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p>The study is based on interviews and case studies, but the external validity (generalizability) of the alignments could not be assessed accurately. Future research would benefit from insights obtained from quantitative data. The findings supplement existing research on success factors for the service business in manufacturing companies.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>The findings imply that managers contemplating a specific service strategy have to consider the service innovation and reframe the determinant for service innovations accordingly. Companies trying to implement an after‐sales service strategy should focus on a narrow range of determinants for service innovations. The resulting configurations guide managers to set up an efficient and effective service innovation management that helps them to implement their service strategy through successful service innovation project.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>This empirical study shows that the configuration of determinants for service innovation differs for each service strategy. Whereas, the few similarities in determinants on service innovation are mainly other applications of existing theories on service innovation, the differences modify the existing theories.</jats:p></jats:sec>",https://doi.org/10.1108/09564231111175004,CrossRef,explore alignment service strategy service innovation,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspliterature relatively sparse describe company align determinant service innovation different type service strategy study seek explore alignment three type service strategy determinant service innovationsjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa qualitative research design western european capital good manufacturer include service innovation project employ study base multiple source evidence internal documentation service innovation development project importantly interview datum participation internal innovation workshop traditional inductive research method use analyze case studiesjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthese indicate align service strategy determinant service innovation complex configuration determinant associate innovation success alternative configuration determinant create counterproductive effect limit success service innovation project well implementation service strategiesjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe study base interview case study external validity generalizability alignment could assess accurately future research would benefit insight obtain quantitative datum finding supplement exist research success factor service business manufacture companiesjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspthe finding imply manager contemplate specific service strategy consider service innovation reframe determinant service innovation accordingly company try implement service strategy focus narrow range determinant service innovation result configuration guide manager set efficient effective service innovation management help implement service strategy successful service innovation projectjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis empirical study show configuration determinant service innovation differ service strategy whereas similarity determinant service innovation mainly application exist theory service innovation difference modify exist theoriesjatspjatssec,explore alignment service strategy service innovation jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspliterature relatively sparse describe company align determinant service innovation different type service strategy study seek explore alignment three type service strategy determinant service innovationsjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa qualitative research design western european capital good manufacturer include service innovation project employ study base multiple source evidence internal documentation service innovation development project importantly interview datum participation internal innovation workshop traditional inductive research method use analyze case studiesjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthese indicate align service strategy determinant service innovation complex configuration determinant associate innovation success alternative configuration determinant create counterproductive effect limit success service innovation project well implementation service strategiesjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe study base interview case study external validity generalizability alignment could assess accurately future research would benefit insight obtain quantitative datum finding supplement exist research success factor service business manufacture companiesjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspthe finding imply manager contemplate specific service strategy consider service innovation reframe determinant service innovation accordingly company try implement service strategy focus narrow range determinant service innovation result configuration guide manager set efficient effective service innovation management help implement service strategy successful service innovation projectjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis empirical study show configuration determinant service innovation differ service strategy whereas similarity determinant service innovation mainly application exist theory service innovation difference modify exist theoriesjatspjatssec,0.6161616161616161,0.12626262626262627,0.15151515151515152,0.025252525252525252,198.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Mixed Methods,Linking task and goal interdependence to quality service,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>With a twofold aim, the purpose of this paper is to focus on the service climate, including its antecedents, consequences, and a moderator. First, it examines whether task‐ and goal‐interdependent configuration facilitates the level of service climate; second, it tests the strength of the moderating role of service climate between service climate levels and service behavior.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>Among 54 nursing units at six hospitals, the data were collected using multiple methods (surveys, observations, administrative data).</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Mixed‐linear model analyses indicated that the joint effects of task and goal interdependence related significantly to service climate level. Service climate strength moderated the relationship of service climate level to quality service behavior.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p>The research approach may diminish the generalizability of the research results. Further work should test the propositions in other research contexts.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>Quality service behaviors and the service climate could be promoted through well‐designed task‐ and goal‐interdependence structures within units. Assimilating a service climate in units is not enough. To promote high quality service behaviors, managers must direct their efforts toward finding agreement among team members with regard with the importance of service in their unit.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>The paper's findings offer empirical support to the persistent social interaction explanation of climate formation and point to the important role of interdependence for creating and maintaining service climate levels and promoting service behaviors in units.</jats:p></jats:sec>",https://doi.org/10.1108/09564231311323944,CrossRef,link task goal interdependence quality service,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspwith twofold aim purpose paper focus service climate include antecedent consequence moderator first examine whether configuration facilitate level service climate second test strength moderate role service climate service climate level service behaviorjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspamong nursing unit six hospital datum collect use multiple method survey observation administrative datajatspjatssecjatssecjatstitle model analysis indicate joint effect task goal interdependence relate significantly service climate level service climate strength moderate relationship service climate level quality service behaviorjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe research approach may diminish generalizability research result work test proposition research contextsjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspquality service behavior service climate could promote structure within unit assimilate service climate unit enough promote high quality service behavior manager must direct effort toward find agreement among team member regard importance service unitjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe paper finding offer empirical support persistent social interaction explanation climate formation point important role interdependence create maintain service climate level promote service behavior unitsjatspjatssec,link task goal interdependence quality service jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspwith twofold aim purpose paper focus service climate include antecedent consequence moderator first examine whether configuration facilitate level service climate second test strength moderate role service climate service climate level service behaviorjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspamong nursing unit six hospital datum collect use multiple method survey observation administrative datajatspjatssecjatssecjatstitle model analysis indicate joint effect task goal interdependence relate significantly service climate level service climate strength moderate relationship service climate level quality service behaviorjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe research approach may diminish generalizability research result work test proposition research contextsjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspquality service behavior service climate could promote structure within unit assimilate service climate unit enough promote high quality service behavior manager must direct effort toward find agreement among team member regard importance service unitjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe paper finding offer empirical support persistent social interaction explanation climate formation point important role interdependence create maintain service climate level promote service behavior unitsjatspjatssec,0.6827586206896552,0.09655172413793103,0.10344827586206896,0.020689655172413793,145.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Design and Development,"SONATA: Service Programming and Orchestration for Virtualized Software
  Networks","In conventional large-scale networks, creation and management of network
services are costly and complex tasks that often consume a lot of resources,
including time and manpower. Network softwarization and network function
virtualization have been introduced to tackle these problems. They replace the
hardware-based network service components and network control mechanisms with
software components running on general-purpose hardware, aiming at decreasing
costs and complexity of implementing new services, maintaining the implemented
services, and managing available resources in service provisioning platforms
and underlying infrastructures. To experience the full potential of these
approaches, innovative development support tools and service provisioning
environments are needed. To answer these needs, we introduce the SONATA
architecture, a service programming, orchestration, and management framework.
We present a development toolchain for virtualized network services, fully
integrated with a service platform and orchestration system. We motivate the
modular and flexible architecture of our system and discuss its main components
and features, such as function- and service-specific managers that allow fine-
grained service management, slicing support to facilitate multi-tenancy,
recursiveness for improved scalability, and full-featured DevOps support.",http://arxiv.org/abs/1605.05850v1,arXiv,sonata service programming orchestration virtualize software network,conventional largescale network creation management network service costly complex task often consume lot resource include time manpower network softwarization network function virtualization introduce tackle problem replace hardwarebase network service component network control mechanism software component run generalpurpose hardware aim decrease cost complexity implement new service maintain implement service manage available resource service provisioning platform underlie infrastructure experience full potential approach innovative development support tool service provisioning environment need answer need introduce sonata architecture service programming orchestration management framework present development toolchain virtualize network service fully integrate service platform orchestration system motivate modular flexible architecture system discuss main component feature function servicespecific manager allow fine grain service management slicing support facilitate multitenancy recursiveness improved scalability fullfeature devop support,sonata service programming orchestration virtualize software network conventional largescale network creation management network service costly complex task often consume lot resource include time manpower network softwarization network function virtualization introduce tackle problem replace hardwarebase network service component network control mechanism software component run generalpurpose hardware aim decrease cost complexity implement new service maintain implement service manage available resource service provisioning platform underlie infrastructure experience full potential approach innovative development support tool service provisioning environment need answer need introduce sonata architecture service programming orchestration management framework present development toolchain virtualize network service fully integrate service platform orchestration system motivate modular flexible architecture system discuss main component feature function servicespecific manager allow fine grain service management slicing support facilitate multitenancy recursiveness improved scalability fullfeature devop support,0.6752136752136753,0.15384615384615385,0.1452991452991453,0.017094017094017096,117.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Design and Development,"Inter-organizational fault management: Functional and organizational
  core aspects of management architectures","Outsourcing -- successful, and sometimes painful -- has become one of the
hottest topics in IT service management discussions over the past decade. IT
services are outsourced to external service provider in order to reduce the
effort required for and overhead of delivering these services within the own
organization. More recently also IT services providers themselves started to
either outsource service parts or to deliver those services in a
non-hierarchical cooperation with other providers. Splitting a service into
several service parts is a non-trivial task as they have to be implemented,
operated, and maintained by different providers. One key aspect of such
inter-organizational cooperation is fault management, because it is crucial to
locate and solve problems, which reduce the quality of service, quickly and
reliably. In this article we present the results of a thorough use case based
requirements analysis for an architecture for inter-organizational fault
management (ioFMA). Furthermore, a concept of the organizational respective
functional model of the ioFMA is given.",http://arxiv.org/abs/1101.3891v1,arXiv,interorganizational fault management functional organizational core aspect management architecture,outsource successful sometimes painful become one hot topic service management discussion past decade service outsource external service provider order reduce effort require overhead deliver service within organization recently also service provider start either outsource service part deliver service nonhierarchical cooperation provider split service several service part nontrivial task implement operate maintain different provider one key aspect interorganizational cooperation fault management crucial locate solve problem reduce quality service quickly reliably article present result thorough use case base requirement analysis architecture interorganizational fault management iofma furthermore concept organizational respective functional model iofma give,interorganizational fault management functional organizational core aspect management architecture outsource successful sometimes painful become one hot topic service management discussion past decade service outsource external service provider order reduce effort require overhead deliver service within organization recently also service provider start either outsource service part deliver service nonhierarchical cooperation provider split service several service part nontrivial task implement operate maintain different provider one key aspect interorganizational cooperation fault management crucial locate solve problem reduce quality service quickly reliably article present result thorough use case base requirement analysis architecture interorganizational fault management iofma furthermore concept organizational respective functional model iofma give,0.5274725274725275,0.14285714285714285,0.18681318681318682,0.06593406593406594,45.5,0.0,0.0,1.0,0.0
Information Technology,IT Service Management,Design and Development,Managing and Querying Web Services Communities: A Survey,"With the advance of Web Services technologies and the emergence of Web
Services into the information space, tremendous opportunities for empowering
users and organizations appear in various application domains including
electronic commerce, travel, intelligence information gathering and analysis,
health care, digital government, etc. However, the technology to organize,
search, integrate these Web Services has not kept pace with the rapid growth of
the available information space. The number of Web Services to be integrated
may be large and continuously changing. To ease and improve the process of Web
services discovery in an open environment like the Internet, it is suggested to
gather similar Web services into groups known as communities. Although Web
services are intensively investigated, the community management issues have not
been addressed yet In this paper we draw an overview of several Web services
Communities' management approaches based on some currently existing communities
platforms and frameworks. We also discuss different approaches for querying and
selecting Web services under the umbrella of Web services communities'. We
compare the current approaches among each others with respect to some key
requirements.",http://arxiv.org/abs/1103.0921v1,arXiv,manage query web service communitie survey,advance web service technology emergence web service information space tremendous opportunity empower user organization appear various application domain include electronic commerce travel intelligence information gathering analysis health care digital government etc however technology organize search integrate web service keep pace rapid growth available information space number web service integrate may large continuously change ease improve process web service discovery open environment like internet suggest gather similar web service group know community although web service intensively investigate community management issue address yet paper draw overview several web service community management approach base currently exist community platform framework also discuss different approach query select web service umbrella web service community compare current approach among respect key requirement,manage query web service communitie survey advance web service technology emergence web service information space tremendous opportunity empower user organization appear various application domain include electronic commerce travel intelligence information gathering analysis health care digital government etc however technology organize search integrate web service keep pace rapid growth available information space number web service integrate may large continuously change ease improve process web service discovery open environment like internet suggest gather similar web service group know community although web service intensively investigate community management issue address yet paper draw overview several web service community management approach base currently exist community platform framework also discuss different approach query select web service umbrella web service community compare current approach among respect key requirement,0.6434782608695652,0.12173913043478261,0.11304347826086956,0.043478260869565216,115.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Design and Development,"Towards a decentralized data privacy protocol for self-sovereignty in
  the digital world","A typical user interacts with many digital services nowadays, providing these
services with their data. As of now, the management of privacy preferences is
service-centric: Users must manage their privacy preferences according to the
rules of each service provider, meaning that every provider offers its unique
mechanisms for users to control their privacy settings. However, managing
privacy preferences holistically (i.e., across multiple digital services) is
just impractical. In this vision paper, we propose a paradigm shift towards an
enriched user-centric approach for cross-service privacy preferences
management: the realization of a decentralized data privacy protocol.",http://arxiv.org/abs/2404.12837v1,arXiv,towards decentralized data privacy protocol selfsovereignty digital world,typical user interact many digital service nowadays provide service datum management privacy preference servicecentric user must manage privacy preference accord rule service provider mean every provider offer unique mechanism user control privacy setting however manage privacy preference holistically across multiple digital service impractical vision paper propose paradigm shift towards enrich usercentric approach crossservice privacy preference management realization decentralized data privacy protocol,towards decentralized data privacy protocol selfsovereignty digital world typical user interact many digital service nowadays provide service datum management privacy preference servicecentric user must manage privacy preference accord rule service provider mean every provider offer unique mechanism user control privacy setting however manage privacy preference holistically across multiple digital service impractical vision paper propose paradigm shift towards enrich usercentric approach crossservice privacy preference management realization decentralized data privacy protocol,0.5573770491803278,0.13114754098360656,0.13114754098360656,0.04918032786885246,61.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Design and Development,CapExec: Towards Transparently-Sandboxed Services (Extended Version),"Network services are among the riskiest programs executed by production
systems. Such services execute large quantities of complex code and process
data from arbitrary and untrusted network sources, often with high levels of
system privilege. It is desirable to confine system services to a
least-privileged environment so that the potential damage from a malicious
attacker can be limited, but existing mechanisms for sandboxing services
require invasive and system-specific code changes and are insufficient to
confine broad classes of network services.
  Rather than sandboxing one service at a time, we propose that the best place
to add sandboxing to network services is in the service manager that starts
those services. As a first step towards this vision, we propose CapExec, a
process supervisor that can execute a single service within a sandbox based on
a service declaration file in which, required resources whose limited access to
are supported by Caper services, are specified. Using the Capsicum
compartmentalization framework and its Casper service framework, CapExec
provides robust application sandboxing without requiring any modifications to
the application itself. We believe that this is a first step towards ubiquitous
sandboxing of network services without the costs of virtualization.
  Keywords: application security, sandboxing, service manager, Capsicum,
compartmentalization",http://arxiv.org/abs/1909.12282v1,arXiv,capexec towards transparentlysandboxe service extend version,network service among riskiest program execute production system service execute large quantity complex code process datum arbitrary untrusted network source often high level system privilege desirable confine system service leastprivilege environment potential damage malicious attacker limit exist mechanism sandboxe service require invasive systemspecific code change insufficient confine broad class network service rather sandboxe one service time propose good place add sandboxing network service service manager start service first step towards vision propose capexec process supervisor execute single service within sandbox base service declaration file require resource whose limited access support caper service specify use capsicum compartmentalization framework casper service framework capexec provide robust application sandboxing without require modification application believe first step towards ubiquitous sandboxing network service without cost virtualization keyword application security sandboxing service manager capsicum compartmentalization,capexec towards transparentlysandboxe service extend version network service among riskiest program execute production system service execute large quantity complex code process datum arbitrary untrusted network source often high level system privilege desirable confine system service leastprivilege environment potential damage malicious attacker limit exist mechanism sandboxe service require invasive systemspecific code change insufficient confine broad class network service rather sandboxe one service time propose good place add sandboxing network service service manager start service first step towards vision propose capexec process supervisor execute single service within sandbox base service declaration file require resource whose limited access support caper service specify use capsicum compartmentalization framework casper service framework capexec provide robust application sandboxing without require modification application believe first step towards ubiquitous sandboxing network service without cost virtualization keyword application security sandboxing service manager capsicum compartmentalization,0.625,0.109375,0.1640625,0.015625,128.0,0.0,0.0,0.0,1.0
Information Technology,IT Service Management,Theoretical / Conceptual,Blockchain in Service Management and Service Research - Developing a Research Agenda and Managerial Implications,"<p>As blockchain technology is maturing to be confidently used in practice, its applications are becoming evident and, correspondingly, more blockchain research is being published, also extending to more domains than before. To date, scientific research in the field has predominantly focused on subject areas such as finance, computer science, and engineering, while the area of service management has largely neglected this topic. Therefore, we invited a group of renowned scholars from different academic fields to share their views on emerging topics regarding blockchain in service management and service research. Their individual commentaries and conceptual contributions refer to different theoretical and domain perspectives, including managerial implications for service companies as well as forward-looking suggestions for further research.</p>",https://doi.org/10.15358/2511-8676-2021-2-71,CrossRef,blockchain service management service research develop research agenda managerial implication,pas blockchain technology mature confidently use practice application become evident correspondingly blockchain research publish also extend domain date scientific research field predominantly focus subject area finance computer science engineering area service management largely neglect topic therefore invite group renowned scholar different academic field share view emerge topic regard blockchain service management service research individual commentary conceptual contribution refer different theoretical domain perspective include managerial implication service company well forwardlooke suggestion researchp,blockchain service management service research develop research agenda managerial implication pas blockchain technology mature confidently use practice application become evident correspondingly blockchain research publish also extend domain date scientific research field predominantly focus subject area finance computer science engineering area service management largely neglect topic therefore invite group renowned scholar different academic field share view emerge topic regard blockchain service management service research individual commentary conceptual contribution refer different theoretical domain perspective include managerial implication service company well forwardlooke suggestion researchp,0.5774647887323944,0.15492957746478872,0.15492957746478872,0.09859154929577464,71.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Theoretical / Conceptual,Service Management: An Evaluation and the Future,"<jats:p>Deals with the future of service management in specific service
management terms but also in broader, societal terms, from both a
practitioner and a scholarly perspective. Claims that service
management concerns not only what is traditionally known as service
organizations, but also constitutes a future paradigm for organizations
in general. The goods‐services division in its traditional sense is
outdated; it represents a myopic production view, while the service
economy is an expression for customer‐oriented and citizen‐oriented,
value‐enhancing offering. Although service management has taken a giant
step since the late 1970s, we are just beginning to see a new era of
management that will fight the battle for economic survival in the
future service society.</jats:p>",https://doi.org/10.1108/09564239410051920,CrossRef,service management evaluation future,jatspdeal future service management specific service management term also broad societal term practitioner scholarly perspective claim service management concern traditionally know service organization also constitute future paradigm organization general division traditional sense outdate represent myopic production view service economy expression offering although service management take giant step since late begin see new era management fight battle economic survival future service societyjatsp,service management evaluation future jatspdeal future service management specific service management term also broad societal term practitioner scholarly perspective claim service management concern traditionally know service organization also constitute future paradigm organization general division traditional sense outdate represent myopic production view service economy expression offering although service management take giant step since late begin see new era management fight battle economic survival future service societyjatsp,0.5409836065573771,0.13114754098360656,0.21311475409836064,0.04918032786885246,61.0,1.0,0.0,0.0,0.0
Information Technology,IT Service Management,Theoretical / Conceptual,QUIS 9 symposium – service excellence in management,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>To introduce the special issue focusing on the QUIS 9 symposium.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>A brief perspective of the best papers presented at the Quality in Services (QUIS9) symposium held at Karlstad university, Sweden in June 2004.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Outlines some of the highlights surrounding the conference.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>Provides a brief report of the context of the conference.</jats:p></jats:sec>",https://doi.org/10.1108/09564230510592261,CrossRef,quis symposium service excellence management,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspto introduce special issue focus quis symposiumjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa brief perspective good paper present quality service quis symposium hold karlstad university sweden june jatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspoutline highlight surround conferencejatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspprovide brief report context conferencejatspjatssec,quis symposium service excellence management jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspto introduce special issue focus quis symposiumjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa brief perspective good paper present quality service quis symposium hold karlstad university sweden june jatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspoutline highlight surround conferencejatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspprovide brief report context conferencejatspjatssec,0.45454545454545453,0.030303030303030304,0.12121212121212122,0.0,33.0,3.0,0.0,1.0,0.0
Information Technology,IT Service Management,Theoretical / Conceptual,Viable service systems and decision making in service management,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>The purpose of this paper is to highlight how systems thinking contributes to decision making in uncertain contexts that are characteristic of service systems. Based on the assumption that service systems face complex conditions, the paper posits that systems thinking may support the understanding of key issues in service management.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>This paper proposes an interpretation of complexity in the context of service systems, which highlights the perspective change that occurs when a systems approach is adopted. The offered conceptual perspective is then brought to an operational level, in spite of the complexity of the decisions driving a viable system, by modelling a service system as a network of agents, resources, processes and decisions through the use of fuzzy logic. The paper reviews service management research streams, and takes a deeper look at the concepts of service systems and complex service systems. The paper then proceeds to discuss how systems thinking contributes to service management by proposing a systems interpretation of complexity.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>Service management theories and models may be enhanced by integrating prevailing approaches, based on a quantitative and mechanistic view of service systems dynamics, with systems thinking‐based meta‐models that can be used in better understanding service exchanges. The findings of the paper also show how the integration of an engineering approach can be insightful to the understanding of service systems; adopting a Viable Systems Approach (VSA) as a meta‐model can be useful in fully comprehending market behaviour in uncertain conditions.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>The originality of this paper lies in exploring the contribution of systems thinking, in particular of the Viable Systems Approach (VSA), to service management and decision making.</jats:p></jats:sec>",https://doi.org/10.1108/09564231211260396,CrossRef,viable service system decision making service management,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper highlight system think contribute decision making uncertain context characteristic service system base assumption service system face complex condition paper posit system thinking may support understanding key issue service managementjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthis paper propose interpretation complexity context service system highlight perspective change occur system approach adopt offer conceptual perspective bring operational level spite complexity decision drive viable system model service system network agent resource process decision use fuzzy logic paper review service management research stream take deep look concept service system complex service system paper proceed discuss system think contribute service management propose system interpretation complexityjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspservice management theory model may enhance integrate prevail approach base quantitative mechanistic view service system dynamic system use well understanding service exchange finding paper also show integration engineering approach insightful understanding service system adopt viable system approach vsa useful fully comprehend market behaviour uncertain conditionsjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe originality paper lie explore contribution system think particular viable system approach vsa service management decision makingjatspjatssec,viable service system decision making service management jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper highlight system think contribute decision making uncertain context characteristic service system base assumption service system face complex condition paper posit system thinking may support understanding key issue service managementjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthis paper propose interpretation complexity context service system highlight perspective change occur system approach adopt offer conceptual perspective bring operational level spite complexity decision drive viable system model service system network agent resource process decision use fuzzy logic paper review service management research stream take deep look concept service system complex service system paper proceed discuss system think contribute service management propose system interpretation complexityjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspservice management theory model may enhance integrate prevail approach base quantitative mechanistic view service system dynamic system use well understanding service exchange finding paper also show integration engineering approach insightful understanding service system adopt viable system approach vsa useful fully comprehend market behaviour uncertain conditionsjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe originality paper lie explore contribution system think particular viable system approach vsa service management decision makingjatspjatssec,0.60625,0.16875,0.11875,0.01875,160.0,0.0,0.0,0.0,0.0
Information Technology,IT Service Management,Theoretical / Conceptual,A capacity management model in service industries,"<jats:p>The problem of capacity management is one of the most difficult to tackle in business management; a situation which is aggravated in the majority of services, due to uncertain demand and personalized requirements, which make it difficult to plan and assign productive capacity. While overstaffing implies extra costs, insufficient capacity implies a lower level of attention to customer needs and therefore a lack of perceived quality. The present article tackles this problem, presenting a model that enables minimum staffing to be easily determined. By taking into account historical staffing data associated with quality data, minimum recommended workload is calculated as a function of the theoretical staff needed according to standard time. The model has been applied in two real cases.</jats:p>",https://doi.org/10.1108/09564230210431983,CrossRef,capacity management model service industry,jatspthe problem capacity management one difficult tackle business management situation aggravate majority service due uncertain demand personalized requirement make difficult plan assign productive capacity overstaffing imply extra cost insufficient capacity imply low level attention customer need therefore lack perceive quality present article tackle problem present model enable minimum staffing easily determine take account historical staffing datum associate quality datum minimum recommend workload calculate function theoretical staff need accord standard time model apply two real casesjatsp,capacity management model service industry jatspthe problem capacity management one difficult tackle business management situation aggravate majority service due uncertain demand personalized requirement make difficult plan assign productive capacity overstaffing imply extra cost insufficient capacity imply low level attention customer need therefore lack perceive quality present article tackle problem present model enable minimum staffing easily determine take account historical staffing datum associate quality datum minimum recommend workload calculate function theoretical staff need accord standard time model apply two real casesjatsp,0.5066666666666667,0.18666666666666668,0.24,0.02666666666666667,75.0,1.0,0.0,0.0,0.0
Information Technology,Data Management,Quantitative,Data Wrangling and Management in R,"<jats:p>
            This tutorial explores how scholars can organize 'tidy' data, understand R packages to manipulate data, and conduct basic data analysis.
          </jats:p>",https://doi.org/10.46430/phen0063,CrossRef,datum wrangling management,jatsp tutorial explore scholar organize tidy datum understand package manipulate datum conduct basic data analysis jatsp,datum wrangling management jatsp tutorial explore scholar organize tidy datum understand package manipulate datum conduct basic data analysis jatsp,0.625,0.125,0.125,0.0,16.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Quantitative,Data Governance Evaluation of the Data Management Office at King Saud University based on the National Data Management Office standards,"<jats:p>This study aimed to investigate the implementation of data governance at the Data Management Office of King Saud University by examining the adoption of the strategic plan, implementation mechanisms, and compliance with data governance standards and controls established by the National Data Management Office (NDMO), the national regulatory and reference authority for data management and governance.Using a descriptive-analytical approach, a questionnaire was designed based on three dimensions: the strategic dimension, the executive dimension, and the challenges dimension. The study sample included all 15 employees of the Data Management Office at King Saud University. The data were analyzed using IBM SPSS Modeler statistical software.The results of the study at the level of the main dimensions showed that the strategic dimension achieved the highest arithmetic mean (4.51) with a very high degree of compliance, followed by the executive dimension (3.69) with a high degree of compliance, and finally, the challenges dimension obtained a medium degree with an average of (3.05).The study revealed that the lack of data unification and its inconsistency across university departments, as well as the scarcity of financial resources that limit the improvement of the technological infrastructure at the Data Management Office, represent the most important challenges facing the implementation mechanisms of data governance at the Data Management Office at King Saud University.The researcher recommends the necessity of creating a clear framework for cooperation to define roles, responsibilities, and joint operations between the university colleges and the Data Management Office regarding data circulation, and strengthening cooperation with external parties with expertise in the field of data governance to improve implementation processes.</jats:p>",https://doi.org/10.52783/jisem.v10i10s.1530,CrossRef,datum governance evaluation data management office king saud university base national data management office standard,jatspthis study aim investigate implementation datum governance data management office king saud university examine adoption strategic plan implementation mechanism compliance data governance standard control establish national data management office ndmo national regulatory reference authority datum management governanceuse descriptiveanalytical approach questionnaire design base three dimension strategic dimension executive dimension challenge dimension study sample include employee data management office king saud university datum analyze use ibm spss modeler statistical softwarethe result study level main dimension show strategic dimension achieve high arithmetic mean high degree compliance follow executive dimension high degree compliance finally challenge dimension obtain medium degree average study reveal lack data unification inconsistency across university department well scarcity financial resource limit improvement technological infrastructure data management office represent important challenge face implementation mechanism datum governance data management office king saud universitythe researcher recommend necessity create clear framework cooperation define role responsibility joint operation university college data management office regard datum circulation strengthen cooperation external party expertise field datum governance improve implementation processesjatsp,datum governance evaluation data management office king saud university base national data management office standard jatspthis study aim investigate implementation datum governance data management office king saud university examine adoption strategic plan implementation mechanism compliance data governance standard control establish national data management office ndmo national regulatory reference authority datum management governanceuse descriptiveanalytical approach questionnaire design base three dimension strategic dimension executive dimension challenge dimension study sample include employee data management office king saud university datum analyze use ibm spss modeler statistical softwarethe result study level main dimension show strategic dimension achieve high arithmetic mean high degree compliance follow executive dimension high degree compliance finally challenge dimension obtain medium degree average study reveal lack data unification inconsistency across university department well scarcity financial resource limit improvement technological infrastructure data management office represent important challenge face implementation mechanism datum governance data management office king saud universitythe researcher recommend necessity create clear framework cooperation define role responsibility joint operation university college data management office regard datum circulation strengthen cooperation external party expertise field datum governance improve implementation processesjatsp,0.6086956521739131,0.09316770186335403,0.15527950310559005,0.006211180124223602,161.0,2.0,0.0,0.0,0.0
Information Technology,Data Management,Quantitative,Construction of financial data management and analysis system based on big data,"<jats:p>To solve financial data management, the author proposes research on the framework of big data analysis system. In the activities of various enterprises, massive high-frequency data will be generated, and these data are often characterized by infinity, suddenness, disorder, and volatility. Due to the above characteristics of the financial data related to the production activities of the enterprise, the financial data of the enterprise is often different from the actual situation, and the access is not standardized. To solve the above problems, it is necessary to improve the efficiency of enterprise financial management. With the application of big data in the enterprise industry as the background, the author builds a big data-based enterprise financial data analysis system, the construction of the financial data analysis system of electric enterprises is described from three aspects: big data storage, big data preprocessing and financial sharing center construction, to help enterprises improve the accuracy of financial data and the efficiency of financial management.</jats:p>",https://doi.org/10.54691/bcpbm.v37i.3617,CrossRef,construction financial datum management analysis system base big datum,jatspto solve financial datum management author propose research framework big datum analysis system activity various enterprise massive highfrequency datum generate datum often characterize infinity suddenness disorder volatility due characteristic financial datum relate production activity enterprise financial datum enterprise often different actual situation access standardize solve problem necessary improve efficiency enterprise financial management application big datum enterprise industry background author build big database enterprise financial datum analysis system construction financial datum analysis system electric enterprise describe three aspect big datum storage big datum preprocessing financial sharing center construction help enterprise improve accuracy financial datum efficiency financial managementjatsp,construction financial datum management analysis system base big datum jatspto solve financial datum management author propose research framework big datum analysis system activity various enterprise massive highfrequency datum generate datum often characterize infinity suddenness disorder volatility due characteristic financial datum relate production activity enterprise financial datum enterprise often different actual situation access standardize solve problem necessary improve efficiency enterprise financial management application big datum enterprise industry background author build big database enterprise financial datum analysis system construction financial datum analysis system electric enterprise describe three aspect big datum storage big datum preprocessing financial sharing center construction help enterprise improve accuracy financial datum efficiency financial managementjatsp,0.5833333333333334,0.125,0.23958333333333334,0.020833333333333332,96.0,1.0,0.0,0.0,0.0
Information Technology,Data Management,Quantitative,Data literacy and management of research data – a prerequisite for the sharing of research data,"<jats:sec><jats:title content-type=""abstract-subheading"">Purpose</jats:title><jats:p>The purpose of this paper is to investigate the knowledge and attitude about research data management, the use of data management methods and the perceived need for support, in relation to participants’ field of research.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Design/methodology/approach</jats:title><jats:p>This is a quantitative study. Data were collected by an email survey and sent to 792 academic researchers and doctoral students. Total response rate was 18% (<jats:italic>N</jats:italic> = 139). The measurement instrument consisted of six sets of questions: about data management plans, the assignment of additional information to research data, about metadata, standard file naming systems, training at data management methods and the storing of research data.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Findings</jats:title><jats:p>The main finding is that knowledge about the procedures of data management is limited, and data management is not a normal practice in the researcher's work. They were, however, in general, of the opinion that the university should take the lead by recommending and offering access to the necessary tools of data management. Taken together, the results indicate that there is an urgent need to increase the researcher's understanding of the importance of data management that is based on professional knowledge and to provide them with resources and training that enables them to make effective and productive use of data management methods.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Research limitations/implications</jats:title><jats:p>The survey was sent to all members of the population but not a sample of it. Because of the response rate, the results cannot be generalized to all researchers at the university. Nevertheless, the findings may provide an important understanding about their research data procedures, in particular what characterizes their knowledge about data management and attitude towards it.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Practical implications</jats:title><jats:p>Awareness of these issues is essential for information specialists at academic libraries, together with other units within the universities, to be able to design infrastructures and develop services that suit the needs of the research community. The findings can be used, to develop data policies and services, based on professional knowledge of best practices and recognized standards that assist the research community at data management.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Originality/value</jats:title><jats:p>The study contributes to the existing literature about research data management by examining the results by participants’ field of research. Recognition of the issues is critical in order for information specialists in collaboration with universities to design relevant infrastructures and services for academics and doctoral students that can promote their research data management.</jats:p></jats:sec>",https://doi.org/10.1108/ajim-04-2020-0110,CrossRef,datum literacy management research datum prerequisite sharing research datum,jatssecjatstitle contenttypeabstractsubheadingpurposejatstitlejatspthe purpose paper investigate knowledge attitude research datum management use datum management method perceive need support relation participant field researchjatspjatssecjatssecjatstitle contenttypeabstractsubheadingdesignmethodologyapproachjatstitlejatspthis quantitative study datum collect email survey send academic researcher doctoral student total response rate jatsitalicnjatsitalic measurement instrument consist six set question data management plan assignment additional information research datum metadata standard file naming system training datum management method storing research datajatspjatssecjatssecjatstitle contenttypeabstractsubheadingfindingsjatstitlejatspthe main finding knowledge procedure datum management limited datum management normal practice researcher work however general opinion university take lead recommend offer access necessary tool datum management take together result indicate urgent need increase researcher understand importance datum management base professional knowledge provide resource training enable make effective productive use datum management methodsjatspjatssecjatssecjatstitle contenttypeabstractsubheadingresearch limitationsimplicationsjatstitlejatspthe survey send member population sample response rate result generalize researcher university nevertheless finding may provide important understanding research data procedure particular characterize knowledge data management attitude towards itjatspjatssecjatssecjatstitle contenttypeabstractsubheadingpractical implicationsjatstitlejatspawareness issue essential information specialist academic library together unit within university able design infrastructure develop service suit need research community finding use develop data policy service base professional knowledge good practice recognize standard assist research community datum managementjatspjatssecjatssecjatstitle contenttypeabstractsubheadingoriginalityvaluejatstitlejatspthe study contribute exist literature research datum management examine result participant field research recognition issue critical order information specialist collaboration university design relevant infrastructure service academic doctoral student promote research datum managementjatspjatssec,datum literacy management research datum prerequisite sharing research datum jatssecjatstitle contenttypeabstractsubheadingpurposejatstitlejatspthe purpose paper investigate knowledge attitude research datum management use datum management method perceive need support relation participant field researchjatspjatssecjatssecjatstitle contenttypeabstractsubheadingdesignmethodologyapproachjatstitlejatspthis quantitative study datum collect email survey send academic researcher doctoral student total response rate jatsitalicnjatsitalic measurement instrument consist six set question data management plan assignment additional information research datum metadata standard file naming system training datum management method storing research datajatspjatssecjatssecjatstitle contenttypeabstractsubheadingfindingsjatstitlejatspthe main finding knowledge procedure datum management limited datum management normal practice researcher work however general opinion university take lead recommend offer access necessary tool datum management take together result indicate urgent need increase researcher understand importance datum management base professional knowledge provide resource training enable make effective productive use datum management methodsjatspjatssecjatssecjatstitle contenttypeabstractsubheadingresearch limitationsimplicationsjatstitlejatspthe survey send member population sample response rate result generalize researcher university nevertheless finding may provide important understanding research data procedure particular characterize knowledge data management attitude towards itjatspjatssecjatssecjatstitle contenttypeabstractsubheadingpractical implicationsjatstitlejatspawareness issue essential information specialist academic library together unit within university able design infrastructure develop service suit need research community finding use develop data policy service base professional knowledge good practice recognize standard assist research community datum managementjatspjatssecjatssecjatstitle contenttypeabstractsubheadingoriginalityvaluejatstitlejatspthe study contribute exist literature research datum management examine result participant field research recognition issue critical order information specialist collaboration university design relevant infrastructure service academic doctoral student promote research datum managementjatspjatssec,0.5944700460829493,0.12442396313364056,0.1336405529953917,0.018433179723502304,217.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Quantitative,POURQUOI MANAGEMENT &amp; DATA SCIENCE ABANDONNE L’ÉVALUATION EN DOUBLE AVEUGLE ?,"<jats:p>La globalisation du secteur académique, conjuguée à une accélération sans précédent de la transformation digitale, implique de repenser en profondeur le rôle des revues scientifiques (Mamavi et Zerbib, 2020). C’est en tout cas la conviction de Management &amp; Data Science, une plateforme ouverte de création et de diffusion de la connaissance sur le thème de la transformation digitale. Management &amp; Data Science offre une alternative concrète à la logique du “publish or perish” (Mamavi et Zerbib, 2019) en permettant une reconnaissance de nos auteurs via les altmetrics. La ligne éditoriale de notre revue défend un positionnement fondé sur la rigueur, la pertinence, la vitesse et l'impact alternatif. Management &amp; Data Science estime qu'une étude peut être qualifiée de scientifique dès lors qu'elle répond à au moins deux critères fondamentaux : la transparence et la reproductibilité. Or, le double aveugle ne nous semble pas ici constituer un moyen incontournable pour évaluer ces deux critères.</jats:p>",https://doi.org/10.36863/mds.a.16285,CrossRef,pourquoi management amp datum science abandonne double aveugle,jatspla globalisation secteur académique conjuguée une accélération san précédent transformation digitale implique repenser profondeur rôle des revue scientifique mamavi zerbib tout cas conviction management amp datum science une plateforme ouverte création diffusion connaissance sur thème transformation digitale management amp datum science offre une alternative concrète logique publish perish mamavi zerbib permettant une reconnaissance nos auteur via les altmetric ligne éditoriale notre revue défend positionnement fondé sur rigueur pertinence vitesse limpact alternatif management amp datum science estime quune étude peut être qualifiée scientifique dès lor quelle répond moins deux critères fondamentaux transparence reproductibilité double aveugle nous semble pas ici constituer moyen incontournable pour évaluer deux critèresjatsp,pourquoi management amp datum science abandonne double aveugle jatspla globalisation secteur académique conjuguée une accélération san précédent transformation digitale implique repenser profondeur rôle des revue scientifique mamavi zerbib tout cas conviction management amp datum science une plateforme ouverte création diffusion connaissance sur thème transformation digitale management amp datum science offre une alternative concrète logique publish perish mamavi zerbib permettant une reconnaissance nos auteur via les altmetric ligne éditoriale notre revue défend positionnement fondé sur rigueur pertinence vitesse limpact alternatif management amp datum science estime quune étude peut être qualifiée scientifique dès lor quelle répond moins deux critères fondamentaux transparence reproductibilité double aveugle nous semble pas ici constituer moyen incontournable pour évaluer deux critèresjatsp,0.24761904761904763,0.01904761904761905,0.05714285714285714,0.0,105.0,4.0,1.0,0.0,3.0
Information Technology,Data Management,Qualitative,Fitting random cash management models to data,"Organizations use cash management models to control balances to both avoid
overdrafts and obtain a profit from short-term investments. Most management
models are based on control bounds which are derived from the assumption of a
particular cash flow probability distribution. In this paper, we relax this
strong assumption to fit cash management models to data by means of stochastic
and linear programming. We also introduce ensembles of random cash management
models which are built by randomly selecting a subsequence of the original cash
flow data set. We illustrate our approach by means of a real case study showing
that a small random sample of data is enough to fit sufficiently good
bound-based models.",http://arxiv.org/abs/2401.08548v1,arXiv,fitting random cash management model datum,organization use cash management model control balance avoid overdraft obtain profit shortterm investment management model base control bound derive assumption particular cash flow probability distribution paper relax strong assumption fit cash management model datum mean stochastic linear programming also introduce ensemble random cash management model build randomly select subsequence original cash flow datum set illustrate approach mean real case study show small random sample datum enough fit sufficiently good boundbase model,fitting random cash management model datum organization use cash management model control balance avoid overdraft obtain profit shortterm investment management model base control bound derive assumption particular cash flow probability distribution paper relax strong assumption fit cash management model datum mean stochastic linear programming also introduce ensemble random cash management model build randomly select subsequence original cash flow datum set illustrate approach mean real case study show small random sample datum enough fit sufficiently good boundbase model,0.5070422535211268,0.16901408450704225,0.2112676056338028,0.056338028169014086,71.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Qualitative,UDBMS: Road to Unification for Multi-model Data Management,"A traditional database systems is organized around a single data model that
determines how data can be organized, stored and manipulated. But the vision of
this paper is to develop new principles and techniques to manage multiple data
models against a single, integrated backend. For example, semi-structured,
graph and relational models are examples of data models that may be supported
by a new system. Having a single data platform for managing both
well-structured data and NoSQL data is beneficial to users; this approach
significantly reduces integration, migration, development, maintenance and
operational issues. The problem is challenging: the existing database
principles mainly work for a single model and the research on multi-model data
management is still at an early stage. In this paper, we envision a UDBMS
(Unified Database Management System) for multi-model data management in one
platform. UDBMS will provide several new features such as unified data model
and flexible schema, unified query processing, unified index structure and
cross-model transaction guarantees. We discuss our vision as well as present
multiple research challenges that we need to address.",http://arxiv.org/abs/1612.08050v1,arXiv,udbms road unification multimodel datum management,traditional database system organize around single data model determine datum organize store manipulated vision paper develop new principle technique manage multiple datum model single integrate backend example semistructure graph relational model example data model may support new system single data platform manage wellstructure datum nosql datum beneficial user approach significantly reduce integration migration development maintenance operational issue problem challenge exist database principle mainly work single model research multimodel data management still early stage paper envision udbms unify database management system multimodel datum management one platform udbms provide several new feature unified data model flexible schema unify query process unified index structure crossmodel transaction guarantee discuss vision well present multiple research challenge need address,udbms road unification multimodel datum management traditional database system organize around single data model determine datum organize store manipulated vision paper develop new principle technique manage multiple datum model single integrate backend example semistructure graph relational model example data model may support new system single data platform manage wellstructure datum nosql datum beneficial user approach significantly reduce integration migration development maintenance operational issue problem challenge exist database principle mainly work single model research multimodel data management still early stage paper envision udbms unify database management system multimodel datum management one platform udbms provide several new feature unified data model flexible schema unify query process unified index structure crossmodel transaction guarantee discuss vision well present multiple research challenge need address,0.5132743362831859,0.1504424778761062,0.1504424778761062,0.035398230088495575,113.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Qualitative,"Legitimization of Data Quality Practices in Health Management
  Information Systems Using DHIS2. Case of Malawi","Medical doctors consider data quality management a secondary priority when
delivering health care. Medical practitioners find data quality management
practices intrusive to their operations. Using Health Management Information
System (HMIS) that uses DHIS2 platform, our qualitative case study establishes
that isomorphism leads to legitimization of data quality management practices
among health practitioners and subsequently data quality. This case study
employed the methods of observation, semi structured interviews and review of
artefacts to explore how through isomorphic processes data quality management
practices are legitimized among the stakeholders. Data was collected from
Ministry of Health's (Malawi) HMIS Technical Working Group members in Lilongwe
and from medical practitioners and data clerks in Thyolo district. From the
findings we noted that mimetic isomorphism led to moral and pragmatic
legitimacy while and normative isomorphism led to cognitive legitimacy within
the HMIS structure and helped to attain correctness and timeliness of the data
and reports respectively. Through this understanding we firstly contribute to
literature on organizational issues in IS research. Secondly, we contribute to
practice as we motivate health service managers to capitalize on isomorphic
forces to help legitimization of data quality management practices among health
practitioners.",http://arxiv.org/abs/2108.09942v1,arXiv,legitimization datum quality practice health management information system use dhis case malawi,medical doctor consider datum quality management secondary priority deliver health care medical practitioner find datum quality management practice intrusive operation use health management information system hmis use dhis platform qualitative case study establishe isomorphism lead legitimization datum quality management practice among health practitioner subsequently datum quality case study employ method observation semi structured interview review artefact explore isomorphic process datum quality management practice legitimize among stakeholder datum collect ministry healths malawi hmis technical working group member lilongwe medical practitioner data clerk thyolo district finding note mimetic isomorphism lead moral pragmatic legitimacy normative isomorphism lead cognitive legitimacy within hmis structure help attain correctness timeliness datum report respectively understanding firstly contribute literature organizational issue research secondly contribute practice motivate health service manager capitalize isomorphic force help legitimization datum quality management practice among health practitioner,legitimization datum quality practice health management information system use dhis case malawi medical doctor consider datum quality management secondary priority deliver health care medical practitioner find datum quality management practice intrusive operation use health management information system hmis use dhis platform qualitative case study establishe isomorphism lead legitimization datum quality management practice among health practitioner subsequently datum quality case study employ method observation semi structured interview review artefact explore isomorphic process datum quality management practice legitimize among stakeholder datum collect ministry healths malawi hmis technical working group member lilongwe medical practitioner data clerk thyolo district finding note mimetic isomorphism lead moral pragmatic legitimacy normative isomorphism lead cognitive legitimacy within hmis structure help attain correctness timeliness datum report respectively understanding firstly contribute literature organizational issue research secondly contribute practice motivate health service manager capitalize isomorphic force help legitimization datum quality management practice among health practitioner,0.5909090909090909,0.13636363636363635,0.11363636363636363,0.030303030303030304,132.0,1.0,0.0,0.0,2.0
Information Technology,Data Management,Qualitative,"Data Management in Integrated Research Institutes: Undertaking a Review
  of Research Data Management at the Rosalind Franklin Institute","Managing Research Data, and making it available for use/reuse by others in
line with the UKRI Concordat on Open Research Data and FAIR principles, is a
major issue for research-intensive organisations. In this case study we outline
an institute-wide review of data management in practice, carried out at the
Rosalind Franklin Institute (The Franklin) in partnership with external
consultants, Curlew Research, in March 2022. We aim to describe the processes
involved in undertaking a review of the services already in place that support
good practice in managing research data, and their uptake, with an emphasis on
the methodology used. We conducted interviews with scientific Theme Leads which
set the scope for the Data Management Workshops subsequently held with
Researchers. Workshops were valuable in both providing actionable insights for
data management and in priming the audience for future discussions. The final
report produced for The Franklin, summarising results of the analysis, provides
a snapshot of current practice for the Institute, highlighting what is working
well and where improvements might be made, and provides a benchmark against
which development can be measured in the coming years. The Review will continue
to be conducted on an annual basis, reflecting changes in a fast-moving area
and enabling an agile approach to research data management.",http://arxiv.org/abs/2211.07284v2,arXiv,datum management integrate research institute undertake review research datum management rosalind franklin institute,manage research datum make available usereuse line ukri concordat open research datum fair principle major issue researchintensive organisation case study outline institutewide review datum management practice carry rosalind franklin institute franklin partnership external consultant curlew research march aim describe process involve undertake review service already place support good practice manage research datum uptake emphasis methodology use conduct interview scientific theme lead set scope data management workshop subsequently hold researcher workshop valuable provide actionable insight data management prime audience future discussion final report produce franklin summarise result analysis provide snapshot current practice institute highlight work well improvement might make provide benchmark development measure come year review continue conduct annual basis reflect change fastmoving area enable agile approach research datum management,datum management integrate research institute undertake review research datum management rosalind franklin institute manage research datum make available usereuse line ukri concordat open research datum fair principle major issue researchintensive organisation case study outline institutewide review datum management practice carry rosalind franklin institute franklin partnership external consultant curlew research march aim describe process involve undertake review service already place support good practice manage research datum uptake emphasis methodology use conduct interview scientific theme lead set scope data management workshop subsequently hold researcher workshop valuable provide actionable insight data management prime audience future discussion final report produce franklin summarise result analysis provide snapshot current practice institute highlight work well improvement might make provide benchmark development measure come year review continue conduct annual basis reflect change fastmoving area enable agile approach research datum management,0.5126050420168067,0.18487394957983194,0.15126050420168066,0.025210084033613446,119.0,1.0,0.0,1.0,0.0
Information Technology,Data Management,Qualitative,"Computer Application Research based on Chinese Human Resources and
  Network Information Security Technology Management and Analysis In Chinese
  Universities","This study investigates the current state of computer network security and
human resource management within Chinese universities, emphasizing the growing
importance of safeguarding digital infrastructures. To support the analysis,
interviews were conducted with managers from two leading Chinese cybersecurity
firms and the qualitative data obtained was carefully analyzed to extract key
insights and conclusions.",http://arxiv.org/abs/2411.00474v1,arXiv,computer application research base chinese human resource network information security technology management analysis chinese university,study investigate current state computer network security human resource management within chinese university emphasize grow importance safeguard digital infrastructure support analysis interview conduct manager two lead chinese cybersecurity firm qualitative datum obtain carefully analyze extract key insight conclusion,computer application research base chinese human resource network information security technology management analysis chinese university study investigate current state computer network security human resource management within chinese university emphasize grow importance safeguard digital infrastructure support analysis interview conduct manager two lead chinese cybersecurity firm qualitative datum obtain carefully analyze extract key insight conclusion,0.5526315789473685,0.15789473684210525,0.18421052631578946,0.02631578947368421,38.0,1.0,0.0,0.0,0.0
Information Technology,Data Management,Mixed Methods,Integrated data management: New perspectives for management control,"<jats:p>The purpose of this special issue is to contribute to the international debate on novel approaches to corporate data management for the improvement of man-agement control systems. The theme embraces the interdisciplinary relationships that management controls and the accounting function that it, increasingly, should have with other disciplines. These relationships are permeated by both quantitative and qualitative approaches. Quantitative models include those created through data science and those that refer to mathematics, statistics, and information tech-nology. Moreover, corporate data management models combining qualitative and quantitative approaches are explored and discussed within disciplinary areas that, due to their consolidated history, are close to management control: e.g., legal, soci-ological, historical and other humanities areas. This theme embraces not only business data management but also knowledge management; it is not only about internal (accounting and non-accounting) data, but also about external data of a statistical, economic, and social nature, which are of interest from different disci-plinary perspectives concerning the integrated management of accounting data and Big Data. With the development of new technologies, such as the ‘Internet of Things', and the increasingly extensive applications of blockchain, social net-works, and mobile devices, organizations are generating huge volumes of data in different formats much faster than in the past. In this sense, big data analytics techniques present opportunities to improve decision-making processes of both a strategic and an operational nature, due to their ability to extract knowledge from data, to facilitate problem solving, and to favor predictive and prescriptive ap-proaches to business phenomena. From an organizational point of view, it is im-portant to analyze the impact of Big Data on the professional profiles of actors typically involved in accounting and management control processes.</jats:p>",https://doi.org/10.3280/maco2022-002-s1001,CrossRef,integrate datum management new perspective management control,jatspthe purpose special issue contribute international debate novel approach corporate data management improvement management control system theme embrace interdisciplinary relationship management control accounting function increasingly discipline relationship permeate quantitative qualitative approach quantitative model include create data science refer mathematics statistic information technology moreover corporate data management model combine qualitative quantitative approach explore discuss within disciplinary area due consolidated history close management control legal sociological historical humanity area theme embrace business datum management also knowledge management internal accounting nonaccounting datum also external datum statistical economic social nature interest different disciplinary perspective concern integrate management accounting datum big datum development new technology internet thing increasingly extensive application blockchain social network mobile device organization generate huge volume datum different format much fast past sense big data analytic technique present opportunity improve decisionmake process strategic operational nature due ability extract knowledge datum facilitate problem solve favor predictive prescriptive approach business phenomenon organizational point view important analyze impact big datum professional profile actor typically involve accounting management control processesjatsp,integrate datum management new perspective management control jatspthe purpose special issue contribute international debate novel approach corporate data management improvement management control system theme embrace interdisciplinary relationship management control accounting function increasingly discipline relationship permeate quantitative qualitative approach quantitative model include create data science refer mathematics statistic information technology moreover corporate data management model combine qualitative quantitative approach explore discuss within disciplinary area due consolidated history close management control legal sociological historical humanity area theme embrace business datum management also knowledge management internal accounting nonaccounting datum also external datum statistical economic social nature interest different disciplinary perspective concern integrate management accounting datum big datum development new technology internet thing increasingly extensive application blockchain social network mobile device organization generate huge volume datum different format much fast past sense big data analytic technique present opportunity improve decisionmake process strategic operational nature due ability extract knowledge datum facilitate problem solve favor predictive prescriptive approach business phenomenon organizational point view important analyze impact big datum professional profile actor typically involve accounting management control processesjatsp,0.5182926829268293,0.09146341463414634,0.2682926829268293,0.042682926829268296,164.0,0.0,0.0,0.0,1.0
Information Technology,Data Management,Mixed Methods,DATA ANALYSIS OF METROLOGICAL DATA,"<jats:p>This project report is set to give an interactive visualization and analytical presentation for Meteorological records in Finland. These Meteorological records Data of Finland is recorded by way of integrating the three current infrastructures for numerical weather prediction, observational information and satellite tv for pc image processing and this is recorded. The Meteorological data used in the study consists of near- floor atmospheric elements including wind direction, apparent temperature, cloud layer(s), ceiling peak, visibility, current weather, wind velocity, cloud cowl and precipitation amount and so on. The data consists of hourly recorded data for the past ten years of Finland from 2006-04- 01 at time 00:00:00.000 to 2016-09-09 at time 23:00:00.000. The analysis had been performed out for 2-m floor temperature. Through this analysis, all the valuable insights into the changing weather patterns and environmental conditions in Finland are analyzed and presented in an interactive visualization, providing a solid foundation for understanding and addressing the impacts of Global Warming in the region. This project main objective is to show the complete analysis of the influences of the Global Warming on the Apparent temperature &amp; humidity in Finland over the course of 10 years from 2006 to 2016.     Keywords — Data Analysis, Data Visualization, Meteorological Data, Climate Change, Global Warning, Apparent Temperature, Humidity</jats:p>",https://doi.org/10.55041/ijsrem34399,CrossRef,datum analysis metrological datum,jatspthis project report set give interactive visualization analytical presentation meteorological record finland meteorological record datum finland record way integrate three current infrastructure numerical weather prediction observational information satellite image processing record meteorological datum use study consist near floor atmospheric element include wind direction apparent temperature cloud layer ceile peak visibility current weather wind velocity cloud cowl precipitation amount data consist hourly record datum past ten year finland time time analysis perform floor temperature analysis valuable insight change weather pattern environmental condition finland analyze present interactive visualization provide solid foundation understanding address impact global warming region project main objective show complete analysis influence global warming apparent temperature amp humidity finland course year keyword datum analysis datum visualization meteorological datum climate change global warning apparent temperature humidityjatsp,datum analysis metrological datum jatspthis project report set give interactive visualization analytical presentation meteorological record finland meteorological record datum finland record way integrate three current infrastructure numerical weather prediction observational information satellite image processing record meteorological datum use study consist near floor atmospheric element include wind direction apparent temperature cloud layer ceile peak visibility current weather wind velocity cloud cowl precipitation amount data consist hourly record datum past ten year finland time time analysis perform floor temperature analysis valuable insight change weather pattern environmental condition finland analyze present interactive visualization provide solid foundation understanding address impact global warming region project main objective show complete analysis influence global warming apparent temperature amp humidity finland course year keyword datum analysis datum visualization meteorological datum climate change global warning apparent temperature humidityjatsp,0.608,0.072,0.2,0.0,125.0,1.0,3.0,2.0,0.0
Information Technology,Data Management,Mixed Methods,Data Shuffling—A New Masking Approach for Numerical Data,"<jats:p> This study discusses a new procedure for masking confidential numerical data—a procedure called data shuffling—in which the values of the confidential variables are “shuffled” among observations. The shuffled data provides a high level of data utility and minimizes the risk of disclosure. From a practical perspective, data shuffling overcomes reservations about using perturbed or modified confidential data because it retains all the desirable properties of perturbation methods and performs better than other masking techniques in both data utility and disclosure risk. In addition, data shuffling can be implemented using only rank-order data, and thus provides a nonparametric method for masking. We illustrate the applicability of data shuffling for small and large data sets. </jats:p>",https://doi.org/10.1287/mnsc.1050.0503,CrossRef,datum shuffle new masking approach numerical datum,jatsp study discuss new procedure mask confidential numerical datum procedure call datum shuffle value confidential variable shuffle among observation shuffled datum provide high level datum utility minimize risk disclosure practical perspective datum shuffle overcomes reservation use perturb modify confidential datum retain desirable property perturbation method perform well mask technique datum utility disclosure risk addition datum shuffle implement use rankorder datum thus provide nonparametric method mask illustrate applicability datum shuffle small large datum set jatsp,datum shuffle new masking approach numerical datum jatsp study discuss new procedure mask confidential numerical datum procedure call datum shuffle value confidential variable shuffle among observation shuffled datum provide high level datum utility minimize risk disclosure practical perspective datum shuffle overcomes reservation use perturb modify confidential datum retain desirable property perturbation method perform well mask technique datum utility disclosure risk addition datum shuffle implement use rankorder datum thus provide nonparametric method mask illustrate applicability datum shuffle small large datum set jatsp,0.5945945945945946,0.12162162162162163,0.12162162162162163,0.02702702702702703,74.0,1.0,0.0,0.0,0.0
Information Technology,Data Management,Mixed Methods,Management trends and implementation of AI in university management,"<jats:p>The objective of this article was to explore managerial trends and the implementation of artificial intelligence in university management, with a particular focus on the Latin American context. To this end, a mixed study was designed, operationalized through a documentary review with bibliometric procedures, a qualitative thematic analysis, a triangulation system, and an integration of data supported by external sources. The results were organized into five management strategies, three emerging trends, five recommendations for managers, and five main themes. These trends reflect significant progress, but also pose challenges, especially in regions with structural inequalities and resource constraints. The data analyzed indicate the need for a balanced approach that combines technological innovation with ethical and social considerations. Furthermore, the findings emphasize the importance of international collaboration and local capacity building to ensure equitable and sustainable implementation of AI. It is concluded that it is cardinal to underline the potential of AI to transform higher education, provided that technical, ethical, and social challenges are addressed comprehensively.</jats:p>",https://doi.org/10.56294/dm2025866,CrossRef,management trend implementation university management,jatspthe objective article explore managerial trend implementation artificial intelligence university management particular focus latin american context end mixed study design operationalize documentary review bibliometric procedure qualitative thematic analysis triangulation system integration datum support external source result organize five management strategy three emerge trend five recommendation manager five main theme trend reflect significant progress also pose challenge especially region structural inequality resource constraint datum analyze indicate need balanced approach combine technological innovation ethical social consideration furthermore finding emphasize importance international collaboration local capacity build ensure equitable sustainable implementation conclude cardinal underline potential transform high education provide technical ethical social challenge address comprehensivelyjatsp,management trend implementation university management jatspthe objective article explore managerial trend implementation artificial intelligence university management particular focus latin american context end mixed study design operationalize documentary review bibliometric procedure qualitative thematic analysis triangulation system integration datum support external source result organize five management strategy three emerge trend five recommendation manager five main theme trend reflect significant progress also pose challenge especially region structural inequality resource constraint datum analyze indicate need balanced approach combine technological innovation ethical social consideration furthermore finding emphasize importance international collaboration local capacity build ensure equitable sustainable implementation conclude cardinal underline potential transform high education provide technical ethical social challenge address comprehensivelyjatsp,0.48514851485148514,0.1188118811881188,0.27722772277227725,0.0297029702970297,101.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Mixed Methods,Assessing Knowledge Management Readiness to Improve Data Quality by Prevent Incorrect Data Input on ERP System in Component Rebuild Center PT Kalcoal,"<jats:p>To fulfil the demand of availability component for supporting the mining operation at PT Kalcoal. Recondition component daily activity of recondition is entanglement from one process to another until the end of process. For transform digitalization, recondition component activity will using Enterprise Resource Planning (ERP) in every process.  The purpose of this study is to understand the level of knowledge management readiness in the component rebuild center in the Implementation of the ERP work system, to understand the strengths and areas for improvement for Knowledge Management, and to find tools that can be used to implement Knowledge Management in the component rebuild center.  This research using quantitative method, collected through a questionnaire. Furthermore, qualitative data was used to enrich the primary data collected through focus group discussions. By using APO as tools of knowledge management readiness, the results showed that the component rebuild center is still in the expansion phase, where knowledge management efforts are present in the core activity process and the company sees the benefits of knowledge sharing. The component rebuild center can further develop itself by using people as its accelerator. Having committed change groups and leaders will create a culture of knowledge sharing that can be followed by all lines of business in the company. In order for employees to have a single source of knowledge, it is important to create a knowledge management tool that can be done by building a new portal that can be accessed by all employee users. For the source of knowledge to always align the needs and developments of the company, it is necessary to have the ability to grow and store information safely and freely for employees so that information is always updated and well-maintained.</jats:p>",https://doi.org/10.47191/ijcsrr/v7-i5-100,CrossRef,assess knowledge management readiness improve datum quality prevent incorrect datum input erp system component rebuild center kalcoal,jatspto fulfil demand availability component support mining operation kalcoal recondition component daily activity recondition entanglement one process another end process transform digitalization recondition component activity use enterprise resource planning erp every process purpose study understand level knowledge management readiness component rebuild center implementation erp work system understand strength area improvement knowledge management find tool use implement knowledge management component rebuild center research use quantitative method collect questionnaire furthermore qualitative datum use enrich primary datum collect focus group discussion use apo tool knowledge management readiness result show component rebuild center still expansion phase knowledge management effort present core activity process company see benefit knowledge share component rebuild center far develop use people accelerator commit change group leader create culture knowledge sharing follow line business company order employee single source knowledge important create knowledge management tool build new portal access employee user source knowledge always align need development company necessary ability grow store information safely freely employee information always update wellmaintainedjatsp,assess knowledge management readiness improve datum quality prevent incorrect datum input erp system component rebuild center kalcoal jatspto fulfil demand availability component support mining operation kalcoal recondition component daily activity recondition entanglement one process another end process transform digitalization recondition component activity use enterprise resource planning erp every process purpose study understand level knowledge management readiness component rebuild center implementation erp work system understand strength area improvement knowledge management find tool use implement knowledge management component rebuild center research use quantitative method collect questionnaire furthermore qualitative datum use enrich primary datum collect focus group discussion use apo tool knowledge management readiness result show component rebuild center still expansion phase knowledge management effort present core activity process company see benefit knowledge share component rebuild center far develop use people accelerator commit change group leader create culture knowledge sharing follow line business company order employee single source knowledge important create knowledge management tool build new portal access employee user source knowledge always align need development company necessary ability grow store information safely freely employee information always update wellmaintainedjatsp,0.6981132075471698,0.1509433962264151,0.05660377358490566,0.050314465408805034,159.0,0.0,0.0,1.0,1.0
Information Technology,Data Management,Design and Development,Understanding management data systems for enterprise performance management,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>Managing enterprise performance is an important, yet a difficult process due to its complexity. The process involves monitoring the strategic focus of an enterprise, whose performance is measured from the analysis of data generated from a wide range of interrelated business activities performed at different levels within the enterprise. This study aims to investigate management data systems technologies in terms of how they are used and the issues that are related to their effective management within the broader context of enterprise performance management (EPM).</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>A range of recently published research literature on data warehousing, online analytic processing and EPM is reviewed to explore their current state, issues and challenges learned from their practice.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>The findings of the study are reported in two parts. The first part discusses the current business practices of these technologies, and the second part identifies and discusses the issues and challenges the business managers dealing with these technologies face for gaining competitive advantage for their businesses.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>The study findings are intended to assist the business managers to effectively understand the issues and technologies behind EPM implementation.</jats:p></jats:sec>",https://doi.org/10.1108/02635570610640988,CrossRef,understand management datum system enterprise performance management,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspmanage enterprise performance important yet difficult process due complexity process involve monitor strategic focus enterprise whose performance measure analysis datum generate wide range interrelated business activity perform different level within enterprise study aim investigate management datum system technology term use issue relate effective management within broad context enterprise performance management epmjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa range recently publish research literature datum warehouse online analytic processing epm review explore current state issue challenge learn practicejatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthe finding study report two part first part discuss current business practice technology second part identifie discuss issue challenge business manager deal technology face gain competitive advantage businessesjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe study finding intend assist business manager effectively understand issue technology behind epm implementationjatspjatssec,understand management datum system enterprise performance management jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspmanage enterprise performance important yet difficult process due complexity process involve monitor strategic focus enterprise whose performance measure analysis datum generate wide range interrelated business activity perform different level within enterprise study aim investigate management datum system technology term use issue relate effective management within broad context enterprise performance management epmjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspa range recently publish research literature datum warehouse online analytic processing epm review explore current state issue challenge learn practicejatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthe finding study report two part first part discuss current business practice technology second part identifie discuss issue challenge business manager deal technology face gain competitive advantage businessesjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthe study finding intend assist business manager effectively understand issue technology behind epm implementationjatspjatssec,0.6052631578947368,0.13157894736842105,0.14035087719298245,0.02631578947368421,114.0,1.0,0.0,0.0,0.0
Information Technology,Data Management,Design and Development,Need for Data Standardization and Infrastructure of Research Data Management to Promote Using Real-world Data,"<jats:p>Real-world data (RWD) have been increasingly used for regulatory decision-making and as a control group for new drug approval applications. RWD is also helpful in understanding information such as risk factors (e.g., pre-existing medical conditions, personal protective equipment, travel, contacts, smoking, and exposure to animals) and vaccination status for the coronavirus disease 2019 (COVID-19). The methodology of utilizing RWD is inconsistent across healthcare institutions. However, there are possible solutions to standardize RWD for clinical data use, which include the use of Clinical Data Interchange Standards Consortium (CDISC) standards, tools, and concepts. This study examines the availability of CDISC and other international standards for the utilization of RWD with concrete examples and presents the potential platform for implementation.
We consider the solution currently available to temporarily convert clinical data-warehouse (DWH) data into the Fast Healthcare Interoperability Resources (FHIR) format to comply with the CDISC standard. This approach would allow for converting institution-level standards to national standards as an interim solution until FHIR is supported, mapping national standards to international standards. We believe that the ideal research environment is a data platform that complies with national and international regulations related to RWD applications. Within such a platform, users can share data freely, rather than rely on a specific facility or vendor. Data platform developments are progressing in Japan and globally. In Japan, initiatives to use research data on research data platforms are being conducted. We are experimenting with implementing tools and knowledge shared by CDISC.</jats:p>",https://doi.org/10.47912/jscdm.210,CrossRef,need datum standardization infrastructure research datum management promote use realworld datum,jatsprealworld datum rwd increasingly use regulatory decisionmaking control group new drug approval application rwd also helpful understand information risk factor preexist medical condition personal protective equipment travel contact smoking exposure animal vaccination status coronavirus disease covid methodology utilize rwd inconsistent across healthcare institution however possible solution standardize rwd clinical datum use include use clinical datum interchange standard consortium cdisc standard tool concept study examine availability cdisc international standard utilization rwd concrete example present potential platform implementation consider solution currently available temporarily convert clinical datawarehouse dwh datum fast healthcare interoperability resource fhir format comply cdisc standard approach would allow convert institutionlevel standard national standard interim solution fhir support mapping national standard international standard believe ideal research environment data platform comply national international regulation relate rwd application within platform user share datum freely rather rely specific facility vendor data platform development progress japan globally japan initiative use research datum research datum platform conduct experiment implement tool knowledge share cdiscjatsp,need datum standardization infrastructure research datum management promote use realworld datum jatsprealworld datum rwd increasingly use regulatory decisionmaking control group new drug approval application rwd also helpful understand information risk factor preexist medical condition personal protective equipment travel contact smoking exposure animal vaccination status coronavirus disease covid methodology utilize rwd inconsistent across healthcare institution however possible solution standardize rwd clinical datum use include use clinical datum interchange standard consortium cdisc standard tool concept study examine availability cdisc international standard utilization rwd concrete example present potential platform implementation consider solution currently available temporarily convert clinical datawarehouse dwh datum fast healthcare interoperability resource fhir format comply cdisc standard approach would allow convert institutionlevel standard national standard interim solution fhir support mapping national standard international standard believe ideal research environment data platform comply national international regulation relate rwd application within platform user share datum freely rather rely specific facility vendor data platform development progress japan globally japan initiative use research datum research datum platform conduct experiment implement tool knowledge share cdiscjatsp,0.554140127388535,0.08280254777070063,0.20382165605095542,0.050955414012738856,157.0,0.0,2.0,0.0,0.0
Information Technology,Data Management,Design and Development,Data Modeling and Management in the Big Data Era,"<jats:p>CFX Inc, an e-commerce start-up based out of India, has built a large e-marketplace that allows sellers and buyers to transact online. The firm currently has 30,000 sellers and aims to have around 50,000 sellers by FY 2015–16. In order to provide best shopping experience to their growing customer base, the firm needs to collect, store and analyze different kinds of data and improve their customer shopping experience. It is in the process of identifying and designing suitable data management systems to sustain and manage their business growth. The management needs a concrete set of recommendations in terms of the nature of solution, choice of the database, a data model that suits CFX's requirements, cost-benefit trade-offs involved and implementation considerations.</jats:p>",https://doi.org/10.1108/case.iima.2020.000057,CrossRef,datum modeling management big datum era,jatspcfx inc ecommerce startup base india build large emarketplace allow seller buyer transact online firm currently seller aim around seller order provide good shopping experience grow customer base firm need collect store analyze different kind datum improve customer shopping experience process identify design suitable datum management system sustain manage business growth management need concrete set recommendation term nature solution choice database data model suit cfxs requirement costbenefit tradeoff involve implementation considerationsjatsp,datum modeling management big datum era jatspcfx inc ecommerce startup base india build large emarketplace allow seller buyer transact online firm currently seller aim around seller order provide good shopping experience grow customer base firm need collect store analyze different kind datum improve customer shopping experience process identify design suitable datum management system sustain manage business growth management need concrete set recommendation term nature solution choice database data model suit cfxs requirement costbenefit tradeoff involve implementation considerationsjatsp,0.6056338028169014,0.19718309859154928,0.07042253521126761,0.014084507042253521,35.5,1.0,1.0,0.0,0.0
Information Technology,Data Management,Design and Development,Towards an Enhanced Data- and Knowledge Management Capability: A Data Life Cycle Model Proposition for Integrated Vehicle Health Management,"<jats:p>The creation, capturing, using and sharing of knowledge is based on data. The rate of data creation, collection, and elicitation through wide range experiments, simulations and measurements is rapidly increasing within Integrated Vehicle Health Management (IVHM). In addition, Knowledge Management (KM), data abstraction, analyses, storage and accessibility challenges persist, resulting in loss of knowledge and increased costs. This growth in the creation of research data, algorithms, technical papers, reports and logs, requires both a strategy and tool to address these challenges. A Data Life Cycle Model (DLCM) ensures the efficient and effective abstraction and management of both data and knowledge outputs. IVHM which depend heavily on high-quality data to perform data-driven, model-based and hybrid computational analysis of asset health. IVHM Centre does not yet have a systematic and coherent approach to its data management. The absence of a DLCM means that valuable knowledge might be lost or is difficult to find. Data visualization is fragmented and done on a project by project basis leading to increased costs. There is insufficient algorithm documentation and communication for easy transition between subsequent researchers and personnel. A systematic review of DLCMs, frameworks, standards and process models pertaining to data- and KM in the context of IVHM, found that there is no DLCM that is consistent with IVHM data and knowledge management requirements. Specifically, there is a need to develop a DLCM based on Open System Architecture for Condition-Based Maintenance framework.</jats:p>",https://doi.org/10.36001/phmconf.2019.v11i1.842,CrossRef,towards enhance datum knowledge management capability data life cycle model proposition integrate vehicle health management,jatspthe creation capturing use sharing knowledge base datum rate data creation collection elicitation wide range experiment simulation measurement rapidly increase within integrate vehicle health management ivhm addition knowledge management datum abstraction analyse storage accessibility challenges persist result loss knowledge increase cost growth creation research datum algorithm technical paper report log require strategy tool address challenge data life cycle model dlcm ensure efficient effective abstraction management datum knowledge output ivhm depend heavily highquality datum perform datadriven modelbased hybrid computational analysis asset health ivhm centre yet systematic coherent approach data management absence dlcm mean valuable knowledge might lose difficult find datum visualization fragment project project basis lead increase cost insufficient algorithm documentation communication easy transition subsequent researcher personnel systematic review dlcms framework standard process model pertain datum context ivhm find dlcm consistent ivhm datum knowledge management requirement specifically need develop dlcm base open system architecture conditionbased maintenance frameworkjatsp,towards enhance datum knowledge management capability data life cycle model proposition integrate vehicle health management jatspthe creation capturing use sharing knowledge base datum rate data creation collection elicitation wide range experiment simulation measurement rapidly increase within integrate vehicle health management ivhm addition knowledge management datum abstraction analyse storage accessibility challenges persist result loss knowledge increase cost growth creation research datum algorithm technical paper report log require strategy tool address challenge data life cycle model dlcm ensure efficient effective abstraction management datum knowledge output ivhm depend heavily highquality datum perform datadriven modelbased hybrid computational analysis asset health ivhm centre yet systematic coherent approach data management absence dlcm mean valuable knowledge might lose difficult find datum visualization fragment project project basis lead increase cost insufficient algorithm documentation communication easy transition subsequent researcher personnel systematic review dlcms framework standard process model pertain datum context ivhm find dlcm consistent ivhm datum knowledge management requirement specifically need develop dlcm base open system architecture conditionbased maintenance frameworkjatsp,0.5958904109589042,0.1095890410958904,0.11643835616438356,0.02054794520547945,146.0,1.0,0.0,0.0,1.0
Information Technology,Data Management,Design and Development,Contextual Data-Integrated Newsvendor Solution with Operational Data Analytics (ODA),"<jats:p> We study the data-integrated newsvendor problem in which the random demand depends on a set of covariates. Observing from the solutions analyzed in the existing studies, we identify the equivariant class of operational statistics (i.e., the mapping from the demand and covariate data to the inventory decision) to develop the operational data analytics (ODA) framework for the contextual newsvendor problem. The equivariant property is intuitively appealing, and it is justified by the fact that, regardless of the sample size, no other decision rule can uniformly dominate the optimal operational statistic within the equivariant class. We also demonstrate that nonequivariant solutions can produce unstable empirical performance with limited samples, whereas equivariant solutions exhibit robustness. When the distribution family of the demand is known but the coefficients of the demand function are unknown, we can directly validate the decision performance of operational statistics within the equivariant class and derive the uniformly optimal solution. When the distribution family of the demand is unknown, we formulate the data integration model as a subclass of equivariant operational statistics, obtained through adaptively boosting some candidate solution. For decision validation, we project the validation data to the demand for the covariates of interests, and the projection is constructed by utilizing the structure of the candidate solution. We demonstrate the superior small-sample performance of adaptive boosting and establish the consistency of the boosted operational statistics. Our ODA formulation, building on the inherent characteristics of the contextual newsvendor problem, highlights the importance of understanding structural properties in data-integrated decision making. </jats:p><jats:p> This paper was accepted by David Simchi-Levi, operations management. </jats:p><jats:p> Supplemental Material: The online appendices are available at https://doi.org/10.1287/mnsc.2023.04164 . </jats:p>",https://doi.org/10.1287/mnsc.2023.04164,CrossRef,contextual dataintegrate newsvendor solution operational data analytic oda,jatsp study dataintegrated newsvendor problem random demand depend set covariate observe solution analyze exist study identify equivariant class operational statistic mapping demand covariate datum inventory decision develop operational data analytic oda framework contextual newsvendor problem equivariant property intuitively appealing justify fact regardless sample size decision rule uniformly dominate optimal operational statistic within equivariant class also demonstrate nonequivariant solution produce unstable empirical performance limited sample whereas equivariant solution exhibit robustness distribution family demand know coefficient demand function unknown directly validate decision performance operational statistic within equivariant class derive uniformly optimal solution distribution family demand unknown formulate data integration model subclass equivariant operational statistic obtain adaptively boost candidate solution decision validation project validation datum demand covariate interest projection construct utilize structure candidate solution demonstrate superior smallsample performance adaptive boosting establish consistency boosted operational statistic oda formulation building inherent characteristic contextual newsvendor problem highlight importance understand structural property dataintegrate decision make jatspjatsp paper accept david simchilevi operations management jatspjatsp supplemental material online appendix available httpsdoiorgmnsc jatsp,contextual dataintegrate newsvendor solution operational data analytic oda jatsp study dataintegrated newsvendor problem random demand depend set covariate observe solution analyze exist study identify equivariant class operational statistic mapping demand covariate datum inventory decision develop operational data analytic oda framework contextual newsvendor problem equivariant property intuitively appealing justify fact regardless sample size decision rule uniformly dominate optimal operational statistic within equivariant class also demonstrate nonequivariant solution produce unstable empirical performance limited sample whereas equivariant solution exhibit robustness distribution family demand know coefficient demand function unknown directly validate decision performance operational statistic within equivariant class derive uniformly optimal solution distribution family demand unknown formulate data integration model subclass equivariant operational statistic obtain adaptively boost candidate solution decision validation project validation datum demand covariate interest projection construct utilize structure candidate solution demonstrate superior smallsample performance adaptive boosting establish consistency boosted operational statistic oda formulation building inherent characteristic contextual newsvendor problem highlight importance understand structural property dataintegrate decision make jatspjatsp paper accept david simchilevi operations management jatspjatsp supplemental material online appendix available httpsdoiorgmnsc jatsp,0.49079754601226994,0.1411042944785276,0.22699386503067484,0.04294478527607362,163.0,1.0,0.0,0.0,1.0
Information Technology,Data Management,Theoretical / Conceptual,"A Systematic Literature Review on Task Allocation and Performance
  Management Techniques in Cloud Data Center","As cloud computing usage grows, cloud data centers play an increasingly
important role. To maximize resource utilization, ensure service quality, and
enhance system performance, it is crucial to allocate tasks and manage
performance effectively. The purpose of this study is to provide an extensive
analysis of task allocation and performance management techniques employed in
cloud data centers. The aim is to systematically categorize and organize
previous research by identifying the cloud computing methodologies, categories,
and gaps. A literature review was conducted, which included the analysis of 463
task allocations and 480 performance management papers. The review revealed
three task allocation research topics and seven performance management methods.
Task allocation research areas are resource allocation, load-Balancing, and
scheduling. Performance management includes monitoring and control, power and
energy management, resource utilization optimization, quality of service
management, fault management, virtual machine management, and network
management. The study proposes new techniques to enhance cloud computing work
allocation and performance management. Short-comings in each approach can guide
future research. The research's findings on cloud data center task allocation
and performance management can assist academics, practitioners, and cloud
service providers in optimizing their systems for dependability,
cost-effectiveness, and scalability. Innovative methodologies can steer future
research to fill gaps in the literature.",http://arxiv.org/abs/2402.13135v1,arXiv,systematic literature review task allocation performance management technique cloud datum center,cloud computing usage grow cloud datum center play increasingly important role maximize resource utilization ensure service quality enhance system performance crucial allocate task manage performance effectively purpose study provide extensive analysis task allocation performance management technique employ cloud datum center aim systematically categorize organize previous research identify cloud compute methodology category gap literature review conduct include analysis task allocation performance management paper review reveal three task allocation research topic seven performance management method task allocation research area resource allocation loadbalancing scheduling performance management include monitoring control power energy management resource utilization optimization quality service management fault management virtual machine management network management study propose new technique enhance cloud computing work allocation performance management shortcoming approach guide future research researchs finding cloud datum center task allocation performance management assist academic practitioner cloud service provider optimize system dependability costeffectiveness scalability innovative methodology steer future research fill gap literature,systematic literature review task allocation performance management technique cloud datum center cloud computing usage grow cloud datum center play increasingly important role maximize resource utilization ensure service quality enhance system performance crucial allocate task manage performance effectively purpose study provide extensive analysis task allocation performance management technique employ cloud datum center aim systematically categorize organize previous research identify cloud compute methodology category gap literature review conduct include analysis task allocation performance management paper review reveal three task allocation research topic seven performance management method task allocation research area resource allocation loadbalancing scheduling performance management include monitoring control power energy management resource utilization optimization quality service management fault management virtual machine management network management study propose new technique enhance cloud computing work allocation performance management shortcoming approach guide future research researchs finding cloud datum center task allocation performance management assist academic practitioner cloud service provider optimize system dependability costeffectiveness scalability innovative methodology steer future research fill gap literature,0.678082191780822,0.11643835616438356,0.08904109589041095,0.02054794520547945,146.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Theoretical / Conceptual,"The Changing Locus of Health Data Production and Use: Patient-Generated
  Health Data, Observations of Daily Living, and Personal Health Information
  Management","Despite the growing attention of researcher, healthcare managers and policy
makers, data gathering and information management practices are largely
untheorized areas. In this work are presented and discussed some early-stage
conceptualizations: Patient-Generated Health Data (PGHD), Observations of Daily
Living (ODLs) and Personal Health Information Management (PHIM). As I shall try
to demonstrate, these labels are not neutral rather they underpin quite
different perspectives with respect to health, patient-doctor relationship, and
the status of data.",http://arxiv.org/abs/1606.09589v3,arXiv,change locus health datum production use patientgenerate health datum observation daily living personal health information management,despite grow attention researcher healthcare manager policy maker datum gathering information management practice largely untheorized area work present discuss earlystage conceptualization patientgenerate health datum pghd observation daily living odls personal health information management phim shall try demonstrate label neutral rather underpin quite different perspective respect health patientdoctor relationship status datum,change locus health datum production use patientgenerate health datum observation daily living personal health information management despite grow attention researcher healthcare manager policy maker datum gathering information management practice largely untheorized area work present discuss earlystage conceptualization patientgenerate health datum pghd observation daily living odls personal health information management phim shall try demonstrate label neutral rather underpin quite different perspective respect health patientdoctor relationship status datum,0.64,0.12,0.12,0.06,50.0,1.0,0.0,1.0,0.0
Information Technology,Data Management,Theoretical / Conceptual,"Exploring Data Management Challenges and Solutions in Agile Software
  Development: A Literature Review and Practitioner Survey","Context: Managing data related to a software product and its development
poses significant challenges for software projects and agile development teams.
These include integrating data from diverse sources and ensuring data quality
amidst continuous change and adaptation. Objective: The paper systematically
explores data management challenges and potential solutions in agile projects,
aiming to provide insights into data management challenges and solutions for
both researchers and practitioners. Method: We employed a mixed-methods
approach, including a systematic literature review (SLR) to understand the
state-of-research followed by a survey with practitioners to reflect on the
state-of-practice. The SLR reviewed 45 studies, identifying and categorizing
data management aspects along with their associated challenges and solutions.
The practitioner survey captured practical experiences and solutions from 32
industry practitioners who were significantly involved in data management to
complement the findings from the SLR. Results: Our findings identified major
data management challenges in practice, such as managing data integration
processes, capturing diverse data, automating data collection, and meeting
real-time analysis requirements. To address the challenges, solutions such as
automation tools, decentralized data management practices, and ontology-based
approaches have been identified. The solutions enhance data integration,
improve data quality, and enable real-time decision-making by providing
flexible frameworks tailored to agile project needs. Conclusion: The study
pinpointed significant challenges and actionable solutions in data management
for agile software development. Our findings provide practical implications for
practitioners and researchers, emphasizing the development of effective data
management practices and tools to address those challenges and improve project
success.",http://arxiv.org/abs/2402.00462v4,arXiv,explore datum management challenge solution agile software development literature review practitioner survey,context manage datum relate software product development pose significant challenge software project agile development team include integrate datum diverse source ensure datum quality amidst continuous change adaptation objective paper systematically explore datum management challenge potential solution agile project aim provide insight data management challenge solution researcher practitioner method employ mixedmethod approach include systematic literature review slr understand stateofresearch follow survey practitioner reflect stateofpractice slr review study identify categorize datum management aspect along associate challenge solution practitioner survey capture practical experience solution industry practitioner significantly involve datum management complement finding slr result finding identify major data management challenge practice manage datum integration process capture diverse datum automate data collection meeting realtime analysis requirement address challenge solution automation tool decentralize data management practice ontologybase approach identify solution enhance datum integration improve data quality enable realtime decisionmake provide flexible framework tailor agile project need conclusion study pinpoint significant challenge actionable solution datum management agile software development finding provide practical implication practitioner researcher emphasize development effective datum management practice tool address challenge improve project success,explore datum management challenge solution agile software development literature review practitioner survey context manage datum relate software product development pose significant challenge software project agile development team include integrate datum diverse source ensure datum quality amidst continuous change adaptation objective paper systematically explore datum management challenge potential solution agile project aim provide insight data management challenge solution researcher practitioner method employ mixedmethod approach include systematic literature review slr understand stateofresearch follow survey practitioner reflect stateofpractice slr review study identify categorize datum management aspect along associate challenge solution practitioner survey capture practical experience solution industry practitioner significantly involve datum management complement finding slr result finding identify major data management challenge practice manage datum integration process capture diverse datum automate data collection meeting realtime analysis requirement address challenge solution automation tool decentralize data management practice ontologybase approach identify solution enhance datum integration improve data quality enable realtime decisionmake provide flexible framework tailor agile project need conclusion study pinpoint significant challenge actionable solution datum management agile software development finding provide practical implication practitioner researcher emphasize development effective datum management practice tool address challenge improve project success,0.6666666666666666,0.15204678362573099,0.1286549707602339,0.011695906432748537,171.0,0.0,0.0,0.0,0.0
Information Technology,Data Management,Theoretical / Conceptual,"Designing for Recommending Intermediate States in A Scientific Workflow
  Management System","To process a large amount of data sequentially and systematically, proper
management of workflow components (i.e., modules, data, configurations,
associations among ports and links) in a Scientific Workflow Management System
(SWfMS) is inevitable. Managing data with provenance in a SWfMS to support
reusability of workflows, modules, and data is not a simple task. Handling such
components is even more burdensome for frequently assembled and executed
complex workflows for investigating large datasets with different technologies
(i.e., various learning algorithms or models). However, a great many studies
propose various techniques and technologies for managing and recommending
services in a SWfMS, but only a very few studies consider the management of
data in a SWfMS for efficient storing and facilitating workflow executions.
Furthermore, there is no study to inquire about the effectiveness and
efficiency of such data management in a SWfMS from a user perspective. In this
paper, we present and evaluate a GUI version of such a novel approach of
intermediate data management with two use cases (Plant Phenotyping and
Bioinformatics). The technique we call GUI-RISPTS (Recommending Intermediate
States from Pipelines Considering Tool-States) can facilitate executions of
workflows with processed data (i.e., intermediate outcomes of modules in a
workflow) and can thus reduce the computational time of some modules in a
SWfMS. We integrated GUI-RISPTS with an existing workflow management system
called SciWorCS. In SciWorCS, we present an interface that users use for
selecting the recommendation of intermediate states (i.e., modules' outcomes).
We investigated GUI-RISP's effectiveness from users' perspectives along with
measuring its overhead in terms of storage and efficiency in workflow
execution.",http://arxiv.org/abs/2010.04880v1,arXiv,design recommend intermediate state scientific workflow management system,process large amount datum sequentially systematically proper management workflow component module datum configuration association among port link scientific workflow management system swfms inevitable manage datum provenance swfms support reusability workflow module datum simple task handle component even burdensome frequently assemble execute complex workflow investigate large dataset different technology various learning algorithm model however great many study propose various technique technology manage recommend service swfms study consider management datum swfms efficient storing facilitate workflow execution furthermore study inquire effectiveness efficiency datum management swfms user perspective paper present evaluate gui version novel approach intermediate datum management two use case plant phenotype bioinformatics technique call guirispt recommend intermediate state pipeline consider toolstate facilitate execution workflow process datum intermediate outcome module workflow thus reduce computational time module swfms integrate guirispt exist workflow management system call sciworc sciworc present interface user use select recommendation intermediate state module outcome investigate guirisps effectiveness user perspective along measure overhead term storage efficiency workflow execution,design recommend intermediate state scientific workflow management system process large amount datum sequentially systematically proper management workflow component module datum configuration association among port link scientific workflow management system swfms inevitable manage datum provenance swfms support reusability workflow module datum simple task handle component even burdensome frequently assemble execute complex workflow investigate large dataset different technology various learning algorithm model however great many study propose various technique technology manage recommend service swfms study consider management datum swfms efficient storing facilitate workflow execution furthermore study inquire effectiveness efficiency datum management swfms user perspective paper present evaluate gui version novel approach intermediate datum management two use case plant phenotype bioinformatics technique call guirispt recommend intermediate state pipeline consider toolstate facilitate execution workflow process datum intermediate outcome module workflow thus reduce computational time module swfms integrate guirispt exist workflow management system call sciworc sciworc present interface user use select recommendation intermediate state module outcome investigate guirisps effectiveness user perspective along measure overhead term storage efficiency workflow execution,0.5128205128205128,0.12179487179487179,0.16666666666666666,0.05128205128205128,156.0,3.0,0.0,0.0,0.0
Information Technology,Data Management,Theoretical / Conceptual,"DroneXNFT: An NFT-Driven Framework for Secure Autonomous UAV Operations
  and Flight Data Management","Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for
managing digital assets, providing transparency and secure ownership records on
a blockchain. In this paper, we present a theoretical framework for leveraging
NFTs to manage UAV (Unmanned Aerial Vehicle) flight data. Our approach focuses
on ensuring data integrity, ownership transfer, and secure data sharing among
stakeholders. This framework utilizes cryptographic methods, smart contracts,
and access control mechanisms to enable a tamper-proof and privacy-preserving
management system for UAV flight data.",http://arxiv.org/abs/2409.06507v1,arXiv,dronexnft nftdriven framework secure autonomous uav operation flight datum management,nonfungible tokens nft emerge revolutionary method manage digital asset provide transparency secure ownership record blockchain paper present theoretical framework leverage nft manage uav unmanned aerial vehicle flight datum approach focus ensure datum integrity ownership transfer secure datum sharing among stakeholder framework utilize cryptographic method smart contract access control mechanism enable tamperproof privacypreserve management system uav flight datum,dronexnft nftdriven framework secure autonomous uav operation flight datum management nonfungible tokens nft emerge revolutionary method manage digital asset provide transparency secure ownership record blockchain paper present theoretical framework leverage nft manage uav unmanned aerial vehicle flight datum approach focus ensure datum integrity ownership transfer secure datum sharing among stakeholder framework utilize cryptographic method smart contract access control mechanism enable tamperproof privacypreserve management system uav flight datum,0.5789473684210527,0.10526315789473684,0.2631578947368421,0.0,57.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Quantitative,Implementasi Algoritma Support Vector Machine dan Chi Square untuk Analisis Sentimen User Feedback Aplikasi,"<jats:p>In order to adapt with evolving requirements and perform continuous software maintenance, it is essential for the software developers to understand the content of user feedback. User feedback such as bug report could provide so much information regarding the product from user's point of view, especially parts that need improvements. However, it is often difficult to read all the feedback for products with enormous number of users as manually reading and analyzing each feedback could take too much time and effort. This research aims to develop a model for automatic feedback classification by implementing Support Vector Machine for the classifier's algorithm and Chi-square method for feature selection. The model is developed using Python programming language and is then evaluated under different scenarios in order to measure its performance. Using a ratio of training and testing set of 80:20, our model achieved 77% accuracy, 50% precision, 55% recall, and 73% F1-score with 6.63 critical value and C=100 and gamma 0.001 as the SVM hyperparameters.</jats:p>",https://doi.org/10.31937/ti.v12i2.1828,CrossRef,implementasi algoritma support vector machine dan chi square untuk analisis sentiman user feedback aplikasi,jatspin order adapt evolving requirement perform continuous software maintenance essential software developer understand content user feedback user feedback bug report could provide much information regard product user point view especially part need improvement however often difficult read feedback product enormous number user manually read analyze feedback could take much time effort research aim develop model automatic feedback classification implement support vector machine classifier algorithm chisquare method feature selection model develop use python programming language evaluate different scenario order measure performance use ratio training testing set model achieve accuracy precision recall fscore critical value gamma svm hyperparametersjatsp,implementasi algoritma support vector machine dan chi square untuk analisis sentiman user feedback aplikasi jatspin order adapt evolving requirement perform continuous software maintenance essential software developer understand content user feedback user feedback bug report could provide much information regard product user point view especially part need improvement however often difficult read feedback product enormous number user manually read analyze feedback could take much time effort research aim develop model automatic feedback classification implement support vector machine classifier algorithm chisquare method feature selection model develop use python programming language evaluate different scenario order measure performance use ratio training testing set model achieve accuracy precision recall fscore critical value gamma svm hyperparametersjatsp,0.625,0.16666666666666666,0.09375,0.041666666666666664,96.0,1.0,0.0,0.0,1.0
Information Technology,User Support,Quantitative,Expert Consensus Survey on Digital Health Tools for Patients With Serious Mental Illness: Optimizing for User Characteristics and User Support,"<jats:sec>
            <jats:title>Background</jats:title>
            <jats:p>Digital technology is increasingly being used to enhance health care in various areas of medicine. In the area of serious mental illness, it is important to understand the special characteristics of target users that may influence motivation and competence to use digital health tools, as well as the resources and training necessary for these patients to facilitate the use of this technology.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Objective</jats:title>
            <jats:p>The aim of this study was to conduct a quantitative expert consensus survey to identify key characteristics of target users (patients and health care professionals), barriers and facilitators for appropriate use, and resources needed to optimize the use of digital health tools in patients with serious mental illness.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Methods</jats:title>
            <jats:p>A panel of 40 experts in digital behavioral health who met the participation criteria completed a 19-question survey, rating predefined responses on a 9-point Likert scale. Consensus was determined using a chi-square test of score distributions across three ranges (1-3, 4-6, 7-9). Categorical ratings of first, second, or third line were designated based on the lowest category into which the CI of the mean ratings fell, with a boundary &gt;6.5 for first line. Here, we report experts’ responses to nine questions (265 options) that focused on (1) user characteristics that would promote or hinder the use of digital health tools, (2) potential benefits or motivators and barriers or unintended consequences of digital health tool use, and (3) support and training for patients and health care professionals.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Results</jats:title>
            <jats:p>Among patient characteristics most likely to promote use of digital health tools, experts endorsed interest in using state-of-the-art technology, availability of necessary resources, good occupational functioning, and perception of the tool as beneficial. Certain disease-associated signs and symptoms (eg, more severe symptoms, substance abuse problems, and a chaotic living situation) were considered likely to make it difficult for patients to use digital health tools. Enthusiasm among health care professionals for digital health tools and availability of staff and equipment to support their use were identified as variables to enable health care professionals to successfully incorporate digital health tools into their practices. The experts identified a number of potential benefits of and barriers to use of digital health tools by patients and health care professionals. Experts agreed that both health care professionals and patients would need to be trained in the use of these new technologies.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Conclusions</jats:title>
            <jats:p>These results provide guidance to the mental health field on how to optimize the development and deployment of digital health tools for patients with serious mental illness.</jats:p>
          </jats:sec>",https://doi.org/10.2196/mental.9777,CrossRef,expert consensus survey digital health tool patient serious mental illness optimize user characteristic user support,jatssec jatstitlebackgroundjatstitle jatspdigital technology increasingly use enhance health care various area medicine area serious mental illness important understand special characteristic target user may influence motivation competence use digital health tool well resource training necessary patient facilitate use technologyjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthe aim study conduct quantitative expert consensus survey identify key characteristic target user patient health care professional barrier facilitator appropriate use resource need optimize use digital health tool patient serious mental illnessjatsp jatssec jatssec jatstitlemethodsjatstitle jatspa panel expert digital behavioral health meet participation criterion complete question survey rating predefine response point likert scale consensus determine use chisquare test score distribution across three range categorical rating first second third line designate base low category mean rating fall boundary first line report expert response nine question option focus user characteristic would promote hinder use digital health tool potential benefit motivator barrier unintended consequence digital health tool use support training patient health care professionalsjatsp jatssec jatssec jatstitleresultsjatstitle jatspamong patient characteristic likely promote use digital health tool expert endorse interest use stateoftheart technology availability necessary resource good occupational functioning perception tool beneficial certain diseaseassociated sign symptom severe symptom substance abuse problem chaotic living situation consider likely make difficult patient use digital health tool enthusiasm among health care professional digital health tool availability staff equipment support use identify variable enable health care professional successfully incorporate digital health tool practice expert identify number potential benefit barrier use digital health tool patient health care professional expert agree health care professional patient would need train use new technologiesjatsp jatssec jatssec jatstitleconclusionsjatstitle jatspthese result provide guidance mental health field optimize development deployment digital health tool patient serious mental illnessjatsp jatssec,expert consensus survey digital health tool patient serious mental illness optimize user characteristic user support jatssec jatstitlebackgroundjatstitle jatspdigital technology increasingly use enhance health care various area medicine area serious mental illness important understand special characteristic target user may influence motivation competence use digital health tool well resource training necessary patient facilitate use technologyjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthe aim study conduct quantitative expert consensus survey identify key characteristic target user patient health care professional barrier facilitator appropriate use resource need optimize use digital health tool patient serious mental illnessjatsp jatssec jatssec jatstitlemethodsjatstitle jatspa panel expert digital behavioral health meet participation criterion complete question survey rating predefine response point likert scale consensus determine use chisquare test score distribution across three range categorical rating first second third line designate base low category mean rating fall boundary first line report expert response nine question option focus user characteristic would promote hinder use digital health tool potential benefit motivator barrier unintended consequence digital health tool use support training patient health care professionalsjatsp jatssec jatssec jatstitleresultsjatstitle jatspamong patient characteristic likely promote use digital health tool expert endorse interest use stateoftheart technology availability necessary resource good occupational functioning perception tool beneficial certain diseaseassociated sign symptom severe symptom substance abuse problem chaotic living situation consider likely make difficult patient use digital health tool enthusiasm among health care professional digital health tool availability staff equipment support use identify variable enable health care professional successfully incorporate digital health tool practice expert identify number potential benefit barrier use digital health tool patient health care professional expert agree health care professional patient would need train use new technologiesjatsp jatssec jatssec jatstitleconclusionsjatstitle jatspthese result provide guidance mental health field optimize development deployment digital health tool patient serious mental illnessjatsp jatssec,0.5257352941176471,0.09926470588235294,0.21691176470588236,0.014705882352941176,90.66666666666667,1.0,0.0,0.0,4.0
Information Technology,User Support,Quantitative,"The Effect of Enterprise Resource Planning (ERP) System Implementation, User Training, and Management Support on User Satisfaction in Manufacturing Companies","<jats:p>This study examines the impact of Enterprise Resource Planning (ERP) system implementation, User Training, and Management Support on User Satisfaction within manufacturing companies. Using a quantitative approach, data were collected from 160 respondents and analyzed using Structural Equation Modeling-Partial Least Squares (SEM-PLS). The results indicate that all three factors—ERP system implementation, User Training, and Management Support—have a positive and significant effect on User Satisfaction. Among these, User Training emerged as the most influential factor, followed by Management Support and ERP system implementation. These findings underscore the critical role of human-centric factors in ensuring successful ERP adoption and highlight the importance of comprehensive training and strong management involvement. The study offers practical insights for organizations aiming to enhance user satisfaction with ERP systems, emphasizing the need for a holistic approach that integrates technical and human factors.</jats:p>",https://doi.org/10.58812/wsist.v2i02.1209,CrossRef,effect enterprise resource planning erp system implementation user training management support user satisfaction manufacture company,jatspthis study examine impact enterprise resource planning erp system implementation user training management support user satisfaction within manufacturing company use quantitative approach datum collect respondent analyze use structural equation modelingpartial least square sempls result indicate three factor erp system implementation user training management support positive significant effect user satisfaction among user training emerge influential factor follow management support erp system implementation finding underscore critical role humancentric factor ensure successful erp adoption highlight importance comprehensive training strong management involvement study offer practical insight organization aim enhance user satisfaction erp system emphasize need holistic approach integrate technical human factorsjatsp,effect enterprise resource planning erp system implementation user training management support user satisfaction manufacture company jatspthis study examine impact enterprise resource planning erp system implementation user training management support user satisfaction within manufacturing company use quantitative approach datum collect respondent analyze use structural equation modelingpartial least square sempls result indicate three factor erp system implementation user training management support positive significant effect user satisfaction among user training emerge influential factor follow management support erp system implementation finding underscore critical role humancentric factor ensure successful erp adoption highlight importance comprehensive training strong management involvement study offer practical insight organization aim enhance user satisfaction erp system emphasize need holistic approach integrate technical human factorsjatsp,0.6082474226804123,0.14432989690721648,0.17525773195876287,0.010309278350515464,97.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Quantitative,User Engagement Within an Online Peer Support Community (Depression Connect) and Recovery-Related Changes in Empowerment: Longitudinal User Survey,"<jats:sec>
            <jats:title>Background</jats:title>
            <jats:p>The chronic nature of depression and limited availability of evidence-based treatments emphasize the need for complementary recovery-oriented services, such as peer support interventions (PSIs). Peer support is associated with positive effects on clinical and personal recovery from mental illness, but little is known about the processes of engagement that foster change, and studies targeting individuals with depression specifically are limited.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Objective</jats:title>
            <jats:p>This study aimed to evaluate whether the level of user engagement, assessed on several dimensions, in an online peer support community for individuals with depression promotes empowerment and the use of self-management strategies and reduces symptom severity and disability.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Methods</jats:title>
            <jats:p>In a longitudinal survey conducted from June 2019 to September 2020, we analyzed the data of the users of Depression Connect (DC), an online peer support community hosted by the Dutch Patient Association for Depression and the Pro Persona Mental Health Care institute, on measures of empowerment, self-management, depression, and disability. Of the 301 respondents, 49 (16.3%) respondents completed the survey again after 3 months and 74 (24.6%) respondents, after 6 months. Analysis of 3 parameters (ie, total time spent on the platform, number of page views, and number of posts) derived from their data logs yielded 4 engagement profiles. Linear mixed models were fitted to determine whether the outcomes had significantly changed over time and differed for the various profiles.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Results</jats:title>
            <jats:p>Baseline engagement with the online peer support community was “very low” (177/301, 58.8%) or “low” (87/301, 28.9%) for most of the participants, with few showing “medium” (30/301, 9.9%) or “high” engagement patterns (7/301, 2.3%), while user profiles did not differ in demographic and clinical characteristics. Empowerment, self-management, depressive symptoms, and disability improved over time, but none were associated with the intensity or nature of user engagement.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Conclusions</jats:title>
            <jats:p>With most DC members showing very low to low engagement and only a few being identified as high-engaged users, it is likely that this flexibility in use frequency is what provides value to online PSI users. In other more formal supportive environments for depression, a certain level of engagement is predetermined either by their organizational or by their societal context; at DC, users can adapt the intensity and nature of their engagement to their current needs on their personal road to recovery. This study added to the current knowledge base on user engagement for PSIs because previous studies targeting depression with an online format focused on active users, precluding passive and flexible engagement. Future studies should explore the content and quality of the interactions in online PSIs to identify optimal user engagement as a function of current, self-reported clinical parameters and reasons to engage in the PSI.</jats:p>
          </jats:sec>",https://doi.org/10.2196/39912,CrossRef,user engagement within online peer support community depression connect recoveryrelate change empowerment longitudinal user survey,jatssec jatstitlebackgroundjatstitle jatspthe chronic nature depression limited availability evidencebase treatment emphasize need complementary recoveryoriente service peer support intervention psis peer support associate positive effect clinical personal recovery mental illness little know process engagement foster change study target individual depression specifically limitedjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthis study aim evaluate whether level user engagement assess several dimension online peer support community individual depression promote empowerment use selfmanagement strategy reduce symptom severity disabilityjatsp jatssec jatssec jatstitlemethodsjatstitle jatspin longitudinal survey conduct june september analyze datum user depression connect online peer support community host dutch patient association depression pro persona mental health care institute measure empowerment selfmanagement depression disability respondent respondent complete survey month respondent month analysis parameter total time spend platform number page view number post derive data log yield engagement profile linear mixed model fit determine whether outcome significantly change time differ various profilesjatsp jatssec jatssec jatstitleresultsjatstitle jatspbaseline engagement online peer support community low low participant show medium high engagement pattern user profile differ demographic clinical characteristic empowerment selfmanagement depressive symptom disability improve time none associate intensity nature user engagementjatsp jatssec jatssec jatstitleconclusionsjatstitle jatspwith member show low low engagement identify highengaged user likely flexibility use frequency provide value online psi user formal supportive environment depression certain level engagement predetermine either organizational societal context user adapt intensity nature engagement current need personal road recovery study add current knowledge base user engagement psis previous study target depression online format focus active user preclude passive flexible engagement future study explore content quality interaction online psis identify optimal user engagement function current selfreporte clinical parameter reason engage psijatsp jatssec,user engagement within online peer support community depression connect recoveryrelate change empowerment longitudinal user survey jatssec jatstitlebackgroundjatstitle jatspthe chronic nature depression limited availability evidencebase treatment emphasize need complementary recoveryoriente service peer support intervention psis peer support associate positive effect clinical personal recovery mental illness little know process engagement foster change study target individual depression specifically limitedjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthis study aim evaluate whether level user engagement assess several dimension online peer support community individual depression promote empowerment use selfmanagement strategy reduce symptom severity disabilityjatsp jatssec jatssec jatstitlemethodsjatstitle jatspin longitudinal survey conduct june september analyze datum user depression connect online peer support community host dutch patient association depression pro persona mental health care institute measure empowerment selfmanagement depression disability respondent respondent complete survey month respondent month analysis parameter total time spend platform number page view number post derive data log yield engagement profile linear mixed model fit determine whether outcome significantly change time differ various profilesjatsp jatssec jatssec jatstitleresultsjatstitle jatspbaseline engagement online peer support community low low participant show medium high engagement pattern user profile differ demographic clinical characteristic empowerment selfmanagement depressive symptom disability improve time none associate intensity nature user engagementjatsp jatssec jatssec jatstitleconclusionsjatstitle jatspwith member show low low engagement identify highengaged user likely flexibility use frequency provide value online psi user formal supportive environment depression certain level engagement predetermine either organizational societal context user adapt intensity nature engagement current need personal road recovery study add current knowledge base user engagement psis previous study target depression online format focus active user preclude passive flexible engagement future study explore content quality interaction online psis identify optimal user engagement function current selfreporte clinical parameter reason engage psijatsp jatssec,0.5190839694656488,0.07633587786259542,0.20610687022900764,0.007633587786259542,87.33333333333333,2.0,0.0,3.0,6.0
Information Technology,User Support,Quantitative,Anwenderunterstützung bei der digitalisierten Produktionsplanung/User support in digital production planning,"<p>In der Produktionsplanung kommt vermehrt Simulationssoftware zum Einsatz, um Zeit und Kosten zu reduzieren. Viele Anwender benutzen die Programme allerdings nur gelegentlich. Aufgrund des relativ geringen Übungsgrades besteht ein hoher Bedarf an Unterstützung. In marktgängigen Softwarewerkzeugen sind jedoch bislang kaum wirksame Unterstützungsfunktionen implementiert. Basierend auf Anwenderbefragungen in Unternehmen innerhalb des europäischen Forschungsprojektes DREAM (simulation based application Decision support in Real-time for Efficient Agile Manufacturing) werden drei Konzepte für die Benutzerunterstützung vorgeschlagen.</p>
          <p>&amp;nbsp;</p>
          <p>Production planning is increasingly performed by the application of simulation software in order to reduce costs and time. But many users use this kind of software just occasionally. Due to this low level of usage, there is a great demand in support. For those software packages, useful and efficient support tools were not implemented until now. Based on surveys realized in some companies in the European project DREAM three different concepts of user support are suggested.</p>",https://doi.org/10.37544/1436-4980-2016-04-59,CrossRef,anwenderunterstützung bei der digitalisierten produktionsplanunguser support digital production planning,pin der produktionsplanung kommt vermehrt simulationssoftware zum einsatz zeit und kosten reduzieren viele anwender benutzen die programme allerding nur gelegentlich aufgrund des relativ geringen übungsgrades besteht ein hoher bedarf unterstützung marktgängigen softwarewerkzeugen sind jedoch bislang kaum wirksame unterstützungsfunktionen implementiert basierend auf anwenderbefragungen unternehman innerhalb des europäischen forschungsprojekte dream simulation base application decision support realtime efficient agile manufacturing werden drei konzepte für die benutzerunterstützung vorgeschlagenp pampnbspp pproduction planning increasingly perform application simulation software order reduce cost time many user use kind software occasionally due low level usage great demand support software package useful efficient support tool implement base survey realize company european project dream three different concept user support suggestedp,anwenderunterstützung bei der digitalisierten produktionsplanunguser support digital production planning pin der produktionsplanung kommt vermehrt simulationssoftware zum einsatz zeit und kosten reduzieren viele anwender benutzen die programme allerding nur gelegentlich aufgrund des relativ geringen übungsgrades besteht ein hoher bedarf unterstützung marktgängigen softwarewerkzeugen sind jedoch bislang kaum wirksame unterstützungsfunktionen implementiert basierend auf anwenderbefragungen unternehman innerhalb des europäischen forschungsprojekte dream simulation base application decision support realtime efficient agile manufacturing werden drei konzepte für die benutzerunterstützung vorgeschlagenp pampnbspp pproduction planning increasingly perform application simulation software order reduce cost time many user use kind software occasionally due low level usage great demand support software package useful efficient support tool implement base survey realize company european project dream three different concept user support suggestedp,0.42201834862385323,0.07339449541284404,0.11009174311926606,0.01834862385321101,109.0,0.0,0.0,0.0,4.0
Information Technology,User Support,Qualitative,Public user innovation: exploring the support mechanisms and user roles in a public organisation,"<jats:sec><jats:title content-type=""abstract-subheading"">Purpose</jats:title><jats:p>This article expands literature on user innovation by exploring the mechanisms that support user innovations in the context of a public organisation. Research has hitherto documented support mechanisms for user innovation in producer companies, where users contribute in early or temporary innovation phases as external non-employees or lead-users engaged by the producer. Complementarily, this paper explores a lesser known area of support mechanisms, those that support internal user innovations in a public sector setting.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Design/methodology/approach</jats:title><jats:p>Employing a qualitative study of a Norwegian public hospital at the interface between users (personnel and patients) and organisational support (facilitators who orchestrate user innovations), this article analyses in-house user innovation based on observations, text documentation and interviews over a four-year period.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Findings</jats:title><jats:p>In this public hospital, holistic organisational facilitation of “public user innovators” formed the key support mechanism built on “people” (facilitating co-creation), “process” (facilitating ideas, project realisation and implementation) and “coordination” (facilitating systems and communication). The findings show that public and producer organisational mechanisms both resemble and differ in many respects, as illustrated by the framework developed to describe these characteristics, such as that producers insource users, while the public organisation outsources production.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-subheading"">Originality/value</jats:title><jats:p>The originality of the article lies in the identification and description of “public user innovation”, a new term developed from this study of a public organisation in contrast to the dominant literature on producer companies. This article contributes new insights by differentiating the roles of user innovators and the mechanisms that support such innovations. New implications are drawn from the public side of organisational support in user innovation research.</jats:p></jats:sec>",https://doi.org/10.1108/ejim-04-2022-0217,CrossRef,public user innovation explore support mechanism user role public organisation,jatssecjatstitle contenttypeabstractsubheadingpurposejatstitlejatspthis article expand literature user innovation explore mechanism support user innovation context public organisation research hitherto document support mechanism user innovation producer company user contribute early temporary innovation phase external nonemployee leaduser engage producer complementarily paper explore lesser know area support mechanism support internal user innovation public sector settingjatspjatssecjatssecjatstitle contenttypeabstractsubheadingdesignmethodologyapproachjatstitlejatspemploye qualitative study norwegian public hospital interface user personnel patient organisational support facilitator orchestrate user innovation article analyse inhouse user innovation base observation text documentation interview fouryear periodjatspjatssecjatssecjatstitle contenttypeabstractsubheadingfindingsjatstitlejatspin public hospital holistic organisational facilitation public user innovator form key support mechanism build people facilitate cocreation process facilitate idea project realisation implementation coordination facilitate system communication finding show public producer organisational mechanism resemble differ many respect illustrate framework develop describe characteristic producer insource user public organisation outsource productionjatspjatssecjatssecjatstitle contenttypeabstractsubheadingoriginalityvaluejatstitlejatspthe originality article lie identification description public user innovation new term develop study public organisation contrast dominant literature producer company article contribute new insight differentiate role user innovator mechanism support innovation new implication draw public side organisational support user innovation researchjatspjatssec,public user innovation explore support mechanism user role public organisation jatssecjatstitle contenttypeabstractsubheadingpurposejatstitlejatspthis article expand literature user innovation explore mechanism support user innovation context public organisation research hitherto document support mechanism user innovation producer company user contribute early temporary innovation phase external nonemployee leaduser engage producer complementarily paper explore lesser know area support mechanism support internal user innovation public sector settingjatspjatssecjatssecjatstitle contenttypeabstractsubheadingdesignmethodologyapproachjatstitlejatspemploye qualitative study norwegian public hospital interface user personnel patient organisational support facilitator orchestrate user innovation article analyse inhouse user innovation base observation text documentation interview fouryear periodjatspjatssecjatssecjatstitle contenttypeabstractsubheadingfindingsjatstitlejatspin public hospital holistic organisational facilitation public user innovator form key support mechanism build people facilitate cocreation process facilitate idea project realisation implementation coordination facilitate system communication finding show public producer organisational mechanism resemble differ many respect illustrate framework develop describe characteristic producer insource user public organisation outsource productionjatspjatssecjatssecjatstitle contenttypeabstractsubheadingoriginalityvaluejatstitlejatspthe originality article lie identification description public user innovation new term develop study public organisation contrast dominant literature producer company article contribute new insight differentiate role user innovator mechanism support innovation new implication draw public side organisational support user innovation researchjatspjatssec,0.625,0.05952380952380952,0.16666666666666666,0.0,168.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Qualitative,Integrating Key User Characteristics in User-Centered Design of Digital Support Systems for Seniors’ Physical Activity Interventions to Prevent Falls: Protocol for a Usability Study,"<jats:sec>
            <jats:title>Background</jats:title>
            <jats:p>The goal of user-centered design (UCD) is to understand the users’ perspective and to use that knowledge to shape more effective solutions. The UCD approach provides insight into users’ needs and requirements and thereby improves the design of the developed services. However, involving users in the development process does not guarantee that feedback from different subgroups of users will shape the development in ways that will make the solutions more useful for the entire target user population.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Objective</jats:title>
            <jats:p>The aim of this study was to describe a protocol for systematic analysis and prioritization of feedback from user subgroups in the usability testing of a digital motivation support for fall-preventive physical activity (PA) interventions in seniors (aged 65 years and older). This protocol can help researchers and developers to systematically exploit feedback from relevant user subgroups in UCD.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Methods</jats:title>
            <jats:p>Gender, PA level, and level of technology experience have been identified in the literature to influence users’ experience and use of digital support systems for fall-preventive PA interventions in seniors. These 3 key user characteristics were dichotomized and used to define 8 (ie, 23) possible user subgroups. The presented method enables systematic tracking of the user subgroups’ contributions in iterative development. The method comprises (1) compilation of difficulties and deficiencies in the digital applications identified in usability testing, (2) clustering of the identified difficulties and deficiencies, and (3) prioritization of deficiencies to be rectified. Tracking user subgroup representation in the user feedback ensures that the development process is prioritized according to the needs of different subgroups. Mainly qualitative data collection methods are used.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Results</jats:title>
            <jats:p>A protocol was developed to ensure that feedback from users representing all possible variants of 3 selected key user characteristics (gender, PA level, and level of technology experience) is considered in the iterative usability testing of a digital support for seniors’ PA. The method was applied in iterative usability testing of two digital applications during spring/summer 2018. Results from the study on the users’ experiences and the iterative modification of the digital applications are expected to be published during 2021.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>Conclusions</jats:title>
            <jats:p>Methods for systematic collection, analysis, and prioritization of feedback from user subgroups might be particularly important in heterogenous user groups (eg, seniors). This study can contribute to identifying and improving the understanding of potential differences between user subgroups of seniors in their use and experiences of digital support for fall-preventive PA interventions. This knowledge may be relevant for developing digital support systems that are appropriate, useful, and attractive to users and for enabling the design of digital support systems that target specific user subgroups (ie, tailoring of the support). The protocol needs to be further used and investigated in order to validate its potential value.</jats:p>
          </jats:sec>
          <jats:sec>
            <jats:title>International Registered Report Identifier (IRRID)</jats:title>
            <jats:p>RR1-10.2196/20061</jats:p>
          </jats:sec>",https://doi.org/10.2196/20061,CrossRef,integrate key user characteristic usercentered design digital support system senior physical activity intervention prevent fall protocol usability study,jatssec jatstitlebackgroundjatstitle jatspthe goal usercentered design ucd understand user perspective use knowledge shape effective solution ucd approach provide insight user need requirement thereby improve design develop service however involve user development process guarantee feedback different subgroup user shape development way make solution useful entire target user populationjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthe aim study describe protocol systematic analysis prioritization feedback user subgroup usability testing digital motivation support fallpreventive physical activity intervention senior age year old protocol help researcher developer systematically exploit feedback relevant user subgroup ucdjatsp jatssec jatssec jatstitlemethodsjatstitle jatspgend level level technology experience identify literature influence user experience use digital support system fallpreventive intervention senior key user characteristic dichotomize use define possible user subgroup present method enable systematic tracking user subgroup contribution iterative development method comprise compilation difficulty deficiency digital application identify usability testing clustering identify difficulty deficiency prioritization deficiency rectify tracking user subgroup representation user feedback ensure development process prioritize accord need different subgroup mainly qualitative data collection method usedjatsp jatssec jatssec jatstitleresultsjatstitle jatspa protocol develop ensure feedback user represent possible variant select key user characteristics gender level level technology experience consider iterative usability testing digital support senior method apply iterative usability testing two digital application springsummer result study user experience iterative modification digital application expect publish jatsp jatssec jatssec jatstitleconclusionsjatstitle jatspmethod systematic collection analysis prioritization feedback user subgroup might particularly important heterogenous user group senior study contribute identify improve understanding potential difference user subgroup senior use experience digital support fallpreventive intervention knowledge may relevant develop digital support system appropriate useful attractive user enable design digital support system target specific user subgroup tailor support protocol need far use investigate order validate potential valuejatsp jatssec jatssec jatstitleinternational register report identifi irridjatstitle jatsprrjatsp jatssec,integrate key user characteristic usercentered design digital support system senior physical activity intervention prevent fall protocol usability study jatssec jatstitlebackgroundjatstitle jatspthe goal usercentered design ucd understand user perspective use knowledge shape effective solution ucd approach provide insight user need requirement thereby improve design develop service however involve user development process guarantee feedback different subgroup user shape development way make solution useful entire target user populationjatsp jatssec jatssec jatstitleobjectivejatstitle jatspthe aim study describe protocol systematic analysis prioritization feedback user subgroup usability testing digital motivation support fallpreventive physical activity intervention senior age year old protocol help researcher developer systematically exploit feedback relevant user subgroup ucdjatsp jatssec jatssec jatstitlemethodsjatstitle jatspgend level level technology experience identify literature influence user experience use digital support system fallpreventive intervention senior key user characteristic dichotomize use define possible user subgroup present method enable systematic tracking user subgroup contribution iterative development method comprise compilation difficulty deficiency digital application identify usability testing clustering identify difficulty deficiency prioritization deficiency rectify tracking user subgroup representation user feedback ensure development process prioritize accord need different subgroup mainly qualitative data collection method usedjatsp jatssec jatssec jatstitleresultsjatstitle jatspa protocol develop ensure feedback user represent possible variant select key user characteristics gender level level technology experience consider iterative usability testing digital support senior method apply iterative usability testing two digital application springsummer result study user experience iterative modification digital application expect publish jatsp jatssec jatssec jatstitleconclusionsjatstitle jatspmethod systematic collection analysis prioritization feedback user subgroup might particularly important heterogenous user group senior study contribute identify improve understanding potential difference user subgroup senior use experience digital support fallpreventive intervention knowledge may relevant develop digital support system appropriate useful attractive user enable design digital support system target specific user subgroup tailor support protocol need far use investigate order validate potential valuejatsp jatssec jatssec jatstitleinternational register report identifi irridjatstitle jatsprrjatsp jatssec,0.5265017667844523,0.13427561837455831,0.15901060070671377,0.024734982332155476,141.5,0.0,0.0,1.0,6.0
Information Technology,User Support,Qualitative,Beyond formalized plans: User involvement in support in daily living – users’ and support workers’ experiences,"<jats:sec><jats:title>Background:</jats:title><jats:p> User involvement, based on respect and carried out through dialogue, has been shown to lead to increased self-respect, self-confidence and positive identity. In Sweden, the Social Service Act requires that interventions be designed and implemented together with the individual concerned. The basic criterion for social support is prolonged severe mental illness (usually at least 6 months), with no criteria for specific diagnosis or institutional history. The most common form of social support is ‘support in daily living’, a community care intervention for people aged 18 years or older who have their own homes and living arrangements. </jats:p></jats:sec><jats:sec><jats:title>Aim:</jats:title><jats:p> This article aims to deepen our understanding of user involvement at the individual level in the provision of an ongoing social work intervention. What elements of user involvement can be found in users’ and support workers’ descriptions of helpful support in daily living? </jats:p></jats:sec><jats:sec><jats:title>Method:</jats:title><jats:p> Qualitative interviews were conducted with 18 users, who had experienced support in daily living as helpful, and 16 interviews with the users’ support workers. </jats:p></jats:sec><jats:sec><jats:title>Results:</jats:title><jats:p> Three major, interconnected themes emerged: Constant dialogue; Framing the flexibility, in relation to formalized intervention plans and regulations; The importance of ‘small things’, decisions concerning daily life. </jats:p></jats:sec><jats:sec><jats:title>Conclusion:</jats:title><jats:p> Both users and support workers described user involvement at the individual, micro-level to be an integral part of helpful support in daily living. It was possible to create a space for dialogue and co-creation in which users were involved in formulating and deciding the contents of their support at an informal level, to influence their own everyday lives. While a formal framework of rules, restrictions and plans surrounds meetings between users and professionals, a facilitating factor may be the absence of too detailed plans and regulations, leaving trust to users and professionals and their capacity to manage most of the choices they have to make. </jats:p></jats:sec>",https://doi.org/10.1177/0020764019894603,CrossRef,beyond formalize plan user involvement support daily live user support worker experience,jatssecjatstitlebackgroundjatstitlejatsp user involvement base respect carry dialogue show lead increase selfrespect selfconfidence positive identity sweden social service act require intervention design implement together individual concern basic criterion social support prolong severe mental illness usually least month criterion specific diagnosis institutional history common form social support support daily live community care intervention people age year old home living arrangement jatspjatssecjatssecjatstitleaimjatstitlejatsp article aim deepen understanding user involvement individual level provision ongoing social work intervention element user involvement find user support worker description helpful support daily living jatspjatssecjatssecjatstitlemethodjatstitlejatsp qualitative interview conduct user experience support daily live helpful interview user support worker jatspjatssecjatssecjatstitleresultsjatstitlejatsp three major interconnect theme emerge constant dialogue frame flexibility relation formalize intervention plan regulation importance small thing decision concern daily life jatspjatssecjatssecjatstitleconclusionjatstitlejatsp user support worker describe user involvement individual microlevel integral part helpful support daily live possible create space dialogue cocreation user involve formulate decide content support informal level influence everyday life formal framework rule restriction plan surround meeting user professional facilitating factor may absence detailed plan regulation leave trust user professional capacity manage choice make jatspjatssec,beyond formalize plan user involvement support daily live user support worker experience jatssecjatstitlebackgroundjatstitlejatsp user involvement base respect carry dialogue show lead increase selfrespect selfconfidence positive identity sweden social service act require intervention design implement together individual concern basic criterion social support prolong severe mental illness usually least month criterion specific diagnosis institutional history common form social support support daily live community care intervention people age year old home living arrangement jatspjatssecjatssecjatstitleaimjatstitlejatsp article aim deepen understanding user involvement individual level provision ongoing social work intervention element user involvement find user support worker description helpful support daily living jatspjatssecjatssecjatstitlemethodjatstitlejatsp qualitative interview conduct user experience support daily live helpful interview user support worker jatspjatssecjatssecjatstitleresultsjatstitlejatsp three major interconnect theme emerge constant dialogue frame flexibility relation formalize intervention plan regulation importance small thing decision concern daily life jatspjatssecjatssecjatstitleconclusionjatstitlejatsp user support worker describe user involvement individual microlevel integral part helpful support daily live possible create space dialogue cocreation user involve formulate decide content support informal level influence everyday life formal framework rule restriction plan surround meeting user professional facilitating factor may absence detailed plan regulation leave trust user professional capacity manage choice make jatspjatssec,0.5795454545454546,0.09659090909090909,0.19318181818181818,0.03409090909090909,176.0,0.0,0.0,5.0,2.0
Information Technology,User Support,Qualitative,WEARABLES IN LONG-TERM DEMENTIA RESEARCH: A MIXED METHOD STUDY OF USER EXPERIENCES AND SUPPORT NEEDS,"<jats:title>Abstract</jats:title>
               <jats:p>Passive wearables data collection may be specifically beneficial to aging research featuring dementia populations, who have caregiving and cognitive burdens that can make study participation and reliable data collection more difficult, especially as dementia progresses. This three-phase project aims to inform best practice recommendations to enhance recruitment and adherence in long-term wearables research featuring this population. Based on our systematic review and preliminary in-house data testing, we selected three wearables offering different capabilities and form (from Garmin, Pulse HR, and AngelSense) to test real world usability, data quality, and support needs. This is the first study to recruit persons living with dementia and their caregivers to evaluate multiple devices outside of a laboratory or focus group setting (N=12 dyads). The person living with dementia assented to wearing each wearable for two weeks. Their caregiver rated many facets of each device following its use with the Quebec User Evaluation of Satisfaction with Assistive Technology measure. Open-ended questions and a cumulative semi-structured interview provided context and in-depth comparative perspectives of their experiences in the study. Wearable durability, simplicity, and data availability/monitoring capacity were important to participant favorability and adherence. Technical help and check-ins were also deemed highly valuable. Data indicate how the devices suited the dyads’ needs or caused issues, as well as how study staff could better support ongoing use. Collectively, our findings suggest ideal criteria to guide wearable selection and key protocol factors that can enhance participant recruitment and adherence in long-term dementia research.</jats:p>",https://doi.org/10.1093/geroni/igae098.3187,CrossRef,wearable longterm dementia research mixed method study user experience support need,jatstitleabstractjatstitle jatsppassive wearable data collection may specifically beneficial age research feature dementia population caregive cognitive burden make study participation reliable data collection difficult especially dementia progress threephase project aim inform good practice recommendation enhance recruitment adherence longterm wearable research feature population base systematic review preliminary inhouse datum testing select three wearable offer different capability form garmin pulse angelsense test real world usability datum quality support need first study recruit person live dementia caregiver evaluate multiple device outside laboratory focus group set dyad person live dementia assent wear wearable two week caregiver rate many facet device follow use quebec user evaluation satisfaction assistive technology measure openende question cumulative semistructure interview provide context indepth comparative perspective experience study wearable durability simplicity datum availabilitymonitoring capacity important participant favorability adherence technical help checkin also deem highly valuable datum indicate device suit dyad need cause issue well study staff could well support ongoing use collectively finding suggest ideal criterion guide wearable selection key protocol factor enhance participant recruitment adherence longterm dementia researchjatsp,wearable longterm dementia research mixed method study user experience support need jatstitleabstractjatstitle jatsppassive wearable data collection may specifically beneficial age research feature dementia population caregive cognitive burden make study participation reliable data collection difficult especially dementia progress threephase project aim inform good practice recommendation enhance recruitment adherence longterm wearable research feature population base systematic review preliminary inhouse datum testing select three wearable offer different capability form garmin pulse angelsense test real world usability datum quality support need first study recruit person live dementia caregiver evaluate multiple device outside laboratory focus group set dyad person live dementia assent wear wearable two week caregiver rate many facet device follow use quebec user evaluation satisfaction assistive technology measure openende question cumulative semistructure interview provide context indepth comparative perspective experience study wearable durability simplicity datum availabilitymonitoring capacity important participant favorability adherence technical help checkin also deem highly valuable datum indicate device suit dyad need cause issue well study staff could well support ongoing use collectively finding suggest ideal criterion guide wearable selection key protocol factor enhance participant recruitment adherence longterm dementia researchjatsp,0.5568862275449101,0.09580838323353294,0.19161676646706588,0.041916167664670656,167.0,1.0,0.0,1.0,0.0
Information Technology,User Support,Qualitative,Analyzing User Costs In a Hospital: Methodological Implication of Space Syntax to Support Whole-life Target Value Design,"<jats:p>Research Hypothesis:  H1: Space Syntax analysis can be used to simulate a user’s experience and movement for investigating design alternatives in the design of healthcare facilities.  H2: Space Syntax can efficiently be used to support Whole-life Target Value Design (TVD).  Purpose: This paper investigates a methodological implication of Space Syntax to Whole- life TVD in the design of healthcare facilities.  Research Design/Method: Three hypothetical hospital ward design alternatives are selected – shallow-plan, deep-plan, and courtyard-plan type – to analyze user costs in hospital design to determine which alternative is the most cost-efficient. These three hypothetical design alternatives are evaluated using a Space Syntax program, and then the findings are interpreted to determine user costs.  Findings: The study finds that the deep-plan type has four “low” scores, the shallow-plan type has three “high” and one “medium” score, and the courtyard type has two “high” scores and two “medium” scores. Thus, the deep-plan type is determined to be the lowest user cost type, and the shallow-plan type is expected to have the highest user costs.  Limitations: User costs are discussed in qualitative basis such as high, medium, or low with proportion to the simulation due to the lack of empirical evidence in financial value.  Implications: Space Syntax assures valid results of spatial analysis in relation to users’ movement within the built environment.  Value for practitioners: Space Syntax allows designers to visually compare design alternatives relating to space planning during set-based design using spatial analysis applications.</jats:p>",https://doi.org/10.60164/a7g7i1d4c,CrossRef,analyze user cost hospital methodological implication space syntax support wholelife target value design,jatspresearch hypothesis space syntax analysis use simulate user experience movement investigate design alternative design healthcare facility space syntax efficiently use support wholelife target value design tvd purpose paper investigate methodological implication space syntax whole life tvd design healthcare facility research designmethod three hypothetical hospital ward design alternative select shallowplan deepplan courtyardplan type analyze user cost hospital design determine alternative costefficient three hypothetical design alternative evaluate use space syntax program finding interpret determine user cost finding study find deepplan type four low score shallowplan type three high one medium score courtyard type two high score two medium score thus deepplan type determined low user cost type shallowplan type expect high user cost limitation user cost discuss qualitative basis high medium low proportion simulation due lack empirical evidence financial value implication space syntax assure valid result spatial analysis relation user movement within build environment value practitioner space syntax allow designer visually compare design alternative relate space planning setbase design use spatial analysis applicationsjatsp,analyze user cost hospital methodological implication space syntax support wholelife target value design jatspresearch hypothesis space syntax analysis use simulate user experience movement investigate design alternative design healthcare facility space syntax efficiently use support wholelife target value design tvd purpose paper investigate methodological implication space syntax whole life tvd design healthcare facility research designmethod three hypothetical hospital ward design alternative select shallowplan deepplan courtyardplan type analyze user cost hospital design determine alternative costefficient three hypothetical design alternative evaluate use space syntax program finding interpret determine user cost finding study find deepplan type four low score shallowplan type three high one medium score courtyard type two high score two medium score thus deepplan type determined low user cost type shallowplan type expect high user cost limitation user cost discuss qualitative basis high medium low proportion simulation due lack empirical evidence financial value implication space syntax assure valid result spatial analysis relation user movement within build environment value practitioner space syntax allow designer visually compare design alternative relate space planning setbase design use spatial analysis applicationsjatsp,0.5900621118012422,0.11180124223602485,0.17391304347826086,0.018633540372670808,161.0,1.0,0.0,0.0,0.0
Information Technology,User Support,Mixed Methods,"Reaction or Speculation: Building Computational Support for Users in
  Catching-Up Series Based on an Emerging Media Consumption Phenomenon","A growing number of people are using catch-up TV services rather than
watching simultaneously with other audience members at the time of broadcast.
However, computational support for such catching-up users has not been well
explored. In particular, we are observing an emerging phenomenon in online
media consumption experiences in which speculation plays a vital role. As the
phenomenon of speculation implicitly assumes simultaneity in media consumption,
there is a gap for catching-up users, who cannot directly appreciate the
consumption experiences. This conversely suggests that there is potential for
computational support to enhance the consumption experiences of catching-up
users. Accordingly, we conducted a series of studies to pave the way for
developing computational support for catching-up users. First, we conducted
semi-structured interviews to understand how people are engaging with
speculation during media consumption. As a result, we discovered the
distinctive aspects of speculation-based consumption experiences in contrast to
social viewing experiences sharing immediate reactions that have been discussed
in previous studies. We then designed two prototypes for supporting catching-up
users based on our quantitative analysis of Twitter data in regard to reaction-
and speculation-based media consumption. Lastly, we evaluated the prototypes in
a user experiment and, based on its results, discussed ways to empower
catching-up users with computational supports in response to recent
transformations in media consumption.",http://arxiv.org/abs/2102.06422v1,arXiv,reaction speculation build computational support user catchingup series base emerge medium consumption phenomenon,grow number people use catchup service rather watch simultaneously audience member time broadcast however computational support catchingup user well explore particular observe emerge phenomenon online medium consumption experience speculation play vital role phenomenon speculation implicitly assume simultaneity media consumption gap catchingup user directly appreciate consumption experience conversely suggest potential computational support enhance consumption experience catchingup user accordingly conduct series study pave way develop computational support catchingup user first conduct semistructure interview understand people engage speculation media consumption result discover distinctive aspect speculationbase consumption experience contrast social viewing experience share immediate reaction discuss previous study design two prototype support catchingup user base quantitative analysis twitter datum regard reaction speculationbase medium consumption lastly evaluate prototype user experiment base result discuss way empower catchingup user computational support response recent transformation media consumption,reaction speculation build computational support user catchingup series base emerge medium consumption phenomenon grow number people use catchup service rather watch simultaneously audience member time broadcast however computational support catchingup user well explore particular observe emerge phenomenon online medium consumption experience speculation play vital role phenomenon speculation implicitly assume simultaneity media consumption gap catchingup user directly appreciate consumption experience conversely suggest potential computational support enhance consumption experience catchingup user accordingly conduct series study pave way develop computational support catchingup user first conduct semistructure interview understand people engage speculation media consumption result discover distinctive aspect speculationbase consumption experience contrast social viewing experience share immediate reaction discuss previous study design two prototype support catchingup user base quantitative analysis twitter datum regard reaction speculationbase medium consumption lastly evaluate prototype user experiment base result discuss way empower catchingup user computational support response recent transformation media consumption,0.6046511627906976,0.15503875968992248,0.10852713178294573,0.06976744186046512,129.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Mixed Methods,"Questionnaires and Qualitative Feedback Methods to Measure User
  Experience in Mixed Reality","Evaluating the user experience of a software system is an essential final
step of every research. Several concepts such as flow, affective state,
presences, or immersion exist to measure user experience. Typical measurement
techniques analyze physiological data, gameplay data, and questionnaires.
Qualitative feedback methods are another approach to collect detailed user
insights. In this position paper, we will discuss how we used questionnaires
and qualitative feedback methods in previous mixed reality work to measure user
experience. We will present several measurement examples, discuss their current
limitations, and provide guideline propositions to support comparable mixed
reality user experience research in the future.",http://arxiv.org/abs/2104.06221v1,arXiv,questionnaire qualitative feedback method measure user experience mixed reality,evaluate user experience software system essential final step every research several concept flow affective state presence immersion exist measure user experience typical measurement technique analyze physiological data gameplay datum questionnaire qualitative feedback method another approach collect detailed user insight position paper discuss use questionnaire qualitative feedback method previous mixed reality work measure user experience present several measurement example discuss current limitation provide guideline proposition support comparable mixed reality user experience research future,questionnaire qualitative feedback method measure user experience mixed reality evaluate user experience software system essential final step every research several concept flow affective state presence immersion exist measure user experience typical measurement technique analyze physiological data gameplay datum questionnaire qualitative feedback method another approach collect detailed user insight position paper discuss use questionnaire qualitative feedback method previous mixed reality work measure user experience present several measurement example discuss current limitation provide guideline proposition support comparable mixed reality user experience research future,0.6666666666666666,0.08333333333333333,0.2222222222222222,0.0,72.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Mixed Methods,A Framework To Improve User Story Sets Through Collaboration,"Agile methodologies have become increasingly popular in recent years. Due to
its inherent nature, agile methodologies involve stakeholders with a wide range
of expertise and require interaction between them, relying on collaboration and
customer involvement. Hence, agile methodologies encourage collaboration
between all team members so that more efficient and effective processes are
maintained. Generating requirements can be challenging, as it requires the
participation of multiple stakeholders who describe various aspects of the
project and possess a shared understanding of essential concepts. One simple
method for capturing requirements using natural language is through user
stories, which document the agreed-upon properties of a project. Stakeholders
try to strive for completeness while generating user stories, but the final
user story set may still be flawed. To address this issue, we propose SCOUT:
Supporting Completeness of User Story Sets, which employs a natural language
processing pipeline to extract key concepts from user stories and construct a
knowledge graph by connecting related terms. The knowledge graph and different
heuristics are then utilized to enhance the quality and completeness of the
user story sets by generating suggestions for the stakeholders. We perform a
user study to evaluate SCOUT and demonstrate its performance in constructing
user stories. The quantitative and qualitative results indicate that SCOUT
significantly enhance the quality and completeness of the user story sets. Our
contribution is threefold. First, we develop heuristics to suggest new concepts
to include in user stories by considering both the individuals' and other team
members' contributions. Second, we implement an open-source collaborative tool
to support writing user stories and ensuring their quality. Third, we share the
experimental setup and materials.",http://arxiv.org/abs/2301.10070v1,arXiv,framework improve user story set collaboration,agile methodology become increasingly popular recent year due inherent nature agile methodology involve stakeholder wide range expertise require interaction rely collaboration customer involvement hence agile methodology encourage collaboration team member efficient effective process maintain generating requirement challenging require participation multiple stakeholder describe various aspect project possess share understanding essential concept one simple method capturing requirement use natural language user story document agreedupon property project stakeholder try strive completeness generate user story final user story set may still flawed address issue propose scout support completeness user story set employ natural language processing pipeline extract key concept user story construct knowledge graph connect relate term knowledge graph different heuristic utilize enhance quality completeness user story set generate suggestion stakeholder perform user study evaluate scout demonstrate performance construct user story quantitative qualitative result indicate scout significantly enhance quality completeness user story set contribution threefold first develop heuristic suggest new concept include user story consider individual team member contribution second implement opensource collaborative tool support writing user story ensure quality third share experimental setup material,framework improve user story set collaboration agile methodology become increasingly popular recent year due inherent nature agile methodology involve stakeholder wide range expertise require interaction rely collaboration customer involvement hence agile methodology encourage collaboration team member efficient effective process maintain generating requirement challenging require participation multiple stakeholder describe various aspect project possess share understanding essential concept one simple method capturing requirement use natural language user story document agreedupon property project stakeholder try strive completeness generate user story final user story set may still flawed address issue propose scout support completeness user story set employ natural language processing pipeline extract key concept user story construct knowledge graph connect relate term knowledge graph different heuristic utilize enhance quality completeness user story set generate suggestion stakeholder perform user study evaluate scout demonstrate performance construct user story quantitative qualitative result indicate scout significantly enhance quality completeness user story set contribution threefold first develop heuristic suggest new concept include user story consider individual team member contribution second implement opensource collaborative tool support writing user story ensure quality third share experimental setup material,0.5380116959064327,0.2046783625730994,0.16374269005847952,0.04093567251461988,171.0,0.0,0.0,1.0,0.0
Information Technology,User Support,Mixed Methods,"Exploring User Acceptance Of Portable Intelligent Personal Assistants: A
  Hybrid Approach Using PLS-SEM And fsQCA","This research explores the factors driving user acceptance of Rabbit R1, a
newly developed portable intelligent personal assistant (PIPA) that aims to
redefine user interaction and control. The study extends the technology
acceptance model (TAM) by incorporating artificial intelligence-specific
factors (conversational intelligence, task intelligence, and perceived
naturalness), user interface design factors (simplicity in information design
and visual aesthetics), and user acceptance and loyalty. Using a purposive
sampling method, we gathered data from 824 users in the US and analyzed the
sample through partial least squares structural equation modeling (PLS-SEM) and
fuzzy set qualitative comparative analysis (fsQCA). The findings reveal that
all hypothesized relationships, including both direct and indirect effects, are
supported. Additionally, fsQCA supports the PLS-SEM findings and identifies
three configurations leading to high and low user acceptance. This research
enriches the literature and provides valuable insights for system designers and
marketers of PIPAs, guiding strategic decisions to foster widespread adoption
and long-term engagement.",http://arxiv.org/abs/2408.17119v1,arXiv,explore user acceptance portable intelligent personal assistant hybrid approach use plssem fsqca,research explore factor drive user acceptance rabbit newly develop portable intelligent personal assistant pipa aim redefine user interaction control study extend technology acceptance model tam incorporate artificial intelligencespecific factor conversational intelligence task intelligence perceive naturalness user interface design factor simplicity information design visual aesthetic user acceptance loyalty use purposive sampling method gather datum user analyze sample partial least square structural equation modeling plssem fuzzy set qualitative comparative analysis fsqca finding reveal hypothesize relationship include direct indirect effect support additionally fsqca support plssem finding identifie three configuration lead high low user acceptance research enrich literature provide valuable insight system designer marketer pipa guide strategic decision foster widespread adoption longterm engagement,explore user acceptance portable intelligent personal assistant hybrid approach use plssem fsqca research explore factor drive user acceptance rabbit newly develop portable intelligent personal assistant pipa aim redefine user interaction control study extend technology acceptance model tam incorporate artificial intelligencespecific factor conversational intelligence task intelligence perceive naturalness user interface design factor simplicity information design visual aesthetic user acceptance loyalty use purposive sampling method gather datum user analyze sample partial least square structural equation modeling plssem fuzzy set qualitative comparative analysis fsqca finding reveal hypothesize relationship include direct indirect effect support additionally fsqca support plssem finding identifie three configuration lead high low user acceptance research enrich literature provide valuable insight system designer marketer pipa guide strategic decision foster widespread adoption longterm engagement,0.5596330275229358,0.11926605504587157,0.21100917431192662,0.027522935779816515,109.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Mixed Methods,"PromptCharm: Text-to-Image Generation through Multi-modal Prompting and
  Refinement","The recent advancements in Generative AI have significantly advanced the
field of text-to-image generation. The state-of-the-art text-to-image model,
Stable Diffusion, is now capable of synthesizing high-quality images with a
strong sense of aesthetics. Crafting text prompts that align with the model's
interpretation and the user's intent thus becomes crucial. However, prompting
remains challenging for novice users due to the complexity of the stable
diffusion model and the non-trivial efforts required for iteratively editing
and refining the text prompts. To address these challenges, we propose
PromptCharm, a mixed-initiative system that facilitates text-to-image creation
through multi-modal prompt engineering and refinement. To assist novice users
in prompting, PromptCharm first automatically refines and optimizes the user's
initial prompt. Furthermore, PromptCharm supports the user in exploring and
selecting different image styles within a large database. To assist users in
effectively refining their prompts and images, PromptCharm renders model
explanations by visualizing the model's attention values. If the user notices
any unsatisfactory areas in the generated images, they can further refine the
images through model attention adjustment or image inpainting within the rich
feedback loop of PromptCharm. To evaluate the effectiveness and usability of
PromptCharm, we conducted a controlled user study with 12 participants and an
exploratory user study with another 12 participants. These two studies show
that participants using PromptCharm were able to create images with higher
quality and better aligned with the user's expectations compared with using two
variants of PromptCharm that lacked interaction or visualization support.",http://arxiv.org/abs/2403.04014v1,arXiv,promptcharm texttoimage generation multimodal prompt refinement,recent advancement generative significantly advance field texttoimage generation stateoftheart texttoimage model stable diffusion capable synthesize highquality image strong sense aesthetic craft text prompt align model interpretation user intent thus become crucial however prompt remain challenge novice user due complexity stable diffusion model nontrivial effort require iteratively editing refine text prompt address challenge propose promptcharm mixedinitiative system facilitate texttoimage creation multimodal prompt engineering refinement assist novice user prompt promptcharm first automatically refine optimize user initial prompt furthermore promptcharm support user explore select different image style within large database assist user effectively refine prompt image promptcharm render model explanation visualize model attention value user notice unsatisfactory area generate image far refine image model attention adjustment image inpainte within rich feedback loop promptcharm evaluate effectiveness usability promptcharm conduct control user study participant exploratory user study another participant two study show participant use promptcharm able create image high quality well align user expectation compare use two variant promptcharm lack interaction visualization support,promptcharm texttoimage generation multimodal prompt refinement recent advancement generative significantly advance field texttoimage generation stateoftheart texttoimage model stable diffusion capable synthesize highquality image strong sense aesthetic craft text prompt align model interpretation user intent thus become crucial however prompt remain challenge novice user due complexity stable diffusion model nontrivial effort require iteratively editing refine text prompt address challenge propose promptcharm mixedinitiative system facilitate texttoimage creation multimodal prompt engineering refinement assist novice user prompt promptcharm first automatically refine optimize user initial prompt furthermore promptcharm support user explore select different image style within large database assist user effectively refine prompt image promptcharm render model explanation visualize model attention value user notice unsatisfactory area generate image far refine image model attention adjustment image inpainte within rich feedback loop promptcharm evaluate effectiveness usability promptcharm conduct control user study participant exploratory user study another participant two study show participant use promptcharm able create image high quality well align user expectation compare use two variant promptcharm lack interaction visualization support,0.5759493670886076,0.10759493670886076,0.1518987341772152,0.06962025316455696,158.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Design and Development,Theory-based habit modeling for enhancing behavior prediction in behavior change support systems,"<jats:title>Abstract</jats:title><jats:p>Psychological theories of habit posit that when a strong habit is formed through behavioral repetition, it can trigger behavior automatically in the same environment. Given the reciprocal relationship between habit and behavior, changing lifestyle behaviors is largely a task of breaking old habits and creating new and healthy ones. Thus, representing users’ habit strengths can be very useful for behavior change support systems, for example, to predict behavior or to decide when an intervention reaches its intended effect. However, habit strength is not directly observable and existing self-report measures are taxing for users. In this paper, building on recent computational models of habit formation, we propose a method to enable intelligent systems to compute habit strength based on observable behavior. The hypothesized advantage of using computed habit strength for behavior prediction was tested using data from two intervention studies on dental behavior change (<jats:inline-formula><jats:alternatives><jats:tex-math>$$N = 36$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>36</mml:mn></mml:mrow></mml:math></jats:alternatives></jats:inline-formula>and<jats:inline-formula><jats:alternatives><jats:tex-math>$$N = 75$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:math></jats:alternatives></jats:inline-formula>), where we instructed participants to brush their teeth twice a day for three weeks and monitored their behaviors using accelerometers. The results showed that for the task of predicting future brushing behavior, the theory-based model that computed habit strength achieved an accuracy of 68.6% (Study 1) and 76.1% (Study 2), which outperformed the model that relied on self-reported behavioral determinants but showed no advantage over models that relied on past behavior. We discuss the implications of our results for research on behavior change support systems and habit formation.</jats:p>",https://doi.org/10.1007/s11257-022-09326-x,CrossRef,theorybase habit modeling enhance behavior prediction behavior change support system,jatstitleabstractjatstitlejatsppsychological theory habit posit strong habit form behavioral repetition trigger behavior automatically environment give reciprocal relationship habit behavior change lifestyle behavior largely task break old habit create new healthy one thus represent user habit strength useful behavior change support system example predict behavior decide intervention reach intended effect however habit strength directly observable exist selfreport measure tax user paper building recent computational model habit formation propose method enable intelligent system compute habit strength base observable behavior hypothesize advantage use computed habit strength behavior prediction test use datum two intervention study dental behavior change jatsinlineformulajatsalternativesjatstexmathn jatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmrowmmlminmmlmimmlmommlmommlmnmmlmnmmlmrowmmlmathjatsalternativesjatsinlineformulaandjatsinlineformulajatsalternativesjatstexmathn jatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmrowmmlminmmlmimmlmommlmommlmnmmlmnmmlmrowmmlmathjatsalternativesjatsinlineformula instruct participant brush tooth twice day three week monitor behavior use accelerometer result show task predict future brushing behavior theorybased model compute habit strength achieve accuracy study study outperform model rely selfreporte behavioral determinant show advantage model rely past behavior discuss implication result research behavior change support system habit formationjatsp,theorybase habit modeling enhance behavior prediction behavior change support system jatstitleabstractjatstitlejatsppsychological theory habit posit strong habit form behavioral repetition trigger behavior automatically environment give reciprocal relationship habit behavior change lifestyle behavior largely task break old habit create new healthy one thus represent user habit strength useful behavior change support system example predict behavior decide intervention reach intended effect however habit strength directly observable exist selfreport measure tax user paper building recent computational model habit formation propose method enable intelligent system compute habit strength base observable behavior hypothesize advantage use computed habit strength behavior prediction test use datum two intervention study dental behavior change jatsinlineformulajatsalternativesjatstexmathn jatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmrowmmlminmmlmimmlmommlmommlmnmmlmnmmlmrowmmlmathjatsalternativesjatsinlineformulaandjatsinlineformulajatsalternativesjatstexmathn jatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathmlmmlmrowmmlminmmlmimmlmommlmommlmnmmlmnmmlmrowmmlmathjatsalternativesjatsinlineformula instruct participant brush tooth twice day three week monitor behavior use accelerometer result show task predict future brushing behavior theorybased model compute habit strength achieve accuracy study study outperform model rely selfreporte behavioral determinant show advantage model rely past behavior discuss implication result research behavior change support system habit formationjatsp,0.5540540540540541,0.14864864864864866,0.12162162162162163,0.04054054054054054,148.0,1.0,1.0,1.0,0.0
Information Technology,User Support,Design and Development,Personalized home-care support for the elderly: a field experience with a social robot at home,"<jats:title>Abstract</jats:title><jats:p>Socially assistive robotics (SAR) is getting a lot of attention for its potential in assisting elderly users. However, for robotic assistive applications to be effective, they need to satisfy the particular needs of each user and be well perceived. For this purpose, a personalization based on user’s characteristics such as personality and cognitive profile, and their dynamic changes is a crucial factor. Moreover, most of the existing solutions rely on the availability of specific technological infrastructures, generally requiring high economic investment, and that cannot be easily placed in different environments. Personalization and adaptation of assistive robotics applications to different user’s characteristics and needs, and even to different technological environments, are still not fully addressed in real environments. In the present work, the results of the UPA4SAR project are presented. The project aimed at providing a social robotic system to deliver assistive tasks for home care of patients with mild cognitive impairment in a personalized and adaptive way. We introduce the general architecture of the system and the developed robotic behaviors. Personalization and dynamic adaptation of assistive tasks are realized using a service-oriented approach by taking into account both user’s characteristics and environmental dynamic conditions. Field experimentation of the project was carried out with 7 patients, using the robotic system autonomously running in their homes for a total of 118 days. Results showed a reliable functioning of the proposed robotic system, a generally positive reaction, and a good acceptability rate from patients.</jats:p>",https://doi.org/10.1007/s11257-022-09333-y,CrossRef,personalize homecare support elderly field experience social robot home,jatstitleabstractjatstitlejatspsocially assistive robotic sar get lot attention potential assist elderly user however robotic assistive application effective need satisfy particular need user well perceive purpose personalization base user characteristic personality cognitive profile dynamic change crucial factor moreover exist solution rely availability specific technological infrastructure generally require high economic investment easily place different environment personalization adaptation assistive robotic application different user characteristic need even different technological environment still fully address real environment present work result upasar project present project aim provide social robotic system deliver assistive task home care patient mild cognitive impairment personalized adaptive way introduce general architecture system develop robotic behavior personalization dynamic adaptation assistive task realize use serviceoriente approach take account user characteristic environmental dynamic condition field experimentation project carry patient use robotic system autonomously run home total day result show reliable functioning propose robotic system generally positive reaction good acceptability rate patientsjatsp,personalize homecare support elderly field experience social robot home jatstitleabstractjatstitlejatspsocially assistive robotic sar get lot attention potential assist elderly user however robotic assistive application effective need satisfy particular need user well perceive purpose personalization base user characteristic personality cognitive profile dynamic change crucial factor moreover exist solution rely availability specific technological infrastructure generally require high economic investment easily place different environment personalization adaptation assistive robotic application different user characteristic need even different technological environment still fully address real environment present work result upasar project present project aim provide social robotic system deliver assistive task home care patient mild cognitive impairment personalized adaptive way introduce general architecture system develop robotic behavior personalization dynamic adaptation assistive task realize use serviceoriente approach take account user characteristic environmental dynamic condition field experimentation project carry patient use robotic system autonomously run home total day result show reliable functioning propose robotic system generally positive reaction good acceptability rate patientsjatsp,0.4791666666666667,0.125,0.3194444444444444,0.0763888888888889,144.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Design and Development,Using scaffolding to formalize digital coach support for low-literate learners,"<jats:title>Abstract</jats:title><jats:p>In this study, we attempt to specify the cognitive support behavior of a previously designed embodied conversational agent coach that provides learning support to low-literates. Three knowledge gaps are identified in the existing work: an incomplete specification of the behaviors that make up ‘support,’ an incomplete specification of how this support can be personalized, and unclear speech recognition rules. We use the socio-cognitive engineering method to update our foundation of knowledge with new online banking exercises, low-level scaffolding and user modeling theory, and speech recognition. We then refine the design of our coach agent by creating comprehensive cognitive support rules that adapt support based on learner needs (the ‘Generalized’ approach) and attune the coach’s support delay to user performance in previous exercises (the ‘Individualized’ approach). A prototype is evaluated in a 3-week within- and between-subjects experiment. Results show that the specified cognitive support is effective: Learners complete all exercises, interact meaningfully with the coach, and improve their online banking self-efficacy. Counter to hypotheses, the Individualized approach does not improve on the Generalized approach. Whether this indicates suboptimal operationalization or a deeper problem with the Individualized approach remains as future work.</jats:p>",https://doi.org/10.1007/s11257-020-09278-0,CrossRef,use scaffold formalize digital coach support lowliterate learner,jatstitleabstractjatstitlejatspin study attempt specify cognitive support behavior previously design embody conversational agent coach provide learn support lowliterate three knowledge gap identify exist work incomplete specification behavior make support incomplete specification support personalize unclear speech recognition rule use sociocognitive engineering method update foundation knowledge new online banking exercise lowlevel scaffolding user modeling theory speech recognition refine design coach agent create comprehensive cognitive support rule adapt support base learner need generalized approach attune coach support delay user performance previous exercise individualized approach prototype evaluate week within betweensubject experiment result show specify cognitive support effective learner complete exercise interact meaningfully coach improve online banking selfefficacy counter hypothesis individualized approach improve generalized approach whether indicate suboptimal operationalization deep problem individualized approach remain future workjatsp,use scaffold formalize digital coach support lowliterate learner jatstitleabstractjatstitlejatspin study attempt specify cognitive support behavior previously design embody conversational agent coach provide learn support lowliterate three knowledge gap identify exist work incomplete specification behavior make support incomplete specification support personalize unclear speech recognition rule use sociocognitive engineering method update foundation knowledge new online banking exercise lowlevel scaffolding user modeling theory speech recognition refine design coach agent create comprehensive cognitive support rule adapt support base learner need generalized approach attune coach support delay user performance previous exercise individualized approach prototype evaluate week within betweensubject experiment result show specify cognitive support effective learner complete exercise interact meaningfully coach improve online banking selfefficacy counter hypothesis individualized approach improve generalized approach whether indicate suboptimal operationalization deep problem individualized approach remain future workjatsp,0.5083333333333333,0.2,0.2,0.016666666666666666,120.0,1.0,0.0,1.0,0.0
Information Technology,User Support,Design and Development,“Tell Me Why”: using natural language justifications in a recipe recommender system to support healthier food choices,"<jats:title>Abstract</jats:title><jats:p>Users of online recipe websites tend to prefer unhealthy foods. Their popularity undermines the healthiness of traditional food recommender systems, as many users lack nutritional knowledge to make informed food decisions. Moreover, the presented information is often unrelated to nutrition or difficult to understand. To alleviate this, we present a methodology to generate natural language justifications that emphasize the nutritional content, health risks, or benefits of recommended recipes. Our framework takes a user and two recipes as input and produces an automatically generated natural language justification as output, based on the user’s characteristics and the recipes’ features, following a knowledge-based recommendation approach. We evaluated our methodology in two crowdsourcing studies. In Study 1 (<jats:inline-formula><jats:alternatives><jats:tex-math>$$N=502$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>502</mml:mn>
                  </mml:mrow>
                </mml:math></jats:alternatives></jats:inline-formula>), we compared user food choices for two personalized recommendation approaches, based on either a (1) single-style justification or (2) comparative justification was shown, using a no justification baseline. The recommendations were either popularity-based or health-aware, the latter based on the health and nutritional needs of the user. We found that comparative justification styles were effective in supporting choices for our health-aware recommendations, confirming the impact of our methodology on food choices. In Study 2 (<jats:inline-formula><jats:alternatives><jats:tex-math>$$N=504$$</jats:tex-math><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"">
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>504</mml:mn>
                  </mml:mrow>
                </mml:math></jats:alternatives></jats:inline-formula>), we used the same methodology to compare the effectiveness of eight different comparative justification strategies. We presented pairs of recipes twice to users: once <jats:italic>without</jats:italic> and once <jats:italic>with</jats:italic> a pairwise justification. Results indicated that justifications led to significantly healthier choices for first course meals, while strategies that compared food features and emphasized health risks, benefits, and a user’s lifestyle were most effective, catering to health-related choice motivations.
</jats:p>",https://doi.org/10.1007/s11257-023-09377-8,CrossRef,tell use natural language justification recipe recommender system support healthy food choice,jatstitleabstractjatstitlejatspuser online recipe website tend prefer unhealthy food popularity undermine healthiness traditional food recommender system many user lack nutritional knowledge make informed food decision moreover present information often unrelated nutrition difficult understand alleviate present methodology generate natural language justification emphasize nutritional content health risk benefit recommend recipe framework take user two recipe input produce automatically generate natural language justification output base user characteristic recipe feature follow knowledgebase recommendation approach evaluate methodology two crowdsource study study jatsinlineformulajatsalternativesjatstexmathnjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathml mmlmrow mmlminmmlmi mmlmommlmo mmlmnmmlmn mmlmrow mmlmathjatsalternativesjatsinlineformula compare user food choice two personalize recommendation approach base either singlestyle justification comparative justification show use justification baseline recommendation either popularitybase healthaware latter base health nutritional need user find comparative justification style effective support choice healthaware recommendation confirm impact methodology food choice study jatsinlineformulajatsalternativesjatstexmathnjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathml mmlmrow mmlminmmlmi mmlmommlmo mmlmnmmlmn mmlmrow mmlmathjatsalternativesjatsinlineformula use methodology compare effectiveness eight different comparative justification strategy present pair recipe twice user jatsitalicwithoutjatsitalic jatsitalicwithjatsitalic pairwise justification result indicate justification lead significantly healthy choice first course meal strategy compare food feature emphasize health risk benefit user lifestyle effective catering healthrelate choice motivation jatsp,tell use natural language justification recipe recommender system support healthy food choice jatstitleabstractjatstitlejatspuser online recipe website tend prefer unhealthy food popularity undermine healthiness traditional food recommender system many user lack nutritional knowledge make informed food decision moreover present information often unrelated nutrition difficult understand alleviate present methodology generate natural language justification emphasize nutritional content health risk benefit recommend recipe framework take user two recipe input produce automatically generate natural language justification output base user characteristic recipe feature follow knowledgebase recommendation approach evaluate methodology two crowdsource study study jatsinlineformulajatsalternativesjatstexmathnjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathml mmlmrow mmlminmmlmi mmlmommlmo mmlmnmmlmn mmlmrow mmlmathjatsalternativesjatsinlineformula compare user food choice two personalize recommendation approach base either singlestyle justification comparative justification show use justification baseline recommendation either popularitybase healthaware latter base health nutritional need user find comparative justification style effective support choice healthaware recommendation confirm impact methodology food choice study jatsinlineformulajatsalternativesjatstexmathnjatstexmathmmlmath xmlnsmmlhttpwwwworgmathmathml mmlmrow mmlminmmlmi mmlmommlmo mmlmnmmlmn mmlmrow mmlmathjatsalternativesjatsinlineformula use methodology compare effectiveness eight different comparative justification strategy present pair recipe twice user jatsitalicwithoutjatsitalic jatsitalicwithjatsitalic pairwise justification result indicate justification lead significantly healthy choice first course meal strategy compare food feature emphasize health risk benefit user lifestyle effective catering healthrelate choice motivation jatsp,0.5730337078651685,0.1348314606741573,0.1404494382022472,0.028089887640449437,35.6,2.0,2.0,0.0,1.0
Information Technology,User Support,Design and Development,AI-Driven Customer Support: Transforming User Experience and Operational Efficiency,"<jats:p>The integration of artificial intelligence in customer support operations represents a transformative shift in how organizations deliver service and manage customer relationships. This comprehensive article examines how AI technologies, particularly Large Language Models, Case Deflection Systems, and Predictive Suggestion Systems, are revolutionizing traditional support paradigms. The article investigates the impact of AI implementation across multiple dimensions, including operational efficiency, customer satisfaction, cost optimization, and service quality. Through empirical evidence and case studies, this article demonstrates how AI-driven support solutions address traditional challenges while creating new opportunities for enhanced customer engagement. The findings reveal significant improvements in areas such as response time, accuracy, self-service capabilities, and agent productivity, while highlighting the importance of structured implementation approaches and ongoing optimization strategies.</jats:p>",https://doi.org/10.71097/ijsat.v16.i1.2600,CrossRef,aidriven customer support transform user experience operational efficiency,jatspthe integration artificial intelligence customer support operation represent transformative shift organization deliver service manage customer relationship comprehensive article examine technology particularly large language model case deflection system predictive suggestion system revolutionize traditional support paradigm article investigate impact implementation across multiple dimension include operational efficiency customer satisfaction cost optimization service quality empirical evidence case study article demonstrate aidriven support solution address traditional challenge create new opportunity enhanced customer engagement finding reveal significant improvement area response time accuracy selfservice capability agent productivity highlight importance structured implementation approach ongoing optimization strategiesjatsp,aidriven customer support transform user experience operational efficiency jatspthe integration artificial intelligence customer support operation represent transformative shift organization deliver service manage customer relationship comprehensive article examine technology particularly large language model case deflection system predictive suggestion system revolutionize traditional support paradigm article investigate impact implementation across multiple dimension include operational efficiency customer satisfaction cost optimization service quality empirical evidence case study article demonstrate aidriven support solution address traditional challenge create new opportunity enhanced customer engagement finding reveal significant improvement area response time accuracy selfservice capability agent productivity highlight importance structured implementation approach ongoing optimization strategiesjatsp,0.6704545454545454,0.13636363636363635,0.14772727272727273,0.011363636363636364,88.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Theoretical / Conceptual,Conceptual framework of intelligent decision support based on user digital life traces and ontology-based user categorisation,"<jats:title>Abstract</jats:title>
               <jats:p>The paper presents conceptual framework and information model of intelligent decision support based on traces of user digital lives and ontology-based user categorisation. The conceptual framework defines components that provide information revealed from the traces of user digital lives, generalize this information, and make ontology inference. The information model defines information flows between the components of the conceptual framework. The novelties of this research are grouping users with common preferences and decision making behaviours based on the user digital traces, and context-sensitive ontology-based categorization of users into the user groups.</jats:p>",https://doi.org/10.1088/1742-6596/1801/1/012005,CrossRef,conceptual framework intelligent decision support base user digital life trace ontologybase user categorisation,jatstitleabstractjatstitle jatspthe paper present conceptual framework information model intelligent decision support base trace user digital life ontologybase user categorisation conceptual framework define component provide information reveal trace user digital life generalize information make ontology inference information model define information flow component conceptual framework novelty research group user common preference decision making behaviour base user digital trace contextsensitive ontologybased categorization user user groupsjatsp,conceptual framework intelligent decision support base user digital life trace ontologybase user categorisation jatstitleabstractjatstitle jatspthe paper present conceptual framework information model intelligent decision support base trace user digital life ontologybase user categorisation conceptual framework define component provide information reveal trace user digital life generalize information make ontology inference information model define information flow component conceptual framework novelty research group user common preference decision making behaviour base user digital trace contextsensitive ontologybased categorization user user groupsjatsp,0.6774193548387096,0.11290322580645161,0.12903225806451613,0.0,62.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Theoretical / Conceptual,Making Order in User Experience Research to Support Its Application in Design and Beyond,"<jats:p>The term User Experience (UX) was introduced to define the dynamics of the human-product interaction, and it was thought that design would have been a main recipient of UX research. However, it can be claimed that the outcomes of UX studies were not seamlessly transferred into design research and practice. Among the possible reasons, this paper addresses the fragmentary knowledge ascribable to the field of UX. The authors reviewed the literature analyzing the conceptual contributions that interpret UX, proposing definitions and/or a theoretical framework. This allowed the authors to provide an overview of recurring elements of UX, highlighting their relationships and affecting factors. This research aims to clarify the overall understanding of UX, along with its key components (the user, interaction, the system, and context) and dimensions (ergonomic, affective, and the cognitive experiences). The authors built a semantic construction inspired by the structure of a grammatical sentence to highlight the relationship between those components. Therefore, UX is defined by a subject/user who performs an action-interaction towards an object-system. A complement-context better defines the condition(s) where the action-interaction takes place. This work is expected to lay the foundations for the understanding of approaches and methods employed in UX studies, especially in design.</jats:p>",https://doi.org/10.3390/app11156981,CrossRef,make order user experience research support application design beyond,jatspthe term user experience introduce define dynamic humanproduct interaction think design would main recipient research however claim outcome study seamlessly transfer design research practice among possible reason paper address fragmentary knowledge ascribable field author review literature analyze conceptual contribution interpret propose definition andor theoretical framework allow author provide overview recur element highlight relationship affect factor research aim clarify overall understanding along key component user interaction system context dimension ergonomic affective cognitive experience author build semantic construction inspire structure grammatical sentence highlight relationship component therefore define subjectuser perform actioninteraction towards objectsystem complementcontext well define condition actioninteraction take place work expect lay foundation understanding approach method employ study especially designjatsp,make order user experience research support application design beyond jatspthe term user experience introduce define dynamic humanproduct interaction think design would main recipient research however claim outcome study seamlessly transfer design research practice among possible reason paper address fragmentary knowledge ascribable field author review literature analyze conceptual contribution interpret propose definition andor theoretical framework allow author provide overview recur element highlight relationship affect factor research aim clarify overall understanding along key component user interaction system context dimension ergonomic affective cognitive experience author build semantic construction inspire structure grammatical sentence highlight relationship component therefore define subjectuser perform actioninteraction towards objectsystem complementcontext well define condition actioninteraction take place work expect lay foundation understanding approach method employ study especially designjatsp,0.5740740740740741,0.16666666666666666,0.1388888888888889,0.046296296296296294,108.0,0.0,0.0,0.0,0.0
Information Technology,User Support,Theoretical / Conceptual,User-Centered Evaluation Framework to Support the Interaction Design for Augmented Reality Applications,"<jats:p>The advancement of Augmented Reality (AR) technology has been remarkable, enabling the augmentation of user perception with timely information. This progress holds great promise in the field of interaction design. However, the mere advancement of technology is not enough to ensure widespread adoption. The user dimension has been somewhat overlooked in AR research due to a lack of attention to user motivations, needs, usability, and perceived value. The critical aspects of AR technology tend to be overshadowed by the technology itself. To ensure appropriate future assessments, it is necessary to thoroughly examine and categorize all the methods used for AR technology validation. By identifying and classifying these evaluation methods, researchers and practitioners will be better equipped to develop and validate new AR techniques and applications. Therefore, comprehensive and systematic evaluations are critical to the advancement and sustainability of AR technology. This paper presents a theoretical framework derived from a cluster analysis of the most efficient evaluation methods for AR extracted from 399 papers. Evaluation methods were clustered according to the application domains and the human–computer interaction aspects to be investigated. This framework should facilitate rapid development cycles prioritizing user requirements, ultimately leading to groundbreaking interaction methods accessible to a broader audience beyond research and development centers.</jats:p>",https://doi.org/10.3390/mti8050041,CrossRef,usercentered evaluation framework support interaction design augmented reality application,jatspthe advancement augmented reality technology remarkable enable augmentation user perception timely information progress hold great promise field interaction design however mere advancement technology enough ensure widespread adoption user dimension somewhat overlook research due lack attention user motivation need usability perceive value critical aspect technology tend overshadow technology ensure appropriate future assessment necessary thoroughly examine categorize method use technology validation identify classify evaluation method researcher practitioner well equip develop validate new technique application therefore comprehensive systematic evaluation critical advancement sustainability technology paper present theoretical framework derive cluster analysis efficient evaluation method extract paper evaluation method cluster accord application domain human computer interaction aspect investigate framework facilitate rapid development cycle prioritize user requirement ultimately lead groundbreake interaction method accessible broad audience beyond research development centersjatsp,usercentered evaluation framework support interaction design augmented reality application jatspthe advancement augmented reality technology remarkable enable augmentation user perception timely information progress hold great promise field interaction design however mere advancement technology enough ensure widespread adoption user dimension somewhat overlook research due lack attention user motivation need usability perceive value critical aspect technology tend overshadow technology ensure appropriate future assessment necessary thoroughly examine categorize method use technology validation identify classify evaluation method researcher practitioner well equip develop validate new technique application therefore comprehensive systematic evaluation critical advancement sustainability technology paper present theoretical framework derive cluster analysis efficient evaluation method extract paper evaluation method cluster accord application domain human computer interaction aspect investigate framework facilitate rapid development cycle prioritize user requirement ultimately lead groundbreake interaction method accessible broad audience beyond research development centersjatsp,0.6016260162601627,0.10569105691056911,0.2032520325203252,0.04878048780487805,123.0,1.0,0.0,0.0,0.0
Information Technology,User Support,Theoretical / Conceptual,Geosensors to Support Crop Production: Current Applications and User Requirements,"<jats:p>Sensor technology, which benefits from high temporal measuring resolution, real-time data transfer and high spatial resolution of sensor data that shows in-field variations, has the potential to provide added value for crop production. The present paper explores how sensors and sensor networks have been utilised in the crop production process and what their added-value and the main bottlenecks are from the perspective of users. The focus is on sensor based applications and on requirements that users pose for them. Literature and two use cases were reviewed and applications were classified according to the crop production process: sensing of growth conditions, fertilising, irrigation, plant protection, harvesting and fleet control. The potential of sensor technology was widely acknowledged along the crop production chain. Users of the sensors require easy-to-use and reliable applications that are actionable in crop production at reasonable costs. The challenges are to develop sensor technology, data interoperability and management tools as well as data and measurement services in a way that requirements can be met, and potential benefits and added value can be realized in the farms in terms of higher yields, improved quality of yields, decreased input costs and production risks, and less work time and load.</jats:p>",https://doi.org/10.3390/s110706656,CrossRef,geosensor support crop production current application user requirement,jatspsensor technology benefit high temporal measuring resolution realtime data transfer high spatial resolution sensor datum show infield variation potential provide add value crop production present paper explore sensor sensor network utilise crop production process addedvalue main bottleneck perspective user focus sensor base application requirement user pose literature two use case review application classify accord crop production process sensing growth condition fertilise irrigation plant protection harvesting fleet control potential sensor technology widely acknowledge along crop production chain user sensor require easytouse reliable application actionable crop production reasonable cost challenge develop sensor technology datum interoperability management tool well datum measurement service way requirement meet potential benefit add value realize farm term high yield improve quality yield decrease input cost production risk less work time loadjatsp,geosensor support crop production current application user requirement jatspsensor technology benefit high temporal measuring resolution realtime data transfer high spatial resolution sensor datum show infield variation potential provide add value crop production present paper explore sensor sensor network utilise crop production process addedvalue main bottleneck perspective user focus sensor base application requirement user pose literature two use case review application classify accord crop production process sensing growth condition fertilise irrigation plant protection harvesting fleet control potential sensor technology widely acknowledge along crop production chain user sensor require easytouse reliable application actionable crop production reasonable cost challenge develop sensor technology datum interoperability management tool well datum measurement service way requirement meet potential benefit add value realize farm term high yield improve quality yield decrease input cost production risk less work time loadjatsp,0.6747967479674797,0.13821138211382114,0.10569105691056911,0.008130081300813009,123.0,1.0,0.0,0.0,0.0
Information Technology,User Support,Theoretical / Conceptual,Transfer climate in end‐user computing,"<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>Although end‐user computing (EUC) training has received significant attention among academics and practitioners, the effective transfer of trained EUC skills is a relatively neglected issue. Analysis of factors affecting the EUC transfer process will aid in understanding and improving training transfer. Hence, the purpose of this paper is to underscore key trainee characteristics and facets of the work environment that influence EUC training transfer.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>The theoretical framework includes prior computer experience, computer anxiety, computer self‐efficacy, pre‐training motivation and perceived job utility as significant trainee factors influencing the EUC transfer process. In addition, the model includes supervisory support as an important constituent of the EUC transfer process.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>The model highlights the mediating roles of computer self‐efficacy and pre‐training motivation in predicting motivation to transfer. In addition, it points out that several factors work simultaneously to influence motivation to transfer EUC training.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>Supervisory support in the pre‐ and post‐training environment is extremely crucial in determining EUC training success. Specifically, supervisors should be able to communicate to employees the purpose and importance of training, the relevance of computer training to their jobs and the outcomes expected.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>This paper contributes to the literature by emphasizing the importance of supervisory support and individual characteristics in predicting motivation to transfer.</jats:p></jats:sec>",https://doi.org/10.1108/09727980910972181,CrossRef,transfer climate computing,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspalthough computing euc training receive significant attention among academic practitioner effective transfer train euc skill relatively neglect issue analysis factor affect euc transfer process aid understanding improve training transfer hence purpose paper underscore key trainee characteristic facet work environment influence euc training transferjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe theoretical framework include prior computer experience computer anxiety computer motivation perceive job utility significant trainee factor influence euc transfer process addition model include supervisory support important constituent euc transfer processjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthe model highlight mediating role computer motivation predict motivation transfer addition point several factor work simultaneously influence motivation transfer euc trainingjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspsupervisory support environment extremely crucial determine euc training success specifically supervisor able communicate employee purpose importance train relevance computer training job outcome expectedjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis paper contribute literature emphasize importance supervisory support individual characteristic predict motivation transferjatspjatssec,transfer climate computing jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspalthough computing euc training receive significant attention among academic practitioner effective transfer train euc skill relatively neglect issue analysis factor affect euc transfer process aid understanding improve training transfer hence purpose paper underscore key trainee characteristic facet work environment influence euc training transferjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspthe theoretical framework include prior computer experience computer anxiety computer motivation perceive job utility significant trainee factor influence euc transfer process addition model include supervisory support important constituent euc transfer processjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthe model highlight mediating role computer motivation predict motivation transfer addition point several factor work simultaneously influence motivation transfer euc trainingjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspsupervisory support environment extremely crucial determine euc training success specifically supervisor able communicate employee purpose importance train relevance computer training job outcome expectedjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspthis paper contribute literature emphasize importance supervisory support individual characteristic predict motivation transferjatspjatssec,0.5789473684210527,0.11278195488721804,0.15037593984962405,0.03759398496240601,133.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Quantitative,"Transformers for Secure Hardware Systems: Applications, Challenges, and
  Outlook","The rise of hardware-level security threats, such as side-channel attacks,
hardware Trojans, and firmware vulnerabilities, demands advanced detection
mechanisms that are more intelligent and adaptive. Traditional methods often
fall short in addressing the complexity and evasiveness of modern attacks,
driving increased interest in machine learning-based solutions. Among these,
Transformer models, widely recognized for their success in natural language
processing and computer vision, have gained traction in the security domain due
to their ability to model complex dependencies, offering enhanced capabilities
in identifying vulnerabilities, detecting anomalies, and reinforcing system
integrity. This survey provides a comprehensive review of recent advancements
on the use of Transformers in hardware security, examining their application
across key areas such as side-channel analysis, hardware Trojan detection,
vulnerability classification, device fingerprinting, and firmware security.
Furthermore, we discuss the practical challenges of applying Transformers to
secure hardware systems, and highlight opportunities and future research
directions that position them as a foundation for next-generation
hardware-assisted security. These insights pave the way for deeper integration
of AI-driven techniques into hardware security frameworks, enabling more
resilient and intelligent defenses.",http://arxiv.org/abs/2505.22605v1,arXiv,transformer secure hardware system application challenge outlook,rise hardwarelevel security threat sidechannel attack hardware trojan firmware vulnerability demand advanced detection mechanism intelligent adaptive traditional method often fall short address complexity evasiveness modern attack drive increase interest machine learningbase solution among transformer model widely recognize success natural language processing computer vision gain traction security domain due ability model complex dependency offer enhanced capability identify vulnerability detect anomaly reinforce system integrity survey provide comprehensive review recent advancement use transformer hardware security examine application across key area sidechannel analysis hardware trojan detection vulnerability classification device fingerprinting firmware security furthermore discuss practical challenge apply transformer secure hardware system highlight opportunity future research direction position foundation nextgeneration hardwareassiste security insight pave way deep integration aidriven technique hardware security framework enable resilient intelligent defense,transformer secure hardware system application challenge outlook rise hardwarelevel security threat sidechannel attack hardware trojan firmware vulnerability demand advanced detection mechanism intelligent adaptive traditional method often fall short address complexity evasiveness modern attack drive increase interest machine learningbase solution among transformer model widely recognize success natural language processing computer vision gain traction security domain due ability model complex dependency offer enhanced capability identify vulnerability detect anomaly reinforce system integrity survey provide comprehensive review recent advancement use transformer hardware security examine application across key area sidechannel analysis hardware trojan detection vulnerability classification device fingerprinting firmware security furthermore discuss practical challenge apply transformer secure hardware system highlight opportunity future research direction position foundation nextgeneration hardwareassiste security insight pave way deep integration aidriven technique hardware security framework enable resilient intelligent defense,0.6528925619834711,0.10743801652892562,0.1487603305785124,0.024793388429752067,121.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Quantitative,Information Flow Coverage Metrics for Hardware Security Verification,"Security graphs model attacks, defenses, mitigations, and vulnerabilities on
computer networks and systems. With proper attributes, they provide security
metrics using standard graph algorithms. A hyperflow graph is a
register-transfer level (RTL) hardware security graph that facilitates security
verification. A hyperflow graph models information flows and is annotated with
attributes that allow security metrics to measure flow paths, flow conditions,
and flow rates. Hyperflow graphs enable the understanding of hardware
vulnerabilities related to confidentiality, integrity, and availability, as
shown on the OpenTitan hardware root of trust under several threat models.",http://arxiv.org/abs/2304.08263v1,arXiv,information flow coverage metric hardware security verification,security graph model attack defense mitigation vulnerability computer network system proper attribute provide security metric use standard graph algorithm hyperflow graph registertransfer level rtl hardware security graph facilitate security verification hyperflow graph model information flow annotate attribute allow security metric measure flow path flow condition flow rate hyperflow graph enable understanding hardware vulnerability relate confidentiality integrity availability show opentitan hardware root trust several threat model,information flow coverage metric hardware security verification security graph model attack defense mitigation vulnerability computer network system proper attribute provide security metric use standard graph algorithm hyperflow graph registertransfer level rtl hardware security graph facilitate security verification hyperflow graph model information flow annotate attribute allow security metric measure flow path flow condition flow rate hyperflow graph enable understanding hardware vulnerability relate confidentiality integrity availability show opentitan hardware root trust several threat model,0.7384615384615385,0.1076923076923077,0.12307692307692308,0.0,65.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Quantitative,The Emergence of Hardware Fuzzing: A Critical Review of its Significance,"In recent years, there has been a notable surge in attention towards hardware
security, driven by the increasing complexity and integration of processors,
SoCs, and third-party IPs aimed at delivering advanced solutions. However, this
complexity also introduces vulnerabilities and bugs into hardware systems,
necessitating early detection during the IC design cycle to uphold system
integrity and mitigate re-engineering costs. While the Design Verification (DV)
community employs dynamic and formal verification strategies, they encounter
challenges such as scalability for intricate designs and significant human
intervention, leading to prolonged verification durations. As an alternative
approach, hardware fuzzing, inspired by software testing methodologies, has
gained prominence for its efficacy in identifying bugs within complex hardware
designs. Despite the introduction of various hardware fuzzing techniques,
obstacles such as inefficient conversion of hardware modules into software
models impede their effectiveness. This Systematization of Knowledge (SoK)
initiative delves into the fundamental principles of existing hardware fuzzing,
methodologies, and their applicability across diverse hardware designs.
Additionally, it evaluates factors such as the utilization of golden reference
models (GRMs), coverage metrics, and toolchains to gauge their potential for
broader adoption, akin to traditional formal verification methods. Furthermore,
this work examines the reliability of existing hardware fuzzing techniques in
identifying vulnerabilities and identifies research gaps for future
advancements in design verification techniques.",http://arxiv.org/abs/2403.12812v1,arXiv,emergence hardware fuzze critical review significance,recent year notable surge attention towards hardware security drive increase complexity integration processor soc thirdparty ips aim deliver advanced solution however complexity also introduce vulnerability bug hardware system necessitating early detection design cycle uphold system integrity mitigate reengineere cost design verification community employ dynamic formal verification strategy encounter challenge scalability intricate design significant human intervention lead prolong verification duration alternative approach hardware fuzzing inspire software testing methodology gain prominence efficacy identify bug within complex hardware design despite introduction various hardware fuzze technique obstacle inefficient conversion hardware module software model impede effectiveness systematization knowledge sok initiative delf fundamental principle exist hardware fuzze methodology applicability across diverse hardware design additionally evaluate factor utilization golden reference model grm coverage metric toolchain gauge potential broad adoption akin traditional formal verification method furthermore work examine reliability exist hardware fuzze technique identify vulnerability identify research gap future advancement design verification technique,emergence hardware fuzze critical review significance recent year notable surge attention towards hardware security drive increase complexity integration processor soc thirdparty ips aim deliver advanced solution however complexity also introduce vulnerability bug hardware system necessitating early detection design cycle uphold system integrity mitigate reengineere cost design verification community employ dynamic formal verification strategy encounter challenge scalability intricate design significant human intervention lead prolong verification duration alternative approach hardware fuzzing inspire software testing methodology gain prominence efficacy identify bug within complex hardware design despite introduction various hardware fuzze technique obstacle inefficient conversion hardware module software model impede effectiveness systematization knowledge sok initiative delf fundamental principle exist hardware fuzze methodology applicability across diverse hardware design additionally evaluate factor utilization golden reference model grm coverage metric toolchain gauge potential broad adoption akin traditional formal verification method furthermore work examine reliability exist hardware fuzze technique identify vulnerability identify research gap future advancement design verification technique,0.6620689655172414,0.08275862068965517,0.15862068965517243,0.027586206896551724,145.0,0.0,0.0,1.0,0.0
Computer Engineering,Hardware Systems,Quantitative,"Explainability as a Requirement for Hardware: Introducing Explainable
  Hardware (XHW)","In today's age of digital technology, ethical concerns regarding computing
systems are increasing. While the focus of such concerns currently is on
requirements for software, this article spotlights the hardware domain,
specifically microchips. For example, the opaqueness of modern microchips
raises security issues, as malicious actors can manipulate them, jeopardizing
system integrity. As a consequence, governments invest substantially to
facilitate a secure microchip supply chain. To combat the opaqueness of
hardware, this article introduces the concept of Explainable Hardware (XHW).
Inspired by and building on previous work on Explainable AI (XAI) and
explainable software systems, we develop a framework for achieving XHW
comprising relevant stakeholders, requirements they might have concerning
hardware, and possible explainability approaches to meet these requirements.
Through an exploratory survey among 18 hardware experts, we showcase
applications of the framework and discover potential research gaps. Our work
lays the foundation for future work and structured debates on XHW.",http://arxiv.org/abs/2302.14661v2,arXiv,explainability requirement hardware introduce explainable hardware xhw,today age digital technology ethical concern regard computing system increase focus concern currently requirement software article spotlight hardware domain specifically microchip example opaqueness modern microchip raise security issue malicious actor manipulate jeopardize system integrity consequence government invest substantially facilitate secure microchip supply chain combat opaqueness hardware article introduce concept explainable hardware xhw inspire build previous work explainable xai explainable software system develop framework achieve xhw comprise relevant stakeholder requirement might concern hardware possible explainability approach meet requirement exploratory survey among hardware expert showcase application framework discover potential research gap work lay foundation future work structured debate xhw,explainability requirement hardware introduce explainable hardware xhw today age digital technology ethical concern regard computing system increase focus concern currently requirement software article spotlight hardware domain specifically microchip example opaqueness modern microchip raise security issue malicious actor manipulate jeopardize system integrity consequence government invest substantially facilitate secure microchip supply chain combat opaqueness hardware article introduce concept explainable hardware xhw inspire build previous work explainable xai explainable software system develop framework achieve xhw comprise relevant stakeholder requirement might concern hardware possible explainability approach meet requirement exploratory survey among hardware expert showcase application framework discover potential research gap work lay foundation future work structured debate xhw,0.6288659793814433,0.12371134020618557,0.15463917525773196,0.030927835051546393,97.0,0.0,0.0,1.0,0.0
Computer Engineering,Hardware Systems,Quantitative,NLS: Natural-Level Synthesis for Hardware Implementation Through GenAI,"This paper introduces Natural-Level Synthesis, an innovative approach for
generating hardware using generative artificial intelligence on both the system
level and component-level. NLS bridges a gap in current hardware development
processes, where algorithm and application engineers' involvement typically
ends at the requirements stage. With NLS, engineers can participate more deeply
in the development, synthesis, and test stages by using Gen-AI models to
convert natural language descriptions directly into Hardware Description
Language code. This approach not only streamlines hardware development but also
improves accessibility, fostering a collaborative workflow between hardware and
algorithm engineers. We developed the NLS tool to facilitate natural
language-driven HDL synthesis, enabling rapid generation of system-level HDL
designs while significantly reducing development complexity. Evaluated through
case studies and benchmarks using Performance, Power, and Area metrics, NLS
shows its potential to enhance resource efficiency in hardware development.
This work provides a extensible, efficient solution for hardware synthesis and
establishes a Visual Studio Code Extension to assess Gen-AI-driven HDL
generation and system integration, laying a foundation for future AI-enhanced
and AI-in-the-loop Electronic Design Automation tools.",http://arxiv.org/abs/2504.01981v1,arXiv,nls naturallevel synthesis hardware implementation genai,paper introduce naturallevel synthesis innovative approach generate hardware use generative artificial intelligence system level componentlevel nls bridge gap current hardware development process algorithm application engineer involvement typically end requirement stage nls engineer participate deeply development synthesis test stage use genai model convert natural language description directly hardware description language code approach streamline hardware development also improve accessibility foster collaborative workflow hardware algorithm engineer develop nls tool facilitate natural languagedriven hdl synthesis enable rapid generation systemlevel hdl design significantly reduce development complexity evaluate case study benchmark use performance power area metric nls show potential enhance resource efficiency hardware development work provide extensible efficient solution hardware synthesis establish visual studio code extension assess genaidriven hdl generation system integration lay foundation future aienhance aiintheloop electronic design automation tool,nls naturallevel synthesis hardware implementation genai paper introduce naturallevel synthesis innovative approach generate hardware use generative artificial intelligence system level componentlevel nls bridge gap current hardware development process algorithm application engineer involvement typically end requirement stage nls engineer participate deeply development synthesis test stage use genai model convert natural language description directly hardware description language code approach streamline hardware development also improve accessibility foster collaborative workflow hardware algorithm engineer develop nls tool facilitate natural languagedriven hdl synthesis enable rapid generation systemlevel hdl design significantly reduce development complexity evaluate case study benchmark use performance power area metric nls show potential enhance resource efficiency hardware development work provide extensible efficient solution hardware synthesis establish visual studio code extension assess genaidriven hdl generation system integration lay foundation future aienhance aiintheloop electronic design automation tool,0.64,0.12,0.16,0.04,125.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Qualitative,Generic Low-Latency Masking in Hardware,"<jats:p>In this work, we introduce a generalized concept for low-latency masking that is applicable to any implementation and protection order, and (in its most extreme form) does not require on-the-fly randomness. The main idea of our approach is to avoid collisions of shared variables in nonlinear circuit parts and to skip the share compression. We show the feasibility of our approach on a full implementation of a one-round unrolled Ascon variant and on an AES S-box case study. Additionally, we discuss possible trade-offs to make our approach interesting for practical implementations. As a result, we obtain a first-order masked AES S-box that is calculated in a single clock cycle with rather high implementation costs (60.7 kGE), and a two-cycle variant with much less implementation costs (6.7 kGE). The side-channel resistance of our Ascon S-box designs up to order three are then verified using the formal analysis tool of [BGI+18]. Furthermore, we introduce a taint checking based verification approach that works specifically for our low-latency approach and allows us to verify large circuits like our low-latency AES S-box design in reasonable time.</jats:p>",https://doi.org/10.46586/tches.v2018.i2.1-21,CrossRef,generic lowlatency mask hardware,jatspin work introduce generalized concept lowlatency masking applicable implementation protection order extreme form require onthefly randomness main idea approach avoid collision share variable nonlinear circuit part skip share compression show feasibility approach full implementation oneround unroll ascon variant aes sbox case study additionally discuss possible tradeoff make approach interesting practical implementation result obtain firstorder mask aes sbox calculate single clock cycle rather high implementation cost kge twocycle variant much less implementation cost kge sidechannel resistance ascon sbox design order three verify use formal analysis tool bgi furthermore introduce taint check base verification approach work specifically lowlatency approach allow verify large circuit like lowlatency sbox design reasonable timejatsp,generic lowlatency mask hardware jatspin work introduce generalized concept lowlatency masking applicable implementation protection order extreme form require onthefly randomness main idea approach avoid collision share variable nonlinear circuit part skip share compression show feasibility approach full implementation oneround unroll ascon variant aes sbox case study additionally discuss possible tradeoff make approach interesting practical implementation result obtain firstorder mask aes sbox calculate single clock cycle rather high implementation cost kge twocycle variant much less implementation cost kge sidechannel resistance ascon sbox design order three verify use formal analysis tool bgi furthermore introduce taint check base verification approach work specifically lowlatency approach allow verify large circuit like lowlatency sbox design reasonable timejatsp,0.616822429906542,0.102803738317757,0.14953271028037382,0.056074766355140186,107.0,2.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Qualitative,Prime-Field Masking in Hardware and its Soundness against Low-Noise SCA Attacks,"<jats:p>A recent study suggests that arithmetic masking in prime fields leads to stronger security guarantees against passive physical adversaries than Boolean masking. Indeed, it is a common observation that the desired security amplification of Boolean masking collapses when the noise level in the measurements is too low. Arithmetic encodings in prime fields can help to maintain an exponential increase of the attack complexity in the number of shares even in such a challenging context. In this work, we contribute to this emerging topic in two main directions. First, we propose novel masked hardware gadgets for secure squaring in prime fields (since squaring is non-linear in non-binary fields) which prove to be significantly more resource-friendly than corresponding masked multiplications. We then formally show their local and compositional security for arbitrary orders. Second, we attempt to &gt;experimentally evaluate the performance vs. security tradeoff of prime-field masking. In order to enable a first comparative case study in this regard, we exemplarily consider masked implementations of the AES as well as the recently proposed AESprime. AES-prime is a block cipher partially resembling the standard AES, but based on arithmetic operations modulo a small Mersenne prime. We present cost and performance figures for masked AES and AES-prime implementations, and experimentally evaluate their susceptibility to low-noise side-channel attacks. We consider both the dynamic and the static power consumption for our low-noise analyses and emulate strong adversaries. Static power attacks are indeed known as a threat for side-channel countermeasures that require a certain noise level to be effective because of the adversary’s ability to reduce the noise through intra-trace averaging. Our results show consistently that for the noise levels in our practical experiments, the masked prime-field implementations provide much higher security for the same number of shares. This compensates for the overheads prime computations lead to and remains true even if / despite leaking each share with a similar Signal-to-Noise Ratio (SNR) as their binary equivalents. We hope our results open the way towards new cipher designs tailored to best exploit the advantages of prime-field masking.</jats:p>",https://doi.org/10.46586/tches.v2023.i2.482-518,CrossRef,primefield mask hardware soundness lownoise sca attack,jatspa recent study suggest arithmetic masking prime field lead strong security guarantee passive physical adversary boolean mask indeed common observation desire security amplification boolean masking collapse noise level measurement low arithmetic encoding prime field help maintain exponential increase attack complexity number share even challenging context work contribute emerge topic two main direction first propose novel mask hardware gadget secure square prime field since square nonlinear nonbinary field prove significantly resourcefriendly correspond mask multiplication formally show local compositional security arbitrary order second attempt gtexperimentally evaluate performance security tradeoff primefield masking order enable first comparative case study regard exemplarily consider mask implementation aes well recently propose aesprime aesprime block cipher partially resemble standard aes base arithmetic operation modulo small mersenne prime present cost performance figure mask aes aesprime implementation experimentally evaluate susceptibility lownoise sidechannel attack consider dynamic static power consumption lownoise analysis emulate strong adversary static power attack indeed know threat sidechannel countermeasure require certain noise level effective adversary ability reduce noise intratrace average result show consistently noise level practical experiment mask primefield implementation provide much high security number share compensate overhead prime computation lead remain true even despite leak share similar signaltonoise ratio snr binary equivalent hope result open way towards new cipher design tailor well exploit advantage primefield maskingjatsp,primefield mask hardware soundness lownoise sca attack jatspa recent study suggest arithmetic masking prime field lead strong security guarantee passive physical adversary boolean mask indeed common observation desire security amplification boolean masking collapse noise level measurement low arithmetic encoding prime field help maintain exponential increase attack complexity number share even challenging context work contribute emerge topic two main direction first propose novel mask hardware gadget secure square prime field since square nonlinear nonbinary field prove significantly resourcefriendly correspond mask multiplication formally show local compositional security arbitrary order second attempt gtexperimentally evaluate performance security tradeoff primefield masking order enable first comparative case study regard exemplarily consider mask implementation aes well recently propose aesprime aesprime block cipher partially resemble standard aes base arithmetic operation modulo small mersenne prime present cost performance figure mask aes aesprime implementation experimentally evaluate susceptibility lownoise sidechannel attack consider dynamic static power consumption lownoise analysis emulate strong adversary static power attack indeed know threat sidechannel countermeasure require certain noise level effective adversary ability reduce noise intratrace average result show consistently noise level practical experiment mask primefield implementation provide much high security number share compensate overhead prime computation lead remain true even despite leak share similar signaltonoise ratio snr binary equivalent hope result open way towards new cipher design tailor well exploit advantage primefield maskingjatsp,0.4354066985645933,0.1339712918660287,0.23923444976076555,0.08133971291866028,209.0,1.0,0.0,0.0,1.0
Computer Engineering,Hardware Systems,Qualitative,Provable Secure Parallel Gadgets,"<jats:p>Side-channel attacks are a fundamental threat to the security of cryptographic implementations. One of the most prominent countermeasures against side-channel attacks is masking, where each intermediate value of the computation is secret shared, thereby concealing the computation’s sensitive information. An important security model to study the security of masking schemes is the random probing model, in which the adversary obtains each intermediate value of the computation with some probability p. To construct secure masking schemes, an important building block is the refreshing gadget, which updates the randomness of the secret shared intermediate values. Recently, Dziembowski, Faust, and Zebrowski (ASIACRYPT’19) analyzed the security of a simple refreshing gadget by using a new technique called the leakage diagram. In this work, we follow the approach of Dziembowski et al. and significantly improve its methodology. Concretely, we refine the notion of a leakage diagram via so-called dependency graphs, and show how to use this technique for arbitrary complex circuits via composition results and approximation techniques. To illustrate the power of our new techniques, as a case study, we designed provably secure parallel gadgets for the random probing model, and adapted the ISW multiplication such that all gadgets can be parallelized. Finally, we evaluate concrete security levels, and show how our new methodology can further improve the concrete security level of masking schemes. This results in a compiler provable secure up to a noise level of O(1) for affine circuits and O(1/√n) in general.</jats:p>",https://doi.org/10.46586/tches.v2023.i4.420-459,CrossRef,provable secure parallel gadget,jatspsidechannel attack fundamental threat security cryptographic implementation one prominent countermeasure sidechannel attack mask intermediate value computation secret share thereby conceal computation sensitive information important security model study security mask scheme random probe model adversary obtain intermediate value computation probability construct secure masking scheme important building block refreshing gadget update randomness secret share intermediate value recently dziembowski faust zebrowski asiacrypt analyze security simple refreshing gadget use new technique call leakage diagram work follow approach dziembowski significantly improve methodology concretely refine notion leakage diagram via socalle dependency graph show use technique arbitrary complex circuit via composition result approximation technique illustrate power new technique case study design provably secure parallel gadget random probe model adapt isw multiplication gadget parallelize finally evaluate concrete security level show new methodology far improve concrete security level mask scheme result compiler provable secure noise level affine circuit generaljatsp,provable secure parallel gadget jatspsidechannel attack fundamental threat security cryptographic implementation one prominent countermeasure sidechannel attack mask intermediate value computation secret share thereby conceal computation sensitive information important security model study security mask scheme random probe model adversary obtain intermediate value computation probability construct secure masking scheme important building block refreshing gadget update randomness secret share intermediate value recently dziembowski faust zebrowski asiacrypt analyze security simple refreshing gadget use new technique call leakage diagram work follow approach dziembowski significantly improve methodology concretely refine notion leakage diagram via socalle dependency graph show use technique arbitrary complex circuit via composition result approximation technique illustrate power new technique case study design provably secure parallel gadget random probe model adapt isw multiplication gadget parallelize finally evaluate concrete security level show new methodology far improve concrete security level mask scheme result compiler provable secure noise level affine circuit generaljatsp,0.5428571428571428,0.1357142857142857,0.17142857142857143,0.05,140.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Qualitative,Unrolled Cryptography on Silicon,"<jats:p>Cryptographic primitives with low-latency performance have gained momentum lately due to an increased demand for real-time applications. Block ciphers such as PRINCE enable data encryption (resp. decryption) within a single clock cycle at a moderately high operating frequency when implemented in a fully-unrolled fashion. Unsurprisingly, many typical environments for unrolled ciphers require protection against physical adversaries as well. Yet, recent works suggest that most common SCA countermeasures are hard to apply to low-latency circuits. Hardware masking, for example, requires register stages to offer resistance, thus adding delay and defeating the purpose of unrolling. On another note, it has been indicated that unrolled primitives without any additional means of protection offer an intrinsic resistance to SCA attacks due to their parallelism, asynchronicity and speed of execution. In this work, we take a closer look at the physical security properties provided by unrolled cryptographic IC implementations. We are able to confirm that the nature of unrolling indeed bears the potential to decrease the susceptibility of cipher implementations significantly when reset methods are applied. With respect to certain adversarial models, e.g., ciphertext-only access, an amazingly high level of protection can be achieved. While this seems to be a great result for cryptographic hardware engineers, there is an attack vector hidden in plain sight which still threatens the security of unrolled implementations remarkably – namely the static power consumption of CMOS-based circuits. We point out that essentially all reasons which make it hard to extract meaningful information from the dynamic behavior of unrolled primitives are not an issue when exploiting the static currents for key recovery. Our evaluation is based on real-silicon measurements of an unrolled PRINCE core in a custom 40nm ASIC. The presented results serve as a neat educational case study to demonstrate the broad differences between dynamic and static power information leakage in the light of technological advancement.</jats:p>",https://doi.org/10.46586/tches.v2020.i4.416-442,CrossRef,unroll cryptography silicon,jatspcryptographic primitive lowlatency performance gain momentum lately due increase demand realtime application block cipher prince enable datum encryption resp decryption within single clock cycle moderately high operating frequency implement fullyunrolled fashion unsurprisingly many typical environment unrolled cipher require protection physical adversary well yet recent work suggest common sca countermeasure hard apply lowlatency circuit hardware mask example require register stage offer resistance thus add delay defeat purpose unroll another note indicate unrolled primitive without additional mean protection offer intrinsic resistance sca attack due parallelism asynchronicity speed execution work take close look physical security property provide unrolled cryptographic implementation able confirm nature unroll indeed bear potential decrease susceptibility cipher implementation significantly reset method apply respect certain adversarial model ciphertextonly access amazingly high level protection achieve seem great result cryptographic hardware engineer attack vector hide plain sight still threaten security unrolled implementation remarkably namely static power consumption cmosbased circuit point essentially reason make hard extract meaningful information dynamic behavior unrolled primitive issue exploit static current key recovery evaluation base realsilicon measurement unrolled prince core custom asic present result serve neat educational case study demonstrate broad difference dynamic static power information leakage light technological advancementjatsp,unroll cryptography silicon jatspcryptographic primitive lowlatency performance gain momentum lately due increase demand realtime application block cipher prince enable datum encryption resp decryption within single clock cycle moderately high operating frequency implement fullyunrolled fashion unsurprisingly many typical environment unrolled cipher require protection physical adversary well yet recent work suggest common sca countermeasure hard apply lowlatency circuit hardware mask example require register stage offer resistance thus add delay defeat purpose unroll another note indicate unrolled primitive without additional mean protection offer intrinsic resistance sca attack due parallelism asynchronicity speed execution work take close look physical security property provide unrolled cryptographic implementation able confirm nature unroll indeed bear potential decrease susceptibility cipher implementation significantly reset method apply respect certain adversarial model ciphertextonly access amazingly high level protection achieve seem great result cryptographic hardware engineer attack vector hide plain sight still threaten security unrolled implementation remarkably namely static power consumption cmosbased circuit point essentially reason make hard extract meaningful information dynamic behavior unrolled primitive issue exploit static current key recovery evaluation base realsilicon measurement unrolled prince core custom asic present result serve neat educational case study demonstrate broad difference dynamic static power information leakage light technological advancementjatsp,0.4293193717277487,0.17801047120418848,0.2198952879581152,0.06806282722513089,95.5,1.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Qualitative,"Concurrent software‐hardware optimisation of adaptive estimating, identifying and filtering systems","<jats:sec><jats:title content-type=""abstract-heading"">Purpose</jats:title><jats:p>The purpose of this paper is to present the methods of concurrent optimization of the analogue and digital parts (software‐hardware) of estimating, identifying and filtering systems with adaptively adjusted analogue parts – adaptive estimation systems (AES).</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title><jats:p>Concurrent (complete) optimization of AES permits the determination of the most efficient algorithms for computing the estimates and the controls adjusting analogue units of AES in the way maximally improving the quality of observations delivered by them to the digital part. Performance of AES is assessed by the mean square error (MSE) of estimates which is constructed employing the models of input excitation, analogue and digital parts. Global extremum of MSE is searched by Bayesian methods taking into account the always bounded input range of AES and its possible overloading.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Findings</jats:title><jats:p>There are determined upper boundaries of potentially achievable accuracy of estimates, as well as optimal estimating and controlling observation units' algorithms, ensuring their achievement. New effects appearing in completely optimal AES are analysed.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Research limitations/implications</jats:title><jats:p>The paper presents the backgrounds of new and analytically complex approach. To clarify basic ideas and methods, the simplest but useful for applications single input‐single output and single input‐multiple output models of ASE were considered. The obtained results create wide field for further investigations.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Practical implications</jats:title><jats:p>The results of the paper can be applied in the development of new classes of high‐efficient adaptive data acquisition, measurement, controlling, communication and other systems.</jats:p></jats:sec><jats:sec><jats:title content-type=""abstract-heading"">Originality/value</jats:title><jats:p>Concurrent optimisation of AES is important task having no general solution until now. Known approaches allow only the separate optimisation of the analogue and digital parts. Presented original approach enables the correct formalisation and solution of this task that permits the design and realization of systems with characteristics close to theoretically achievable ones and exceeding the characteristics of the known systems of similar predestination.</jats:p></jats:sec>",https://doi.org/10.1108/03684920810873245,CrossRef,concurrent optimisation adaptive estimate identifying filter system,jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper present method concurrent optimization analogue digital part estimate identifying filter system adaptively adjust analogue part adaptive estimation system aesjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspconcurrent complete optimization aes permit determination efficient algorithm compute estimate control adjust analogue unit aes way maximally improve quality observation deliver digital part performance aes assess mean square error mse estimate construct employ model input excitation analogue digital part global extremum mse search bayesian method take account always bound input range aes possible overloadingjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthere determined upper boundary potentially achievable accuracy estimate well optimal estimating control observation unit algorithm ensure achievement new effect appear completely optimal aes analysedjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe paper present background new analytically complex approach clarify basic idea method simple useful application single output single output model ase consider obtain result create wide field investigationsjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspthe result paper apply development new class adaptive data acquisition measurement control communication systemsjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspconcurrent optimisation aes important task general solution know approach allow separate optimisation analogue digital part present original approach enable correct formalisation solution task permit design realization system characteristic close theoretically achievable one exceed characteristic know system similar predestinationjatspjatssec,concurrent optimisation adaptive estimate identifying filter system jatssecjatstitle contenttypeabstractheadingpurposejatstitlejatspthe purpose paper present method concurrent optimization analogue digital part estimate identifying filter system adaptively adjust analogue part adaptive estimation system aesjatspjatssecjatssecjatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitlejatspconcurrent complete optimization aes permit determination efficient algorithm compute estimate control adjust analogue unit aes way maximally improve quality observation deliver digital part performance aes assess mean square error mse estimate construct employ model input excitation analogue digital part global extremum mse search bayesian method take account always bound input range aes possible overloadingjatspjatssecjatssecjatstitle contenttypeabstractheadingfindingsjatstitlejatspthere determined upper boundary potentially achievable accuracy estimate well optimal estimating control observation unit algorithm ensure achievement new effect appear completely optimal aes analysedjatspjatssecjatssecjatstitle contenttypeabstractheadingresearch limitationsimplicationsjatstitlejatspthe paper present background new analytically complex approach clarify basic idea method simple useful application single output single output model ase consider obtain result create wide field investigationsjatspjatssecjatssecjatstitle contenttypeabstractheadingpractical implicationsjatstitlejatspthe result paper apply development new class adaptive data acquisition measurement control communication systemsjatspjatssecjatssecjatstitle contenttypeabstractheadingoriginalityvaluejatstitlejatspconcurrent optimisation aes important task general solution know approach allow separate optimisation analogue digital part present original approach enable correct formalisation solution task permit design realization system characteristic close theoretically achievable one exceed characteristic know system similar predestinationjatspjatssec,0.5191256830601093,0.14207650273224043,0.22950819672131148,0.04918032786885246,91.5,3.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Mixed Methods,LOGARITHMIC AMPLIFIERS FOR SOFTWARE HARDWARE MAGNETIC TRACKING  SYSTEMS,"<jats:p>The work deals with the problem of signal conversion in magnetic tracking devices. Magnetic tracking technology is based on computing the spatial position of an object being tracked upon measuring reference magnetic fields in low-frequency electromagnetic radiation spectrum. Magnetic tracking devices are key components of navigation sensors for virtual and augmented reality. It has been shown that the main problem one faces when developing sensory devices for magnetic tracking is the fact that signals should be measured in a wide measurement range. We have analyzed possible ways to solve the stated problem by digital and combined methods. The latter have proven to be more efficient. They consist in signal amplification due to analog compression, which is performed by logarithmic amplifiers whose negative  feedback circuits contain components with non-linear volt-ampere characteristics (typically, diodes or bipo- lar transistors are used). It has been shown that the parameters of logarithmic signal compression can be  controlled by modified circuits with auxiliary resistance dividers. The resistance dividers scale the logarithmic volt-ampere characteristics of emitter p-n junctions of bipolar n-p-n and p-n-p transistors. A substantial advantage of circuits with resistance dividers is that they provide the possibility to expand the range of the output voltage of logarithmic amplifiers and optimize the transition between the linear and logarithmic amplification regions. The work presents the results of simulation and experimental investigations into a logarithmic amplifier for a magnetic tracking system. Simulation was carried out using SPICE (Simulation Program with Integrated Circuit Emphasis) models. We applied an integrated approach,which provides collections of transient characteristics of logarithmic amplifiers at different sets of the  parameters of resistance dividers. The simulation results have been verified using our own software- firmware magnetic tracking tools – Magnetic Tracking System Integrated Development Environment. The signal converter was built upon a programmable system-on-chip PSoC 5LP by Cypress Semiconductor.</jats:p>",https://doi.org/10.15276/eltecs.33.109.2020.4,CrossRef,logarithmic amplifier software hardware magnetic tracking system,jatspthe work deal problem signal conversion magnetic tracking device magnetic tracking technology base compute spatial position object track upon measure reference magnetic field lowfrequency electromagnetic radiation spectrum magnetic tracking device key component navigation sensor virtual augmented reality show main problem one face develop sensory device magnetic tracking fact signal measure wide measurement range analyze possible way solve stated problem digital combined method latter prove efficient consist signal amplification due analog compression perform logarithmic amplifier whose negative feedback circuit contain component nonlinear voltampere characteristic typically diode bipo lar transistor use show parameter logarithmic signal compression control modify circuit auxiliary resistance divider resistance divider scale logarithmic voltampere characteristic emitter junction bipolar npn pnp transistor substantial advantage circuit resistance divider provide possibility expand range output voltage logarithmic amplifier optimize transition linear logarithmic amplification region work present result simulation experimental investigation logarithmic amplifier magnetic tracking system simulation carry use spice simulation program integrated circuit emphasis model apply integrated approachwhich provide collection transient characteristic logarithmic amplifier different set parameter resistance divider simulation result verify use software firmware magnetic tracking tool magnetic tracking system integrate development environment signal converter build upon programmable systemonchip psoc cypress semiconductorjatsp,logarithmic amplifier software hardware magnetic tracking system jatspthe work deal problem signal conversion magnetic tracking device magnetic tracking technology base compute spatial position object track upon measure reference magnetic field lowfrequency electromagnetic radiation spectrum magnetic tracking device key component navigation sensor virtual augmented reality show main problem one face develop sensory device magnetic tracking fact signal measure wide measurement range analyze possible way solve stated problem digital combined method latter prove efficient consist signal amplification due analog compression perform logarithmic amplifier whose negative feedback circuit contain component nonlinear voltampere characteristic typically diode bipo lar transistor use show parameter logarithmic signal compression control modify circuit auxiliary resistance divider resistance divider scale logarithmic voltampere characteristic emitter junction bipolar npn pnp transistor substantial advantage circuit resistance divider provide possibility expand range output voltage logarithmic amplifier optimize transition linear logarithmic amplification region work present result simulation experimental investigation logarithmic amplifier magnetic tracking system simulation carry use spice simulation program integrated circuit emphasis model apply integrated approachwhich provide collection transient characteristic logarithmic amplifier different set parameter resistance divider simulation result verify use software firmware magnetic tracking tool magnetic tracking system integrate development environment signal converter build upon programmable systemonchip psoc cypress semiconductorjatsp,0.5684210526315789,0.11052631578947368,0.21052631578947367,0.021052631578947368,190.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Mixed Methods,Non-Profiled Deep Learning-based Side-Channel attacks with Sensitivity Analysis,"<jats:p>Deep Learning has recently been introduced as a new alternative to perform Side-Channel analysis [MPP16]. Until now, studies have been focused on applying Deep Learning techniques to perform Profiled Side-Channel attacks where an attacker has a full control of a profiling device and is able to collect a large amount of traces for different key values in order to characterize the device leakage prior to the attack. In this paper we introduce a new method to apply Deep Learning techniques in a Non-Profiled context, where an attacker can only collect a limited number of side-channel traces for a fixed unknown key value from a closed device. We show that by combining key guesses with observations of Deep Learning metrics, it is possible to recover information about the secret key. The main interest of this method is that it is possible to use the power of Deep Learning and Neural Networks in a Non-Profiled scenario. We show that it is possible to exploit the translation-invariance property of Convolutional Neural Networks [CDP17] against de-synchronized traces also during Non-Profiled side-channel attacks. In this case, we show that this method can outperform classic Non-Profiled attacks such as Correlation Power Analysis. We also highlight that it is possible to break masked implementations in black-box, without leakages combination pre-preprocessing and with no assumptions nor knowledge about the masking implementation. To carry the attack, we introduce metrics based on Sensitivity Analysis that can reveal both the secret key value as well as points of interest, such as leakages and masks locations in the traces. The results of our experiments demonstrate the interests of this new method and show that this attack can be performed in practice.</jats:p>",https://doi.org/10.46586/tches.v2019.i2.107-131,CrossRef,nonprofile deep learningbase sidechannel attack sensitivity analysis,jatspdeep learning recently introduce new alternative perform sidechannel analysis mpp study focus apply deep learning technique perform profile sidechannel attack attacker full control profiling device able collect large amount trace different key value order characterize device leakage prior attack paper introduce new method apply deep learning technique nonprofiled context attacker collect limited number sidechannel trace fix unknown key value closed device show combine key guess observation deep learning metric possible recover information secret key main interest method possible use power deep learning neural network nonprofiled scenario show possible exploit translationinvariance property convolutional neural network cdp desynchronized trace also nonprofile sidechannel attack case show method outperform classic nonprofile attack correlation power analysis also highlight possible break mask implementation blackbox without leakage combination prepreprocesse assumption knowledge masking implementation carry attack introduce metric base sensitivity analysis reveal secret key value well point interest leakage mask location trace result experiment demonstrate interest new method show attack perform practicejatsp,nonprofile deep learningbase sidechannel attack sensitivity analysis jatspdeep learning recently introduce new alternative perform sidechannel analysis mpp study focus apply deep learning technique perform profile sidechannel attack attacker full control profiling device able collect large amount trace different key value order characterize device leakage prior attack paper introduce new method apply deep learning technique nonprofiled context attacker collect limited number sidechannel trace fix unknown key value closed device show combine key guess observation deep learning metric possible recover information secret key main interest method possible use power deep learning neural network nonprofiled scenario show possible exploit translationinvariance property convolutional neural network cdp desynchronized trace also nonprofile sidechannel attack case show method outperform classic nonprofile attack correlation power analysis also highlight possible break mask implementation blackbox without leakage combination prepreprocesse assumption knowledge masking implementation carry attack introduce metric base sensitivity analysis reveal secret key value well point interest leakage mask location trace result experiment demonstrate interest new method show attack perform practicejatsp,0.564935064935065,0.14935064935064934,0.23376623376623376,0.025974025974025976,154.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Mixed Methods,Power Analysis on NTRU Prime,"<jats:p>This paper applies a variety of power analysis techniques to several implementations of NTRU Prime, a Round 2 submission to the NIST PQC Standardization Project. The techniques include vertical correlation power analysis, horizontal indepth correlation power analysis, online template attacks, and chosen-input simple power analysis. The implementations include the reference one, the one optimized using smladx, and three protected ones. Adversaries in this study can fully recover private keys with one single trace of short observation span, with few template traces from a fully controlled device similar to the target and no a priori power model, or sometimes even with the naked eye. The techniques target the constant-time generic polynomial multiplications in the product scanning method. Though in this work they focus on the decapsulation, they also work on the key generation and encapsulation of NTRU Prime. Moreover, they apply to the ideal-lattice-based cryptosystems where each private-key coefficient comes from a small set of possibilities.</jats:p>",https://doi.org/10.46586/tches.v2020.i1.123-151,CrossRef,power analysis ntru prime,jatspthis paper apply variety power analysis technique several implementation ntru prime round submission nist pqc standardization project technique include vertical correlation power analysis horizontal indepth correlation power analysis online template attack choseninput simple power analysis implementation include reference one one optimize use smladx three protect one adversary study fully recover private key one single trace short observation span template trace fully control device similar target priori power model sometimes even naked eye technique target constanttime generic polynomial multiplication product scan method though work focus decapsulation also work key generation encapsulation ntru prime moreover apply ideallatticebased cryptosystem privatekey coefficient come small set possibilitiesjatsp,power analysis ntru prime jatspthis paper apply variety power analysis technique several implementation ntru prime round submission nist pqc standardization project technique include vertical correlation power analysis horizontal indepth correlation power analysis online template attack choseninput simple power analysis implementation include reference one one optimize use smladx three protect one adversary study fully recover private key one single trace short observation span template trace fully control device similar target priori power model sometimes even naked eye technique target constanttime generic polynomial multiplication product scan method though work focus decapsulation also work key generation encapsulation ntru prime moreover apply ideallatticebased cryptosystem privatekey coefficient come small set possibilitiesjatsp,0.5392156862745098,0.09803921568627451,0.17647058823529413,0.058823529411764705,51.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Mixed Methods,Garbled Circuits from an SCA Perspective,"<jats:p>Garbling schemes, invented in the 80’s by Yao (FOCS’86), have been a versatile and fundamental tool in modern cryptography. A prominent application of garbled circuits is constant round secure two-party computation, which led to a long line of study of this object, where one of the most influential optimizations is Free-XOR (Kolesnikov and Schneider ICALP’08), introducing a global offset Δ for all garbled wire values where XOR gates are computed locally without garbling them. To date, garbling schemes were not studied per their side-channel attacks (SCA) security characteristics, even though SCA pose a significant security threat to cryptographic devices. In this research we, demonstrate that adversaries utilizing advanced SCA tools such as horizontal attacks, mixed with advanced hypothesis building and standard (vertical) SCA tools, can jeopardize garbling implementations.Our main observation is that garbling schemes utilizing a global secret Δ open a door to quite trivial side-channel attacks. We model our side-channel attacks on the garbler’s device and discuss the asymmetric setting where various computations are not performed on the evaluator side. This enables dangerous leakage extraction on the garbler and renders our attack impossible on the evaluator’s side.Theoretically, we first demonstrate on a simulated environment, that such attacks are quite devastating. Concretely, our attack is capable of extracting Δ when the circuit embeds only 8 input non-linear gates with fifth/first-order attack Success-Rates of 0.65/0.7. With as little as 3 such gates, our attack reduces the first-order Guessing Entropy of Δ from 128 to ∼ 48-bits. We further demonstrate our attack via an implementation and power measurements data over an STM 32-bit processor software implementing circuit garbling, and discuss their limitations and mitigation tactics on logical, protocol and implementation layers.</jats:p>",https://doi.org/10.46586/tches.v2023.i2.54-79,CrossRef,garbled circuit sca perspective,jatspgarble scheme invent yao focs versatile fundamental tool modern cryptography prominent application garbled circuit constant round secure twoparty computation lead long line study object one influential optimization freexor kolesnikov schneider icalp introduce global offset garbled wire value xor gate compute locally without garble date garbling scheme study per sidechannel attack sca security characteristic even though sca pose significant security threat cryptographic device research demonstrate adversary utilize advanced sca tool horizontal attack mix advanced hypothesis building standard vertical sca tool jeopardize garble implementationsour main observation garble scheme utilize global secret open door quite trivial sidechannel attack model sidechannel attack garbler device discuss asymmetric setting various computation perform evaluator side enable dangerous leakage extraction garbler render attack impossible evaluator sidetheoretically first demonstrate simulated environment attack quite devastating concretely attack capable extract circuit embed input nonlinear gate fifthfirstorder attack successrate little gate attack reduce firstorder guess entropy bit far demonstrate attack via implementation power measurement datum stm bit processor software implement circuit garbling discuss limitation mitigation tactic logical protocol implementation layersjatsp,garbled circuit sca perspective jatspgarble scheme invent yao focs versatile fundamental tool modern cryptography prominent application garbled circuit constant round secure twoparty computation lead long line study object one influential optimization freexor kolesnikov schneider icalp introduce global offset garbled wire value xor gate compute locally without garble date garbling scheme study per sidechannel attack sca security characteristic even though sca pose significant security threat cryptographic device research demonstrate adversary utilize advanced sca tool horizontal attack mix advanced hypothesis building standard vertical sca tool jeopardize garble implementationsour main observation garble scheme utilize global secret open door quite trivial sidechannel attack model sidechannel attack garbler device discuss asymmetric setting various computation perform evaluator side enable dangerous leakage extraction garbler render attack impossible evaluator sidetheoretically first demonstrate simulated environment attack quite devastating concretely attack capable extract circuit embed input nonlinear gate fifthfirstorder attack successrate little gate attack reduce firstorder guess entropy bit far demonstrate attack via implementation power measurement datum stm bit processor software implement circuit garbling discuss limitation mitigation tactic logical protocol implementation layersjatsp,0.47619047619047616,0.10119047619047619,0.24404761904761904,0.05357142857142857,168.0,0.0,0.0,0.0,1.0
Computer Engineering,Hardware Systems,Mixed Methods,Efficient and Private Computations with Code-Based Masking,"<jats:p>Code-based masking is a very general type of masking scheme that covers Boolean masking, inner product masking, direct sum masking, and so on. The merits of the generalization are twofold. Firstly, the higher algebraic complexity of the sharing function decreases the information leakage in “low noise conditions” and may increase the “statistical security order” of an implementation (with linear leakages). Secondly, the underlying error-correction codes can offer improved fault resistance for the encoded variables. Nevertheless, this higher algebraic complexity also implies additional challenges. On the one hand, a generic multiplication algorithm applicable to any linear code is still unknown. On the other hand, masking schemes with higher algebraic complexity usually come with implementation overheads, as for example witnessed by inner-product masking. In this paper, we contribute to these challenges in two directions. Firstly, we propose a generic algorithm that allows us (to the best of our knowledge for the first time) to compute on data shared with linear codes. Secondly, we introduce a new amortization technique that can significantly mitigate the implementation overheads of code-based masking, and illustrate this claim with a case study. Precisely, we show that, although performing every single code-based masked operation is relatively complex, processing multiple secrets in parallel leads to much better performances. This property enables code-based masked implementations of the AES to compete with the state-of-the-art in randomness complexity. Since our masked operations can be instantiated with various linear codes, we hope that these investigations open new avenues for the study of code-based masking schemes, by specializing the codes for improved performances, better side-channel security or improved fault tolerance.</jats:p>",https://doi.org/10.46586/tches.v2020.i2.128-171,CrossRef,efficient private computation codebased masking,jatspcodebase masking general type mask scheme cover boolean mask inner product mask direct sum masking merit generalization twofold firstly high algebraic complexity sharing function decrease information leakage low noise condition may increase statistical security order implementation linear leakage secondly underlying errorcorrection code offer improved fault resistance encode variable nevertheless high algebraic complexity also imply additional challenge one hand generic multiplication algorithm applicable linear code still unknown hand mask scheme high algebraic complexity usually come implementation overhead example witness innerproduct mask paper contribute challenge two direction firstly propose generic algorithm allow good knowledge first time compute datum share linear code secondly introduce new amortization technique significantly mitigate implementation overhead codebased masking illustrate claim case study precisely show although perform every single codebase mask operation relatively complex processing multiple secret parallel lead much well performance property enable codebase mask implementation aes compete stateoftheart randomness complexity since mask operation instantiate various linear code hope investigation open new avenue study codebased masking scheme specialize code improved performance well sidechannel security improved fault tolerancejatsp,efficient private computation codebased masking jatspcodebase masking general type mask scheme cover boolean mask inner product mask direct sum masking merit generalization twofold firstly high algebraic complexity sharing function decrease information leakage low noise condition may increase statistical security order implementation linear leakage secondly underlying errorcorrection code offer improved fault resistance encode variable nevertheless high algebraic complexity also imply additional challenge one hand generic multiplication algorithm applicable linear code still unknown hand mask scheme high algebraic complexity usually come implementation overhead example witness innerproduct mask paper contribute challenge two direction firstly propose generic algorithm allow good knowledge first time compute datum share linear code secondly introduce new amortization technique significantly mitigate implementation overhead codebased masking illustrate claim case study precisely show although perform every single codebase mask operation relatively complex processing multiple secret parallel lead much well performance property enable codebase mask implementation aes compete stateoftheart randomness complexity since mask operation instantiate various linear code hope investigation open new avenue study codebased masking scheme specialize code improved performance well sidechannel security improved fault tolerancejatsp,0.42011834319526625,0.10650887573964497,0.20118343195266272,0.09467455621301775,84.5,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Design and Development,"Cycle-Accurate Evaluation of Software-Hardware Co-Design of Decimal
  Computation in RISC-V Ecosystem","Software-hardware co-design solutions for decimal computation can provide
several Pareto points to development of embedded systems in terms of hardware
cost and performance. This paper demonstrates how to accurately evaluate such
co-design solutions using RISC-V ecosystem. In a software-hardware co-design
solution, a part of solution requires dedicated hardware. In our evaluation
framework, we develop new decimal oriented instructions supported by an
accelerator. The framework can realize cycle-accurate analysis for performance
as well as hardware overhead for co-design solutions for decimal computation.
The obtained performance result is compared with an estimation with dummy
functions.",http://arxiv.org/abs/2003.05315v1,arXiv,cycleaccurate evaluation softwarehardware codesign decimal computation riscv ecosystem,softwarehardware codesign solution decimal computation provide several pareto point development embed system term hardware cost performance paper demonstrate accurately evaluate codesign solution use riscv ecosystem softwarehardware codesign solution part solution require dedicated hardware evaluation framework develop new decimal orient instruction support accelerator framework realize cycleaccurate analysis performance well hardware overhead codesign solution decimal computation obtain performance result compare estimation dummy function,cycleaccurate evaluation softwarehardware codesign decimal computation riscv ecosystem softwarehardware codesign solution decimal computation provide several pareto point development embed system term hardware cost performance paper demonstrate accurately evaluate codesign solution use riscv ecosystem softwarehardware codesign solution part solution require dedicated hardware evaluation framework develop new decimal orient instruction support accelerator framework realize cycleaccurate analysis performance well hardware overhead codesign solution decimal computation obtain performance result compare estimation dummy function,0.6885245901639344,0.13114754098360656,0.14754098360655737,0.03278688524590164,61.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Design and Development,"HENNC: Hardware Engine for Artificial Neural Network-based Chaotic
  Oscillators","This letter introduces a framework for the automatic generation of hardware
cores for Artificial Neural Network (ANN)-based chaotic oscillators. The
framework trains the model to approximate a chaotic system, then performs
design space exploration yielding potential hardware architectures for its
implementation. The framework then generates the corresponding synthesizable
High-Level Synthesis code and a validation testbench from a selected solution.
The hardware design primarily targets FPGAs. The proposed framework offers a
rapid hardware design process of candidate architectures superior to manually
designed works in terms of hardware cost and throughput. The source code is
available on GitHub.",http://arxiv.org/abs/2407.19165v1,arXiv,hennc hardware engine artificial neural networkbase chaotic oscillator,letter introduce framework automatic generation hardware core artificial neural network annbase chaotic oscillator framework train model approximate chaotic system perform design space exploration yield potential hardware architecture implementation framework generate corresponding synthesizable highlevel synthesis code validation testbench select solution hardware design primarily target fpgas propose framework offer rapid hardware design process candidate architecture superior manually design work term hardware cost throughput source code available github,hennc hardware engine artificial neural networkbase chaotic oscillator letter introduce framework automatic generation hardware core artificial neural network annbase chaotic oscillator framework train model approximate chaotic system perform design space exploration yield potential hardware architecture implementation framework generate corresponding synthesizable highlevel synthesis code validation testbench select solution hardware design primarily target fpgas propose framework offer rapid hardware design process candidate architecture superior manually design work term hardware cost throughput source code available github,0.5846153846153846,0.1076923076923077,0.2,0.03076923076923077,65.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Design and Development,"Hardware Architecture of Wireless Power Transfer, RFID, and WIPT Systems","In this work, we provide an overview of the hardware architecture of wireless
power transfer (WPT), RFID, and wireless information and power transfer (WIPT)
systems. The historical milestones and structure differences among WPT, RFID,
and WIPT are introduced.",http://arxiv.org/abs/2102.06876v1,arXiv,hardware architecture wireless power transfer rfid wipt system,work provide overview hardware architecture wireless power transfer wpt rfid wireless information power transfer wipt system historical milestone structure difference among wpt rfid wipt introduce,hardware architecture wireless power transfer rfid wipt system work provide overview hardware architecture wireless power transfer wpt rfid wireless information power transfer wipt system historical milestone structure difference among wpt rfid wipt introduce,0.72,0.08,0.16,0.0,25.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Design and Development,"LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware
  Debugging","This paper presents LLM4SecHW, a novel framework for hardware debugging that
leverages domain specific Large Language Model (LLM). Despite the success of
LLMs in automating various software development tasks, their application in the
hardware security domain has been limited due to the constraints of commercial
LLMs and the scarcity of domain specific data. To address these challenges, we
propose a unique approach to compile a dataset of open source hardware design
defects and their remediation steps, utilizing version control data. This
dataset provides a substantial foundation for training machine learning models
for hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this
dataset, enabling the identification and rectification of bugs in hardware
designs. This pioneering approach offers a reference workflow for the
application of fine tuning domain specific LLMs in other research areas. We
evaluate the performance of our proposed system on various open source hardware
designs, demonstrating its efficacy in accurately identifying and correcting
defects. Our work brings a new perspective on automating the quality control
process in hardware design.",http://arxiv.org/abs/2401.16448v1,arXiv,llmsechw leverage domain specific large language model hardware debugging,paper present llmsechw novel framework hardware debug leverage domain specific large language model llm despite success llm automate various software development task application hardware security domain limit due constraint commercial llm scarcity domain specific datum address challenge propose unique approach compile dataset open source hardware design defect remediation step utilize version control datum dataset provide substantial foundation training machine learning model hardware llmsechw employ fine tuning medium sized llm base dataset enable identification rectification bug hardware design pioneer approach offer reference workflow application fine tuning domain specific llm research area evaluate performance propose system various open source hardware design demonstrate efficacy accurately identify correct defect work bring new perspective automate quality control process hardware design,llmsechw leverage domain specific large language model hardware debugging paper present llmsechw novel framework hardware debug leverage domain specific large language model llm despite success llm automate various software development task application hardware security domain limit due constraint commercial llm scarcity domain specific datum address challenge propose unique approach compile dataset open source hardware design defect remediation step utilize version control datum dataset provide substantial foundation training machine learning model hardware llmsechw employ fine tuning medium sized llm base dataset enable identification rectification bug hardware design pioneer approach offer reference workflow application fine tuning domain specific llm research area evaluate performance propose system various open source hardware design demonstrate efficacy accurately identify correct defect work bring new perspective automate quality control process hardware design,0.6347826086956522,0.09565217391304348,0.19130434782608696,0.017391304347826087,115.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Design and Development,"DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation
  and Optimization tools for Modern AI/Non-AI Workloads","We introduce DRAGON, an open-source, fast and explainable hardware simulation
and optimization toolchain that enables hardware architects to simulate
hardware designs, and to optimize hardware designs to efficiently execute
workloads.
  The DRAGON toolchain provides the following tools: Hardware Model Generator
(DGen), Hardware Simulator (DSim) and Hardware Optimizer (DOpt).
  DSim provides the simulation of running algorithms (represented as data-flow
graphs) on hardware described. DGen describes the hardware in detail, with user
input architectures/technology (represented in a custom description language).
A novel methodology of gradient descent from the simulation allows us optimize
the hardware model (giving the directions for improvements in technology
parameters and design parameters), provided by Dopt.
  DRAGON framework (DSim) is much faster than previously avaible works for
simulation, which is possible through performance-first code writing practices,
mathematical formulas for common computing operations to avoid cycle-accurate
simulation steps, efficient algorithms for mapping, and data-structure
representations for hardware state. DRAGON framework (Dopt) generates
performance optimized architectures for both AI and Non-AI Workloads, and
provides technology improvement directions for 100x-1000x better future
computing systems.",http://arxiv.org/abs/2204.06676v7,arXiv,dragon differentiable graph execution suite hardware simulation optimization tool modern ainonai workload,introduce dragon opensource fast explainable hardware simulation optimization toolchain enable hardware architect simulate hardware design optimize hardware design efficiently execute workload dragon toolchain provide follow tool hardware model generator dgen hardware simulator dsim hardware optimizer dopt dsim provide simulation running algorithm represent dataflow graph hardware describe dgen describe hardware detail user input architecturestechnology represent custom description language novel methodology gradient descent simulation allow optimize hardware model give direction improvement technology parameter design parameter provide dopt dragon framework dsim much fast previously avaible work simulation possible performancefirst code writing practice mathematical formula common computing operation avoid cycleaccurate simulation step efficient algorithm mapping datastructure representation hardware state dragon framework dopt generate performance optimize architecture nonai workload provide technology improvement direction well future computing system,dragon differentiable graph execution suite hardware simulation optimization tool modern ainonai workload introduce dragon opensource fast explainable hardware simulation optimization toolchain enable hardware architect simulate hardware design optimize hardware design efficiently execute workload dragon toolchain provide follow tool hardware model generator dgen hardware simulator dsim hardware optimizer dopt dsim provide simulation running algorithm represent dataflow graph hardware describe dgen describe hardware detail user input architecturestechnology represent custom description language novel methodology gradient descent simulation allow optimize hardware model give direction improvement technology parameter design parameter provide dopt dragon framework dsim much fast previously avaible work simulation possible performancefirst code writing practice mathematical formula common computing operation avoid cycleaccurate simulation step efficient algorithm mapping datastructure representation hardware state dragon framework dopt generate performance optimize architecture nonai workload provide technology improvement direction well future computing system,0.6475409836065574,0.12295081967213115,0.10655737704918032,0.02459016393442623,122.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Theoretical / Conceptual,From Hardware to Hardcore,"<jats:p>The state and relevance of Systems as a field of research and a specific form of scientific inquiry into complex real-world problem situations, can be enhanced significantly by developing and applying more formalized and coherent tools: a new ‘hardware' enabling to build a new ‘hardcore' for systems science. The basis of this new hardware stems from a line of thought emanating from George Spencer-Brown and the ‘Laws of Form', running through the work of Francisco Varela and his calculus for self-reference, being radicalized by Niklas Luhmann and his views on ‘Social Systems', and continued by Dirk Baecker with the application of form theory to management and organizations. In this contribution, the author develops an understanding and appreciation of the potentials of a form-theoretical approach to formalizing systems (real-world phenomena) as well as Systems (field of research). Central aspects will be the power of the form-theoretical hardware as regards systems storytelling, systems diagnostics and abductive reasoning.</jats:p>",https://doi.org/10.4018/ijss.2017010105,CrossRef,hardware hardcore,jatspthe state relevance system field research specific form scientific inquiry complex realworld problem situation enhance significantly develop apply formalized coherent tool new hardware enable build new hardcore system science basis new hardware stem line thought emanating george spencerbrown law form run work francisco varela calculus selfreference radicalize niklas luhmann view social system continue dirk baecker application form theory management organization contribution author develop understanding appreciation potential formtheoretical approach formalizing system realworld phenomena well system field research central aspect power formtheoretical hardware regard system storytelling system diagnostic abductive reasoningjatsp,hardware hardcore jatspthe state relevance system field research specific form scientific inquiry complex realworld problem situation enhance significantly develop apply formalized coherent tool new hardware enable build new hardcore system science basis new hardware stem line thought emanating george spencerbrown law form run work francisco varela calculus selfreference radicalize niklas luhmann view social system continue dirk baecker application form theory management organization contribution author develop understanding appreciation potential formtheoretical approach formalizing system realworld phenomena well system field research central aspect power formtheoretical hardware regard system storytelling system diagnostic abductive reasoningjatsp,0.5454545454545454,0.125,0.17045454545454544,0.011363636363636364,88.0,0.0,0.0,0.0,2.0
Computer Engineering,Hardware Systems,Theoretical / Conceptual,Uncontrolled Learning: Codesign of Neuromorphic Hardware Topology for Neuromorphic Algorithms,"<jats:p>Neuromorphic computing has the potential to revolutionize future technologies and our understanding of intelligence, yet it remains challenging to realize in practice. The learning‐from‐mistakes algorithm, inspired by the brain's simple learning rules of inhibition and pruning, is one of the few brain‐like training methods. This algorithm is implemented in neuromorphic memristive hardware through a codesign process that evaluates essential hardware trade‐offs. While the algorithm effectively trains small networks as binary classifiers and perceptrons, performance declines significantly with increasing network size unless the hardware is tailored to the algorithm. This work investigates the trade‐offs between depth, controllability, and capacity—the number of learnable patterns—in neuromorphic hardware. This highlights the importance of topology and governing equations, providing theoretical tools to evaluate a device's computational capacity based on its measurements and circuit structure. The findings show that breaking neural network symmetry enhances both controllability and capacity. Additionally, by pruning the circuit, neuromorphic algorithms in all‐memristive circuits can utilize stochastic resources to create local contrasts in network weights. Through combined experimental and simulation efforts, the parameters are identified that enable networks to exhibit emergent intelligence from simple rules, advancing the potential of neuromorphic computing.</jats:p>",https://doi.org/10.1002/aisy.202400739,CrossRef,uncontrolled learning codesign neuromorphic hardware topology neuromorphic algorithm,jatspneuromorphic computing potential revolutionize future technology understanding intelligence yet remain challenge realize practice algorithm inspire brain simple learning rule inhibition pruning one training method algorithm implement neuromorphic memristive hardware codesign process evaluate essential hardware algorithm effectively train small network binary classifier perceptron performance decline significantly increase network size unless hardware tailor algorithm work investigate depth controllability capacity number learnable pattern neuromorphic hardware highlight importance topology governing equation provide theoretical tool evaluate device computational capacity base measurement circuit structure finding show break neural network symmetry enhance controllability capacity additionally prune circuit neuromorphic algorithm circuit utilize stochastic resource create local contrast network weight combine experimental simulation effort parameter identify enable network exhibit emergent intelligence simple rule advance potential neuromorphic computingjatsp,uncontrolled learning codesign neuromorphic hardware topology neuromorphic algorithm jatspneuromorphic computing potential revolutionize future technology understanding intelligence yet remain challenge realize practice algorithm inspire brain simple learning rule inhibition pruning one training method algorithm implement neuromorphic memristive hardware codesign process evaluate essential hardware algorithm effectively train small network binary classifier perceptron performance decline significantly increase network size unless hardware tailor algorithm work investigate depth controllability capacity number learnable pattern neuromorphic hardware highlight importance topology governing equation provide theoretical tool evaluate device computational capacity base measurement circuit structure finding show break neural network symmetry enhance controllability capacity additionally prune circuit neuromorphic algorithm circuit utilize stochastic resource create local contrast network weight combine experimental simulation effort parameter identify enable network exhibit emergent intelligence simple rule advance potential neuromorphic computingjatsp,0.5084745762711864,0.1694915254237288,0.16101694915254236,0.03389830508474576,118.0,1.0,0.0,0.0,1.0
Computer Engineering,Hardware Systems,Theoretical / Conceptual,Robust but Relaxed Probing Model,"<jats:p>Masking has become a widely applied and heavily researched method to protect cryptographic implementations against Side-Channel Analysis (SCA) attacks. The success of masking is primarily attributed to its strong theoretical foundation enabling it to formally prove security by modeling physical properties through socalled probing models. Specifically, the robust d-probing model enables us to prove the security for arbitrarily masked hardware circuits, manually or with the assistance of automated tools, even when considering the imperfect nature of physical hardware, including the occurrence of physical defaults such as glitches. However, the generic strategy employed by the robust d-probing model comes with a downside: It tends to over-conservatively model the information leakage caused by glitches meaning that the robust d-probing model considers glitches that can never occur in practice. This implies that in theory, an adversary could gain more information than she would obtain in practice. From a designer’s perspective, this entails that (1) securely designed hardware circuits may need to be withdrawn due to potential insecurity under the robust d-probing model and (2) designs that satisfy the security requirements of the robust d-probing model may incur unnecessary overhead, such as increased circuit size or latency.In this work, we refine the formal treatment of glitches within the robust d-probing model to address glitches more accurately within a formal adversary model. Unlike the robust d-probing model, our approach considers glitches based on the operations performed and the data processed, ensuring that only manifesting glitches are accounted for. As a result, we introduce the Robust but Relaxed (RR) d-probing model, a formal adversary model maintaining the same level of security as the robust d-probing model but without the overly conservative treatment of glitches. Leveraging our new model, we prove the security of LUT-based Masked Dual-Rail with Pre-charge Logic (LMDPL) gadgets, a class of physically secure gadgets reported as insecure based on the robust d-probing model. We provide manual proofs and automated security evaluations employing an updated version of PROLEAD capable of verifying the security of masked circuits under our new model.</jats:p>",https://doi.org/10.46586/tches.v2024.i4.451-482,CrossRef,robust relaxed probe model,jatspmaske become widely apply heavily research method protect cryptographic implementation sidechannel analysis sca attack success masking primarily attribute strong theoretical foundation enable formally prove security model physical property socalled probe model specifically robust dprobing model enable prove security arbitrarily mask hardware circuit manually assistance automate tool even consider imperfect nature physical hardware include occurrence physical default glitch however generic strategy employ robust dprobing model come downside tend overconservatively model information leakage cause glitch mean robust dprobing model consider glitch never occur practice imply theory adversary could gain information would obtain practice designer perspective entail securely design hardware circuit may need withdraw due potential insecurity robust dprobing model design satisfy security requirement robust dprobing model may incur unnecessary overhead increase circuit size latencyin work refine formal treatment glitch within robust dprobing model address glitch accurately within formal adversary model unlike robust dprobing model approach consider glitch base operation perform datum process ensure manifest glitch account result introduce robust relaxed dprobe model formal adversary model maintain level security robust dprobing model without overly conservative treatment glitch leverage new model prove security lutbased mask dualrail precharge logic lmdpl gadget class physically secure gadget report insecure base robust dprobing model provide manual proof automated security evaluation employ update version prolead capable verify security mask circuit new modeljatsp,robust relaxed probe model jatspmaske become widely apply heavily research method protect cryptographic implementation sidechannel analysis sca attack success masking primarily attribute strong theoretical foundation enable formally prove security model physical property socalled probe model specifically robust dprobing model enable prove security arbitrarily mask hardware circuit manually assistance automate tool even consider imperfect nature physical hardware include occurrence physical default glitch however generic strategy employ robust dprobing model come downside tend overconservatively model information leakage cause glitch mean robust dprobing model consider glitch never occur practice imply theory adversary could gain information would obtain practice designer perspective entail securely design hardware circuit may need withdraw due potential insecurity robust dprobing model design satisfy security requirement robust dprobing model may incur unnecessary overhead increase circuit size latencyin work refine formal treatment glitch within robust dprobing model address glitch accurately within formal adversary model unlike robust dprobing model approach consider glitch base operation perform datum process ensure manifest glitch account result introduce robust relaxed dprobe model formal adversary model maintain level security robust dprobing model without overly conservative treatment glitch leverage new model prove security lutbased mask dualrail precharge logic lmdpl gadget class physically secure gadget report insecure base robust dprobing model provide manual proof automated security evaluation employ update version prolead capable verify security mask circuit new modeljatsp,0.5258215962441315,0.15023474178403756,0.16901408450704225,0.07042253521126761,213.0,0.0,0.0,0.0,0.0
Computer Engineering,Hardware Systems,Theoretical / Conceptual,Hardware for Deep Learning Acceleration,"<jats:p>Deep learning (DL) has proven to be one of the most pivotal components of machine learning given its notable performance in a variety of application domains. Neural networks (NNs) for DL are tailored to specific application domains by varying in their topology and activation nodes. Nevertheless, the major operation type (with the largest computational complexity) is commonly multiply‐accumulate operation irrespective of their topology. Recent trends in DL highlight the evolution of NNs such that they become deeper and larger, and thus their prohibitive computational complexity. To cope with the consequent prohibitive latency for computation, 1) general‐purpose hardware, e.g., central processing units and graphics processing units, has been redesigned, and 2) various DL accelerators have been newly introduced, e.g., neural processing units, and computing‐in‐memory units for deep NN‐based DL, and neuromorphic processors for spiking NN‐based DL. In this review, these accelerators and their pros and cons are overviewed with particular focus on their performance and memory bandwidth.</jats:p>",https://doi.org/10.1002/aisy.202300762,CrossRef,hardware deep learning acceleration,jatspdeep learning prove one pivotal component machine learning give notable performance variety application domain neural network tailor specific application domain vary topology activation nod nevertheless major operation type large computational complexity commonly operation irrespective topology recent trend highlight evolution become deep large thus prohibitive computational complexity cope consequent prohibitive latency computation hardware central processing unit graphic processing unit redesign various accelerator newly introduce neural processing unit unit deep neuromorphic processor spike review accelerator pro con overviewe particular focus performance memory bandwidthjatsp,hardware deep learning acceleration jatspdeep learning prove one pivotal component machine learning give notable performance variety application domain neural network tailor specific application domain vary topology activation nod nevertheless major operation type large computational complexity commonly operation irrespective topology recent trend highlight evolution become deep large thus prohibitive computational complexity cope consequent prohibitive latency computation hardware central processing unit graphic processing unit redesign various accelerator newly introduce neural processing unit unit deep neuromorphic processor spike review accelerator pro con overviewe particular focus performance memory bandwidthjatsp,0.5185185185185185,0.09876543209876543,0.24691358024691357,0.06172839506172839,81.0,0.0,1.0,0.0,0.0
Computer Engineering,Hardware Systems,Theoretical / Conceptual,Diseño de Hardware y Software de Systems on Chip empleando tecnología Xilinx EDK,"<jats:p>El presente artículo resume el proceso empleado para obtener el primer System on Chip (SoC) diseñado, desarrollado, y emulado en la Escuela Politécnica del Ejército (ESPE) y en el Ecuador. Se demostrará que combinando las ventajas del diseño sobre Field Programable Gate Arrays (FPGAs) empleando la reutilización de IP Cores y plataformas, junto al uso de la tecnología de desarrollo Xilinx EDK, se puede diseñar tanto el hardware como el software de un chip de manera rápida y económicamente fiable. Además, se detalla el uso de la metodología Platform Based Design (PBD) y del concepto de co-diseño de hardware y software para diseñar las capas de hardware, sistema operativo y aplicación de un chip. La capa de hardware contiene una serie de IP Cores gobernados por un procesador MicroBlaze trabajando dentro de la arquitectura CoreConnect de IBM. Mientras que la capa de sistema operativo está conformada por drivers, librerías y el Sistema Operativo en Tiempo Real (RTOS) Xilkernel. Por último, la capa de aplicación tiene la funcionalidad de controlar una planta de temperatura, mediante la selección de dos técnicas de control: ON-OFF o PID. Cabe destacar que el co-diseño se desarrolló considerando un adecuado enfoque conceptual, arquitectural, y metodológico1.</jats:p>",https://doi.org/10.24133/maskay.v2i1.146,CrossRef,diseño hardware software system chip empleando tecnología xilinx edk,jatspel presente artículo resume proceso empleado para obtener primer system chip soc diseñado desarrollado emulado escuela politécnica del ejército espe ecuador demostrará que combinando las ventajas del diseño sobre field programable gate arrays fpgas empleando reutilización core plataformas junto uso tecnología desarrollo xilinx edk puede diseñar tanto hardware como software chip manera rápida económicamente fiable además detalla uso metodología platform base design pbd del concepto codiseño hardware software para diseñar las capas hardware sistema operativo aplicación chip capa hardware contiene una serie core gobernado por procesador microblaze trabajando dentro arquitectura coreconnect ibm mientras que capa sistema operativo está conformada por driver librerías sistema operativo tiempo real rto xilkernel por último capa aplicación tiene funcionalidad controlar una planta temperatura mediante selección dos técnicas control onoff pid cabe destacar que codiseño desarrolló considerando adecuado enfoque conceptual arquitectural metodológicojatsp,diseño hardware software system chip empleando tecnología xilinx edk jatspel presente artículo resume proceso empleado para obtener primer system chip soc diseñado desarrollado emulado escuela politécnica del ejército espe ecuador demostrará que combinando las ventajas del diseño sobre field programable gate arrays fpgas empleando reutilización core plataformas junto uso tecnología desarrollo xilinx edk puede diseñar tanto hardware como software chip manera rápida económicamente fiable además detalla uso metodología platform base design pbd del concepto codiseño hardware software para diseñar las capas hardware sistema operativo aplicación chip capa hardware contiene una serie core gobernado por procesador microblaze trabajando dentro arquitectura coreconnect ibm mientras que capa sistema operativo está conformada por driver librerías sistema operativo tiempo real rto xilkernel por último capa aplicación tiene funcionalidad controlar una planta temperatura mediante selección dos técnicas control onoff pid cabe destacar que codiseño desarrolló considerando adecuado enfoque conceptual arquitectural metodológicojatsp,0.17647058823529413,0.029411764705882353,0.029411764705882353,0.0,136.0,2.0,3.0,0.0,6.0
Computer Engineering,Computer Architecture,Quantitative,Direct-execution computer architecture,"<jats:p>The Direct-Execution Architecture is a language-directed computer architecture. It can accept a highlevel-language program and directly executes it without compilation, assembly, linkage editing or loading. It offers a means to eliminate compilers, loaders etc. and attacks the problem of mounting software cost. In addition, the advent of microprocessors has demonstrated that highly complex digital hardware can be built reliably and inexpensively. Using this hardware to implement the Direct-Execution Architecture redistributes apportionment of costs between the hardware and software. The paper surveys the Direct-Execution Architecture, presents the relationship between language and architecture, and explains how a Direct-Execution system works. It also brings up the use of Direct-Execution for a highly interactive program writing, debugging, execution system. With this system, program writing could proceed like English composition. This paper then discusses the issue of a single high-level machine language, and the potential role of the interpreters. Finally, it attempts to fortell what could happen to the Direct-Execution Architecture in the next five to 10 years.</jats:p>",https://doi.org/10.1145/859412.859415,CrossRef,directexecution computer architecture,jatspthe directexecution architecture languagedirecte computer architecture accept highlevellanguage program directly execute without compilation assembly linkage editing loading offer means eliminate compiler loader etc attack problem mount software cost addition advent microprocessor demonstrate highly complex digital hardware build reliably inexpensively use hardware implement directexecution architecture redistribute apportionment cost hardware software paper survey directexecution architecture present relationship language architecture explain directexecution system work also bring use directexecution highly interactive program write debug execution system system program writing could proceed like english composition paper discuss issue single highlevel machine language potential role interpreter finally attempt fortell could happen directexecution architecture next five yearsjatsp,directexecution computer architecture jatspthe directexecution architecture languagedirecte computer architecture accept highlevellanguage program directly execute without compilation assembly linkage editing loading offer means eliminate compiler loader etc attack problem mount software cost addition advent microprocessor demonstrate highly complex digital hardware build reliably inexpensively use hardware implement directexecution architecture redistribute apportionment cost hardware software paper survey directexecution architecture present relationship language architecture explain directexecution system work also bring use directexecution highly interactive program write debug execution system system program writing could proceed like english composition paper discuss issue single highlevel machine language potential role interpreter finally attempt fortell could happen directexecution architecture next five yearsjatsp,0.64,0.12,0.08,0.07,100.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Quantitative,"The nature of ""computer architecture""","<jats:p>""The finest words in the world are only vain sounds if you cannot understand them."" Anatole FranceThere are several different interpretations of what ""computer architecture"" is, and what the phrase means. An informal survey of professionals who routinely deal with computers was conducted to determine better the perceived meaning of ""computer architecture"". From this I hoped to identify potential areas of misunderstanding when discussing the various aspects of computer architecture.</jats:p>",https://doi.org/10.1145/859463.859464,CrossRef,nature computer architecture,jatspthe fine word world vain sound understand anatole francethere several different interpretation computer architecture phrase mean informal survey professional routinely deal computer conduct determine well perceive meaning computer architecture hope identify potential area misunderstanding discuss various aspect computer architecturejatsp,nature computer architecture jatspthe fine word world vain sound understand anatole francethere several different interpretation computer architecture phrase mean informal survey professional routinely deal computer conduct determine well perceive meaning computer architecture hope identify potential area misunderstanding discuss various aspect computer architecturejatsp,0.5384615384615384,0.1282051282051282,0.20512820512820512,0.07692307692307693,39.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Quantitative,MisSPECulation,"<jats:p>A majority of the papers published in leading computer architecture conferences use SPEC CPU2000, or its predecessor SPEC CPU95, which has become the de facto standard for measuring processor and/or memory-hierarchy performance. However, in most cases a subset of the suite's benchmarks are simulated. For example: 27 papers were published in ISCA 2002, 16 used SPEC CINT2000, 4 used the whole suite, and only 3 papers explained their omissions.This paper quantifies the extent of this phenomenon in the ISCA, Micro, and HPCA conferences: 173 papers were surveyed, 115 used benchmarks from SPEC CINT, but only 23 used the whole suite. If this current trend continues, by the year 2005 80% of the papers will use the full CINT2000 suite, a year after CPU2004 shall be announced.We claim that results based upon a subset of a benchmark suite are speculative and conflict with Amdahl's Law. The law implies that we must present the speedup of using the proposed technique on the whole suite. Projecting the law (by statistically supplying values for the missing benchmarks) to several published papers reduces promising results to average ones. Speedups are reduced from 1.42 to 1.16 in one case, from 1.43 to 1.13 in another, and from 1.76 to 1.15 in a third.Finally, we have found that the disregard for CFP2000 is unwarranted in papers that explore the data cache domain, the suite displays a higher data cache miss rate than CINT2000, which is used more frequently.</jats:p>",https://doi.org/10.1145/871656.859625,CrossRef,misspeculation,jatspa majority paper publish lead computer architecture conference use spec cpu predecessor spec cpu become facto standard measure processor andor memoryhierarchy performance however case subset suite benchmark simulate example paper publish isca use spec cint use whole suite paper explain omissionsthis paper quantifie extent phenomenon isca micro hpca conference paper survey use benchmark spec cint use whole suite current trend continue year paper use full cint suite year cpu shall announcedwe claim result base upon subset benchmark suite speculative conflict amdahls law law imply must present speedup use propose technique whole suite project law statistically supply value miss benchmark several publish paper reduce promise result average one speedup reduce one case another thirdfinally find disregard cfp unwarranted paper explore datum cache domain suite display high data cache miss rate cint use frequentlyjatsp,misspeculation jatspa majority paper publish lead computer architecture conference use spec cpu predecessor spec cpu become facto standard measure processor andor memoryhierarchy performance however case subset suite benchmark simulate example paper publish isca use spec cint use whole suite paper explain omissionsthis paper quantifie extent phenomenon isca micro hpca conference paper survey use benchmark spec cint use whole suite current trend continue year paper use full cint suite year cpu shall announcedwe claim result base upon subset benchmark suite speculative conflict amdahls law law imply must present speedup use propose technique whole suite project law statistically supply value miss benchmark several publish paper reduce promise result average one speedup reduce one case another thirdfinally find disregard cfp unwarranted paper explore datum cache domain suite display high data cache miss rate cint use frequentlyjatsp,0.5227272727272727,0.12878787878787878,0.12878787878787878,0.030303030303030304,132.0,1.0,0.0,1.0,0.0
Computer Engineering,Computer Architecture,Quantitative,Stock Price Predictor: Implementing Stocks Predictive Model Using Deep Learning,"<jats:p>Purpose–This paper proposes a novel deep neural network model, specifically long short-term  memory  (LSTM)  networks,for  predicting  stock  prices  using  historical  data  and financial indicators.

Method–LTSM  can  handle  long  sequenceswhile  capturing temporal  dependencies, making it an excellent choice for NLP or timeseries. The model is trained and tested on the Ayala Corporation (AYALY)stock dataset from 2016 to 2019, using four financial indicators: earnings  per  share  (EPS),  EPS  growth,  price/earnings  ratio,  and  price/earnings-to-growth ratio.

Results–The results show that the model achieves high accuracy and outperforms other Deep  Neural  Network variantsas  confirmed by  assessing  its  performance  using  suitable metrics  like  mean  squared  error  and  mean  absolute  error.It  effectively  explored  and selected  relevant  financial  indicators,  implemented  data  preprocessing  techniques,  and trained the model using historical data.

Conclusion–The projecteffectively explored and selected relevant financial indicators and trained LSTM modelsusing historical data, and, thus,met its objectives todevelop a deep neural network model for stock price prediction.

Recommendations–The authors recommend that future researchers continue to explore the  integration  of  a diverse  set  of  financial  indicators, employ  rigorous  comparative analyses,  and  experiment  with  different  time  frames  for  future  predictionsto further enhance prediction accuracy.

Research  Implications–This  papercontributesto  the  ongoing  development  of  machine-learning studies, especially in the Philippines, particularly fortime-series forecasting. With more  accurate  predictions  of  stock  prices,  the study could enable  investors  to  make informed investment decisions, trading strategies,and financial decision-making processes.

Keywords–DeepNeural Network, Long Short-Term Memory (LSTM) Networks, Machine Learning, Stock Price Prediction, Time Series Forecasting</jats:p>",https://doi.org/10.25147/ijcsr.2017.001.1.209,CrossRef,stock price predictor implement stock predictive model use deep learning,jatsppurpose paper propose novel deep neural network model specifically long shortterm memory lstm networksfor predict stock price use historical datum financial indicator method ltsm handle long sequenceswhile capture temporal dependency make excellent choice nlp timeserie model train test ayala corporation ayalystock dataset use four financial indicator earning per share eps eps growth priceearning ratio priceearningstogrowth ratio result result show model achieve high accuracy outperform deep neural network variantsas confirm assess performance use suitable metric like mean square error mean absolute errorit effectively explore select relevant financial indicator implement datum preprocesse technique train model use historical datum conclusion projecteffectively explore select relevant financial indicator train lstm modelsuse historical datum thusmet objective todevelop deep neural network model stock price prediction recommendation author recommend future researcher continue explore integration diverse set financial indicator employ rigorous comparative analysis experiment different time frame future predictionsto far enhance prediction accuracy research implication papercontributesto ongoing development machinelearne study especially philippine particularly fortimeserie forecasting accurate prediction stock price study could enable investor make informed investment decision trade strategiesand financial decisionmake process keyword deepneural network long shortterm memory lstm network machine learn stock price prediction time series forecastingjatsp,stock price predictor implement stock predictive model use deep learning jatsppurpose paper propose novel deep neural network model specifically long shortterm memory lstm networksfor predict stock price use historical datum financial indicator method ltsm handle long sequenceswhile capture temporal dependency make excellent choice nlp timeserie model train test ayala corporation ayalystock dataset use four financial indicator earning per share eps eps growth priceearning ratio priceearningstogrowth ratio result result show model achieve high accuracy outperform deep neural network variantsas confirm assess performance use suitable metric like mean square error mean absolute errorit effectively explore select relevant financial indicator implement datum preprocesse technique train model use historical datum conclusion projecteffectively explore select relevant financial indicator train lstm modelsuse historical datum thusmet objective todevelop deep neural network model stock price prediction recommendation author recommend future researcher continue explore integration diverse set financial indicator employ rigorous comparative analysis experiment different time frame future predictionsto far enhance prediction accuracy research implication papercontributesto ongoing development machinelearne study especially philippine particularly fortimeserie forecasting accurate prediction stock price study could enable investor make informed investment decision trade strategiesand financial decisionmake process keyword deepneural network long shortterm memory lstm network machine learn stock price prediction time series forecastingjatsp,0.48677248677248675,0.164021164021164,0.20634920634920634,0.031746031746031744,189.0,0.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Quantitative,An embedded DRAM architecture for large-scale spatial-lattice computations,"<jats:p>Spatial-lattice computations with finite-range interactions are an important class of easily parallelized computations. This class includes many simple and direct algorithms for physical simulation, virtual-reality simulation, agent-based modeling, logic simulation, 2D and 3D image processing and rendering, and other volumetric data processing tasks. The range of applicability of such algorithms is completely dependant upon the lattice-sizes and processing speeds that are computationally feasible. Using embedded DRAM and a new technique for organizing SIMD memory and communications we can efficiently utilize 1 Tbit/sec of sustained memory bandwidth in each chip in an indefinitely scalable array of chips. This allows a 10,000-fold speedup per memory chip for these algorithms compared to the CAM-8 lattice gas computer, and is about one million times faster per memory chip for these calculations than a CM-2.</jats:p>",https://doi.org/10.1145/342001.339672,CrossRef,embed dram architecture largescale spatiallattice computation,jatspspatiallattice computation finiterange interaction important class easily parallelize computation class include many simple direct algorithm physical simulation virtualreality simulation agentbase modeling logic simulation image processing rendering volumetric datum processing task range applicability algorithms completely dependant upon latticesize processing speed computationally feasible use embed dram new technique organize simd memory communication efficiently utilize tbitsec sustained memory bandwidth chip indefinitely scalable array chip allow fold speedup per memory chip algorithm compare cam lattice gas computer one million time fast per memory chip calculation cmjatsp,embed dram architecture largescale spatiallattice computation jatspspatiallattice computation finiterange interaction important class easily parallelize computation class include many simple direct algorithm physical simulation virtualreality simulation agentbase modeling logic simulation image processing rendering volumetric datum processing task range applicability algorithms completely dependant upon latticesize processing speed computationally feasible use embed dram new technique organize simd memory communication efficiently utilize tbitsec sustained memory bandwidth chip indefinitely scalable array chip allow fold speedup per memory chip algorithm compare cam lattice gas computer one million time fast per memory chip calculation cmjatsp,0.5121951219512195,0.08536585365853659,0.14634146341463414,0.07317073170731707,82.0,1.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Qualitative,"Does Unsupervised Architecture Representation Learning Help Neural
  Architecture Search?","Existing Neural Architecture Search (NAS) methods either encode neural
architectures using discrete encodings that do not scale well, or adopt
supervised learning-based methods to jointly learn architecture representations
and optimize architecture search on such representations which incurs search
bias. Despite the widespread use, architecture representations learned in NAS
are still poorly understood. We observe that the structural properties of
neural architectures are hard to preserve in the latent space if architecture
representation learning and search are coupled, resulting in less effective
search performance. In this work, we find empirically that pre-training
architecture representations using only neural architectures without their
accuracies as labels considerably improve the downstream architecture search
efficiency. To explain these observations, we visualize how unsupervised
architecture representation learning better encourages neural architectures
with similar connections and operators to cluster together. This helps to map
neural architectures with similar performance to the same regions in the latent
space and makes the transition of architectures in the latent space relatively
smooth, which considerably benefits diverse downstream search strategies.",http://arxiv.org/abs/2006.06936v2,arXiv,unsupervise architecture representation learning help neural architecture search,exist neural architecture search method either encode neural architecture use discrete encoding scale well adopt supervise learningbase method jointly learn architecture representation optimize architecture search representation incur search bias despite widespread use architecture representation learn nas still poorly understand observe structural property neural architecture hard preserve latent space architecture representation learning search couple result less effective search performance work find empirically pretraine architecture representation use neural architecture without accuracy label considerably improve downstream architecture search efficiency explain observation visualize unsupervised architecture representation learn well encourage neural architecture similar connection operator cluster together help map neural architecture similar performance region latent space make transition architecture latent space relatively smooth considerably benefit diverse downstream search strategy,unsupervise architecture representation learning help neural architecture search exist neural architecture search method either encode neural architecture use discrete encoding scale well adopt supervise learningbase method jointly learn architecture representation optimize architecture search representation incur search bias despite widespread use architecture representation learn nas still poorly understand observe structural property neural architecture hard preserve latent space architecture representation learning search couple result less effective search performance work find empirically pretraine architecture representation use neural architecture without accuracy label considerably improve downstream architecture search efficiency explain observation visualize unsupervised architecture representation learn well encourage neural architecture similar connection operator cluster together help map neural architecture similar performance region latent space make transition architecture latent space relatively smooth considerably benefit diverse downstream search strategy,0.5175438596491229,0.15789473684210525,0.16666666666666666,0.08771929824561403,57.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Qualitative,"Sensor Networks Architecture for Vehicles and Pedestrians Traffic
  Control","In this paper we present a sensor network based architecture for urban
traffic management, hierarchically structured on three layers: sensing,
processing& aggregation and control. On proposed architecture we define traffic
decongestion methods for vehicles and also for pedestrians. Finally, we
presented a case study on how traffic control can be implemented in a concrete
situation, based on the proposed architecture, pointing future directions of
development.",http://arxiv.org/abs/1807.09222v1,arXiv,sensor network architecture vehicle pedestrian traffic control,paper present sensor network base architecture urban traffic management hierarchically structure three layer sense processing aggregation control propose architecture define traffic decongestion method vehicle also pedestrian finally present case study traffic control implement concrete situation base propose architecture point future direction development,sensor network architecture vehicle pedestrian traffic control paper present sensor network base architecture urban traffic management hierarchically structure three layer sense processing aggregation control propose architecture define traffic decongestion method vehicle also pedestrian finally present case study traffic control implement concrete situation base propose architecture point future direction development,0.6190476190476191,0.14285714285714285,0.11904761904761904,0.07142857142857142,42.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Qualitative,"A Study of the Learning Progress in Neural Architecture Search
  Techniques","In neural architecture search, the structure of the neural network to best
model a given dataset is determined by an automated search process. Efficient
Neural Architecture Search (ENAS), proposed by Pham et al. (2018), has recently
received considerable attention due to its ability to find excellent
architectures within a comparably short search time. In this work, which is
motivated by the quest to further improve the learning speed of architecture
search, we evaluate the learning progress of the controller which generates the
architectures in ENAS. We measure the progress by comparing the architectures
generated by it at different controller training epochs, where architectures
are evaluated after having re-trained them from scratch. As a surprising
result, we find that the learning curves are completely flat, i.e., there is no
observable progress of the controller in terms of the performance of its
generated architectures. This observation is consistent across the CIFAR-10 and
CIFAR-100 datasets and two different search spaces. We conclude that the high
quality of the models generated by ENAS is a result of the search space design
rather than the controller training, and our results indicate that one-shot
architecture design is an efficient alternative to architecture search by ENAS.",http://arxiv.org/abs/1906.07590v1,arXiv,study learn progress neural architecture search technique,neural architecture search structure neural network good model give dataset determine automate search process efficient neural architecture search ena propose pham recently receive considerable attention due ability find excellent architecture within comparably short search time work motivate quest far improve learn speed architecture search evaluate learn progress controller generate architecture ena measure progress compare architecture generate different controller training epoch architecture evaluate retrain scratch surprising result find learn curve completely flat observable progress controller term performance generate architecture observation consistent across cifar cifar dataset two different search space conclude high quality model generate ena result search space design rather controller training result indicate oneshot architecture design efficient alternative architecture search ena,study learn progress neural architecture search technique neural architecture search structure neural network good model give dataset determine automate search process efficient neural architecture search ena propose pham recently receive considerable attention due ability find excellent architecture within comparably short search time work motivate quest far improve learn speed architecture search evaluate learn progress controller generate architecture ena measure progress compare architecture generate different controller training epoch architecture evaluate retrain scratch surprising result find learn curve completely flat observable progress controller term performance generate architecture observation consistent across cifar cifar dataset two different search space conclude high quality model generate ena result search space design rather controller training result indicate oneshot architecture design efficient alternative architecture search ena,0.4954954954954955,0.18018018018018017,0.15315315315315314,0.04504504504504504,111.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Qualitative,Conceptual Modeling for Computer Organization and Architecture,"Understanding computer system hardware, including how computers operate, is
essential for undergraduate students in computer engineering and science.
Literature shows students learning computer organization and assembly language
often find fundamental concepts difficult to comprehend within the topic
materials. Tools have been introduced to improve students comprehension of the
interaction between computer architecture, assembly language, and the operating
system. One such tool is the Little Man Computer (LMC) model that operates in a
way similar to a computer but that is easier to understand. Even though LMC
does not have modern CPUs with multiple cores nor executes multiple
instructions, it nevertheless shows the basic principles of the von Neumann
architecture. LMC aims to introduce students to such concepts as code and
instruction sets. In this paper, LMC is used for an additional purpose: a tool
with which to experiment using a new modeling language (i.e., a thinging
machine; TM) in the area of computer organization and architecture without
involving complexity in the subject. That is, the simplicity of LMC facilitates
the application of TM without going deep into computer
organization/architecture materials. Accordingly, the paper (a) provides a new
way for using the LMC model for whatever purpose (e.g., education) and (b)
demonstrates that TM can be used to build an abstract level of description in
the organization/architect field. The resultant schematics from the TM model of
LMC offer an initial case study that supports our thesis that TM is a viable
method for hardware/software-independent descriptions in the computer
organization and architect field of study.",http://arxiv.org/abs/2103.01773v1,arXiv,conceptual modeling computer organization architecture,understand computer system hardware include computer operate essential undergraduate student computer engineering science literature show student learn computer organization assembly language often find fundamental concept difficult comprehend within topic material tool introduce improve student comprehension interaction computer architecture assembly language operating system one tool little man computer lmc model operate way similar computer easy understand even though lmc modern cpu multiple core execute multiple instruction nevertheless show basic principle von neumann architecture lmc aim introduce student concept code instruction set paper lmc use additional purpose tool experiment use new modeling language thinge machine area computer organization architecture without involve complexity subject simplicity lmc facilitate application without deep computer organizationarchitecture material accordingly paper provide new way use lmc model whatever purpose education demonstrate use build abstract level description organizationarchitect field resultant schematic model lmc offer initial case study support thesis viable method hardwaresoftwareindependent description computer organization architect field study,conceptual modeling computer organization architecture understand computer system hardware include computer operate essential undergraduate student computer engineering science literature show student learn computer organization assembly language often find fundamental concept difficult comprehend within topic material tool introduce improve student comprehension interaction computer architecture assembly language operating system one tool little man computer lmc model operate way similar computer easy understand even though lmc modern cpu multiple core execute multiple instruction nevertheless show basic principle von neumann architecture lmc aim introduce student concept code instruction set paper lmc use additional purpose tool experiment use new modeling language thinge machine area computer organization architecture without involve complexity subject simplicity lmc facilitate application without deep computer organizationarchitecture material accordingly paper provide new way use lmc model whatever purpose education demonstrate use build abstract level description organizationarchitect field resultant schematic model lmc offer initial case study support thesis viable method hardwaresoftwareindependent description computer organization architect field study,0.5743243243243243,0.14189189189189189,0.14864864864864866,0.060810810810810814,148.0,0.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Qualitative,On the use of SPEC benchmarks in computer architecture research,"<jats:p>Benchmarks, in particular the SPEC CPU benchmarks, are frequently used in academic computer research. With ASPLOS-7 as an example, observations about such usage are reported, and suggestions are made for a meaningful use of benchmarks in computer architecture research. Forward-looking computer architecture research may need more than one benchmark collection.</jats:p>",https://doi.org/10.1145/250015.250018,CrossRef,use spec benchmark computer architecture research,jatspbenchmark particular spec cpu benchmark frequently use academic computer research asplo example observation usage report suggestion make meaningful use benchmark computer architecture research forwardlooke computer architecture research may need one benchmark collectionjatsp,use spec benchmark computer architecture research jatspbenchmark particular spec cpu benchmark frequently use academic computer research asplo example observation usage report suggestion make meaningful use benchmark computer architecture research forwardlooke computer architecture research may need one benchmark collectionjatsp,0.5625,0.09375,0.09375,0.03125,32.0,0.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Mixed Methods,Computer architecture courses in electrical engineering departments,"<jats:p>This paper traces the history of computer architecture courses in electrical engineering departments. Previously unpublished data from the Fall 1972 COSINE survey are given to show current computer architecture course offerings and texts. Computer architecture courses offered in 1972-73 are analyzed, compared with ACM and COSINE recommendations, and classified into five categories: introductory computer engineering courses with a computer architecture flavor, software-oriented computer organization courses, hardware-oriented computer organization courses, case study courses, and topical seminars. Future trends in computer architecture education are predicted.</jats:p>",https://doi.org/10.1145/633642.803984,CrossRef,computer architecture course electrical engineering department,jatspthis paper trace history computer architecture course electrical engineering department previously unpublishe datum fall cosine survey give show current computer architecture course offering text computer architecture course offer analyze compare acm cosine recommendation classify five category introductory computer engineering course computer architecture flavor softwareoriente computer organization course hardwareoriente computer organization course case study course topical seminar future trend computer architecture education predictedjatsp,computer architecture course electrical engineering department jatspthis paper trace history computer architecture course electrical engineering department previously unpublishe datum fall cosine survey give show current computer architecture course offering text computer architecture course offer analyze compare acm cosine recommendation classify five category introductory computer engineering course computer architecture flavor softwareoriente computer organization course hardwareoriente computer organization course case study course topical seminar future trend computer architecture education predictedjatsp,0.7419354838709677,0.08064516129032258,0.08064516129032258,0.016129032258064516,62.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Mixed Methods,A Software Based Many-Core Architecture Simulator,"<jats:p>As technology continuously advances, engineers are constantly faced with challenges that require numerous computational designs and implementations that, usually, go beyond practical feasibility, considering the available resources at hand. An area that might be considered for dealing with these problems relates to the use of many-core architectures for parallel processing. This type of architecture can be extremely efficient for intensive computational tasks and has the power to operate with low energy and low clock frequencies; however scalability issues attached to the process can significantly affect its design. This paper presents the technicalities involved in developing a scalable many-core software-based simulator named SImulator for Many-Cores (SIMC) that includes features such as package routing and efficient inter-process communication. It is intended as a project goal that SIMC becomes a useful software package that allows students with interests in simulating many-core based hardware projects as software systems. It is also intended that by practicing with SIMC on a diverse set of problems, students can acquire experience in analyzing metrics, such as speed and latency, among others that are commonly used in this sort of scenario. The type of practice provided by SIMC promotes a way of fixing the several hardware related concepts involved as well as to enlarge and refine student´s skills in programming. For the case study described in this paper, the validation of SIMC has been carried out by means of solving a relatively trivial problem i.e., that of the execution of simple morphological filters, where the allocation of tasks can be optimized for improving either the execution speed or latency. SIMC allows a direct comparison of values of both metrics, as well as a quantitative evaluation of the implemented network as a whole.</jats:p>",https://doi.org/10.5753/ijcae.2023.4831,CrossRef,software base manycore architecture simulator,jatspas technology continuously advance engineer constantly face challenge require numerous computational design implementation usually beyond practical feasibility consider available resource hand area might consider deal problem relate use manycore architecture parallel processing type architecture extremely efficient intensive computational task power operate low energy low clock frequency however scalability issue attach process significantly affect design paper present technicality involve develop scalable manycore softwarebase simulator name simulator manycore simc include feature package routing efficient interprocess communication intend project goal simc become useful software package allow student interest simulate manycore base hardware project software system also intend practice simc diverse set problem student acquire experience analyze metric speed latency among commonly use sort scenario type practice provide simc promote way fix several hardware relate concept involve well enlarge refine skill programming case study describe paper validation simc carry mean solve relatively trivial problem execution simple morphological filter allocation task optimize improve either execution speed latency simc allow direct comparison value metric well quantitative evaluation implement network wholejatsp,software base manycore architecture simulator jatspas technology continuously advance engineer constantly face challenge require numerous computational design implementation usually beyond practical feasibility consider available resource hand area might consider deal problem relate use manycore architecture parallel processing type architecture extremely efficient intensive computational task power operate low energy low clock frequency however scalability issue attach process significantly affect design paper present technicality involve develop scalable manycore softwarebase simulator name simulator manycore simc include feature package routing efficient interprocess communication intend project goal simc become useful software package allow student interest simulate manycore base hardware project software system also intend practice simc diverse set problem student acquire experience analyze metric speed latency among commonly use sort scenario type practice provide simc promote way fix several hardware relate concept involve well enlarge refine skill programming case study describe paper validation simc carry mean solve relatively trivial problem execution simple morphological filter allocation task optimize improve either execution speed latency simc allow direct comparison value metric well quantitative evaluation implement network wholejatsp,0.524390243902439,0.18292682926829268,0.14634146341463414,0.06707317073170732,164.0,0.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Mixed Methods,Ten ways to waste a parallel computer,"<jats:p>As clock speed increases taper off and hardware designers struggle to scale parallelism within a chip, software developers and researchers must face the challenge of writing portable software with no clear architectural target. On the hardware side, energy considerations will dominate many of the design decisions, and will ultimately limit what systems and applications can be built. This is especially true at the high end, where the next major milestone of exascale computing will be unattainable without major improvements in efficiency.</jats:p>
          <jats:p>Although hardware designers have long worried about the efficiency of their designs, especially for battery-operated devices, software developers in general have not. To illustrate this point, I will describe some of the top ways to waste time and therefore energy waiting for communication, synchronization, or interactions with users or other systems. Data movement, rather than computation, is the big consumer of energy, yet software often moves data up and down the memory hierarchy or across a network multiple times. At the same time, hardware designers need to take into account the constraints of the computational problems that will run on their systems, as a design that is poorly matched to the computational requirements will end up being inefficient. Drawing on my own experience in scientific computing, I will give examples of how to make the combination of hardware, algorithms and software more efficient, but also describe some of the challenges that are inherent in the application problems we want to solve. The community needs to take an integrated approach to the problem, and consider how much business or science can be done per Joule, rather than optimizing a particular component of the system in isolation. This will require rethinking the algorithms, programming models, and hardware in concert, and therefore an unprecedented level of collaboration and cooperation between hardware and software designers.</jats:p>",https://doi.org/10.1145/1555815.1555755,CrossRef,ten way waste parallel computer,jatspa clock speed increase taper hardware designer struggle scale parallelism within chip software developer researcher must face challenge write portable software clear architectural target hardware side energy consideration dominate many design decision ultimately limit system application build especially true high end next major milestone exascale computing unattainable without major improvement efficiencyjatsp jatspalthough hardware designer long worry efficiency design especially batteryoperate device software developer general illustrate point describe top way waste time therefore energy wait communication synchronization interaction user system datum movement rather computation big consumer energy yet software often move datum memory hierarchy across network multiple time time hardware designer need take account constraint computational problem run system design poorly match computational requirement end inefficient drawing experience scientific computing give example make combination hardware algorithm software efficient also describe challenge inherent application problem want solve community need take integrated approach problem consider much business science per joule rather optimize particular component system isolation require rethink algorithms programming model hardware concert therefore unprecedented level collaboration cooperation hardware software designersjatsp,ten way waste parallel computer jatspa clock speed increase taper hardware designer struggle scale parallelism within chip software developer researcher must face challenge write portable software clear architectural target hardware side energy consideration dominate many design decision ultimately limit system application build especially true high end next major milestone exascale computing unattainable without major improvement efficiencyjatsp jatspalthough hardware designer long worry efficiency design especially batteryoperate device software developer general illustrate point describe top way waste time therefore energy wait communication synchronization interaction user system datum movement rather computation big consumer energy yet software often move datum memory hierarchy across network multiple time time hardware designer need take account constraint computational problem run system design poorly match computational requirement end inefficient drawing experience scientific computing give example make combination hardware algorithm software efficient also describe challenge inherent application problem want solve community need take integrated approach problem consider much business science per joule rather optimize particular component system isolation require rethink algorithms programming model hardware concert therefore unprecedented level collaboration cooperation hardware software designersjatsp,0.5773809523809523,0.1130952380952381,0.16071428571428573,0.05952380952380952,168.0,0.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Mixed Methods,Training-free Neural Architecture Search for RNNs and Transformers,"Neural architecture search (NAS) has allowed for the automatic creation of
new and effective neural network architectures, offering an alternative to the
laborious process of manually designing complex architectures. However,
traditional NAS algorithms are slow and require immense amounts of computing
power. Recent research has investigated training-free NAS metrics for image
classification architectures, drastically speeding up search algorithms. In
this paper, we investigate training-free NAS metrics for recurrent neural
network (RNN) and BERT-based transformer architectures, targeted towards
language modeling tasks. First, we develop a new training-free metric, named
hidden covariance, that predicts the trained performance of an RNN architecture
and significantly outperforms existing training-free metrics. We experimentally
evaluate the effectiveness of the hidden covariance metric on the NAS-Bench-NLP
benchmark. Second, we find that the current search space paradigm for
transformer architectures is not optimized for training-free neural
architecture search. Instead, a simple qualitative analysis can effectively
shrink the search space to the best performing architectures. This conclusion
is based on our investigation of existing training-free metrics and new metrics
developed from recent transformer pruning literature, evaluated on our own
benchmark of trained BERT architectures. Ultimately, our analysis shows that
the architecture search space and the training-free metric must be developed
together in order to achieve effective results.",http://arxiv.org/abs/2306.00288v1,arXiv,trainingfree neural architecture search rnn transformer,neural architecture search nas allow automatic creation new effective neural network architecture offer alternative laborious process manually design complex architecture however traditional nas algorithm slow require immense amount computing power recent research investigate trainingfree nas metric image classification architecture drastically speed search algorithm paper investigate trainingfree nas metric recurrent neural network rnn bertbase transformer architecture target towards language modeling task first develop new trainingfree metric name hide covariance predict train performance rnn architecture significantly outperform exist trainingfree metric experimentally evaluate effectiveness hidden covariance metric nasbenchnlp benchmark second find current search space paradigm transformer architecture optimize trainingfree neural architecture search instead simple qualitative analysis effectively shrink search space good performing architecture conclusion base investigation exist trainingfree metric new metric develop recent transformer pruning literature evaluate benchmark train bert architecture ultimately analysis show architecture search space trainingfree metric must develop together order achieve effective result,trainingfree neural architecture search rnn transformer neural architecture search nas allow automatic creation new effective neural network architecture offer alternative laborious process manually design complex architecture however traditional nas algorithm slow require immense amount computing power recent research investigate trainingfree nas metric image classification architecture drastically speed search algorithm paper investigate trainingfree nas metric recurrent neural network rnn bertbase transformer architecture target towards language modeling task first develop new trainingfree metric name hide covariance predict train performance rnn architecture significantly outperform exist trainingfree metric experimentally evaluate effectiveness hidden covariance metric nasbenchnlp benchmark second find current search space paradigm transformer architecture optimize trainingfree neural architecture search instead simple qualitative analysis effectively shrink search space good performing architecture conclusion base investigation exist trainingfree metric new metric develop recent transformer pruning literature evaluate benchmark train bert architecture ultimately analysis show architecture search space trainingfree metric must develop together order achieve effective result,0.43356643356643354,0.16783216783216784,0.2097902097902098,0.06993006993006994,143.0,2.0,0.0,0.0,1.0
Computer Engineering,Computer Architecture,Mixed Methods,Omega: An Architecture for AI Unification,"We introduce the open-ended, modular, self-improving Omega AI unification
architecture which is a refinement of Solomonoff's Alpha architecture, as
considered from first principles. The architecture embodies several crucial
principles of general intelligence including diversity of representations,
diversity of data types, integrated memory, modularity, and higher-order
cognition. We retain the basic design of a fundamental algorithmic substrate
called an ""AI kernel"" for problem solving and basic cognitive functions like
memory, and a larger, modular architecture that re-uses the kernel in many
ways. Omega includes eight representation languages and six classes of neural
networks, which are briefly introduced. The architecture is intended to
initially address data science automation, hence it includes many problem
solving methods for statistical tasks. We review the broad software
architecture, higher-order cognition, self-improvement, modular neural
architectures, intelligent agents, the process and memory hierarchy, hardware
abstraction, peer-to-peer computing, and data abstraction facility.",http://arxiv.org/abs/1805.12069v1,arXiv,omega architecture unification,introduce openende modular selfimprove omega unification architecture refinement solomonoff alpha architecture consider first principle architecture embody several crucial principle general intelligence include diversity representation diversity datum type integrate memory modularity higherorder cognition retain basic design fundamental algorithmic substrate call kernel problem solve basic cognitive function like memory large modular architecture reuse kernel many way omega include eight representation language six class neural network briefly introduce architecture intend initially address datum science automation hence include many problem solve method statistical task review broad software architecture higherorder cognition selfimprovement modular neural architecture intelligent agent process memory hierarchy hardware abstraction peertopeer computing datum abstraction facility,omega architecture unification introduce openende modular selfimprove omega unification architecture refinement solomonoff alpha architecture consider first principle architecture embody several crucial principle general intelligence include diversity representation diversity datum type integrate memory modularity higherorder cognition retain basic design fundamental algorithmic substrate call kernel problem solve basic cognitive function like memory large modular architecture reuse kernel many way omega include eight representation language six class neural network briefly introduce architecture intend initially address datum science automation hence include many problem solve method statistical task review broad software architecture higherorder cognition selfimprovement modular neural architecture intelligent agent process memory hierarchy hardware abstraction peertopeer computing datum abstraction facility,0.5980392156862745,0.11764705882352941,0.20588235294117646,0.029411764705882353,102.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Design and Development,The IEEE Computer Society task force on computer architecture,"<jats:p>The subject of computer architecture as currently taught in most computer engineering and computer science programs is a mixture of architectural principles, organizational strategies, and implementation techniques. This blurring of the hierarchy of system levels that characterize the structure of a computer has made it very difficult for students (and often instructors as well) to determine what were the forces that led to the design decisions they have seen reflected in machines.</jats:p>
          <jats:p>In view of these circumstances, a task force was established by the IEEE Computer Society to prepare a detailed specification for a course of study in computer architecture for students whose major interest is in computer engineering or computer science.</jats:p>",https://doi.org/10.1145/633617.803545,CrossRef,ieee computer society task force computer architecture,jatspthe subject computer architecture currently teach computer engineering computer science program mixture architectural principle organizational strategy implementation technique blurring hierarchy system level characterize structure computer make difficult student often instructor well determine force lead design decision see reflect machinesjatsp jatspin view circumstance task force establish ieee computer society prepare detailed specification course study computer architecture student whose major interest computer engineering computer sciencejatsp,ieee computer society task force computer architecture jatspthe subject computer architecture currently teach computer engineering computer science program mixture architectural principle organizational strategy implementation technique blurring hierarchy system level characterize structure computer make difficult student often instructor well determine force lead design decision see reflect machinesjatsp jatspin view circumstance task force establish ieee computer society prepare detailed specification course study computer architecture student whose major interest computer engineering computer sciencejatsp,0.6349206349206349,0.14285714285714285,0.1111111111111111,0.047619047619047616,63.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Design and Development,Disbursed control computer architecture,"<jats:p>Disbursed Control Computer Architecture, comprising totally pipelined computer, a number of components interconnected in a pipeline:Control storage for control and input-output address maker, plurality of other control storage for corresponding plurality of data address makers, and another control storage for operators and operational registers.Any mentioned control storage contains, as a part of a program, a plurality of appropriate section of a control word. Control and input-output address maker issues control address to all mentioned control storage and receives its own section of control word.Plurality of data address makers receives plurality of corresponding sections of control word and issue corresponding plurality of data addresses to operands and results storage, which, in turn, is issuing and receiving data to and from operational registers and bus joint and to condition and status logic.Each clock cycle, new control address initiates new control word, sections of which contain all commands and addresses for enactment of next control and input-output address, by control and input-output address maker, and of next plurality of data addresses, by plurality of data address makers.Following in pipeline, new commands and data submitted to operators and operational registers direct performance of new primary (originated by the task) operations every clock cycle.Several clock cycles are allotted along pipeline to data address makers, allowing the most complex address preparations.Also comprising: interconnect of totally pipelined computer with other computers, operating via input-output devices with separate sending and receiving ports.</jats:p>",https://doi.org/10.1145/333680.333695,CrossRef,disburse control computer architecture,jatspdisbursed control computer architecture comprise totally pipeline computer number component interconnect pipelinecontrol storage control inputoutput address maker plurality control storage correspond plurality datum address maker another control storage operator operational registersany mention control storage contain part program plurality appropriate section control word control inputoutput address maker issue control address mention control storage receive section control wordplurality datum address maker receive plurality correspond section control word issue correspond plurality datum address operand result storage turn issue receive datum operational register bus joint condition status logiceach clock cycle new control address initiate new control word section contain command address enactment next control inputoutput address control inputoutput address maker next plurality datum address plurality datum address makersfollowe pipeline new command datum submit operator operational register direct performance new primary originate task operation every clock cycleseveral clock cycle allot along pipeline datum address maker allow complex address preparationsalso comprise interconnect totally pipeline computer computer operate via inputoutput device separate sending receive portsjatsp,disburse control computer architecture jatspdisbursed control computer architecture comprise totally pipeline computer number component interconnect pipelinecontrol storage control inputoutput address maker plurality control storage correspond plurality datum address maker another control storage operator operational registersany mention control storage contain part program plurality appropriate section control word control inputoutput address maker issue control address mention control storage receive section control wordplurality datum address maker receive plurality correspond section control word issue correspond plurality datum address operand result storage turn issue receive datum operational register bus joint condition status logiceach clock cycle new control address initiate new control word section contain command address enactment next control inputoutput address control inputoutput address maker next plurality datum address plurality datum address makersfollowe pipeline new command datum submit operator operational register direct performance new primary originate task operation every clock cycleseveral clock cycle allot along pipeline datum address maker allow complex address preparationsalso comprise interconnect totally pipeline computer computer operate via inputoutput device separate sending receive portsjatsp,0.6645569620253164,0.08860759493670886,0.10126582278481013,0.0189873417721519,158.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Design and Development,Lessons Learned Using ArchC in Computer Architecture Laboratory,"<jats:p>This paper presents a set of laboratory experiments based on the ArchC Architecture Description Language designed to fulfill the practical knowledge on Computer Architecture. These activities were designed over the last years and have been used in our discipline of Laboratory of Computer Architecture, where seventh semester students apply the knowledge they acquired in the theory classes. We present the experiments, covering 10 distinct topics in Computer Architecture, along with specific sections of the text-book to which they refer. We also show some of the experiences we acquired during the last years both on learning outcomes and student feedback.</jats:p>",https://doi.org/10.5753/ijcae.2016.4868,CrossRef,lesson learn use archc computer architecture laboratory,jatspthis paper present set laboratory experiment base archc architecture description language design fulfill practical knowledge computer architecture activity design last year use discipline laboratory computer architecture seventh semester student apply knowledge acquire theory class present experiment cover distinct topic computer architecture along specific section textbook refer also show experience acquire last year learn outcome student feedbackjatsp,lesson learn use archc computer architecture laboratory jatspthis paper present set laboratory experiment base archc architecture description language design fulfill practical knowledge computer architecture activity design last year use discipline laboratory computer architecture seventh semester student apply knowledge acquire theory class present experiment cover distinct topic computer architecture along specific section textbook refer also show experience acquire last year learn outcome student feedbackjatsp,0.6607142857142857,0.125,0.14285714285714285,0.017857142857142856,56.0,0.0,0.0,2.0,0.0
Computer Engineering,Computer Architecture,Design and Development,Integrating Continuous Assessment into Undergraduate Computer Architecture using Automated Grading,"<jats:p>Continuous assessment (CA) improves student engagement and understanding through regular evaluations and rapid feedback. This approach was integrated into a foundational Computer Architecture course using frequent quizzes. To manage large class sizes and limited teaching assistance, automated grading software was used. This paper discusses the implementation of automated grading for quizzes, detailing the process, and presenting course results and student feedback. Observations based on student feedback and outcomes suggest that integrating CA through quizzes is beneficial for student engagement and learning.</jats:p>",https://doi.org/10.5753/ijcae.2024.5341,CrossRef,integrate continuous assessment undergraduate computer architecture use automated grading,jatspcontinuous assessment improve student engagement understanding regular evaluation rapid feedback approach integrate foundational computer architecture course use frequent quiz manage large class size limited teaching assistance automate grading software use paper discuss implementation automated grading quiz detail process present course result student feedback observation base student feedback outcome suggest integrate quiz beneficial student engagement learningjatsp,integrate continuous assessment undergraduate computer architecture use automated grading jatspcontinuous assessment improve student engagement understanding regular evaluation rapid feedback approach integrate foundational computer architecture course use frequent quiz manage large class size limited teaching assistance automate grading software use paper discuss implementation automated grading quiz detail process present course result student feedback observation base student feedback outcome suggest integrate quiz beneficial student engagement learningjatsp,0.6545454545454545,0.16363636363636364,0.18181818181818182,0.0,55.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Design and Development,Integrated computer architecture development system,"<jats:p>Development in systems architecture of separate soft-and hardware components introduces high inefficiencies, due to redundancies and seldom used functions on the levels of implementation. A better approach offers a methodology for an integrated software, firmware, and hardware design. Required are, however, immense computer resources with graphical capabilities. But it gives help in the development under constraints. We present such a system and show its capabilities in the development of a defect-free sorter module.</jats:p>",https://doi.org/10.1145/146628.140900,CrossRef,integrate computer architecture development system,jatspdevelopment system architecture separate softand hardware component introduce high inefficiency due redundancy seldom use function level implementation well approach offer methodology integrate software firmware hardware design require however immense computer resource graphical capability give help development constraint present system show capability development defectfree sorter modulejatsp,integrate computer architecture development system jatspdevelopment system architecture separate softand hardware component introduce high inefficiency due redundancy seldom use function level implementation well approach offer methodology integrate software firmware hardware design require however immense computer resource graphical capability give help development constraint present system show capability development defectfree sorter modulejatsp,0.6222222222222222,0.1111111111111111,0.17777777777777778,0.044444444444444446,45.0,0.0,0.0,0.0,0.0
Computer Engineering,Computer Architecture,Theoretical / Conceptual,Modeling Network Architecture: A Cloud Case Study,"The Internet s ability to support a wide range of services depends on the
network architecture and theoretical and practical innovations necessary for
future networks. Network architecture in this context refers to the structure
of a computer network system as well as interactions among its physical
components, their configuration, and communication protocols. Various
descriptions of architecture have been developed over the years with an
unusually large number of superficial icons and symbols. This situation has
created a need for more coherent systematic representations of network
architecture. This paper is intended to refine the design, analysis, and
documentation of network architecture by adopting a conceptual model called a
thinging (abstract) machine (TM), which views all components of a network in
terms of a single notion: the flow of things in a TM. Since cloud computing has
become increasingly popular in the last few years as a model for a shared pool
of networks, servers, storage, and applications, we apply the TM to model a
real case study of cloud networks. The resultant model introduces an integrated
representation of computer networks.",http://arxiv.org/abs/2004.10350v1,arXiv,model network architecture cloud case study,internet ability support wide range service depend network architecture theoretical practical innovation necessary future network network architecture context refer structure computer network system well interaction among physical component configuration communication protocol various description architecture develop year unusually large number superficial icon symbol situation create need coherent systematic representation network architecture paper intend refine design analysis documentation network architecture adopt conceptual model call thinge abstract machine view component network term single notion flow thing since cloud computing become increasingly popular last year model share pool network server storage application apply model real case study cloud network resultant model introduce integrate representation computer network,model network architecture cloud case study internet ability support wide range service depend network architecture theoretical practical innovation necessary future network network architecture context refer structure computer network system well interaction among physical component configuration communication protocol various description architecture develop year unusually large number superficial icon symbol situation create need coherent systematic representation network architecture paper intend refine design analysis documentation network architecture adopt conceptual model call thinge abstract machine view component network term single notion flow thing since cloud computing become increasingly popular last year model share pool network server storage application apply model real case study cloud network resultant model introduce integrate representation computer network,0.6568627450980392,0.08823529411764706,0.17647058823529413,0.0196078431372549,102.0,0.0,0.0,1.0,0.0
Computer Engineering,Digital Systems Design,Quantitative,Proposing Digital Design Methodology for Furniture Products by Integrating Generative Design Approach to Conventional Process,"<jats:p>Purpose: Considering the growing digital transformations in design field, this research aims to explore the advance language of design - generative design. The study focuses on integration of generative design and parametric modeling techniques with conventional furniture design process to develop a digital design and development methodology for furniture products by doing practical work in Rhino and Grasshopper.&#x0D;
Methodology: For this purpose, a comparative analysis is drawn and three practicals performed in Rhino Grasshopper.&#x0D;
Results: The author learned one of the design tool (Grasshopper) and investigate the possible ways to integrate this digital design process with the conventional process. These examples illustrate the liberty to design and explore any form that is imaginable and offers flexibility in the development process to make multiple design options. This digital way of designing leads to better accuracy, quicker adaptation to the initial concepts, ability to produce new alternatives, ease of revision, quality and realistic results and most importantly ready to manufacture products. This research was carried out, specifically, keeping the industrial environment of Pakistan Furniture Industry in reference.&#x0D;
Unique Contribution to Theory, Policy and Practice: This research proposal helped the author to create an awareness at a very initial level in the targeted scope with the hope to encourage authorities to take some serious steps towards the institutionalization of technological advancement in the design education sector. This research not only honed the author’s knowledge in the state of the art but also enabled him to share more advance knowledge about CAD tools with his students. By following and integrating advance design tools to the design process, developments in furniture industry in Pakistan can be made possible in a short time.  </jats:p>",https://doi.org/10.47941/jts.1368,CrossRef,propose digital design methodology furniture product integrate generative design approach conventional process,jatsppurpose consider grow digital transformation design field research aim explore advance language design generative design study focus integration generative design parametric modeling technique conventional furniture design process develop digital design development methodology furniture product practical work rhino grasshopperxd methodology purpose comparative analysis draw three practical perform rhino grasshopperxd result author learn one design tool grasshopper investigate possible way integrate digital design process conventional process example illustrate liberty design explore form imaginable offer flexibility development process make multiple design option digital way designing lead well accuracy quick adaptation initial concept ability produce new alternative ease revision quality realistic result importantly ready manufacture product research carry specifically keep industrial environment pakistan furniture industry referencexd unique contribution theory policy practice research proposal help author create awareness initial level target scope hope encourage authority take serious step towards institutionalization technological advancement design education sector research hone author knowledge state art also enable share advance knowledge cad tool student follow integrate advance design tool design process development furniture industry pakistan make possible short time jatsp,propose digital design methodology furniture product integrate generative design approach conventional process jatsppurpose consider grow digital transformation design field research aim explore advance language design generative design study focus integration generative design parametric modeling technique conventional furniture design process develop digital design development methodology furniture product practical work rhino grasshopperxd methodology purpose comparative analysis draw three practical perform rhino grasshopperxd result author learn one design tool grasshopper investigate possible way integrate digital design process conventional process example illustrate liberty design explore form imaginable offer flexibility development process make multiple design option digital way designing lead well accuracy quick adaptation initial concept ability produce new alternative ease revision quality realistic result importantly ready manufacture product research carry specifically keep industrial environment pakistan furniture industry referencexd unique contribution theory policy practice research proposal help author create awareness initial level target scope hope encourage authority take serious step towards institutionalization technological advancement design education sector research hone author knowledge state art also enable share advance knowledge cad tool student follow integrate advance design tool design process development furniture industry pakistan make possible short time jatsp,0.6294117647058823,0.12941176470588237,0.17058823529411765,0.023529411764705882,170.0,0.0,0.0,0.0,1.0
Computer Engineering,Digital Systems Design,Quantitative,Digital Design of Smart Museum Based on Artificial Intelligence,"<jats:p>Today, as the soft power of culture is becoming more and more important, it is very important to pay attention to the learning and dissemination of culture. As the carrier of this process, the use of advanced technology to improve the museum is of great significance. This paper studies the digital design of smart museum based on artificial intelligence in order to explore the application of smart museum in artificial intelligence, analyze the spatial design of smart museum by using digital technology, explore a feasible method to give full play to the function of smart museum, and put forward some suggestions on the spatial design of smart museum. The design of the smart museum is no longer restricted by time and space and uses digital technology to double use virtual things and dynamic space. Through the detailed analysis of the application of artificial intelligence and digitization in the spatial design of the smart museum, combined with the information decision tree algorithm and data heterogeneous network algorithm, this study constructs the model of the information processing architecture of smart museum and the requirements of digital museum and makes a decision-making analysis of the comparison results of existing data. It includes the digital design of smart museum display technology, display effect, and other display-related contents. Analyzing the impact of smart museum on the object can provide data support for the feasibility of digital space design of smart museum based on artificial intelligence. The results of regression data processing show that the spatial visual sense of digital design wisdom museum is very strong, reaching the level of 5.0, and the picture aesthetic effect is up to 4.8.</jats:p>",https://doi.org/10.1155/2021/4894131,CrossRef,digital design smart museum base artificial intelligence,jatsptoday soft power culture become important important pay attention learning dissemination culture carrier process use advanced technology improve museum great significance paper study digital design smart museum base artificial intelligence order explore application smart museum artificial intelligence analyze spatial design smart museum use digital technology explore feasible method give full play function smart museum put forward suggestion spatial design smart museum design smart museum long restrict time space use digital technology double use virtual thing dynamic space detailed analysis application artificial intelligence digitization spatial design smart museum combine information decision tree algorithm datum heterogeneous network algorithm study construct model information processing architecture smart museum requirement digital museum make decisionmake analysis comparison result exist datum include digital design smart museum display technology display effect displayrelate content analyze impact smart museum object provide data support feasibility digital space design smart museum base artificial intelligence result regression datum processing show spatial visual sense digital design wisdom museum strong reach level picture aesthetic effect jatsp,digital design smart museum base artificial intelligence jatsptoday soft power culture become important important pay attention learning dissemination culture carrier process use advanced technology improve museum great significance paper study digital design smart museum base artificial intelligence order explore application smart museum artificial intelligence analyze spatial design smart museum use digital technology explore feasible method give full play function smart museum put forward suggestion spatial design smart museum design smart museum long restrict time space use digital technology double use virtual thing dynamic space detailed analysis application artificial intelligence digitization spatial design smart museum combine information decision tree algorithm datum heterogeneous network algorithm study construct model information processing architecture smart museum requirement digital museum make decisionmake analysis comparison result exist datum include digital design smart museum display technology display effect displayrelate content analyze impact smart museum object provide data support feasibility digital space design smart museum base artificial intelligence result regression datum processing show spatial visual sense digital design wisdom museum strong reach level picture aesthetic effect jatsp,0.5590062111801242,0.12422360248447205,0.21739130434782608,0.006211180124223602,161.0,2.0,0.0,1.0,0.0
Computer Engineering,Digital Systems Design,Quantitative,Visual Art Design of Digital Works Guided by Big Data,"<jats:p>With the rapid development of digital technology, the development speed of digital media is also relatively fast. Digital media technology has a great impact on people’s lifestyles and aesthetic concepts, and it also has a greater impact on visual art, creative thinking communication methods, and expression methods. In this study, the quality enhancement of digital images has been intensively studied based on the guidance of big data of eye-movement gaze points. A large amount of visual data are collected from public social resources, and the optimization research of image sensory quality is carried out in-depth using the acquired big data. Next, the region of interest (ROI) is obtained by combining the data with a two-dimensional Gaussian distribution model-fitting method, and the obtained data clustered and improved based on the K-means clustering algorithm to obtain ROI fixation points. Finally, discontinuities in the choice of sharpness in graphics and video playback are pointed out, and the final fixation data analysis is utilized. Results show that targeted optimization is very effective in improving the quality of digital images and saving space, enabling users to enjoy higher-quality visual digital images. The proposed method can be used to improve the dynamic resolution of images and videos.</jats:p>",https://doi.org/10.1155/2022/5636449,CrossRef,visual art design digital work guide big datum,jatspwith rapid development digital technology development speed digital medium also relatively fast digital medium technology great impact people lifestyle aesthetic concept also great impact visual art creative thinking communication method expression method study quality enhancement digital image intensively study base guidance big datum eyemovement gaze point large amount visual datum collect public social resource optimization research image sensory quality carry indepth use acquire big datum next region interest roi obtain combine datum twodimensional gaussian distribution modelfitting method obtain datum cluster improve base kmeans cluster algorithm obtain roi fixation point finally discontinuitie choice sharpness graphic video playback point final fixation datum analysis utilize result show target optimization effective improve quality digital image save space enable user enjoy higherquality visual digital image propose method use improve dynamic resolution image videosjatsp,visual art design digital work guide big datum jatspwith rapid development digital technology development speed digital medium also relatively fast digital medium technology great impact people lifestyle aesthetic concept also great impact visual art creative thinking communication method expression method study quality enhancement digital image intensively study base guidance big datum eyemovement gaze point large amount visual datum collect public social resource optimization research image sensory quality carry indepth use acquire big datum next region interest roi obtain combine datum twodimensional gaussian distribution modelfitting method obtain datum cluster improve base kmeans cluster algorithm obtain roi fixation point finally discontinuitie choice sharpness graphic video playback point final fixation datum analysis utilize result show target optimization effective improve quality digital image save space enable user enjoy higherquality visual digital image propose method use improve dynamic resolution image videosjatsp,0.5546875,0.1328125,0.234375,0.0390625,128.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Quantitative,Deliberations on design,"<jats:sec>
               <jats:title content-type=""abstract-heading"">Purpose</jats:title>
               <jats:p> – The purpose of this paper is to encourage libraries to be as involved as possible in the design of the services they provide, be that traditional Web services or sophisticated discovery services. An inordinate reliance upon turn key applications that afford little to no opportunity for customization will not allow the author to be responsive to patron needs. </jats:p>
            </jats:sec>
            <jats:sec>
               <jats:title content-type=""abstract-heading"">Design/methodology/approach</jats:title>
               <jats:p> – This is a viewpoint column, and the content is exploratory in nature. </jats:p>
            </jats:sec>
            <jats:sec>
               <jats:title content-type=""abstract-heading"">Findings</jats:title>
               <jats:p> – The findings, in a sense, are that while in the past, others have been trusted to make critical design decisions, the author now needs to focus on applying information science skills to the design of his Web-based services. </jats:p>
            </jats:sec>
            <jats:sec>
               <jats:title content-type=""abstract-heading"">Originality/value</jats:title>
               <jats:p> – The quality of the digital services offered by libraries is a direct correlation of the level of investment offered. Investing at a more substantial level involves risks that need to be weighed against the potential benefits, but those risks cannot be completely ignored if the goal is a higher level of service excellence.</jats:p>
            </jats:sec>",https://doi.org/10.1108/oclc-05-2014-0023,CrossRef,deliberation design,jatssec jatstitle contenttypeabstractheadingpurposejatstitle jatsp purpose paper encourage library involve possible design service provide traditional web service sophisticated discovery service inordinate reliance upon turn key application afford little opportunity customization allow author responsive patron need jatsp jatssec jatssec jatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitle jatsp viewpoint column content exploratory nature jatsp jatssec jatssec jatstitle contenttypeabstractheadingfindingsjatstitle jatsp finding sense past trust make critical design decision author need focus apply information science skill design webbase service jatsp jatssec jatssec jatstitle contenttypeabstractheadingoriginalityvaluejatstitle jatsp quality digital service offer library direct correlation level investment offer investing substantial level involve risk need weigh potential benefit risk completely ignore goal high level service excellencejatsp jatssec,deliberation design jatssec jatstitle contenttypeabstractheadingpurposejatstitle jatsp purpose paper encourage library involve possible design service provide traditional web service sophisticated discovery service inordinate reliance upon turn key application afford little opportunity customization allow author responsive patron need jatsp jatssec jatssec jatstitle contenttypeabstractheadingdesignmethodologyapproachjatstitle jatsp viewpoint column content exploratory nature jatsp jatssec jatssec jatstitle contenttypeabstractheadingfindingsjatstitle jatsp finding sense past trust make critical design decision author need focus apply information science skill design webbase service jatsp jatssec jatssec jatstitle contenttypeabstractheadingoriginalityvaluejatstitle jatsp quality digital service offer library direct correlation level investment offer investing substantial level involve risk need weigh potential benefit risk completely ignore goal high level service excellencejatsp jatssec,0.44660194174757284,0.13592233009708737,0.1262135922330097,0.009708737864077669,103.0,2.0,0.0,0.0,3.0
Computer Engineering,Digital Systems Design,Quantitative,"Ethnographic Study: Finger Food Systems, Contribution to a Project Program in Food Design","<jats:p>This study consists of an ethnographic survey of 50 forms of finger food found by the author on the four continents of America, Europe, Africa and Asia, involving around 20 countries, presented under four morphological typologies wrapped, agglutinated, laminated and contained – and five construction systems – plate, oven, steam, water and bain-marie. The raw materials used in the collection are cereals (68%), pulses (16%), tubers (10%) and seaweed/leaves (6%). The literature review identifies exceptional qualities of combining whole grains with pulses as a dietary contribution to reducing obesity and improving public health. The results of this research will contribute to the author’s PhD thesis: design of plant-based mobile finger food, mitigating the hegemony of wheat.</jats:p>",https://doi.org/10.30682/diiddsi23t3c,CrossRef,ethnographic study finger food system contribution project program food design,jatspthis study consist ethnographic survey form finger food find author four continent america europe africa asia involve around country present four morphological typology wrap agglutinated laminated contain five construction system plate oven steam water bainmarie raw material use collection cereal pulse tuber seaweedleave literature review identify exceptional quality combine whole grain pulse dietary contribution reduce obesity improve public health result research contribute author phd thesis design plantbase mobile finger food mitigate hegemony wheatjatsp,ethnographic study finger food system contribution project program food design jatspthis study consist ethnographic survey form finger food find author four continent america europe africa asia involve around country present four morphological typology wrap agglutinated laminated contain five construction system plate oven steam water bainmarie raw material use collection cereal pulse tuber seaweedleave literature review identify exceptional quality combine whole grain pulse dietary contribution reduce obesity improve public health result research contribute author phd thesis design plantbase mobile finger food mitigate hegemony wheatjatsp,0.5068493150684932,0.1232876712328767,0.1506849315068493,0.0,73.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Qualitative,ANALYSIS AND DESIGN OF DIGITAL APPLICATION SYSTEMS FOR EMPLOYEE DATA MANAGEMENT IN XYZ STORE,"<jats:p>As technology and information systems develop in the digital era, managing employee data has become very important for organizations and companies. An efficient and accurate employee data input process is the first step in managing human resources optimally. XYZ Shop is a shop located in the Banten area, which sells retail goods to end consumers, usually on a small scale and at home. The shop provides a variety of products, ranging from clothing, food, electronic goods, to household equipment. However, the XYZ store still faces challenges in managing employee data, such as limited time and human energy in carrying out this process because it is still manual. To overcome this problem, an employee data input program was designed to be an effective solution. With this program, the employee data management process can become more efficient, accurate and organized. The author used three techniques for data collection activities, namely observation, interviews and literature study. Development of an application program system for managing employee data at XYZ store using the PHP programming language and MySql database. The application system built is web-based, so it can be accessed easily anywhere and anytime. This provides immediate benefits in day-to-day operational efficiency, allowing human resources to focus on more strategic tasks. With the ability to manage employee data efficiently, stores can easily adapt to company growth, including branch expansion and increased employment</jats:p>",https://doi.org/10.31000/digibis.v3i1.12348,CrossRef,analysis design digital application system employee datum management xyz store,jatspas technology information system develop digital era manage employee datum become important organization company efficient accurate employee datum input process first step manage human resource optimally xyz shop shop locate banten area sell retail good end consumer usually small scale home shop provide variety product range clothing food electronic good household equipment however xyz store still face challenge manage employee datum limited time human energy carry process still manual overcome problem employee datum input program design effective solution program employee datum management process become efficient accurate organize author use three technique datum collection activity namely observation interview literature study development application program system manage employee datum xyz store use php programming language mysql database application system build webbase access easily anywhere anytime provide immediate benefit daytoday operational efficiency allow human resource focus strategic task ability manage employee datum efficiently store easily adapt company growth include branch expansion increase employmentjatsp,analysis design digital application system employee datum management xyz store jatspas technology information system develop digital era manage employee datum become important organization company efficient accurate employee datum input process first step manage human resource optimally xyz shop shop locate banten area sell retail good end consumer usually small scale home shop provide variety product range clothing food electronic good household equipment however xyz store still face challenge manage employee datum limited time human energy carry process still manual overcome problem employee datum input program design effective solution program employee datum management process become efficient accurate organize author use three technique datum collection activity namely observation interview literature study development application program system manage employee datum xyz store use php programming language mysql database application system build webbase access easily anywhere anytime provide immediate benefit daytoday operational efficiency allow human resource focus strategic task ability manage employee datum efficiently store easily adapt company growth include branch expansion increase employmentjatsp,0.5704697986577181,0.1342281879194631,0.1342281879194631,0.0738255033557047,149.0,2.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Qualitative,A Research on the Dynamization Effect of Brand Visual Identity Design: Mediated by Digital Information Smart Media,"<jats:p xml:lang=""en"">The article utilizes the literature research method, case study method, and practical verification method. The article discusses brand visual identity and motion graphics design principles. The article outlines dynamic brand visual identity design trends that digital information and AI enable. It explains AI generative models like GAN and diffusion models that generate graphics and effects. Examples like Stable Diffusion and Midjourney show AI's potential for diverse, abstract visuals in motion graphics. AI could also enable interactive effects by combining with AR/VR. Overall, AI can empower dynamic, personalized graphic design and branding. Key points are that dynamic design brings interactivity and better conveys brand meaning. Brand visual design is diversifying, with core brand image and dynamic performance reinforcing each other. AI can boost efficiency, innovation, and meaning in dynamic design. Though mainstream, 2D branding remains relevant. The article highlights the future potential of AI in motion graphics and visual storytelling, as it can generate new interpretations and experiences.</jats:p>",https://doi.org/10.55267/iadt.07.14078,CrossRef,research dynamization effect brand visual identity design mediate digital information smart medium,jatsp xmllangenthe article utilize literature research method case study method practical verification method article discuss brand visual identity motion graphic design principle article outline dynamic brand visual identity design trend digital information enable explain generative model like gan diffusion model generate graphic effect example like stable diffusion midjourney show ais potential diverse abstract visual motion graphic could also enable interactive effect combine arvr overall empower dynamic personalize graphic design brand key point dynamic design bring interactivity well convey brand mean brand visual design diversify core brand image dynamic performance reinforce boost efficiency innovation meaning dynamic design though mainstream branding remain relevant article highlight future potential motion graphic visual storytelling generate new interpretation experiencesjatsp,research dynamization effect brand visual identity design mediate digital information smart medium jatsp xmllangenthe article utilize literature research method case study method practical verification method article discuss brand visual identity motion graphic design principle article outline dynamic brand visual identity design trend digital information enable explain generative model like gan diffusion model generate graphic effect example like stable diffusion midjourney show ais potential diverse abstract visual motion graphic could also enable interactive effect combine arvr overall empower dynamic personalize graphic design brand key point dynamic design bring interactivity well convey brand mean brand visual design diversify core brand image dynamic performance reinforce boost efficiency innovation meaning dynamic design though mainstream branding remain relevant article highlight future potential motion graphic visual storytelling generate new interpretation experiencesjatsp,0.45132743362831856,0.1415929203539823,0.26548672566371684,0.017699115044247787,113.0,1.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Qualitative,Principles of Logic Design with Nanoscale Thin Film Memristive Systems for High Performance Digital Circuit Applications,"<jats:p>The characteristic pinched hysteresis behavior of memristors has been reported by stacks of a variety of materials. This paper aims to examine the principles of logic design using such two terminal memristive systems for high performance digital circuit applications. As against logic design with standard CMOS, the benefits of logic design with memristors have been stated. The realization and operation of memristor based AND and OR hybrid logic gates obtained by integrating memristors with standard CMOS logic have been discussed. The IMPLY and MAGIC logic families have been demonstrated by covering MAGIC NOR and NAND logic gate implementation with MAGIC NOR in detail. A qualitative comparison has been drawn towards the end of the paper to conclude on the suitability and application space for each of the logic families studied in this paper. This work also describes the hybrid CMOS-memristive logic family known as MRL (Memristor Ratioed Logic). With the addition of CMOS inverters, this logic family's OR and AND logic gates, which are based on memristive components, are given a full logic structure and signal restoration. The MRL family, in contrast to earlier memristor-based logic families, is compatible with conventional CMOS logic.</jats:p>",https://doi.org/10.4028/p-90x9b8,CrossRef,principle logic design nanoscale thin film memristive system high performance digital circuit application,jatspthe characteristic pinch hysteresis behavior memristor report stack variety material paper aim examine principle logic design use two terminal memristive system high performance digital circuit application logic design standard cmo benefit logic design memristor state realization operation memristor base hybrid logic gate obtain integrate memristor standard cmos logic discuss imply magic logic family demonstrate cover magic nand logic gate implementation magic detail qualitative comparison draw towards end paper conclude suitability application space logic family study paper work also describe hybrid cmosmemristive logic family know mrl memristor ratioe logic addition cmos inverter logic family logic gate base memristive component give full logic structure signal restoration mrl family contrast early memristorbase logic family compatible conventional cmos logicjatsp,principle logic design nanoscale thin film memristive system high performance digital circuit application jatspthe characteristic pinch hysteresis behavior memristor report stack variety material paper aim examine principle logic design use two terminal memristive system high performance digital circuit application logic design standard cmo benefit logic design memristor state realization operation memristor base hybrid logic gate obtain integrate memristor standard cmos logic discuss imply magic logic family demonstrate cover magic nand logic gate implementation magic detail qualitative comparison draw towards end paper conclude suitability application space logic family study paper work also describe hybrid cmosmemristive logic family know mrl memristor ratioe logic addition cmos inverter logic family logic gate base memristive component give full logic structure signal restoration mrl family contrast early memristorbase logic family compatible conventional cmos logicjatsp,0.6260869565217392,0.11304347826086956,0.17391304347826086,0.008695652173913044,115.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Qualitative,Design of Small-Phase Time-Variant Low-pass Digital Fractional Differentiators and Integrators,"<jats:p>The design method and the time-variant FIR architecture for real-time estimation of fractional and integer differentials and integrals are presented in this paper. The proposed FIR architecture is divided into two parts. Small-phase filtering, integer differentiation, and fractional differential and integration on the local data are performed by the first part, which is time-invariant. The second part, which is time-variant, handles fractional and global differentiation and integration. The separation of the two parts is necessary because real-time matrix inversion or an extensive analytical solution, which can be computationally intensive for high-order FIR architectures, would be required by a single time-variant FIR architecture. However, matrix inversion is used in the design method to achieve negligible delay in the filtered, differentiated, and integrated signals. The optimum output obtained by the method of least squares results in the negligible delay. The experimental results show that fractional and integer differentiation and integration can be performed by the proposed solution, although the fractional differentiation and integration process is sensitive to the noise and limited resolution of the measurements. In systems that require closed-loop control, disturbance observation, and real-time identification of model parameters, this solution can be implemented.</jats:p>",https://doi.org/10.14313/jamris/2-2024/15,CrossRef,design smallphase timevariant lowpass digital fractional differentiator integrator,jatspthe design method timevariant fir architecture realtime estimation fractional integer differential integral present paper propose fir architecture divide two part smallphase filtering integer differentiation fractional differential integration local datum perform first part timeinvariant second part timevariant handle fractional global differentiation integration separation two part necessary realtime matrix inversion extensive analytical solution computationally intensive highorder fir architecture would require single timevariant fir architecture however matrix inversion use design method achieve negligible delay filter differentiated integrated signal optimum output obtain method least square result negligible delay experimental result show fractional integer differentiation integration perform propose solution although fractional differentiation integration process sensitive noise limited resolution measurement system require closedloop control disturbance observation realtime identification model parameter solution implementedjatsp,design smallphase timevariant lowpass digital fractional differentiator integrator jatspthe design method timevariant fir architecture realtime estimation fractional integer differential integral present paper propose fir architecture divide two part smallphase filtering integer differentiation fractional differential integration local datum perform first part timeinvariant second part timevariant handle fractional global differentiation integration separation two part necessary realtime matrix inversion extensive analytical solution computationally intensive highorder fir architecture would require single timevariant fir architecture however matrix inversion use design method achieve negligible delay filter differentiated integrated signal optimum output obtain method least square result negligible delay experimental result show fractional integer differentiation integration perform propose solution although fractional differentiation integration process sensitive noise limited resolution measurement system require closedloop control disturbance observation realtime identification model parameter solution implementedjatsp,0.5172413793103449,0.10344827586206896,0.2413793103448276,0.017241379310344827,116.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Qualitative,The Impacts of Digital Technology on Service Design and Experience Innovation: Case Study of Taiwan’s Cultural Heritage under the COVID-19 Pandemic,"<jats:p>The aim of this research is to identify the digital technology impact and experience innovation of cultural heritages in the context of the epidemic. The authors created an analytical framework and used a qualitative exploratory multi-case study of three cultural heritages in Taiwan. The findings indicate that digital technology has facilitated further innovations in cultural heritages under the epidemic to be closer to consumers’ daily life and more connected with the young generation. Compared to traditional cultural heritages, profit-making cultural heritages need sales of its products to sustain operations, while live streaming, which is interactive, is rising as a new way to promote sales. Using multiple digital platforms can maintain consumers’ interest in the cultural heritages, encouraging follow-up visits and thus resulting in more traffic online and offline. This paper illustrates the advantages of digital technology in the context of the epidemic, highlighting the innovative technology of live streaming and social platforms introduced that are different from the traditional cultural heritages.</jats:p>",https://doi.org/10.3390/systems10050184,CrossRef,impact digital technology service design experience innovation case study taiwan cultural heritage covid pandemic,jatspthe aim research identify digital technology impact experience innovation cultural heritage context epidemic author create analytical framework use qualitative exploratory multicase study three cultural heritage taiwan finding indicate digital technology facilitate innovation cultural heritage epidemic close consumer daily life connect young generation compare traditional cultural heritage profitmake cultural heritage need sale product sustain operation live streaming interactive rise new way promote sale use multiple digital platform maintain consumer interest cultural heritage encourage followup visit thus result traffic online offline paper illustrate advantage digital technology context epidemic highlight innovative technology live streaming social platform introduce different traditional cultural heritagesjatsp,impact digital technology service design experience innovation case study taiwan cultural heritage covid pandemic jatspthe aim research identify digital technology impact experience innovation cultural heritage context epidemic author create analytical framework use qualitative exploratory multicase study three cultural heritage taiwan finding indicate digital technology facilitate innovation cultural heritage epidemic close consumer daily life connect young generation compare traditional cultural heritage profitmake cultural heritage need sale product sustain operation live streaming interactive rise new way promote sale use multiple digital platform maintain consumer interest cultural heritage encourage followup visit thus result traffic online offline paper illustrate advantage digital technology context epidemic highlight innovative technology live streaming social platform introduce different traditional cultural heritagesjatsp,0.5,0.1836734693877551,0.2653061224489796,0.02040816326530612,98.0,0.0,1.0,0.0,0.0
Computer Engineering,Digital Systems Design,Mixed Methods,"Visualization of Mobility Digital Twin: Framework Design, Case Study,
  and Future Challenges","A Mobility Digital Twin is an emerging implementation of digital twin
technology in the transportation domain, which creates digital replicas for
various physical mobility entities, such as vehicles, drivers, and pedestrians.
Although a few work have investigated the applications of mobility digital twin
recently, the extent to which it can facilitate safer autonomous vehicles
remains insufficiently explored. In this paper, we first propose visualization
of mobility digital twin, which aims to augment the existing perception systems
in connected and autonomous vehicles through twinning high-fidelity and
manipulable geometry representations for causal traffic participants, such as
surrounding pedestrians and vehicles, in the digital space. An end-to-end
system framework, including image data crowdsourcing, preprocessing,
offloading, and edge-assisted 3D geometry reconstruction, is designed to enable
real-world development of the proposed visualization of mobility digital twin.
We implement the proposed system framework and conduct a case study to assess
the twinning fidelity and physical-to-digital synchronicity within different
image sampling scenarios and wireless network conditions. Based on the case
study, future challenges of the proposed visualization of mobility digital twin
are discussed toward the end of the paper.",http://arxiv.org/abs/2307.09666v1,arXiv,visualization mobility digital twin framework design case study future challenge,mobility digital twin emerge implementation digital twin technology transportation domain create digital replica various physical mobility entity vehicle driver pedestrian although work investigate application mobility digital twin recently extent facilitate safe autonomous vehicle remains insufficiently explore paper first propose visualization mobility digital twin aim augment exist perception system connected autonomous vehicle twin highfidelity manipulable geometry representation causal traffic participant surround pedestrian vehicle digital space endtoend system framework include image datum crowdsourcing preprocessing offloading edgeassiste geometry reconstruction design enable realworld development propose visualization mobility digital twin implement propose system framework conduct case study assess twin fidelity physicaltodigital synchronicity within different image sample scenario wireless network condition base case study future challenge propose visualization mobility digital twin discuss toward end paper,visualization mobility digital twin framework design case study future challenge mobility digital twin emerge implementation digital twin technology transportation domain create digital replica various physical mobility entity vehicle driver pedestrian although work investigate application mobility digital twin recently extent facilitate safe autonomous vehicle remains insufficiently explore paper first propose visualization mobility digital twin aim augment exist perception system connected autonomous vehicle twin highfidelity manipulable geometry representation causal traffic participant surround pedestrian vehicle digital space endtoend system framework include image datum crowdsourcing preprocessing offloading edgeassiste geometry reconstruction design enable realworld development propose visualization mobility digital twin implement propose system framework conduct case study assess twin fidelity physicaltodigital synchronicity within different image sample scenario wireless network condition base case study future challenge propose visualization mobility digital twin discuss toward end paper,0.5378151260504201,0.11764705882352941,0.19327731092436976,0.025210084033613446,119.0,1.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Mixed Methods,"Precarious Experiences: Citizens' Frustrations, Anxieties and Burdens of
  an Online Welfare Benefit System","There is a significant overlap between people who are supported by
income-related social welfare benefits, often in precarious situations, and
those who experience greater digital exclusion. We report on a study of
claimants using the UK's Universal Credit online welfare benefit system
designed as, and still, ""digital by default"". Through data collection involving
remote interviews (n=11) and online surveys (n=66), we expose claimants' own
lived experiences interacting with this system. The claimants explain how
digital channels can contribute to an imbalance of power and agency, at a time
when their own circumstances mean they have reduced abilities, resources and
capacities, and where design choices can adversely affect people's utility to
leverage help from their own wider socio-technical ecosystems. We contribute
eight recommendations from these accounts to inform the future design and
development of digital welfare benefit systems for this population, to reduce
digital barriers and harms.",http://arxiv.org/abs/2405.08515v1,arXiv,precarious experience citizen frustration anxiety burden online welfare benefit system,significant overlap people support incomerelate social welfare benefit often precarious situation experience great digital exclusion report study claimant use uks universal credit online welfare benefit system design still digital default data collection involve remote interview online survey expose claimant live experience interact system claimant explain digital channel contribute imbalance power agency time circumstance mean reduce ability resource capacity design choice adversely affect people utility leverage help wide sociotechnical ecosystem contribute eight recommendation account inform future design development digital welfare benefit system population reduce digital barrier harm,precarious experience citizen frustration anxiety burden online welfare benefit system significant overlap people support incomerelate social welfare benefit often precarious situation experience great digital exclusion report study claimant use uks universal credit online welfare benefit system design still digital default data collection involve remote interview online survey expose claimant live experience interact system claimant explain digital channel contribute imbalance power agency time circumstance mean reduce ability resource capacity design choice adversely affect people utility leverage help wide sociotechnical ecosystem contribute eight recommendation account inform future design development digital welfare benefit system population reduce digital barrier harm,0.5697674418604651,0.12790697674418605,0.23255813953488372,0.03488372093023256,86.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Mixed Methods,"Development and Performance Validation of a Versatile VLBI Digital
  Backend Using the ROACH2 Platform","Customized digital backends for Very Long Baseline Interferometry (VLBI) are
critical components for radio astronomy observatories. There are several
serialized products such as the Digital Baseband Converter (DBBC),
Reconfigurable Open Architecture Computing Hardware (ROACH) Digital BackEnd
(RDBE), and Chinese Data Acquisition System (CDAS). However, the reliance on
high-speed analog-to-digital converters (ADC) and Field Programmable Gate
Arrays (FPGAs) often necessitates dedicated hardware platforms with long
development cycles and prohibitive cost, limiting scalability and adaptability
to evolving observational needs. To address these challenges, we propose a
design leveraging the versatile and cost-effective ROACH2 hardware platform,
developed by CASPER (Collaboration for Astronomy Signal Processing and
Electronics Research). ROACH2's mature technology and streamlined firmware
development capabilities significantly reduce the hardware platform's
development cycle and cost, making it ideal for modern astronomical
applications. This VLBI digital backend, based on the ROACH2 platform,
incorporates key technologies such as Polyphase Filter Banks (PFB) algorithm
implementation, digital complex-to-real baseband signal conversion, Mark5B data
formatter design and two-bit optimal threshold quantization. These features
ensure compatibility with existing systems while providing enhanced
performance. The backend's performance was validated through multi-station VLBI
experiments, demonstrating its ability to achieve good correlation fringes
compared to the customized CDAS2-D system. Furthermore, this platform offers
flexibility for rapid deployment of additional digital backends, such as those
for spectral line observations, showcasing its potential for broader
astronomical applications.",http://arxiv.org/abs/2502.15446v1,arXiv,development performance validation versatile vlbi digital backend use roach platform,customize digital backend long baseline interferometry vlbi critical component radio astronomy observatory several serialized product digital baseband converter dbbc reconfigurable open architecture compute hardware roach digital backend rdbe chinese datum acquisition system cda however reliance highspeed analogtodigital converter adc field programmable gate array fpgas often necessitate dedicated hardware platform long development cycle prohibitive cost limit scalability adaptability evolve observational need address challenge propose design leverage versatile costeffective roach hardware platform develop casper collaboration astronomy signal processing electronic research roachs mature technology streamlined firmware development capability significantly reduce hardware platform development cycle cost make ideal modern astronomical application vlbi digital backend base roach platform incorporate key technology polyphase filter bank pfb algorithm implementation digital complextoreal baseband signal conversion markb datum formatter design twobit optimal threshold quantization feature ensure compatibility exist system provide enhance performance backend performance validate multistation vlbi experiment demonstrate ability achieve good correlation fringe compare customize cdasd system furthermore platform offer flexibility rapid deployment additional digital backend spectral line observation showcase potential broad astronomical application,development performance validation versatile vlbi digital backend use roach platform customize digital backend long baseline interferometry vlbi critical component radio astronomy observatory several serialized product digital baseband converter dbbc reconfigurable open architecture compute hardware roach digital backend rdbe chinese datum acquisition system cda however reliance highspeed analogtodigital converter adc field programmable gate array fpgas often necessitate dedicated hardware platform long development cycle prohibitive cost limit scalability adaptability evolve observational need address challenge propose design leverage versatile costeffective roach hardware platform develop casper collaboration astronomy signal processing electronic research roachs mature technology streamlined firmware development capability significantly reduce hardware platform development cycle cost make ideal modern astronomical application vlbi digital backend base roach platform incorporate key technology polyphase filter bank pfb algorithm implementation digital complextoreal baseband signal conversion markb datum formatter design twobit optimal threshold quantization feature ensure compatibility exist system provide enhance performance backend performance validate multistation vlbi experiment demonstrate ability achieve good correlation fringe compare customize cdasd system furthermore platform offer flexibility rapid deployment additional digital backend spectral line observation showcase potential broad astronomical application,0.5301204819277109,0.09036144578313253,0.18072289156626506,0.024096385542168676,166.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Mixed Methods,Design propositions for nudging in healthcare: Adoption of national electronic health record systems,"<jats:sec><jats:title>Objectives</jats:title><jats:p> Electronic health records (EHRs) are considered important for improving efficiency and reducing costs of a healthcare system. However, the adoption of EHR systems differs among countries and so does the way the decision to participate in EHRs is presented. Nudging is a concept that deals with influencing human behaviour within the research stream of behavioural economics. In this paper, we focus on the effects of the choice architecture on the decision for the adoption of national EHRs. Our study aims to link influences on human behaviour through nudging with the adoption of EHRs to investigate how choice architects can facilitate the adoption of national information systems. </jats:p></jats:sec><jats:sec><jats:title>Methods</jats:title><jats:p> We employ a qualitative explorative research design, namely the case study method. Using theoretical sampling, we selected four cases (i.e., countries) for our study: Estonia, Austria, the Netherlands, and Germany. We collected and analyzed data from various primary and secondary sources: ethnographic observation, interviews, scientific papers, homepages, press releases, newspaper articles, technical specifications, publications from governmental bodies, and formal studies. </jats:p></jats:sec><jats:sec><jats:title>Results</jats:title><jats:p> The findings from our European case studies show that designing for EHR adoption should encompass choice architecture elements (i.e., defaults), technical elements (i.e., choice granularity and access transparency), and institutional elements (i.e., regulations for data protection, information campaigns, and financial incentives) in combination. </jats:p></jats:sec><jats:sec><jats:title>Conclusions</jats:title><jats:p> Our findings provide insights on the design of the adoption environments of large-scale, national EHR systems. Future research could estimate the magnitude of effects of the determinants. </jats:p></jats:sec>",https://doi.org/10.1177/20552076231181208,CrossRef,design proposition nudge healthcare adoption national electronic health record system,jatssecjatstitleobjectivesjatstitlejatsp electronic health record ehrs consider important improve efficiency reduce cost healthcare system however adoption ehr system differ among country way decision participate ehrs present nudge concept deal influence human behaviour within research stream behavioural economic paper focus effect choice architecture decision adoption national ehrs study aim link influence human behaviour nudge adoption ehrs investigate choice architect facilitate adoption national information system jatspjatssecjatssecjatstitlemethodsjatstitlejatsp employ qualitative explorative research design namely case study method use theoretical sampling select four case country study estonia austria netherlands germany collect analyze datum various primary secondary source ethnographic observation interview scientific paper homepage press release newspaper article technical specification publication governmental body formal study jatspjatssecjatssecjatstitleresultsjatstitlejatsp finding european case study show design ehr adoption encompass choice architecture element default technical element choice granularity access transparency institutional element regulation datum protection information campaign financial incentive combination jatspjatssecjatssecjatstitleconclusionsjatstitlejatsp finding provide insight design adoption environment largescale national ehr system future research could estimate magnitude effect determinant jatspjatssec,design proposition nudge healthcare adoption national electronic health record system jatssecjatstitleobjectivesjatstitlejatsp electronic health record ehrs consider important improve efficiency reduce cost healthcare system however adoption ehr system differ among country way decision participate ehrs present nudge concept deal influence human behaviour within research stream behavioural economic paper focus effect choice architecture decision adoption national ehrs study aim link influence human behaviour nudge adoption ehrs investigate choice architect facilitate adoption national information system jatspjatssecjatssecjatstitlemethodsjatstitlejatsp employ qualitative explorative research design namely case study method use theoretical sampling select four case country study estonia austria netherlands germany collect analyze datum various primary secondary source ethnographic observation interview scientific paper homepage press release newspaper article technical specification publication governmental body formal study jatspjatssecjatssecjatstitleresultsjatstitlejatsp finding european case study show design ehr adoption encompass choice architecture element default technical element choice granularity access transparency institutional element regulation datum protection information campaign financial incentive combination jatspjatssecjatssecjatstitleconclusionsjatstitlejatsp finding provide insight design adoption environment largescale national ehr system future research could estimate magnitude effect determinant jatspjatssec,0.5796178343949044,0.12101910828025478,0.15286624203821655,0.012738853503184714,157.0,0.0,3.0,0.0,0.0
Computer Engineering,Digital Systems Design,Mixed Methods,Design of Manufacturing Systems Based on Digital Shadow and Robust Engineering,"<jats:p>In the era of digital transformation, industry is facing multiple challenges due to the need for implementation of the Industry 4.0 standards, as well as the volatility of customer demands. The latter has created the need for the design and operation of more complex manufacturing systems and networks. A case study derived from Process Industries (PIs) is adopted in this research work in order to design a framework for flexible design of production lines, automation of quality control points, and improvement of the performance of the manufacturing system. Therefore, a Digital Shadow of a production line is developed to collect, analyze and identify potential issues (bottlenecks). An edge computing system for reliable and low-latency communications is also implemented. The digital model is validated using statistical Design Of Experiments (DOE) and ANalysis Of VAriance (ANOVA). For the assessment of what-if scenarios, the Digital Shadow model will be used in order to evaluate and find the desired solution. Ultimately, the goal of this research work is to improve the design and performance of the industry’s production section, as well as to increase the production rate and the product mix.</jats:p>",https://doi.org/10.3390/app13085184,CrossRef,design manufacturing system base digital shadow robust engineering,jatspin era digital transformation industry face multiple challenge due need implementation industry standard well volatility customer demand latter create need design operation complex manufacturing system network case study derive process industry pis adopt research work order design framework flexible design production line automation quality control point improvement performance manufacturing system therefore digital shadow production line develop collect analyze identify potential issue bottleneck edge computing system reliable lowlatency communication also implement digital model validate use statistical design experiment doe analysis variance anova assessment whatif scenario digital shadow model use order evaluate find desire solution ultimately goal research work improve design performance industry production section well increase production rate product mixjatsp,design manufacturing system base digital shadow robust engineering jatspin era digital transformation industry face multiple challenge due need implementation industry standard well volatility customer demand latter create need design operation complex manufacturing system network case study derive process industry pis adopt research work order design framework flexible design production line automation quality control point improvement performance manufacturing system therefore digital shadow production line develop collect analyze identify potential issue bottleneck edge computing system reliable lowlatency communication also implement digital model validate use statistical design experiment doe analysis variance anova assessment whatif scenario digital shadow model use order evaluate find desire solution ultimately goal research work improve design performance industry production section well increase production rate product mixjatsp,0.6697247706422018,0.11009174311926606,0.11926605504587157,0.03669724770642202,109.0,1.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Design and Development,Integrated Digital Health Systems Design,"<p>The application of information technology in healthcare has focused primarily on the implementation of specific systems such as electronic health records (EHRs) and clinical decision support systems (CDSSs), mainly for intra-enterprise use. However, for the integrated health system (IHS) to function effectively in a complex inter-enterprise healthcare delivery environment, designers must focus on approaches such as soft systems methodology (SSM) to enable the design of robust integrated digital health systems (IDHSs). A service-oriented architecture (SOA) offers a flexible framework for IDHSs to become de-centralized, fully functional and modular systems with interoperability. This article identifies the design issues in IDHS and explores the potential of an SSM methodology-based SOA for the development of interoperable IDHSs. In the process we compare and contrast the functionalist socio-technical approach to the interpretive SSM. We also describe a prototype SOA application for an IDHS setting and discuss challenges in the application of SOA to healthcare.</p>",https://doi.org/10.4018/jitsa.2009070102,CrossRef,integrate digital health system design,pthe application information technology healthcare focus primarily implementation specific system electronic health record ehrs clinical decision support system cdsss mainly intraenterprise use however integrated health system ihs function effectively complex interenterprise healthcare delivery environment designer must focus approach soft system methodology ssm enable design robust integrate digital health system idhss serviceoriente architecture soa offer flexible framework idhss become decentralize fully functional modular system interoperability article identify design issue idhs explore potential ssm methodologybase soa development interoperable idhss process compare contrast functionalist sociotechnical approach interpretive ssm also describe prototype soa application idhs setting discuss challenge application soa healthcarep,integrate digital health system design pthe application information technology healthcare focus primarily implementation specific system electronic health record ehrs clinical decision support system cdsss mainly intraenterprise use however integrated health system ihs function effectively complex interenterprise healthcare delivery environment designer must focus approach soft system methodology ssm enable design robust integrate digital health system idhss serviceoriente architecture soa offer flexible framework idhss become decentralize fully functional modular system interoperability article identify design issue idhs explore potential ssm methodologybase soa development interoperable idhss process compare contrast functionalist sociotechnical approach interpretive ssm also describe prototype soa application idhs setting discuss challenge application soa healthcarep,0.4948453608247423,0.14432989690721648,0.15463917525773196,0.061855670103092786,97.0,1.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Design and Development,Systems Architecture Design Pattern Catalog for Developing Digital Twins,"<jats:p>A digital twin is a digital replica of a physical entity to which it is remotely connected. A digital twin can provide a rich representation of the corresponding physical entity and enables sophisticated control for various purposes. Although the concept of the digital twin is largely known, designing digital twins based systems has not yet been fully explored. In practice, digital twins can be applied in different ways leading to different architectural designs. To guide the architecture design process, we provide a pattern-oriented approach for architecting digital twin-based systems. To this end, we propose a catalog of digital twin architecture design patterns that can be reused in the broad context of systems engineering. The patterns support the various phases in the systems engineering life cycle process, and are described using a well-defined pattern documentation template. For illustrating the application of digital twin patterns, we adopt a multi-case study approach in the agriculture and food domain.</jats:p>",https://doi.org/10.3390/s20185103,CrossRef,system architecture design pattern catalog develop digital twin,jatspa digital twin digital replica physical entity remotely connect digital twin provide rich representation corresponding physical entity enable sophisticated control various purpose although concept digital twin largely know design digital twin base system yet fully explore practice digital twin apply different way lead different architectural design guide architecture design process provide patternoriented approach architecte digital twinbased system end propose catalog digital twin architecture design pattern reuse broad context system engineer pattern support various phase system engineering life cycle process describe use welldefine pattern documentation template illustrate application digital twin pattern adopt multicase study approach agriculture food domainjatsp,system architecture design pattern catalog develop digital twin jatspa digital twin digital replica physical entity remotely connect digital twin provide rich representation corresponding physical entity enable sophisticated control various purpose although concept digital twin largely know design digital twin base system yet fully explore practice digital twin apply different way lead different architectural design guide architecture design process provide patternoriented approach architecte digital twinbased system end propose catalog digital twin architecture design pattern reuse broad context system engineer pattern support various phase system engineering life cycle process describe use welldefine pattern documentation template illustrate application digital twin pattern adopt multicase study approach agriculture food domainjatsp,0.5051546391752577,0.15463917525773196,0.23711340206185566,0.030927835051546393,97.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Design and Development,Promotion of Intelligent Digital Computer-Aided Design to the Improvement of Rural Public Environment Design,"<jats:p>In order to optimize the rural public environment, protect and build the characteristics and integrity of the rural public environment. This paper introduces the development and research of a digital design platform based on digital computer, taking parallel robot (cross IV) as the object. The basic functional requirement of the digital integrated design platform is parallel robot. In the design stage, it mainly needs six functional modules, including conceptual design module, detailed design module, simulation design module, electromechanical coupling design module, optimization design module, and database module. Based on the analysis and summary of the digital integrated design process of parallel robot, combined with the actual functional requirements, the key technologies and solutions of the digital design platform are determined, the overall framework of the digital design platform is drawn up, and the implementation process of the platform is planned in detail. The Design personnel involved in the design process and their corresponding responsible contents, and the user authority is managed reasonably. Set the parameters of the driving arm and the driven arm. The outer diameter of the driving arm is 58 mm and the thickness is 2 mm. The outer diameter of the driven arm is 14 mm, and the thickness is 2 mm. Their length can be calculated directly according to the parameters provided in the conceptual design. According to the rules set by the software, the automatic assembly operation is carried out to obtain the whole machine model. After entering the SolidWorks motion module, the dynamic interference inspection is carried out first, and then the simulation analysis is carried out. The results show that the selection is correct when the actual model is consistent with the theoretical model. The correct selection and wide application of CAD technology in the production and construction of building decoration engineering will inevitably bring great changes in construction management and concept and become a new trend and trend for construction enterprises to enhance their competitiveness. The aforementioned computer-aided design is a broad application category. It provides a strong foundation for the design of rural public environment.</jats:p>",https://doi.org/10.1155/2022/6253292,CrossRef,promotion intelligent digital computeraide design improvement rural public environment design,jatspin order optimize rural public environment protect build characteristic integrity rural public environment paper introduce development research digital design platform base digital computer take parallel robot cross object basic functional requirement digital integrate design platform parallel robot design stage mainly need six functional module include conceptual design module detailed design module simulation design module electromechanical coupling design module optimization design module database module base analysis summary digital integrate design process parallel robot combine actual functional requirement key technology solution digital design platform determine overall framework digital design platform draw implementation process platform plan detail design personnel involve design process corresponding responsible content user authority manage reasonably set parameter drive arm driven arm outer diameter drive arm thickness outer diameter driven arm thickness length calculate directly accord parameter provide conceptual design accord rule set software automatic assembly operation carry obtain whole machine model enter solidwork motion module dynamic interference inspection carry first simulation analysis carry result show selection correct actual model consistent theoretical model correct selection wide application cad technology production construction build decoration engineering inevitably bring great change construction management concept become new trend trend construction enterprise enhance competitiveness aforementioned computeraide design broad application category provide strong foundation design rural public environmentjatsp,promotion intelligent digital computeraide design improvement rural public environment design jatspin order optimize rural public environment protect build characteristic integrity rural public environment paper introduce development research digital design platform base digital computer take parallel robot cross object basic functional requirement digital integrate design platform parallel robot design stage mainly need six functional module include conceptual design module detailed design module simulation design module electromechanical coupling design module optimization design module database module base analysis summary digital integrate design process parallel robot combine actual functional requirement key technology solution digital design platform determine overall framework digital design platform draw implementation process platform plan detail design personnel involve design process corresponding responsible content user authority manage reasonably set parameter drive arm driven arm outer diameter drive arm thickness outer diameter driven arm thickness length calculate directly accord parameter provide conceptual design accord rule set software automatic assembly operation carry obtain whole machine model enter solidwork motion module dynamic interference inspection carry first simulation analysis carry result show selection correct actual model consistent theoretical model correct selection wide application cad technology production construction build decoration engineering inevitably bring great change construction management concept become new trend trend construction enterprise enhance competitiveness aforementioned computeraide design broad application category provide strong foundation design rural public environmentjatsp,0.6089108910891089,0.14356435643564355,0.21782178217821782,0.019801980198019802,202.0,0.0,0.0,0.0,1.0
Computer Engineering,Digital Systems Design,Design and Development,Digital twin enhanced agile design of ship pipeline systems,"<ns3:p>The shipbuilding industry plays a pivotal role in national strategic security and economic development, and one critical challenge is the pipeline layout design problem. It predominantly relies on designers’ subjective experience, and it is marked by a lack of efficient knowledge sharing and the absence of smart pipe routing algorithms. This paper proposes an agile design system, which integrates ship pipeline design knowledge management, semi-automatic design that involves frequent interaction with human designers, and automatic rule checking. The framework is refined by digital twin concepts, facilitating close collaboration between physical and digital systems. The paradigm shift holds the potential to substantially enhance the efficiency of ship pipeline layout design, while concurrently reducing the reliance on manual labor.</ns3:p>",https://doi.org/10.12688/digitaltwin.17918.2,CrossRef,digital twin enhance agile design ship pipeline system,nspthe shipbuilding industry play pivotal role national strategic security economic development one critical challenge pipeline layout design problem predominantly rely designer subjective experience mark lack efficient knowledge sharing absence smart pipe routing algorithm paper propose agile design system integrate ship pipeline design knowledge management semiautomatic design involve frequent interaction human designer automatic rule check framework refine digital twin concept facilitate close collaboration physical digital system paradigm shift hold potential substantially enhance efficiency ship pipeline layout design concurrently reduce reliance manual labornsp,digital twin enhance agile design ship pipeline system nspthe shipbuilding industry play pivotal role national strategic security economic development one critical challenge pipeline layout design problem predominantly rely designer subjective experience mark lack efficient knowledge sharing absence smart pipe routing algorithm paper propose agile design system integrate ship pipeline design knowledge management semiautomatic design involve frequent interaction human designer automatic rule check framework refine digital twin concept facilitate close collaboration physical digital system paradigm shift hold potential substantially enhance efficiency ship pipeline layout design concurrently reduce reliance manual labornsp,0.5925925925925926,0.09876543209876543,0.2222222222222222,0.037037037037037035,81.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Design and Development,Digital twin enhanced agile design of ship pipeline systems,"<ns3:p>The shipbuilding industry plays a pivotal role in national strategic security and economic development, and one critical challenge is the pipeline layout design problem. It predominantly relies on designers’ subjective experience, and it is marked by a lack of efficient knowledge sharing and the absence of smart pipe routing algorithms. This paper proposes an agile design system, which integrates ship pipeline design knowledge management, semi-automatic design that involves frequent interaction with human designers, and automatic rule checking. The framework is refined by digital twin concepts, facilitating close collaboration between physical and digital systems. The paradigm shift holds the potential to substantially enhance the efficiency of ship pipeline layout design, while concurrently reducing the reliance on manual labor.</ns3:p>",https://doi.org/10.12688/digitaltwin.17918.1,CrossRef,digital twin enhance agile design ship pipeline system,nspthe shipbuilding industry play pivotal role national strategic security economic development one critical challenge pipeline layout design problem predominantly rely designer subjective experience mark lack efficient knowledge sharing absence smart pipe routing algorithm paper propose agile design system integrate ship pipeline design knowledge management semiautomatic design involve frequent interaction human designer automatic rule check framework refine digital twin concept facilitate close collaboration physical digital system paradigm shift hold potential substantially enhance efficiency ship pipeline layout design concurrently reduce reliance manual labornsp,digital twin enhance agile design ship pipeline system nspthe shipbuilding industry play pivotal role national strategic security economic development one critical challenge pipeline layout design problem predominantly rely designer subjective experience mark lack efficient knowledge sharing absence smart pipe routing algorithm paper propose agile design system integrate ship pipeline design knowledge management semiautomatic design involve frequent interaction human designer automatic rule check framework refine digital twin concept facilitate close collaboration physical digital system paradigm shift hold potential substantially enhance efficiency ship pipeline layout design concurrently reduce reliance manual labornsp,0.5925925925925926,0.09876543209876543,0.2222222222222222,0.037037037037037035,81.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Theoretical / Conceptual,Digital Omotenashi: Toward a Smart Tourism Design Systems,"<jats:p>The tourism industry is currently facing many challenges; one of the main challenges is the lack of having smart tourism systems that make use of the recent advances in information and communication technology. Another challenge is designing such smart tourism systems while embracing diversified tourists’ sustainable values of experience (functional values, social values, emotional values, and epistemic values). In light of these challenges, the overall objective of this work is to design a smart tourism experience-centered system that considers social and technical perspectives. The Socio-Technical Systems theory was adopted as a theoretical foundation, and the Design Science Research methodology was used to develop a smart tourism system and a practical design artifact. A case study from the Japanese tourism context was studied by exploring tourists’ sustainable values of experiences and local staffs’ behaviors. The main problem was the dysfunctional communication between local service staffs and foreign tourists during the service process. After identifying the problem and the objectives, a relevant smart tourism system was synthesized and tested as a design artifact. The results of the utility test of the proposed artifact showed its effectiveness and efficiency in facilitating the service process and in creating multi-dimensional values of experience.</jats:p>",https://doi.org/10.3390/su9122175,CrossRef,digital omotenashi toward smart tourism design system,jatspthe tourism industry currently face many challenge one main challenge lack smart tourism system make use recent advance information communication technology another challenge design smart tourism system embrace diversified tourist sustainable value experience functional value social value emotional value epistemic value light challenge overall objective work design smart tourism experiencecentere system consider social technical perspective sociotechnical system theory adopt theoretical foundation design science research methodology use develop smart tourism system practical design artifact case study japanese tourism context study explore tourist sustainable value experience local staff behavior main problem dysfunctional communication local service staff foreign tourist service process identify problem objective relevant smart tourism system synthesize test design artifact result utility test propose artifact show effectiveness efficiency facilitate service process create multidimensional value experiencejatsp,digital omotenashi toward smart tourism design system jatspthe tourism industry currently face many challenge one main challenge lack smart tourism system make use recent advance information communication technology another challenge design smart tourism system embrace diversified tourist sustainable value experience functional value social value emotional value epistemic value light challenge overall objective work design smart tourism experiencecentere system consider social technical perspective sociotechnical system theory adopt theoretical foundation design science research methodology use develop smart tourism system practical design artifact case study japanese tourism context study explore tourist sustainable value experience local staff behavior main problem dysfunctional communication local service staff foreign tourist service process identify problem objective relevant smart tourism system synthesize test design artifact result utility test propose artifact show effectiveness efficiency facilitate service process create multidimensional value experiencejatsp,0.6209677419354839,0.0967741935483871,0.24193548387096775,0.008064516129032258,124.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Theoretical / Conceptual,Online Simulation of Illustration Patterns Based on Digital Art Design,"<jats:p>Illustration art is an important part of graphic design, and is an intuitive means of artistic expression. Based on the gradual development of social networks and modern illustration art, digital illustration technology has become the main means of expression in modern graphic design. Starting from the basic concept of illustration art in the digital age, this study analyzes the application of digital illustration art and promotes the innovative development of the artistic expression of graphic design in China. This study will combine the traditional Chinese painting language with digital illustration creation in an inquiry-based manner, optimize the standard genetic algorithm, verify it through experimental simulation, and find that the model is more innovative based on the original model. This study provides a certain theoretical basis for the development of digital illustration in China and has a certain propaganda effect on the traditional Chinese painting language.</jats:p>",https://doi.org/10.1155/2022/3273364,CrossRef,online simulation illustration pattern base digital art design,jatspillustration art important part graphic design intuitive mean artistic expression base gradual development social network modern illustration art digital illustration technology become main mean expression modern graphic design start basic concept illustration art digital age study analyze application digital illustration art promote innovative development artistic expression graphic design china study combine traditional chinese paint language digital illustration creation inquirybase manner optimize standard genetic algorithm verify experimental simulation find model innovative base original model study provide certain theoretical basis development digital illustration china certain propaganda effect traditional chinese paint languagejatsp,online simulation illustration pattern base digital art design jatspillustration art important part graphic design intuitive mean artistic expression base gradual development social network modern illustration art digital illustration technology become main mean expression modern graphic design start basic concept illustration art digital age study analyze application digital illustration art promote innovative development artistic expression graphic design china study combine traditional chinese paint language digital illustration creation inquirybase manner optimize standard genetic algorithm verify experimental simulation find model innovative base original model study provide certain theoretical basis development digital illustration china certain propaganda effect traditional chinese paint languagejatsp,0.48314606741573035,0.07865168539325842,0.3707865168539326,0.0,89.0,0.0,2.0,0.0,0.0
Computer Engineering,Digital Systems Design,Theoretical / Conceptual,ELDERLY-CENTERED DESIGN APPROACH FOR MOBILE CHAT APPLICATION,"<jats:p>Connection and communication are heavily contingent on the internet and mobile apps, especially in this pandemic. With the blessings of Information and Communication Technology (ICT), the population of this digital era are highly dependent on several mobile applications. Undoubtedly, mobile apps have made our life easier and more straightforward, especially in the communication sector. There are at least hundreds of chat applications worldwide. Most of these communication platforms have been developed with many interactive and complex features designed mainly for the younger generation. However, in the perspective of Bangladesh, the older generation is unfamiliar and less comfortable with the concept and lacks the necessary digital literacy to use these advanced communication platforms. They frequently encounter difficulties in comprehending and using those applications. Thus, the authors described human-computer interaction (HCI) and briefly discussed some of the design issues from older adults' experiences in this report. Furthermore, a suitably designed chat application was  proposed based on understanding the challenges faced by the elderly. With a user-centered approach, the design emphasizes simplicity and minimalism, making it easier for the elderly to communicate through mobile technology.</jats:p>",https://doi.org/10.31436/jisdt.v4i1.263,CrossRef,elderlycentere design approach mobile chat application,jatspconnection communication heavily contingent internet mobile app especially pandemic blessing information communication technology ict population digital era highly dependent several mobile application undoubtedly mobile app make life easy straightforward especially communication sector least hundred chat application worldwide communication platform develop many interactive complex feature design mainly young generation however perspective bangladesh old generation unfamiliar less comfortable concept lack necessary digital literacy use advanced communication platform frequently encounter difficulty comprehend use application thus author describe humancomputer interaction hci briefly discuss design issue old adult experience report furthermore suitably design chat application propose base understand challenge face elderly usercentered approach design emphasize simplicity minimalism make easy elderly communicate mobile technologyjatsp,elderlycentere design approach mobile chat application jatspconnection communication heavily contingent internet mobile app especially pandemic blessing information communication technology ict population digital era highly dependent several mobile application undoubtedly mobile app make life easy straightforward especially communication sector least hundred chat application worldwide communication platform develop many interactive complex feature design mainly young generation however perspective bangladesh old generation unfamiliar less comfortable concept lack necessary digital literacy use advanced communication platform frequently encounter difficulty comprehend use application thus author describe humancomputer interaction hci briefly discuss design issue old adult experience report furthermore suitably design chat application propose base understand challenge face elderly usercentered approach design emphasize simplicity minimalism make easy elderly communicate mobile technologyjatsp,0.4444444444444444,0.12037037037037036,0.23148148148148148,0.12962962962962962,54.0,0.0,0.0,0.0,0.0
Computer Engineering,Digital Systems Design,Theoretical / Conceptual,Design and Research of Digital Media Art Display Based on Virtual Reality and Augmented Reality,"<jats:p>Purpose. To serve as a reference for the evolution of the online digital art display industry, as well as to conduct further studies in the field of digital entertainment art in the showcase design business in order to give solid evidentiary assurances, this article presents a virtual reality which is a technology reality-based digital media art exhibition design with the goal of examining the new construction trend of online media art with in context of existing period and the use of sophisticated technology. Implications. This paper enriches the theory, skills, and means of digital cultural communication, opens up a broader space and vision for digital media art communication, enriches the communication skills and means of digital media, and provides flexible and efficient ideas and methods for the dissemination of digital media art, which is of practical significance for realizing the active and effective dissemination of digital media art. Methodology. The method of this paper is to use the digital three-dimensional panorama technology of virtual reality to explore the digital media art display and digital media art expression form of augmented reality. The role of these methods is to solve the problem of spatial positioning of virtual 3D objects in real scenes and to judge the final detection model, the problem of model making to satisfy AR computing power, and the problem of scene interaction. Research Findings. Through a mix of digital content artwork and virtual reality and augmented reality technologies, this research examines the impact of AR and VR in digital art and analyzes and summarizes a series of design strategies for digital media art display projects. The results show that people are 33.6% more satisfied with VR and AR displays than traditional displays.</jats:p>",https://doi.org/10.1155/2022/6606885,CrossRef,design research digital medium art display base virtual reality augmented reality,jatsppurpose serve reference evolution online digital art display industry well conduct study field digital entertainment art showcase design business order give solid evidentiary assurance article present virtual reality technology realitybase digital medium art exhibition design goal examine new construction trend online medium art context exist period use sophisticated technology implication paper enrich theory skill mean digital cultural communication open broad space vision digital medium art communication enrich communication skill mean digital medium provide flexible efficient idea method dissemination digital medium art practical significance realize active effective dissemination digital medium art methodology method paper use digital threedimensional panorama technology virtual reality explore digital medium art display digital medium art expression form augment reality role method solve problem spatial positioning virtual object real scene judge final detection model problem model make satisfy computing power problem scene interaction research finding mix digital content artwork virtual reality augment reality technology research examine impact digital art analyze summarize series design strategy digital medium art display project result show people satisfied display traditional displaysjatsp,design research digital medium art display base virtual reality augmented reality jatsppurpose serve reference evolution online digital art display industry well conduct study field digital entertainment art showcase design business order give solid evidentiary assurance article present virtual reality technology realitybase digital medium art exhibition design goal examine new construction trend online medium art context exist period use sophisticated technology implication paper enrich theory skill mean digital cultural communication open broad space vision digital medium art communication enrich communication skill mean digital medium provide flexible efficient idea method dissemination digital medium art practical significance realize active effective dissemination digital medium art methodology method paper use digital threedimensional panorama technology virtual reality explore digital medium art display digital medium art expression form augment reality role method solve problem spatial positioning virtual object real scene judge final detection model problem model make satisfy computing power problem scene interaction research finding mix digital content artwork virtual reality augment reality technology research examine impact digital art analyze summarize series design strategy digital medium art display project result show people satisfied display traditional displaysjatsp,0.6130952380952381,0.13095238095238096,0.21428571428571427,0.005952380952380952,168.0,0.0,0.0,0.0,1.0
Computer Engineering,Digital Systems Design,Theoretical / Conceptual,ANFIS Based Thermal Estimation of Ultradeep Submicron Digital Circuit Design,"<jats:p>In this paper, the use of the Adaptive Neuro Fuzzy Inference System (ANFIS) to model the CMOS inverter is discussed as a tool for developing and simulating CMOS logic circuits at the ultradeep submicron technology node of 22nm. The ANFIS structures are built and trained using MATLAB software. The ANFIS network was trained using data obtained from the analytical model (at 298.15K and 398.15K). For training, two methodologies are used: a hybrid learning method based on back-propagation and least-squares estimation, and back-propagation. The effect of the ANFIS model's structure on the accuracy and performance of the CMOS inverter has also been investigated. Further, simulation through HSPICE using (Predictive Technology Model) PTM nominal parameters has been done to compare with ANFIS (trained using an analytical model) results. The comparison of ANFIS and HSPICE suggests the ANFIS modelling procedure's practicality and correctness. The findings demonstrate that the ANFIS simulation is significantly faster and more comparable than the HSPICE simulation and that it can be easily integrated into software tools for designing and simulating complicated CMOS logic circuits.</jats:p>",https://doi.org/10.29292/jics.v16i3.507,CrossRef,anfis base thermal estimation ultradeep submicron digital circuit design,jatspin paper use adaptive neuro fuzzy inference system anfis model cmos inverter discuss tool develop simulate cmos logic circuit ultradeep submicron technology node anfis structure build train use matlab software anfis network train use datum obtain analytical model train two methodology use hybrid learning method base backpropagation leastsquare estimation backpropagation effect anfis model structure accuracy performance cmo inverter also investigate simulation hspice use predictive technology model ptm nominal parameter compare anfis train use analytical model result comparison anfis hspice suggest anfis modelling procedure practicality correctness finding demonstrate anfis simulation significantly fast comparable hspice simulation easily integrate software tool design simulate complicated cmos logic circuitsjatsp,anfis base thermal estimation ultradeep submicron digital circuit design jatspin paper use adaptive neuro fuzzy inference system anfis model cmos inverter discuss tool develop simulate cmos logic circuit ultradeep submicron technology node anfis structure build train use matlab software anfis network train use datum obtain analytical model train two methodology use hybrid learning method base backpropagation leastsquare estimation backpropagation effect anfis model structure accuracy performance cmo inverter also investigate simulation hspice use predictive technology model ptm nominal parameter compare anfis train use analytical model result comparison anfis hspice suggest anfis modelling procedure practicality correctness finding demonstrate anfis simulation significantly fast comparable hspice simulation easily integrate software tool design simulate complicated cmos logic circuitsjatsp,0.4807692307692308,0.11538461538461539,0.09615384615384616,0.038461538461538464,104.0,2.0,0.0,0.0,1.0
Computer Engineering,Signal Processing,Quantitative,To further understand graph signals,"Graph signal processing (GSP) is a framework to analyze and process
graph-structured data. Many research works focus on developing tools such as
Graph Fourier transforms (GFT), filters, and neural network models to handle
graph signals. Such approaches have successfully taken care of ``signal
processing'' in many circumstances. In this paper, we want to put emphasis on
``graph signals'' themselves. Although there are characterizations of graph
signals using the notion of bandwidth derived from GFT, we want to argue here
that graph signals may contain hidden geometric information of the network,
independent of (graph) Fourier theories. We shall provide a framework to
understand such information, and demonstrate how new knowledge on ``graph
signals'' can help with ``signal processing''.",http://arxiv.org/abs/2203.00832v2,arXiv,far understand graph signal,graph signal processing gsp framework analyze process graphstructure datum many research work focus develop tool graph fourier transform gft filter neural network model handle graph signal approach successfully take care signal processing many circumstance paper want put emphasis graph signal although characterization graph signal use notion bandwidth derive gft want argue graph signal may contain hide geometric information network independent graph fouri theory shall provide framework understand information demonstrate new knowledge graph signal help signal processing,far understand graph signal graph signal processing gsp framework analyze process graphstructure datum many research work focus develop tool graph fourier transform gft filter neural network model handle graph signal approach successfully take care signal processing many circumstance paper want put emphasis graph signal although characterization graph signal use notion bandwidth derive gft want argue graph signal may contain hide geometric information network independent graph fouri theory shall provide framework understand information demonstrate new knowledge graph signal help signal processing,0.6052631578947368,0.15789473684210525,0.09210526315789473,0.02631578947368421,76.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Quantitative,Topological Signal Processing over Simplicial Complexes,"The goal of this paper is to establish the fundamental tools to analyze
signals defined over a topological space, i.e. a set of points along with a set
of neighborhood relations. This setup does not require the definition of a
metric and then it is especially useful to deal with signals defined over
non-metric spaces. We focus on signals defined over simplicial complexes. Graph
Signal Processing (GSP) represents a special case of Topological Signal
Processing (TSP), referring to the situation where the signals are associated
only with the vertices of a graph. Even though the theory can be applied to
signals of any order, we focus on signals defined over the edges of a graph and
show how building a simplicial complex of order two, i.e. including triangles,
yields benefits in the analysis of edge signals. After reviewing the basic
principles of algebraic topology, we derive a sampling theory for signals of
any order and emphasize the interplay between signals of different order. Then
we propose a method to infer the topology of a simplicial complex from data. We
conclude with applications to real edge signals and to the analysis of discrete
vector fields to illustrate the benefits of the proposed methodologies.",http://arxiv.org/abs/1907.11577v2,arXiv,topological signal process simplicial complex,goal paper establish fundamental tool analyze signal define topological space set point along set neighborhood relation setup require definition metric especially useful deal signal define nonmetric space focus signal define simplicial complex graph signal processing gsp represent special case topological signal processing tsp refer situation signal associate vertex graph even though theory apply signal order focus signal define edge graph show build simplicial complex order two include triangle yield benefit analysis edge signal review basic principle algebraic topology derive sampling theory signal order emphasize interplay signal different order propose method infer topology simplicial complex datum conclude application real edge signal analysis discrete vector field illustrate benefit propose methodology,topological signal process simplicial complex goal paper establish fundamental tool analyze signal define topological space set point along set neighborhood relation setup require definition metric especially useful deal signal define nonmetric space focus signal define simplicial complex graph signal processing gsp represent special case topological signal processing tsp refer situation signal associate vertex graph even though theory apply signal order focus signal define edge graph show build simplicial complex order two include triangle yield benefit analysis edge signal review basic principle algebraic topology derive sampling theory signal order emphasize interplay signal different order propose method infer topology simplicial complex datum conclude application real edge signal analysis discrete vector field illustrate benefit propose methodology,0.6203703703703703,0.1574074074074074,0.16666666666666666,0.018518518518518517,108.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Quantitative,Recovery of Graph Signals from Sign Measurements,"Sampling and interpolation have been extensively studied, in order to
reconstruct or estimate the entire graph signal from the signal values on a
subset of vertexes, of which most achievements are about continuous signals.
While in a lot of signal processing tasks, signals are not fully observed, and
only the signs of signals are available, for example a rating system may only
provide several simple options. In this paper, the reconstruction of
band-limited graph signals based on sign sampling is discussed and a greedy
sampling strategy is proposed. The simulation experiments are presented, and
the greedy sampling algorithm is compared with random sampling algorithm, which
verify the validity of the proposed approach.",http://arxiv.org/abs/2109.12576v1,arXiv,recovery graph signal sign measurement,sampling interpolation extensively study order reconstruct estimate entire graph signal signal value subset vertex achievement continuous signal lot signal processing task signal fully observe sign signal available example rating system may provide several simple option paper reconstruction bandlimite graph signal base sign sampling discuss greedy sampling strategy propose simulation experiment present greedy sampling algorithm compare random sampling algorithm verify validity propose approach,recovery graph signal sign measurement sampling interpolation extensively study order reconstruct estimate entire graph signal signal value subset vertex achievement continuous signal lot signal processing task signal fully observe sign signal available example rating system may provide several simple option paper reconstruction bandlimite graph signal base sign sampling discuss greedy sampling strategy propose simulation experiment present greedy sampling algorithm compare random sampling algorithm verify validity propose approach,0.5483870967741935,0.1774193548387097,0.14516129032258066,0.03225806451612903,62.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Quantitative,Fast and Accurate Amplitude Demodulation of Wideband Signals,"Amplitude demodulation is a classical operation used in signal processing.
For a long time, its effective applications in practice have been limited to
narrowband signals. In this work, we generalize amplitude demodulation to
wideband signals. We pose demodulation as a recovery problem of an oversampled
corrupted signal and introduce special iterative schemes belonging to the
family of alternating projection algorithms to solve it. Sensibly chosen
structural assumptions on the demodulation outputs allow us to reveal the high
inferential accuracy of the method over a rich set of relevant signals. This
new approach surpasses current state-of-the-art demodulation techniques apt to
wideband signals in computational efficiency by up to many orders of magnitude
with no sacrifice in quality. Such performance opens the door for applications
of the amplitude demodulation procedure in new contexts. In particular, the new
method makes online and large-scale offline data processing feasible, including
the calculation of modulator-carrier pairs in higher dimensions and poor
sampling conditions, independent of the signal bandwidth. We illustrate the
utility and specifics of applications of the new method in practice by using
natural speech and synthetic signals.",http://arxiv.org/abs/2102.04832v2,arXiv,fast accurate amplitude demodulation wideband signal,amplitude demodulation classical operation use signal processing long time effective application practice limit narrowband signal work generalize amplitude demodulation wideband signal pose demodulation recovery problem oversample corrupt signal introduce special iterative scheme belong family alternate projection algorithm solve sensibly choose structural assumption demodulation output allow reveal high inferential accuracy method rich set relevant signal new approach surpass current stateoftheart demodulation technique apt wideband signal computational efficiency many order magnitude sacrifice quality performance open door application amplitude demodulation procedure new context particular new method make online largescale offline datum processing feasible include calculation modulatorcarri pair high dimension poor sampling condition independent signal bandwidth illustrate utility specific application new method practice use natural speech synthetic signal,fast accurate amplitude demodulation wideband signal amplitude demodulation classical operation use signal processing long time effective application practice limit narrowband signal work generalize amplitude demodulation wideband signal pose demodulation recovery problem oversample corrupt signal introduce special iterative scheme belong family alternate projection algorithm solve sensibly choose structural assumption demodulation output allow reveal high inferential accuracy method rich set relevant signal new approach surpass current stateoftheart demodulation technique apt wideband signal computational efficiency many order magnitude sacrifice quality performance open door application amplitude demodulation procedure new context particular new method make online largescale offline datum processing feasible include calculation modulatorcarri pair high dimension poor sampling condition independent signal bandwidth illustrate utility specific application new method practice use natural speech synthetic signal,0.5263157894736842,0.12280701754385964,0.30701754385964913,0.017543859649122806,114.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Quantitative,Parametric Modeling of Non-Stationary Signals,"Parametric modeling of non-stationary signals is addressed in this article.
We present several models based on the characteristic features of the modeled
signal, together with the methods for accurate estimation of model parameters.
Non-stationary signals, viz. transient system response, speech phonemes, and
electrocardiograph signal are fitted by these feature-based models.",http://arxiv.org/abs/1801.09045v1,arXiv,parametric modeling nonstationary signal,parametric modeling nonstationary signal address article present several model base characteristic feature model signal together method accurate estimation model parameter nonstationary signal viz transient system response speech phoneme electrocardiograph signal fit featurebase model,parametric modeling nonstationary signal parametric modeling nonstationary signal address article present several model base characteristic feature model signal together method accurate estimation model parameter nonstationary signal viz transient system response speech phoneme electrocardiograph signal fit featurebase model,0.42424242424242425,0.12121212121212122,0.18181818181818182,0.030303030303030304,33.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Qualitative,Tensor Low Rank Modeling and Its Applications in Signal Processing,"Modeling of multidimensional signal using tensor is more convincing than
representing it as a collection of matrices. The tensor based approaches can
explore the abundant spatial and temporal structures of the mutlidimensional
signal. The backbone of this modeling is the mathematical foundations of tensor
algebra. The linear transform based tensor algebra furnishes low complex and
high performance algebraic structures suitable for the introspection of the
multidimensional signal. A comprehensive introduction of the linear transform
based tensor algebra is provided from the signal processing viewpoint. The rank
of a multidimensional signal is a precious property which gives an insight into
the structural aspects of it. All natural multidimensional signals can be
approximated to a low rank signal without losing significant information. The
low rank approximation is beneficial in many signal processing applications
such as denoising, missing sample estimation, resolution enhancement,
classification, background estimation, object detection, deweathering,
clustering and much more applications. Detailed case study of the ways and
means of the low rank modeling in the above said signal processing applications
are also presented.",http://arxiv.org/abs/1912.03435v1,arXiv,tensor low rank modeling application signal processing,modeling multidimensional signal use tensor convincing represent collection matrix tensor base approach explore abundant spatial temporal structure mutlidimensional signal backbone modeling mathematical foundation tensor algebra linear transform base tensor algebra furnish low complex high performance algebraic structure suitable introspection multidimensional signal comprehensive introduction linear transform base tensor algebra provide signal processing viewpoint rank multidimensional signal precious property give insight structural aspect natural multidimensional signal approximate low rank signal without lose significant information low rank approximation beneficial many signal processing application denoise miss sample estimation resolution enhancement classification background estimation object detection deweathering clustering much application detailed case study way mean low rank modeling say signal processing application also present,tensor low rank modeling application signal processing modeling multidimensional signal use tensor convincing represent collection matrix tensor base approach explore abundant spatial temporal structure mutlidimensional signal backbone modeling mathematical foundation tensor algebra linear transform base tensor algebra furnish low complex high performance algebraic structure suitable introspection multidimensional signal comprehensive introduction linear transform base tensor algebra provide signal processing viewpoint rank multidimensional signal precious property give insight structural aspect natural multidimensional signal approximate low rank signal without lose significant information low rank approximation beneficial many signal processing application denoise miss sample estimation resolution enhancement classification background estimation object detection deweathering clustering much application detailed case study way mean low rank modeling say signal processing application also present,0.4954128440366973,0.11926605504587157,0.26605504587155965,0.009174311926605505,109.0,0.0,0.0,0.0,1.0
Computer Engineering,Signal Processing,Qualitative,Defining Fundamental Frequency for Almost Harmonic Signals,"In this work, we consider the modeling of signals that are almost, but not
quite, harmonic, i.e., composed of sinusoids whose frequencies are close to
being integer multiples of a common frequency. Typically, in applications, such
signals are treated as perfectly harmonic, allowing for the estimation of their
fundamental frequency, despite the signals not actually being periodic. Herein,
we provide three different definitions of a concept of fundamental frequency
for such inharmonic signals and study the implications of the different choices
for modeling and estimation. We show that one of the definitions corresponds to
a misspecified modeling scenario, and provides a theoretical benchmark for
analyzing the behavior of estimators derived under a perfectly harmonic
assumption. The second definition stems from optimal mass transport theory and
yields a robust and easily interpretable concept of fundamental frequency based
on the signals' spectral properties. The third definition interprets the
inharmonic signal as an observation of a randomly perturbed harmonic signal.
This allows for computing a hybrid information theoretical bound on estimation
performance, as well as for finding an estimator attaining the bound. The
theoretical findings are illustrated using numerical examples.",http://arxiv.org/abs/2003.10767v2,arXiv,define fundamental frequency almost harmonic signal,work consider modeling signal almost quite harmonic compose sinusoid whose frequency close integer multiple common frequency typically application signal treat perfectly harmonic allowing estimation fundamental frequency despite signal actually periodic herein provide three different definition concept fundamental frequency inharmonic signal study implication different choice modeling estimation show one definition correspond misspecifie modeling scenario provide theoretical benchmark analyze behavior estimator derive perfectly harmonic assumption second definition stem optimal mass transport theory yield robust easily interpretable concept fundamental frequency base signal spectral property third definition interpret inharmonic signal observation randomly perturb harmonic signal allow compute hybrid information theoretical bind estimation performance well find estimator attain bind theoretical finding illustrate use numerical example,define fundamental frequency almost harmonic signal work consider modeling signal almost quite harmonic compose sinusoid whose frequency close integer multiple common frequency typically application signal treat perfectly harmonic allowing estimation fundamental frequency despite signal actually periodic herein provide three different definition concept fundamental frequency inharmonic signal study implication different choice modeling estimation show one definition correspond misspecifie modeling scenario provide theoretical benchmark analyze behavior estimator derive perfectly harmonic assumption second definition stem optimal mass transport theory yield robust easily interpretable concept fundamental frequency base signal spectral property third definition interpret inharmonic signal observation randomly perturb harmonic signal allow compute hybrid information theoretical bind estimation performance well find estimator attain bind theoretical finding illustrate use numerical example,0.5272727272727272,0.1,0.2545454545454545,0.08181818181818182,110.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Qualitative,"Hilbert Transform, Analytic Signal, and Modulation Analysis for Graph
  Signal Processing","We propose Hilbert transform (HT) and analytic signal (AS) construction for
signals over graphs. This is motivated by the popularity of HT, AS, and
modulation analysis in conventional signal processing, and the observation that
complementary insight is often obtained by viewing conventional signals in the
graph setting. Our definitions of HT and AS use a conjugate-symmetry-like
property exhibited by the graph Fourier transform (GFT). We show that a real
graph signal (GS) can be represented using smaller number of GFT coefficients
than the signal length. We show that the graph HT (GHT) and graph AS (GAS)
operations are linear and shift-invariant over graphs. Using the GAS, we define
the amplitude, phase, and frequency modulations for a graph signal (GS).
Further, we use convex optimization to develop an alternative definition of
envelope for a GS. We illustrate the proposed concepts by showing applications
to synthesized and real-world signals. For example, we show that the GHT is
suitable for anomaly detection/analysis over networks and that GAS reveals
complementary information in speech signals.",http://arxiv.org/abs/1611.05269v3,arXiv,hilbert transform analytic signal modulation analysis graph signal processing,propose hilbert transform analytic signal construction signal graph motivate popularity modulation analysis conventional signal processing observation complementary insight often obtain view conventional signal graph set definition use conjugatesymmetrylike property exhibit graph fouri transform gft show real graph signal represent use small number gft coefficient signal length show graph ght graph gas operation linear shiftinvariant graph use gas define amplitude phase frequency modulation graph signal far use convex optimization develop alternative definition envelope illustrate propose concept show application synthesized realworld signal example show ght suitable anomaly detectionanalysis network gas reveal complementary information speech signal,hilbert transform analytic signal modulation analysis graph signal processing propose hilbert transform analytic signal construction signal graph motivate popularity modulation analysis conventional signal processing observation complementary insight often obtain view conventional signal graph set definition use conjugatesymmetrylike property exhibit graph fouri transform gft show real graph signal represent use small number gft coefficient signal length show graph ght graph gas operation linear shiftinvariant graph use gas define amplitude phase frequency modulation graph signal far use convex optimization develop alternative definition envelope illustrate propose concept show application synthesized realworld signal example show ght suitable anomaly detectionanalysis network gas reveal complementary information speech signal,0.6344086021505376,0.11827956989247312,0.12903225806451613,0.021505376344086023,93.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Qualitative,An interstellar communication method: system design and observations,"A system of synchronized radio telescopes is utilized to search for
hypothetical wide bandwidth interstellar communication signals. Transmitted
signals are hypothesized to have characteristics that enable high channel
capacity and minimally low energy per information bit, while containing
energy-efficient signal elements that are readily discoverable, distinct from
random noise. A hypothesized transmitter signal is described. Signal reception
and discovery processes are detailed. Observations using individual and
multiple synchronized radio telescopes, during 2017 - 2021, are described.
Conclusions and further work are suggested.",http://arxiv.org/abs/2105.03727v2,arXiv,interstellar communication method system design observation,system synchronize radio telescope utilize search hypothetical wide bandwidth interstellar communication signal transmit signal hypothesize characteristic enable high channel capacity minimally low energy per information bit contain energyefficient signal element readily discoverable distinct random noise hypothesize transmitter signal describe signal reception discovery process detailed observation use individual multiple synchronized radio telescope describe conclusion work suggest,interstellar communication method system design observation system synchronize radio telescope utilize search hypothetical wide bandwidth interstellar communication signal transmit signal hypothesize characteristic enable high channel capacity minimally low energy per information bit contain energyefficient signal element readily discoverable distinct random noise hypothesize transmitter signal describe signal reception discovery process detailed observation use individual multiple synchronized radio telescope describe conclusion work suggest,0.4727272727272727,0.14545454545454545,0.23636363636363636,0.03636363636363636,55.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Qualitative,Blind Deconvolution of Graph Signals: Robustness to Graph Perturbations,"We study blind deconvolution of signals defined on the nodes of an undirected
graph. Although observations are bilinear functions of both unknowns, namely
the forward convolutional filter coefficients and the graph signal input, a
filter invertibility requirement along with input sparsity allow for an
efficient linear programming reformulation. Unlike prior art that relied on
perfect knowledge of the graph eigenbasis, here we derive stable recovery
conditions in the presence of small graph perturbations. We also contribute a
provably convergent robust algorithm, which alternates between blind
deconvolution of graph signals and eigenbasis denoising in the Stiefel
manifold. Reproducible numerical tests showcase the algorithm's robustness
under several graph eigenbasis perturbation models.",http://arxiv.org/abs/2412.15133v1,arXiv,blind deconvolution graph signal robustness graph perturbation,study blind deconvolution signal define node undirected graph although observation bilinear function unknown namely forward convolutional filter coefficient graph signal input filter invertibility requirement along input sparsity allow efficient linear programming reformulation unlike prior art rely perfect knowledge graph eigenbasis derive stable recovery condition presence small graph perturbation also contribute provably convergent robust algorithm alternate blind deconvolution graph signal eigenbasis denoise stiefel manifold reproducible numerical test showcase algorithms robustness several graph eigenbasis perturbation model,blind deconvolution graph signal robustness graph perturbation study blind deconvolution signal define node undirected graph although observation bilinear function unknown namely forward convolutional filter coefficient graph signal input filter invertibility requirement along input sparsity allow efficient linear programming reformulation unlike prior art rely perfect knowledge graph eigenbasis derive stable recovery condition presence small graph perturbation also contribute provably convergent robust algorithm alternate blind deconvolution graph signal eigenbasis denoise stiefel manifold reproducible numerical test showcase algorithms robustness several graph eigenbasis perturbation model,0.5405405405405406,0.10810810810810811,0.25675675675675674,0.04054054054054054,74.0,1.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Mixed Methods,"Teaching Digital Signal Processing by Partial Flipping, Active Learning
  and Visualization","Effectiveness of teaching digital signal processing can be enhanced by
reducing lecture time devoted to theory, and increasing emphasis on
applications, programming aspects, visualization and intuitive understanding.
An integrated approach to teaching requires instructors to simultaneously teach
theory and its applications in storage and processing of audio, speech and
biomedical signals. Student engagement can be enhanced by engaging students to
work in groups during the class where students can solve short problems and
short programming assignments or take quizzes. These approaches will increase
student interest in learning the subject and student engagement.",http://arxiv.org/abs/2102.00561v1,arXiv,teach digital signal processing partial flip active learning visualization,effectiveness teach digital signal processing enhance reduce lecture time devote theory increase emphasis application programming aspect visualization intuitive understanding integrated approach teaching require instructor simultaneously teach theory application storage processing audio speech biomedical signal student engagement enhance engage student work group class student solve short problem short programming assignment take quiz approach increase student interest learn subject student engagement,teach digital signal processing partial flip active learning visualization effectiveness teach digital signal processing enhance reduce lecture time devote theory increase emphasis application programming aspect visualization intuitive understanding integrated approach teaching require instructor simultaneously teach theory application storage processing audio speech biomedical signal student engagement enhance engage student work group class student solve short problem short programming assignment take quiz approach increase student interest learn subject student engagement,0.711864406779661,0.1864406779661017,0.06779661016949153,0.01694915254237288,59.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Mixed Methods,Signal Processing on Directed Graphs,"This paper provides an overview of the current landscape of signal processing
(SP) on directed graphs (digraphs). Directionality is inherent to many
real-world (information, transportation, biological) networks and it should
play an integral role in processing and learning from network data. We thus lay
out a comprehensive review of recent advances in SP on digraphs, offering
insights through comparisons with results available for undirected graphs,
discussing emerging directions, establishing links with related areas in
machine learning and causal inference in statistics, as well as illustrating
their practical relevance to timely applications. To this end, we begin by
surveying (orthonormal) signal representations and their graph frequency
interpretations based on novel measures of signal variation for digraphs. We
then move on to filtering, a central component in deriving a comprehensive
theory of SP on digraphs. Indeed, through the lens of filter-based generative
signal models, we explore a unified framework to study inverse problems (e.g.,
sampling and deconvolution on networks), statistical analysis of random
signals, and topology inference of digraphs from nodal observations.",http://arxiv.org/abs/2008.00586v1,arXiv,signal processing direct graph,paper provide overview current landscape signal processing direct graph digraph directionality inherent many realworld information transportation biological network play integral role processing learning network datum thus lay comprehensive review recent advance digraph offering insight comparison result available undirected graph discuss emerge direction establish link related area machine learning causal inference statistic well illustrate practical relevance timely application end begin survey orthonormal signal representation graph frequency interpretation base novel measure signal variation digraph move filter central component derive comprehensive theory digraph indeed lens filterbased generative signal model explore unified framework study inverse problem sampling deconvolution network statistical analysis random signal topology inference digraph nodal observation,signal processing direct graph paper provide overview current landscape signal processing direct graph digraph directionality inherent many realworld information transportation biological network play integral role processing learning network datum thus lay comprehensive review recent advance digraph offering insight comparison result available undirected graph discuss emerge direction establish link related area machine learning causal inference statistic well illustrate practical relevance timely application end begin survey orthonormal signal representation graph frequency interpretation base novel measure signal variation digraph move filter central component derive comprehensive theory digraph indeed lens filterbased generative signal model explore unified framework study inverse problem sampling deconvolution network statistical analysis random signal topology inference digraph nodal observation,0.5673076923076923,0.15384615384615385,0.20192307692307693,0.028846153846153848,104.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Mixed Methods,"Unique Bispectrum Inversion for Signals with Finite Spectral/Temporal
  Support","Retrieving a signal from its triple correlation spectrum, also called
bispectrum, arises in a wide range of signal processing problems. Conventional
methods do not provide an accurate inversion of bispectrum to the underlying
signal. In this paper, we present an approach that uniquely recovers signals
with finite spectral support (band-limited signals) from at least $3B$
measurements of its bispectrum function (BF), where $B$ is the signal's
bandwidth. Our approach also extends to time-limited signals. We propose a
two-step trust region algorithm that minimizes a non-convex objective function.
First, we approximate the signal by a spectral algorithm and then refine the
attained initialization based on a sequence of gradient iterations. Numerical
experiments suggest that our proposed algorithm is able to estimate
band-/time-limited signals from its BF for both complete and undersampled
observations.",http://arxiv.org/abs/2111.06479v3,arXiv,unique bispectrum inversion signal finite spectraltemporal support,retrieve signal triple correlation spectrum also call bispectrum arise wide range signal processing problem conventional method provide accurate inversion bispectrum underlie signal paper present approach uniquely recover signal finite spectral support bandlimite signal least measurement bispectrum function signal bandwidth approach also extend timelimite signal propose twostep trust region algorithm minimize nonconvex objective function first approximate signal spectral algorithm refine attain initialization base sequence gradient iteration numerical experiment suggest propose algorithm able estimate bandtimelimite signal complete undersampled observation,unique bispectrum inversion signal finite spectraltemporal support retrieve signal triple correlation spectrum also call bispectrum arise wide range signal processing problem conventional method provide accurate inversion bispectrum underlie signal paper present approach uniquely recover signal finite spectral support bandlimite signal least measurement bispectrum function signal bandwidth approach also extend timelimite signal propose twostep trust region algorithm minimize nonconvex objective function first approximate signal spectral algorithm refine attain initialization base sequence gradient iteration numerical experiment suggest propose algorithm able estimate bandtimelimite signal complete undersampled observation,0.4155844155844156,0.14285714285714285,0.18181818181818182,0.05194805194805195,77.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Mixed Methods,A Geometric Algebra Framework for a Multidimensional Analytic Signal,"This work examines the problem of extending the one-dimensional analytic
signal, which is ubiquitous throughout signal processing, to higher dimensional
signals. Bulow et al. and Felsberg et al. have previously used techniques from
Clifford algebra and analysis to extend the one-dimensional analytic signal to
higher dimensions. However, each author sets forth a different definition of a
multidimensional analytic signal. Herein we follow an observation of Brackx et
al. and adopt a general definition of an analytic signal that encompasses both
the hypercomplex signal of Bulow et al. and the monogenic signal of Felsberg et
al. within the same mathematical framework. The crux of our approach is
captured by the following statement: A multidimensional analytic signal is
generated by an idempotent. We develop this notion more specifically using
examples from geometric algebra.",http://arxiv.org/abs/2411.10412v1,arXiv,geometric algebra framework multidimensional analytic signal,work examine problem extend onedimensional analytic signal ubiquitous throughout signal processing high dimensional signal bulow felsberg previously use technique clifford algebra analysis extend onedimensional analytic signal high dimension however author set forth different definition multidimensional analytic signal herein follow observation brackx adopt general definition analytic signal encompass hypercomplex signal bulow monogenic signal felsberg within mathematical framework crux approach capture follow statement multidimensional analytic signal generate idempotent develop notion specifically use example geometric algebra,geometric algebra framework multidimensional analytic signal work examine problem extend onedimensional analytic signal ubiquitous throughout signal processing high dimensional signal bulow felsberg previously use technique clifford algebra analysis extend onedimensional analytic signal high dimension however author set forth different definition multidimensional analytic signal herein follow observation brackx adopt general definition analytic signal encompass hypercomplex signal bulow monogenic signal felsberg within mathematical framework crux approach capture follow statement multidimensional analytic signal generate idempotent develop notion specifically use example geometric algebra,0.4931506849315068,0.136986301369863,0.2328767123287671,0.0410958904109589,73.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Mixed Methods,"3-D generalized analytic signal associated with linear canonical
  transform in Clifford biquaternion domain","The analytic signal is a useful mathematical tool. It separates qualitative
and quantitative information of a signal in form of the local phase and local
amplitude. The Clifford Fourier transform (CFT) plays a vital role in the
representation of multidimensional signals. By generalizing the CFT to the
Clifford linear canonical transform (CLCT), we present a new type of Clifford
biquaternionic analytic signal. Due to the advantages of more freedom, the
envelop detection problems of 3D images, with the help of this new analytic
signal, can get a better visual appearance. Synthesis examples are presented to
demonstrate these advantages.",http://arxiv.org/abs/2204.12787v1,arXiv,generalize analytic signal associate linear canonical transform clifford biquaternion domain,analytic signal useful mathematical tool separate qualitative quantitative information signal form local phase local amplitude clifford fouri transform cft play vital role representation multidimensional signal generalize cft clifford linear canonical transform clct present new type clifford biquaternionic analytic signal due advantage freedom envelop detection problem image help new analytic signal get well visual appearance synthesis example present demonstrate advantage,generalize analytic signal associate linear canonical transform clifford biquaternion domain analytic signal useful mathematical tool separate qualitative quantitative information signal form local phase local amplitude clifford fouri transform cft play vital role representation multidimensional signal generalize cft clifford linear canonical transform clct present new type clifford biquaternionic analytic signal due advantage freedom envelop detection problem image help new analytic signal get well visual appearance synthesis example present demonstrate advantage,0.4406779661016949,0.06779661016949153,0.2711864406779661,0.01694915254237288,59.0,1.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Design and Development,Graph signal processing with categorical perspective,"In this paper, we propose a framework for graph signal processing using
category theory. The aim is to generalize a few recent works on probabilistic
approaches to graph signal processing, which handle signal and graph
uncertainties.",http://arxiv.org/abs/2302.12421v1,arXiv,graph signal processing categorical perspective,paper propose framework graph signal processing use category theory aim generalize recent work probabilistic approach graph signal processing handle signal graph uncertainty,graph signal processing categorical perspective paper propose framework graph signal processing use category theory aim generalize recent work probabilistic approach graph signal processing handle signal graph uncertainty,0.8181818181818182,0.045454545454545456,0.09090909090909091,0.0,22.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Design and Development,Signal Transformation for Effective Multi-Channel Signal Processing,"Electroencephalography (EEG) is an non-invasive method to record the
electrical activity of the brain. The EEG signals are low bandwidth and
recorded from multiple electrodes simultaneously in a time synchronized manner.
Typical EEG signal processing involves extracting features from all the
individual channels separately and then fusing these features for downstream
applications. In this paper, we propose a signal transformation, using basic
signal processing, to combine the individual channels of a low-bandwidth
signal, like the EEG into a single-channel high-bandwidth signal, like audio.
Further this signal transformation is bi-directional, namely the high-bandwidth
single-channel can be transformed to generate the individual low-bandwidth
signals without any loss of information. Such a transformation when applied to
EEG signals overcomes the need to process multiple signals and allows for a
single-channel processing. The advantage of this signal transformation is that
it allows the use of pre-trained single-channel pre-trained models, for
multi-channel signal processing and analysis. We further show the utility of
the signal transformation on publicly available EEG dataset.",http://arxiv.org/abs/2412.17478v1,arXiv,signal transformation effective multichannel signal processing,electroencephalography eeg noninvasive method record electrical activity brain eeg signal low bandwidth record multiple electrode simultaneously time synchronize manner typical eeg signal processing involve extract feature individual channel separately fuse feature downstream application paper propose signal transformation use basic signal processing combine individual channel lowbandwidth signal like eeg singlechannel highbandwidth signal like audio far signal transformation bidirectional namely highbandwidth singlechannel transform generate individual lowbandwidth signal without loss information transformation apply eeg signal overcome need process multiple signal allow singlechannel process advantage signal transformation allow use pretraine singlechannel pretraine model multichannel signal processing analysis far show utility signal transformation publicly available eeg dataset,signal transformation effective multichannel signal processing electroencephalography eeg noninvasive method record electrical activity brain eeg signal low bandwidth record multiple electrode simultaneously time synchronize manner typical eeg signal processing involve extract feature individual channel separately fuse feature downstream application paper propose signal transformation use basic signal processing combine individual channel lowbandwidth signal like eeg singlechannel highbandwidth signal like audio far signal transformation bidirectional namely highbandwidth singlechannel transform generate individual lowbandwidth signal without loss information transformation apply eeg signal overcome need process multiple signal allow singlechannel process advantage signal transformation allow use pretraine singlechannel pretraine model multichannel signal processing analysis far show utility signal transformation publicly available eeg dataset,0.5588235294117647,0.11764705882352941,0.13725490196078433,0.06862745098039216,102.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Design and Development,"Towards Goal-Oriented Semantic Signal Processing: Applications and
  Future Challenges","Advances in machine learning technology have enabled real-time extraction of
semantic information in signals which can revolutionize signal processing
techniques and improve their performance significantly for the next generation
of applications. With the objective of a concrete representation and efficient
processing of the semantic information, we propose and demonstrate a formal
graph-based semantic language and a goal filtering method that enables
goal-oriented signal processing. The proposed semantic signal processing
framework can easily be tailored for specific applications and goals in a
diverse range of signal processing applications. To illustrate its wide range
of applicability, we investigate several use cases and provide details on how
the proposed goal-oriented semantic signal processing framework can be
customized. We also investigate and propose techniques for communications where
sensor data is semantically processed and semantic information is exchanged
across a sensor network.",http://arxiv.org/abs/2109.11885v1,arXiv,towards goaloriente semantic signal processing application future challenge,advance machine learning technology enable realtime extraction semantic information signal revolutionize signal processing technique improve performance significantly next generation application objective concrete representation efficient processing semantic information propose demonstrate formal graphbased semantic language goal filtering method enable goaloriente signal process propose semantic signal processing framework easily tailor specific application goal diverse range signal processing application illustrate wide range applicability investigate several use case provide detail propose goaloriente semantic signal processing framework customize also investigate propose technique communication sensor datum semantically process semantic information exchange across sensor network,towards goaloriente semantic signal processing application future challenge advance machine learning technology enable realtime extraction semantic information signal revolutionize signal processing technique improve performance significantly next generation application objective concrete representation efficient processing semantic information propose demonstrate formal graphbased semantic language goal filtering method enable goaloriente signal process propose semantic signal processing framework easily tailor specific application goal diverse range signal processing application illustrate wide range applicability investigate several use case provide detail propose goaloriente semantic signal processing framework customize also investigate propose technique communication sensor datum semantically process semantic information exchange across sensor network,0.5632183908045977,0.16091954022988506,0.1839080459770115,0.04597701149425287,87.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Design and Development,"Signal denoising based on the Schrödinger operator's eigenspectrum and
  a curvature constraint","Recently, a new Signal processing method, named Semi-Classical Signal
Analysis (SCSA), has been proposed for denoising Magnetic Resonance
Spectroscopy (MRS) signals. It is based on the Schr\""odinger Operator's
eigenspectrum. It allows an efficient noise reduction while preserving MRS
signal's peaks. In this paper, we propose to extend this approach to different
signals, in particular pulse shaped signals, by including an optimization that
considers curvature constraints. The performance of the method is measured by
analyzing noisy signal data and comparing with other denoising methods. Results
indicate that the proposed method not only produces good denoising performance
but also guarantees the peaks are well preserved in the denoising process.",http://arxiv.org/abs/1908.07758v1,arXiv,signal denoising base schrödinger operator eigenspectrum curvature constraint,recently new signal processing method name semiclassical signal analysis scsa propose denoise magnetic resonance spectroscopy mrs signal base schrodinger operator eigenspectrum allow efficient noise reduction preserve mrs signal peak paper propose extend approach different signal particular pulse shape signal include optimization consider curvature constraint performance method measure analyze noisy signal datum compare denoising method result indicate propose method produce good denoising performance also guarantee peak well preserve denoising process,signal denoising base schrödinger operator eigenspectrum curvature constraint recently new signal processing method name semiclassical signal analysis scsa propose denoise magnetic resonance spectroscopy mrs signal base schrodinger operator eigenspectrum allow efficient noise reduction preserve mrs signal peak paper propose extend approach different signal particular pulse shape signal include optimization consider curvature constraint performance method measure analyze noisy signal datum compare denoising method result indicate propose method produce good denoising performance also guarantee peak well preserve denoising process,0.5507246376811594,0.14492753623188406,0.15942028985507245,0.043478260869565216,69.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Design and Development,Number Theoretic Transforms for Secure Signal Processing,"Multimedia contents are inherently sensitive signals that must be protected
whenever they are outsourced to an untrusted environment. This problem becomes
a challenge when the untrusted environment must perform some processing on the
sensitive signals; a paradigmatic example is Cloud-based signal processing
services. Approaches based on Secure Signal Processing (SSP) address this
challenge by proposing novel mechanisms for signal processing in the encrypted
domain and interactive secure protocols to achieve the goal of protecting
signals without disclosing the sensitive information they convey.
  This work presents a novel and comprehensive set of approaches and primitives
to efficiently process signals in an encrypted form, by using Number Theoretic
Transforms (NTTs) in innovative ways. This usage of NTTs paired with
appropriate signal pre- and post-coding enables a whole range of easily
composable signal processing operations comprising, among others, filtering,
generalized convolutions, matrix-based processing or error correcting codes.
The main focus is on unattended processing, in which no interaction from the
client is needed; for implementation purposes, efficient lattice-based somewhat
homomorphic cryptosystems are used. We exemplify these approaches and evaluate
their performance and accuracy, proving that the proposed framework opens up a
wide variety of new applications for secured outsourced-processing of
multimedia contents.",http://arxiv.org/abs/1607.05229v2,arXiv,number theoretic transform secure signal processing,multimedia content inherently sensitive signal must protect whenever outsource untrusted environment problem become challenge untrusted environment must perform processing sensitive signal paradigmatic example cloudbase signal processing service approach base secure signal processing ssp address challenge propose novel mechanism signal processing encrypt domain interactive secure protocol achieve goal protect signal without disclose sensitive information convey work present novel comprehensive set approach primitive efficiently process signal encrypt form use number theoretic transform ntt innovative way usage ntt pair appropriate signal pre postcoding enable whole range easily composable signal processing operation comprise among filter generalize convolution matrixbase processing error correcting code main focus unattended processing interaction client need implementation purpose efficient latticebase somewhat homomorphic cryptosystem use exemplify approach evaluate performance accuracy prove propose framework open wide variety new application secured outsourcedprocessing multimedia content,number theoretic transform secure signal processing multimedia content inherently sensitive signal must protect whenever outsource untrusted environment problem become challenge untrusted environment must perform processing sensitive signal paradigmatic example cloudbase signal processing service approach base secure signal processing ssp address challenge propose novel mechanism signal processing encrypt domain interactive secure protocol achieve goal protect signal without disclose sensitive information convey work present novel comprehensive set approach primitive efficiently process signal encrypt form use number theoretic transform ntt innovative way usage ntt pair appropriate signal pre postcoding enable whole range easily composable signal processing operation comprise among filter generalize convolution matrixbase processing error correcting code main focus unattended processing interaction client need implementation purpose efficient latticebase somewhat homomorphic cryptosystem use exemplify approach evaluate performance accuracy prove propose framework open wide variety new application secured outsourcedprocessing multimedia content,0.5615384615384615,0.14615384615384616,0.2076923076923077,0.038461538461538464,130.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Theoretical / Conceptual,"The performance of microwave photonic signal processors based on
  microcombs with different input signal waveforms","Microwave photonic (MWP) signal processors, which process microwave signals
based on pho-tonic technologies, bring advantages intrinsic to photonics such
as low loss, large processing bandwidth, and strong immunity to electromagnetic
interference. Optical microcombs can offer a large number of wavelength
channels and compact device footprints, which make them powerful
multi-wavelength sources for MWP signal processors to realize a variety of
processing functions. In this paper, we experimentally demonstrate the
capability of microcomb-based MWP signal processors to handle diverse input
signal waveforms. In addition, we quantify the processing accuracy for
different input signal waveforms, including Gaussian, triangle, parabolic,
super Gaussian, and nearly square waveforms. Finally, we analyze the factors
contributing to the dif-ference in the processing accuracy among the different
input waveforms, and our theoretical analysis well elucidates the experimental
results. These results provide a guidance for micro-comb-based MWP signal
processors when processing microwave signals of various waveforms.",http://arxiv.org/abs/2403.12978v1,arXiv,performance microwave photonic signal processor base microcomb different input signal waveform,microwave photonic mwp signal processor process microwave signal base photonic technology bring advantage intrinsic photonic low loss large processing bandwidth strong immunity electromagnetic interference optical microcomb offer large number wavelength channel compact device footprint make powerful multiwavelength source mwp signal processor realize variety processing function paper experimentally demonstrate capability microcombbased mwp signal processor handle diverse input signal waveform addition quantify processing accuracy different input signal waveform include gaussian triangle parabolic super gaussian nearly square waveform finally analyze factor contribute difference processing accuracy among different input waveform theoretical analysis well elucidate experimental result result provide guidance microcombbased mwp signal processor process microwave signal various waveform,performance microwave photonic signal processor base microcomb different input signal waveform microwave photonic mwp signal processor process microwave signal base photonic technology bring advantage intrinsic photonic low loss large processing bandwidth strong immunity electromagnetic interference optical microcomb offer large number wavelength channel compact device footprint make powerful multiwavelength source mwp signal processor realize variety processing function paper experimentally demonstrate capability microcombbased mwp signal processor handle diverse input signal waveform addition quantify processing accuracy different input signal waveform include gaussian triangle parabolic super gaussian nearly square waveform finally analyze factor contribute difference processing accuracy among different input waveform theoretical analysis well elucidate experimental result result provide guidance microcombbased mwp signal processor process microwave signal various waveform,0.5480769230769231,0.125,0.21153846153846154,0.057692307692307696,104.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Theoretical / Conceptual,"Theory for the Accuracy of Microcomb Photonic Microwave Transversal
  Signal Processors","Photonic RF transversal signal processors, which are equivalent to
reconfigurable electrical digital signal processors but implemented with
photonic technologies, have been widely used for modern high-speed information
processing. With the capability of generating large numbers of wavelength
channels with compact micro-resonators, optical microcombs bring new
opportunities for realizing photonic RF transversal signal processors that have
greatly reduced size, power consumption, and complexity. Recently, a variety of
signal processing functions have been demonstrated using microcomb-based
photonic RF transversal signal processors. Here, we provide detailed analysis
for quantifying the processing accuracy of microcomb-based photonic RF
transversal signal processors. First, we investigate the theoretical
limitations of the processing accuracy determined by tap number, signal
bandwidth, and pulse waveform. Next, we discuss the practical error sources
from different components of the signal processors. Finally, we analyze the
contributions of the theoretical limitations and the experimental factors to
the overall processing inaccuracy both theoretically and experimentally. These
results provide a useful guide for designing microcomb-based photonic RF
transversal signal processors to optimize their accuracy.",http://arxiv.org/abs/2304.04130v1,arXiv,theory accuracy microcomb photonic microwave transversal signal processor,photonic transversal signal processor equivalent reconfigurable electrical digital signal processor implement photonic technology widely use modern highspeed information processing capability generate large number wavelength channel compact microresonator optical microcomb bring new opportunity realize photonic transversal signal processor greatly reduce size power consumption complexity recently variety signal processing function demonstrate use microcombbased photonic transversal signal processor provide detailed analysis quantify processing accuracy microcombbase photonic transversal signal processor first investigate theoretical limitation processing accuracy determine tap number signal bandwidth pulse waveform next discuss practical error source different component signal processor finally analyze contribution theoretical limitation experimental factor overall processing inaccuracy theoretically experimentally result provide useful guide design microcombbase photonic transversal signal processor optimize accuracy,theory accuracy microcomb photonic microwave transversal signal processor photonic transversal signal processor equivalent reconfigurable electrical digital signal processor implement photonic technology widely use modern highspeed information processing capability generate large number wavelength channel compact microresonator optical microcomb bring new opportunity realize photonic transversal signal processor greatly reduce size power consumption complexity recently variety signal processing function demonstrate use microcombbased photonic transversal signal processor provide detailed analysis quantify processing accuracy microcombbase photonic transversal signal processor first investigate theoretical limitation processing accuracy determine tap number signal bandwidth pulse waveform next discuss practical error source different component signal processor finally analyze contribution theoretical limitation experimental factor overall processing inaccuracy theoretically experimentally result provide useful guide design microcombbase photonic transversal signal processor optimize accuracy,0.5892857142857143,0.13392857142857142,0.20535714285714285,0.07142857142857142,112.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Theoretical / Conceptual,Modelling Underwater Acoustic Propagation using One-way Wave Equations,"The primary contribution of this paper is to characterize the propagation of
acoustic signal carrying information through any medium and the interaction of
the travelling acoustic signal with the surrounding medium. We will use the
concept of damped harmonic oscillator to model the medium and Milne's
oscillator technique to map the interaction of the acoustic signal with the
medium. The acoustic signal itself will be modelled using the one-way wave
equation formulated in terms of acoustic pressure and velocity of acoustic
waves through the medium. Using the above-mentioned concepts, we calculated the
effective signal strength, phase shift and time period of the communicated
signal. Numerical results are generated to present the evolution of signal
strength and received signal envelope in underwater environment.",http://arxiv.org/abs/2202.06559v1,arXiv,model underwater acoustic propagation use oneway wave equation,primary contribution paper characterize propagation acoustic signal carry information medium interaction travel acoustic signal surround medium use concept damp harmonic oscillator model medium milne oscillator technique map interaction acoustic signal medium acoustic signal model use oneway wave equation formulate term acoustic pressure velocity acoustic wave medium use abovementioned concept calculate effective signal strength phase shift time period communicate signal numerical result generate present evolution signal strength receive signal envelope underwater environment,model underwater acoustic propagation use oneway wave equation primary contribution paper characterize propagation acoustic signal carry information medium interaction travel acoustic signal surround medium use concept damp harmonic oscillator model medium milne oscillator technique map interaction acoustic signal medium acoustic signal model use oneway wave equation formulate term acoustic pressure velocity acoustic wave medium use abovementioned concept calculate effective signal strength phase shift time period communicate signal numerical result generate present evolution signal strength receive signal envelope underwater environment,0.6338028169014085,0.09859154929577464,0.2112676056338028,0.0,71.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Theoretical / Conceptual,"Near-Field Localization and Sensing with Large-Aperture Arrays: From
  Signal Modeling to Processing","The signal processing community is currently witnessing a growing interest in
near-field signal processing, driven by the trend towards the use of large
aperture arrays with high spatial resolution in the fields of communication,
localization, sensing, imaging, etc. From the perspective of localization and
sensing, this trend breaks the basic far-field assumptions that have dominated
the array signal processing research in the past, presenting new challenges and
promising opportunities.",http://arxiv.org/abs/2406.10941v2,arXiv,nearfield localization sense largeaperture array signal modeling processing,signal processing community currently witness grow interest nearfield signal processing drive trend towards use large aperture array high spatial resolution field communication localization sense imaging etc perspective localization sense trend break basic farfield assumption dominate array signal processing research past present new challenge promising opportunity,nearfield localization sense largeaperture array signal modeling processing signal processing community currently witness grow interest nearfield signal processing drive trend towards use large aperture array high spatial resolution field communication localization sense imaging etc perspective localization sense trend break basic farfield assumption dominate array signal processing research past present new challenge promising opportunity,0.6888888888888889,0.08888888888888889,0.13333333333333333,0.022222222222222223,45.0,0.0,0.0,0.0,0.0
Computer Engineering,Signal Processing,Theoretical / Conceptual,"An Overview of Signal Processing Techniques for Joint Communication and
  Radar Sensing","Joint communication and radar sensing (JCR) represents an emerging research
field aiming to integrate the above two functionalities into a single system,
sharing a majority of hardware and signal processing modules and, in a typical
case, sharing a single transmitted signal. It is recognised as a key approach
in significantly improving spectrum efficiency, reducing device size, cost and
power consumption, and improving performance thanks to potential close
cooperation of the two functions. Advanced signal processing techniques are
critical for making the integration efficient, from transmission signal design
to receiver processing. This paper provides a comprehensive overview of JCR
systems from the signal processing perspective, with a focus on
state-of-the-art. A balanced coverage on both transmitter and receiver is
provided for three types of JCR systems, communication-centric, radar-centric,
and joint design and optimization.",http://arxiv.org/abs/2102.12780v1,arXiv,overview signal processing technique joint communication radar sense,joint communication radar sensing jcr represent emerge research field aim integrate two functionality single system share majority hardware signal processing module typical case share single transmit signal recognise key approach significantly improve spectrum efficiency reduce device size cost power consumption improve performance thank potential close cooperation two function advance signal processing technique critical make integration efficient transmission signal design receiver process paper provide comprehensive overview jcr system signal processing perspective focus stateoftheart balanced coverage transmitter receiver provide three type jcr system communicationcentric radarcentric joint design optimization,overview signal processing technique joint communication radar sense joint communication radar sensing jcr represent emerge research field aim integrate two functionality single system share majority hardware signal processing module typical case share single transmit signal recognise key approach significantly improve spectrum efficiency reduce device size cost power consumption improve performance thank potential close cooperation two function advance signal processing technique critical make integration efficient transmission signal design receiver process paper provide comprehensive overview jcr system signal processing perspective focus stateoftheart balanced coverage transmitter receiver provide three type jcr system communicationcentric radarcentric joint design optimization,0.6395348837209303,0.13953488372093023,0.16279069767441862,0.011627906976744186,86.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Quantitative,Fuzzy Control in Cyber-Physical Systems,"<p>Controllers are devices regulating the operation of other devices or systems. Fuzzy controllers analyze the input data in terms of variables which take on continuous values in the interval [0, 1]. Since fuzzy logic has the advantage of expressing the solution of the problems in the natural language, the use of fuzzy instead of traditional controllers makes easier the mechanization of tasks that have been already successfully performed by humans. In the present paper a theoretical fuzzy control model is developed for the braking system of autonomous vehicles, which are included among the most characteristic examples of Cyber-Physical Systems. For this, a simple geometric approach is followed using triangular fuzzy numbers as the basic tools.</p>",https://doi.org/10.4018/ijcps.2020070103,CrossRef,fuzzy control cyberphysical system,pcontroller device regulate operation device system fuzzy controller analyze input datum term variable take continuous value interval since fuzzy logic advantage express solution problem natural language use fuzzy instead traditional controller make easy mechanization task already successfully perform human present paper theoretical fuzzy control model develop brake system autonomous vehicle include among characteristic example cyberphysical system simple geometric approach follow use triangular fuzzy number basic toolsp,fuzzy control cyberphysical system pcontroller device regulate operation device system fuzzy controller analyze input datum term variable take continuous value interval since fuzzy logic advantage express solution problem natural language use fuzzy instead traditional controller make easy mechanization task already successfully perform human present paper theoretical fuzzy control model develop brake system autonomous vehicle include among characteristic example cyberphysical system simple geometric approach follow use triangular fuzzy number basic toolsp,0.5,0.12121212121212122,0.2727272727272727,0.045454545454545456,66.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Quantitative,Evaluating Robustness of Learning-Enabled Medical Cyber-Physical Systems with Naturally Adversarial Datasets,"<jats:p>
            Medical cyber-physical systems (MCPS) are increasingly adopting learning-enabled components (LECs) to enhance their decision-making capabilities. Due to the safety-critical nature of MCPS, these systems must maintain high performance on both expected and unexpected input data. Therefore, ensuring the robustness of LE-MCPS is crucial for their successful deployment. Existing research predominantly focuses on robustness to
            <jats:italic>synthetic adversarial examples</jats:italic>
            , crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against
            <jats:italic>naturally occurring adversarial examples</jats:italic>
            . We propose a method to evaluate the robustness of LE-MCPS to natural adversarial examples. The method curates naturally adversarial datasets leveraging probabilistic labels obtained from automated weakly-supervised labeling which combines noisy and cheap-to-obtain labeling heuristics. Based on these labels, the method adversarially orders the input data and uses this ordering to construct a sequence of increasingly adversarial datasets for assessing robustness. Our evaluation on six medical CPS case studies and two non-medical case studies demonstrates (1) the efficacy and statistical validity of our approach to generating naturally adversarial datasets, and (2) the utility of our robustness evaluation in classifying robust and non-robust LE-MCPS.
          </jats:p>",https://doi.org/10.1145/3734695,CrossRef,evaluate robustness learningenable medical cyberphysical system naturally adversarial dataset,jatsp medical cyberphysical system mcp increasingly adopt learningenable component lecs enhance decisionmake capability due safetycritical nature mcp system must maintain high performance expect unexpected input datum therefore ensure robustness lemcps crucial successful deployment exist research predominantly focus robustness jatsitalicsynthetic adversarial examplesjatsitalic craft add imperceptible perturbation clean input datum however synthetic adversarial example accurately reflect challenging realworld scenario especially context healthcare datum consequently robustness synthetic adversarial example may necessarily translate robustness jatsitalicnaturally occur adversarial examplesjatsitalic propose method evaluate robustness lemcp natural adversarial example method curate naturally adversarial dataset leverage probabilistic label obtain automate weaklysupervise labeling combine noisy cheaptoobtain labeling heuristic base label method adversarially order input datum use ordering construct sequence increasingly adversarial dataset assess robustness evaluation six medical case study two nonmedical case study demonstrate efficacy statistical validity approach generate naturally adversarial dataset utility robustness evaluation classify robust nonrobust lemcp jatsp,evaluate robustness learningenable medical cyberphysical system naturally adversarial dataset jatsp medical cyberphysical system mcp increasingly adopt learningenable component lecs enhance decisionmake capability due safetycritical nature mcp system must maintain high performance expect unexpected input datum therefore ensure robustness lemcps crucial successful deployment exist research predominantly focus robustness jatsitalicsynthetic adversarial examplesjatsitalic craft add imperceptible perturbation clean input datum however synthetic adversarial example accurately reflect challenging realworld scenario especially context healthcare datum consequently robustness synthetic adversarial example may necessarily translate robustness jatsitalicnaturally occur adversarial examplesjatsitalic propose method evaluate robustness lemcp natural adversarial example method curate naturally adversarial dataset leverage probabilistic label obtain automate weaklysupervise labeling combine noisy cheaptoobtain labeling heuristic base label method adversarially order input datum use ordering construct sequence increasingly adversarial dataset assess robustness evaluation six medical case study two nonmedical case study demonstrate efficacy statistical validity approach generate naturally adversarial dataset utility robustness evaluation classify robust nonrobust lemcp jatsp,0.36879432624113473,0.14184397163120568,0.2978723404255319,0.09929078014184398,141.0,1.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Quantitative,Model Conformance for Cyber-Physical Systems,"<jats:p>Model-based development is an important paradigm for developing cyber-physical systems (CPS). The underlying assumption is that the functional behavior of a model is related to the behavior of a more concretized model or the real system. A formal definition of such a relation is called conformance relation. There are a variety of conformance relations, and the question arises of how to select a conformance relation for the development of CPS. The contribution of this article is a survey of the definitions and algorithms of conformance relations for CPS. Additionally, the article compares several conformance relations and provides guidance on which relation to select for specific problems. Finally, we discuss how to select inputs for testing conformance.</jats:p>",https://doi.org/10.1145/3306157,CrossRef,model conformance cyberphysical system,jatspmodelbase development important paradigm develop cyberphysical system underlie assumption functional behavior model relate behavior concretize model real system formal definition relation call conformance relation variety conformance relation question arise select conformance relation development contribution article survey definition algorithm conformance relation additionally article compare several conformance relation provide guidance relation select specific problem finally discuss select input test conformancejatsp,model conformance cyberphysical system jatspmodelbase development important paradigm develop cyberphysical system underlie assumption functional behavior model relate behavior concretize model real system formal definition relation call conformance relation variety conformance relation question arise select conformance relation development contribution article survey definition algorithm conformance relation additionally article compare several conformance relation provide guidance relation select specific problem finally discuss select input test conformancejatsp,0.6379310344827587,0.10344827586206896,0.1724137931034483,0.034482758620689655,58.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Quantitative,Adaptive embedded control of cyber‐physical systems using reinforcement learning,"<jats:p>Embedded control parameters of cyber‐physical systems (CPS), such as sampling rate, are typically invariant and designed with a worst case scenario in mind. In an over‐engineered system, control parameters are assigned values that satisfy system‐wide performance requirements at the expense of excessive energy and resource overheads. Dynamic and adaptive control parameters can reduce the overhead but are complex and require in‐depth knowledge of the CPS and its operating environment – which typically is unavailable during design time. The authors investigate the application of reinforcement learning (RL) to dynamically adapt high‐level system parameters, at run time, as a function of the system state. RL is an alternative approach to the classical control theory for CPSs that can learn and adapt control properties without the need of an in‐depth controller model. Specifically, we show that RL can modulate sampling times to save processing power without compromising control quality. We apply a novel statistical cloud‐based evaluation framework to study the validity of our approach for the cart‐pole balancing control problem as well as the well‐known mountain car problem. The results show an improved real‐world power efficiency of up to 20% compared with an optimal system with fixed controller settings.</jats:p>",https://doi.org/10.1049/iet-cps.2017.0048,CrossRef,adaptive embed control system use reinforcement learning,jatspembedded control parameter system sampling rate typically invariant design bad case scenario mind system control parameter assign value satisfy performance requirement expense excessive energy resource overhead dynamic adaptive control parameter reduce overhead complex require knowledge operating environment typically unavailable design time author investigate application reinforcement learning dynamically adapt system parameter run time function system state alternative approach classical control theory cpss learn adapt control property without need controller model specifically show modulate sample time save processing power without compromise control quality apply novel statistical evaluation framework study validity approach balance control problem well mountain car problem result show improved power efficiency compare optimal system fix controller settingsjatsp,adaptive embed control system use reinforcement learning jatspembedded control parameter system sampling rate typically invariant design bad case scenario mind system control parameter assign value satisfy performance requirement expense excessive energy resource overhead dynamic adaptive control parameter reduce overhead complex require knowledge operating environment typically unavailable design time author investigate application reinforcement learning dynamically adapt system parameter run time function system state alternative approach classical control theory cpss learn adapt control property without need controller model specifically show modulate sample time save processing power without compromise control quality apply novel statistical evaluation framework study validity approach balance control problem well mountain car problem result show improved power efficiency compare optimal system fix controller settingsjatsp,0.6542056074766355,0.14018691588785046,0.11214953271028037,0.037383177570093455,107.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Quantitative,Modelling and evaluation of the security of cyber‐physical systems using stochastic Petri nets,"<jats:p>This study proposes a stochastic Petri net model for evaluating the security and resilience of cyber‐physical systems (CPSs) in the face of malicious attacks. The basic idea behind the proposed model is to evaluate the security of control loops equipped with intrusion detection systems (IDSs) faced with security attacks. The quantitative analysis is performed in terms of system‐focused quantitative security measures, such as mean time‐to‐failure and availability. By using this model, one can investigate the effects of some attacks and defensive parameters, including the detection interval, the time to physical disruption, and the false‐positive probability of IDSs. This evaluation results can help to improve the security countermeasures of CPSs.</jats:p>",https://doi.org/10.1049/iet-cps.2018.0008,CrossRef,modelling evaluation security system use stochastic petri net,jatspthis study propose stochastic petri net model evaluate security resilience system cpss face malicious attack basic idea behind propose model evaluate security control loop equip intrusion detection system idss face security attack quantitative analysis perform term quantitative security measure mean availability use model one investigate effect attack defensive parameter include detection interval time physical disruption probability idss evaluation result help improve security countermeasure cpssjatsp,modelling evaluation security system use stochastic petri net jatspthis study propose stochastic petri net model evaluate security resilience system cpss face malicious attack basic idea behind propose model evaluate security control loop equip intrusion detection system idss face security attack quantitative analysis perform term quantitative security measure mean availability use model one investigate effect attack defensive parameter include detection interval time physical disruption probability idss evaluation result help improve security countermeasure cpssjatsp,0.609375,0.15625,0.140625,0.0,64.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Qualitative,Systems of Gibbons-Tsarev type and integrable 3-dimensional models,"We review the role of Gibbons-Tsarev-type systems in classification of
integrable multi-dimensional hydrodynamic-type systems. Our main observation is
an universality of Gibbons-Tsarev-type systems. We also constract explicitly a
wide class of 3-dimensional hydrodynamic-type systems corresponding to the
simplest possible Gibbons-Tsarev-type system.",http://arxiv.org/abs/0906.3509v1,arXiv,system gibbonstsarev type integrable dimensional model,review role gibbonstsarevtype system classification integrable multidimensional hydrodynamictype system main observation universality gibbonstsarevtype system also constract explicitly wide class dimensional hydrodynamictype system correspond simple possible gibbonstsarevtype system,system gibbonstsarev type integrable dimensional model review role gibbonstsarevtype system classification integrable multidimensional hydrodynamictype system main observation universality gibbonstsarevtype system also constract explicitly wide class dimensional hydrodynamictype system correspond simple possible gibbonstsarevtype system,0.48148148148148145,0.1111111111111111,0.3333333333333333,0.07407407407407407,27.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Qualitative,Confidentiality Breach Through Acoustic Side-Channel in Cyber-Physical Additive Manufacturing Systems,"<jats:p>In cyber-physical systems, due to the tight integration of the computational, communication, and physical components, most of the information in the cyber-domain manifests in terms of physical actions (such as motion, temperature change, etc.). This leads to the system being prone to physical-to-cyber domain attacks that affect the confidentiality. Physical actions are governed by energy flows, which may be observed. Some of these observable energy flows unintentionally leak information about the cyber-domain and hence are known as the side-channels. Side-channels such as acoustic, thermal, and power allow attackers to acquire the information without actually leveraging the vulnerability of the algorithms implemented in the system. As a case study, we have taken cyber-physical additive manufacturing systems (fused deposition modeling-based three-dimensional (3D) printer) to demonstrate how the acoustic side-channel can be used to breach the confidentiality of the system. In 3D printers, geometry, process, and machine information are the intellectual properties, which are stored in the cyber domain (G-code). We have designed an attack model that consists of digital signal processing, machine-learning algorithms, and context-based post processing to steal the intellectual property in the form of geometry details by reconstructing the G-code and thus the test objects. We have successfully reconstructed various test objects with an average axis prediction accuracy of 86% and an average length prediction error of 11.11%.</jats:p>",https://doi.org/10.1145/3078622,CrossRef,confidentiality breach acoustic sidechannel cyberphysical additive manufacturing system,jatspin cyberphysical system due tight integration computational communication physical component information cyberdomain manifest term physical action motion temperature change etc lead system prone physicaltocyber domain attack affect confidentiality physical action govern energy flow may observe observable energy flow unintentionally leak information cyberdomain hence know sidechannel sidechannel acoustic thermal power allow attacker acquire information without actually leverage vulnerability algorithm implement system case study take cyberphysical additive manufacturing system fuse deposition modelingbase threedimensional printer demonstrate acoustic sidechannel use breach confidentiality system printer geometry process machine information intellectual property store cyber domain gcode design attack model consist digital signal processing machinelearning algorithm contextbase post processing steal intellectual property form geometry detail reconstruct gcode thus test object successfully reconstruct various test object average axis prediction accuracy average length prediction error jatsp,confidentiality breach acoustic sidechannel cyberphysical additive manufacturing system jatspin cyberphysical system due tight integration computational communication physical component information cyberdomain manifest term physical action motion temperature change etc lead system prone physicaltocyber domain attack affect confidentiality physical action govern energy flow may observe observable energy flow unintentionally leak information cyberdomain hence know sidechannel sidechannel acoustic thermal power allow attacker acquire information without actually leverage vulnerability algorithm implement system case study take cyberphysical additive manufacturing system fuse deposition modelingbase threedimensional printer demonstrate acoustic sidechannel use breach confidentiality system printer geometry process machine information intellectual property store cyber domain gcode design attack model consist digital signal processing machinelearning algorithm contextbase post processing steal intellectual property form geometry detail reconstruct gcode thus test object successfully reconstruct various test object average axis prediction accuracy average length prediction error jatsp,0.5905511811023622,0.11023622047244094,0.1889763779527559,0.03937007874015748,127.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Qualitative,Analysing Mission-critical Cyber-physical Systems with AND/OR Graphs and MaxSAT,"<jats:p>
            Cyber-Physical Systems (CPS) often involve complex networks of interconnected software and hardware components that are logically combined to achieve a common goal or mission; for example, keeping a plane in the air or providing energy to a city. Failures in these components may jeopardise the mission of the system. Therefore, identifying the minimal set of critical CPS components that is most likely to fail, and prevent the global system from accomplishing its mission, becomes essential to ensure reliability. In this article, we present a novel approach to identifying the
            <jats:italic>Most Likely Mission-critical Component Set (MLMCS)</jats:italic>
            using AND/OR dependency graphs enriched with independent failure probabilities. We address the MLMCS problem as a Maximum Satisfiability (MaxSAT) problem. We translate probabilities into a negative logarithmic space to linearise the problem within MaxSAT. The experimental results conducted with our open source tool LDA4CPS indicate that the approach is both effective and efficient. We also present a case study on complex aircraft systems that shows the feasibility of our approach and its applicability to mission-critical cyber-physical systems. Finally, we present two MLMCS-based security applications focused on system hardening and forensic investigations.
          </jats:p>",https://doi.org/10.1145/3451169,CrossRef,analyse missioncritical cyberphysical system andor graph maxsat,jatsp cyberphysical system often involve complex network interconnect software hardware component logically combine achieve common goal mission example keep plane air provide energy city failure component may jeopardise mission system therefore identify minimal set critical component likely fail prevent global system accomplish mission become essential ensure reliability article present novel approach identify jatsitalicmost likely missioncritical component set mlmcsjatsitalic use andor dependency graph enrich independent failure probability address mlmcs problem maximum satisfiability maxsat problem translate probability negative logarithmic space linearise problem within maxsat experimental result conduct open source tool ldacp indicate approach effective efficient also present case study complex aircraft system show feasibility approach applicability missioncritical cyberphysical system finally present two mlmcsbase security application focus system hardening forensic investigation jatsp,analyse missioncritical cyberphysical system andor graph maxsat jatsp cyberphysical system often involve complex network interconnect software hardware component logically combine achieve common goal mission example keep plane air provide energy city failure component may jeopardise mission system therefore identify minimal set critical component likely fail prevent global system accomplish mission become essential ensure reliability article present novel approach identify jatsitalicmost likely missioncritical component set mlmcsjatsitalic use andor dependency graph enrich independent failure probability address mlmcs problem maximum satisfiability maxsat problem translate probability negative logarithmic space linearise problem within maxsat experimental result conduct open source tool ldacp indicate approach effective efficient also present case study complex aircraft system show feasibility approach applicability missioncritical cyberphysical system finally present two mlmcsbase security application focus system hardening forensic investigation jatsp,0.5126050420168067,0.14285714285714285,0.226890756302521,0.05042016806722689,119.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Qualitative,Holistic Cyber-Physical Management for Dependable Wireless Control Systems,"<jats:p>Wireless sensor-actuator networks (WSANs) are gaining momentum in industrial process automation as a communication infrastructure for lowering deployment and maintenance costs. In traditional wireless control systems, the plant controller and the network manager operate in isolation, which ignores the significant influence of network reliability on plant control performance. To enhance the dependability of industrial wireless control, we propose a holistic cyber-physical management framework that employs runtime coordination between the plant control and network management. Our design includes a holistic controller that generates actuation signals to physical plants and reconfigures the WSAN to maintain the desired control performance while saving wireless resources. As a concrete example of holistic control, we design a holistic manager that dynamically reconfigures the number of transmissions in the WSAN based on online observations of physical and cyber variables. We have implemented the holistic management framework in the wireless cyber-physicalsimulator (WCPS). A systematic case study is presented based on two five-state plants and a load positioning system using a 16-node WSAN. Simulation results show that the holistic management design has significantly enhanced the dependability of the system against both wireless interferences and physical disturbances, while effectively reducing the number of wireless transmissions.</jats:p>",https://doi.org/10.1145/3185510,CrossRef,holistic cyberphysical management dependable wireless control system,jatspwireless sensoractuator network wsan gain momentum industrial process automation communication infrastructure lower deployment maintenance cost traditional wireless control system plant controller network manager operate isolation ignore significant influence network reliability plant control performance enhance dependability industrial wireless control propose holistic cyberphysical management framework employ runtime coordination plant control network management design include holistic controller generate actuation signal physical plant reconfigure wsan maintain desire control performance save wireless resource concrete example holistic control design holistic manager dynamically reconfigure number transmission wsan base online observation physical cyber variable implement holistic management framework wireless cyberphysicalsimulator wcp systematic case study present base two fivestate plant load position system use node wsan simulation result show holistic management design significantly enhance dependability system wireless interference physical disturbance effectively reduce number wireless transmissionsjatsp,holistic cyberphysical management dependable wireless control system jatspwireless sensoractuator network wsan gain momentum industrial process automation communication infrastructure lower deployment maintenance cost traditional wireless control system plant controller network manager operate isolation ignore significant influence network reliability plant control performance enhance dependability industrial wireless control propose holistic cyberphysical management framework employ runtime coordination plant control network management design include holistic controller generate actuation signal physical plant reconfigure wsan maintain desire control performance save wireless resource concrete example holistic control design holistic manager dynamically reconfigure number transmission wsan base online observation physical cyber variable implement holistic management framework wireless cyberphysicalsimulator wcp systematic case study present base two fivestate plant load position system use node wsan simulation result show holistic management design significantly enhance dependability system wireless interference physical disturbance effectively reduce number wireless transmissionsjatsp,0.5952380952380952,0.11904761904761904,0.18253968253968253,0.023809523809523808,126.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Qualitative,In the mind of an insider attacker on cyber‐physical systems and how not being fooled,"<jats:p>Insider attacks are one of the most serious threats for cyber‐physical systems, they have potentials to inflict destructive damages on physical processes while remaining stealthy. This study dissects several insider attacks by examining their modes of data tampering. To set the scene, a general framework of a cyber‐physical system is constructed, a pattern characterising insider attacks is introduced in the form of attack goals, resources, constraints, modes, and attack paths. The conditions under which the attackers can maintain stealthy are examined in both temporal and spatial domains. With the inside knowledge, an attacker can use an attack graph to exploit system vulnerabilities and determine the high impact targets. To demonstrate the effectiveness of this analysis, a cyber‐physical system is constructed by using networks and a nuclear process control test facility with ports deliberately left open for attackers. Two attack scenarios are staged, and their characteristics and impacts are examined. This case study demonstrates how an insider attacker might mount an attack by using data tampering and how they can maintain stealthy before major damages are done to the physical system. The significance of this study is to uncover the techniques of insider attackers so that vulnerabilities can be mended.</jats:p>",https://doi.org/10.1049/iet-cps.2019.0087,CrossRef,mind insider attacker system fool,jatspinsider attack one serious threat system potential inflict destructive damage physical process remain stealthy study dissect several insider attack examine mode datum tamper set scene general framework system construct pattern characterise insider attack introduce form attack goal resource constraint mode attack path condition attacker maintain stealthy examine temporal spatial domain inside knowledge attacker use attack graph exploit system vulnerability determine high impact target demonstrate effectiveness analysis system construct use network nuclear process control test facility port deliberately leave open attacker two attack scenario stage characteristic impact examine case study demonstrate insider attacker might mount attack use datum tampering maintain stealthy major damage physical system significance study uncover technique insider attacker vulnerability mendedjatsp,mind insider attacker system fool jatspinsider attack one serious threat system potential inflict destructive damage physical process remain stealthy study dissect several insider attack examine mode datum tamper set scene general framework system construct pattern characterise insider attack introduce form attack goal resource constraint mode attack path condition attacker maintain stealthy examine temporal spatial domain inside knowledge attacker use attack graph exploit system vulnerability determine high impact target demonstrate effectiveness analysis system construct use network nuclear process control test facility port deliberately leave open attacker two attack scenario stage characteristic impact examine case study demonstrate insider attacker might mount attack use datum tampering maintain stealthy major damage physical system significance study uncover technique insider attacker vulnerability mendedjatsp,0.6607142857142857,0.09821428571428571,0.15178571428571427,0.008928571428571428,112.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Mixed Methods,Extending Signal Temporal Logic with Quantitative Semantics by Intervals for Robust Monitoring of Cyber-physical Systems,"<jats:p>
            Monitoring is the core procedure of runtime verification of cyber-physical systems (CPS) and provides an evaluation of a signal with respect to a given specification. For formally specifying requirements with time constraints for CPS, Signal Temporal Logic (STL) is a well-known specification language with powerful semantics. However, with existing semantics of STL it is not feasible to monitor signals with spatial deviation and time delay. Therefore, we introduce
            <jats:italic>STL with Quantitative Interval Semantics</jats:italic>
            to solve this problem. Based on this newly developed semantics, we derived an algorithm called
            <jats:italic>RoMoTeS</jats:italic>
            (Robust Monitoring for Temporal Specifications) to monitor a signal with finite length with respect to an STL formula. It provides a real-valued interval for every point in time, which contains all possible signed distances between the deviation polytope determined by the measured data point (exposed to deviation and delay) and the permissive space specified by an STL specification. Furthermore, it is proven that no satisfaction is reported when the signal is potentially falsifying such a specification. Finally, an automatic transmission controller model was used as a case study to show the applicability and usefulness of the proposed algorithm.
          </jats:p>",https://doi.org/10.1145/3377868,CrossRef,extend signal temporal logic quantitative semantic interval robust monitoring cyberphysical system,jatsp monitoring core procedure runtime verification cyberphysical system provide evaluation signal respect give specification formally specify requirement time constraint signal temporal logic stl wellknown specification language powerful semantic however exist semantic stl feasible monitor signal spatial deviation time delay therefore introduce jatsitalicstl quantitative interval semanticsjatsitalic solve problem base newly develop semantic derive algorithm call jatsitalicromotesjatsitalic robust monitoring temporal specification monitor signal finite length respect stl formula provide realvalue interval every point time contain possible sign distance deviation polytope determine measured datum point expose deviation delay permissive space specify stl specification furthermore prove satisfaction report signal potentially falsify specification finally automatic transmission controller model use case study show applicability usefulness propose algorithm jatsp,extend signal temporal logic quantitative semantic interval robust monitoring cyberphysical system jatsp monitoring core procedure runtime verification cyberphysical system provide evaluation signal respect give specification formally specify requirement time constraint signal temporal logic stl wellknown specification language powerful semantic however exist semantic stl feasible monitor signal spatial deviation time delay therefore introduce jatsitalicstl quantitative interval semanticsjatsitalic solve problem base newly develop semantic derive algorithm call jatsitalicromotesjatsitalic robust monitoring temporal specification monitor signal finite length respect stl formula provide realvalue interval every point time contain possible sign distance deviation polytope determine measured datum point expose deviation delay permissive space specify stl specification furthermore prove satisfaction report signal potentially falsify specification finally automatic transmission controller model use case study show applicability usefulness propose algorithm jatsp,0.5446428571428571,0.1875,0.10714285714285714,0.0625,112.0,1.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Mixed Methods,Meta-Learning to Improve Unsupervised Intrusion Detection in Cyber-Physical Systems,"<jats:p>
            <jats:bold>Artificial Intelligence (AI)-</jats:bold>
            based classifiers rely on
            <jats:bold>Machine Learning (ML)</jats:bold>
            algorithms to provide functionalities that system architects are often willing to integrate into critical
            <jats:bold>Cyber-Physical Systems (CPSs)</jats:bold>
            . However, such algorithms may misclassify observations, with potential detrimental effects on the system itself or on the health of people and of the environment. In addition, CPSs may be subject to threats that were not previously known, motivating the need for building
            <jats:bold>Intrusion Detectors (IDs)</jats:bold>
            that can effectively deal with zero-day attacks. Different studies were directed to compare misclassifications of various algorithms to identify the most suitable one for a given system. Unfortunately, even the most suitable algorithm may still show an unsatisfactory number of misclassifications when system requirements are strict. A possible solution may rely on the adoption of meta-learners, which build ensembles of base-learners to reduce misclassifications and that are widely used for supervised learning. Meta-learners have the potential to reduce misclassifications with respect to non-meta learners: however, misleading base-learners may let the meta-learner leaning towards misclassifications and therefore their behavior needs to be carefully assessed through empirical evaluation. To such extent, in this paper we investigate, expand, empirically evaluate, and discuss meta-learning approaches that rely on ensembles of unsupervised algorithms to detect (zero-day) intrusions in CPSs. Our experimental comparison is conducted by means of public datasets belonging to network intrusion detection and biometric authentication systems, which are common IDSs for CPSs. Overall, we selected 21 datasets, 15 unsupervised algorithms and 9 different meta-learning approaches. Results allow discussing the applicability and suitability of meta-learning for unsupervised anomaly detection, comparing metric scores achieved by base algorithms and meta-learners. Analyses and discussion end up showing how the adoption of meta-learners significantly reduces misclassifications when detecting (zero-day) intrusions in CPSs.
          </jats:p>",https://doi.org/10.1145/3467470,CrossRef,metalearne improve unsupervised intrusion detection cyberphysical system,jatsp jatsboldartificial intelligence aijatsbold base classifier rely jatsboldmachine learn mljatsbold algorithm provide functionality system architect often willing integrate critical jatsboldcyberphysical system cpssjatsbold however algorithm may misclassify observation potential detrimental effect system health people environment addition cpss may subject threat previously know motivate need build jatsboldintrusion detector idsjatsbold effectively deal zeroday attack different study direct compare misclassification various algorithm identify suitable one give system unfortunately even suitable algorithm may still show unsatisfactory number misclassification system requirement strict possible solution may rely adoption metalearner build ensemble baselearner reduce misclassification widely use supervised learning metalearner potential reduce misclassification respect nonmeta learner however misleading baselearner may let metalearner lean towards misclassification therefore behavior need carefully assess empirical evaluation extent paper investigate expand empirically evaluate discuss metalearning approach rely ensemble unsupervised algorithm detect zeroday intrusion cpss experimental comparison conduct mean public dataset belong network intrusion detection biometric authentication system common idss cpss overall select dataset unsupervised algorithms different metalearning approach result allow discuss applicability suitability metalearning unsupervised anomaly detection compare metric score achieve base algorithm metalearner analysis discussion end show adoption metalearner significantly reduce misclassification detect zeroday intrusion cpss jatsp,metalearne improve unsupervised intrusion detection cyberphysical system jatsp jatsboldartificial intelligence aijatsbold base classifier rely jatsboldmachine learn mljatsbold algorithm provide functionality system architect often willing integrate critical jatsboldcyberphysical system cpssjatsbold however algorithm may misclassify observation potential detrimental effect system health people environment addition cpss may subject threat previously know motivate need build jatsboldintrusion detector idsjatsbold effectively deal zeroday attack different study direct compare misclassification various algorithm identify suitable one give system unfortunately even suitable algorithm may still show unsatisfactory number misclassification system requirement strict possible solution may rely adoption metalearner build ensemble baselearner reduce misclassification widely use supervised learning metalearner potential reduce misclassification respect nonmeta learner however misleading baselearner may let metalearner lean towards misclassification therefore behavior need carefully assess empirical evaluation extent paper investigate expand empirically evaluate discuss metalearning approach rely ensemble unsupervised algorithm detect zeroday intrusion cpss experimental comparison conduct mean public dataset belong network intrusion detection biometric authentication system common idss cpss overall select dataset unsupervised algorithms different metalearning approach result allow discuss applicability suitability metalearning unsupervised anomaly detection compare metric score achieve base algorithm metalearner analysis discussion end show adoption metalearner significantly reduce misclassification detect zeroday intrusion cpss jatsp,0.43243243243243246,0.16216216216216217,0.1837837837837838,0.07027027027027027,185.0,3.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Mixed Methods,Out-of-distribution Detection in Dependent Data for Cyber-physical Systems with Conformal Guarantees,"<jats:p>Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LEC’s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisher’s method leads to the proposed detector CODiT with bounded false alarms.</jats:p>
          <jats:p>CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees.</jats:p>
          <jats:p>
            We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subject’s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at
            <jats:ext-link xmlns:xlink=""http://www.w3.org/1999/xlink"" ext-link-type=""url"" xlink:href=""https://github.com/kaustubhsridhar/time-series-OOD"">https://github.com/kaustubhsridhar/time-series-OOD</jats:ext-link>
            .
          </jats:p>",https://doi.org/10.1145/3648005,CrossRef,outofdistribution detection dependent datum cyberphysical system conformal guarantee,jatspuncertainty prediction learningenable component hinder deployment safetycritical cyberphysical system shift training distribution learningenable component lec one source uncertainty lec prediction detection shift outofdistribution ood detection individual datapoint therefore gain attention recently many application input form temporal sequence exist technique ood detection timeserie datum either exploit temporal relationship sequence provide guarantee detection propose use deviation indistribution temporal equivariance nonconformity measure conformal anomaly detection framework ood detection timeserie datum compute independent prediction multiple conformal detector base propose measure combine prediction fisher method lead propose detector codit bound false alarmsjatsp jatspcodit perform ood detection fixedlength window consecutive timeserie datapoint use fisher value input window far propose perform ood detection realtime timeserie trace variable length bounded false alarm use codit compute fisher value slide window input trace combine value merging function merging function harmonic mean arithmetic mean geometric mean bonferroni method use combine fisher value slide window input trace combine value use ood detection trace bound false alarm rate guaranteesjatsp jatsp illustrate efficacy codit achieve stateoftheart result two case study ood detection fixedlength window first one autonomous driving system perception vision lec second case study medical walking pattern gait analysis physiological nonvision datum collect forcesensitive resistor attach subject body ood detection variable length trace consider case study autonomous driving system medical gait analysis report result four merging function fisher value compute codit slide window input trace also compare false alarm rate guarantee four merging function autonomous driving system case study code datum train model available jatsextlink xmlnsxlinkhttpwwwworgxlink extlinktypeurl xlinkhrefhttpsgithubcomkaustubhsridhartimeseriesoodhttpsgithubcomkaustubhsridhartimeseriesoodjatsextlink jatsp,outofdistribution detection dependent datum cyberphysical system conformal guarantee jatspuncertainty prediction learningenable component hinder deployment safetycritical cyberphysical system shift training distribution learningenable component lec one source uncertainty lec prediction detection shift outofdistribution ood detection individual datapoint therefore gain attention recently many application input form temporal sequence exist technique ood detection timeserie datum either exploit temporal relationship sequence provide guarantee detection propose use deviation indistribution temporal equivariance nonconformity measure conformal anomaly detection framework ood detection timeserie datum compute independent prediction multiple conformal detector base propose measure combine prediction fisher method lead propose detector codit bound false alarmsjatsp jatspcodit perform ood detection fixedlength window consecutive timeserie datapoint use fisher value input window far propose perform ood detection realtime timeserie trace variable length bounded false alarm use codit compute fisher value slide window input trace combine value merging function merging function harmonic mean arithmetic mean geometric mean bonferroni method use combine fisher value slide window input trace combine value use ood detection trace bound false alarm rate guaranteesjatsp jatsp illustrate efficacy codit achieve stateoftheart result two case study ood detection fixedlength window first one autonomous driving system perception vision lec second case study medical walking pattern gait analysis physiological nonvision datum collect forcesensitive resistor attach subject body ood detection variable length trace consider case study autonomous driving system medical gait analysis report result four merging function fisher value compute codit slide window input trace also compare false alarm rate guarantee four merging function autonomous driving system case study code datum train model available jatsextlink xmlnsxlinkhttpwwwworgxlink extlinktypeurl xlinkhrefhttpsgithubcomkaustubhsridhartimeseriesoodhttpsgithubcomkaustubhsridhartimeseriesoodjatsextlink jatsp,0.6382113821138211,0.1016260162601626,0.15040650406504066,0.02032520325203252,123.0,0.0,0.0,0.0,3.0
Computer Engineering,Cyber-Physical Systems,Mixed Methods,Characterization of Link Quality Fluctuation in Mobile Wireless Sensor Networks,"<jats:p>
            Wireless sensor networks accommodating the mobility of nodes will play important roles in the future. In residential, rehabilitation, and clinical settings, sensor nodes can be attached to the body of a patient for long-term and uninterrupted monitoring of vital biomedical signals. Likewise, in industrial settings, workers as well as mobile robots can carry sensor nodes to augment their perception and to seamlessly interact with their environments. Nevertheless, such applications require reliable communications as well as high throughput. Considering the primary design goals of the sensing platforms (low-power, affordable cost, large-scale deployment, longevity, operating in the ISM band), maintaining reliable links is a formidable challenge. This challenge can partially be alleviated if the nature of link quality fluctuation can be known or estimated on time. Indeed, higher-level protocols such as handover and routing protocols rely on knowledge of link quality fluctuation to seamlessly transfer communication to alternative routes when the quality of existing routes deteriorates. In this article, we present the result of extensive experimental study to characterise link quality fluctuation in mobile environments. The study focuses on slow movements (&lt;5 km h
            <jats:sup>-1</jats:sup>
            ) signifying the movement of people and robots and transceivers complying to the IEEE 802.15.4 specification. Hence, we deployed mobile robots that interact with strategically placed stationary relay nodes. Our study considered different types of link quality characterisation metrics that provide complementary and useful insights. To demonstrate the usefulness of our experiments and observations, we implemented a link quality estimation technique using a Kalman Filter. To set up the model, we employed two link quality metrics along with the statistics we established during our experiments. The article will compare the performance of four proposed approaches with ours.
          </jats:p>",https://doi.org/10.1145/3448737,CrossRef,characterization link quality fluctuation mobile wireless sensor network,jatsp wireless sensor network accommodate mobility node play important role future residential rehabilitation clinical setting sensor node attach body patient longterm uninterrupted monitoring vital biomedical signal likewise industrial setting worker well mobile robot carry sensor node augment perception seamlessly interact environment nevertheless application require reliable communication well high throughput consider primary design goal sense platform lowpower affordable cost largescale deployment longevity operate ism band maintain reliable link formidable challenge challenge partially alleviate nature link quality fluctuation know estimate time indeed higherlevel protocol handover route protocol rely knowledge link quality fluctuation seamlessly transfer communication alternative route quality exist route deteriorate article present result extensive experimental study characterise link quality fluctuation mobile environment study focus slow movement jatssupjatssup signify movement people robot transceiver comply ieee specification hence deploy mobile robot interact strategically place stationary relay nod study consider different type link quality characterisation metric provide complementary useful insight demonstrate usefulness experiment observation implement link quality estimation technique use kalman filter set model employ two link quality metric along statistic establish experiment article compare performance four propose approach jatsp,characterization link quality fluctuation mobile wireless sensor network jatsp wireless sensor network accommodate mobility node play important role future residential rehabilitation clinical setting sensor node attach body patient longterm uninterrupted monitoring vital biomedical signal likewise industrial setting worker well mobile robot carry sensor node augment perception seamlessly interact environment nevertheless application require reliable communication well high throughput consider primary design goal sense platform lowpower affordable cost largescale deployment longevity operate ism band maintain reliable link formidable challenge challenge partially alleviate nature link quality fluctuation know estimate time indeed higherlevel protocol handover route protocol rely knowledge link quality fluctuation seamlessly transfer communication alternative route quality exist route deteriorate article present result extensive experimental study characterise link quality fluctuation mobile environment study focus slow movement jatssupjatssup signify movement people robot transceiver comply ieee specification hence deploy mobile robot interact strategically place stationary relay nod study consider different type link quality characterisation metric provide complementary useful insight demonstrate usefulness experiment observation implement link quality estimation technique use kalman filter set model employ two link quality metric along statistic establish experiment article compare performance four propose approach jatsp,0.5397727272727273,0.14204545454545456,0.1534090909090909,0.045454545454545456,176.0,2.0,0.0,0.0,1.0
Computer Engineering,Cyber-Physical Systems,Mixed Methods,Modeling Adversarial Physical Movement in a Railway Station,"<jats:p>
            Many real-world attacks on cyber-physical systems involve physical intrusions that directly cause damage or facilitate cyber attacks. Hence, in this work, we investigate the security risk of organizations with respect to different adversarial models of physical movement behavior. We study the case in which an intrusion detection mechanism is in place to alert the system administrator when users deviate from their normal movement behavior. We then analyze how different user behaviors may present themselves as different levels of threats in terms of their normal movement behavior within a given building topology. To quantify the differences in movement behavior, we define a
            <jats:italic>WeightTopo</jats:italic>
            metric that takes into account the building topology in addition to the movement pattern. We demonstrate our approach on a railway system case study and show how certain user roles, when abused by attackers, are especially vulnerable in terms of the physical intrusion detection probability. We also evaluate quantitatively how the similarity between an attacker’s movement behavior and a user’s movement behavior affects the detection probability of the evaluated intrusion detection system. Certain individual users are found to pose a higher threat, implying the need for customized monitoring.
          </jats:p>",https://doi.org/10.1145/3349584,CrossRef,model adversarial physical movement railway station,jatsp many realworld attack cyberphysical system involve physical intrusion directly cause damage facilitate cyber attack hence work investigate security risk organization respect different adversarial model physical movement behavior study case intrusion detection mechanism place alert system administrator user deviate normal movement behavior analyze different user behavior may present different level threat term normal movement behavior within give build topology quantify difference movement behavior define jatsitalicweighttopojatsitalic metric take account building topology addition movement pattern demonstrate approach railway system case study show certain user role abuse attacker especially vulnerable term physical intrusion detection probability also evaluate quantitatively similarity attacker movement behavior user movement behavior affect detection probability evaluated intrusion detection system certain individual user find pose high threat imply need customized monitoring jatsp,model adversarial physical movement railway station jatsp many realworld attack cyberphysical system involve physical intrusion directly cause damage facilitate cyber attack hence work investigate security risk organization respect different adversarial model physical movement behavior study case intrusion detection mechanism place alert system administrator user deviate normal movement behavior analyze different user behavior may present different level threat term normal movement behavior within give build topology quantify difference movement behavior define jatsitalicweighttopojatsitalic metric take account building topology addition movement pattern demonstrate approach railway system case study show certain user role abuse attacker especially vulnerable term physical intrusion detection probability also evaluate quantitatively similarity attacker movement behavior user movement behavior affect detection probability evaluated intrusion detection system certain individual user find pose high threat imply need customized monitoring jatsp,0.5785123966942148,0.18181818181818182,0.14049586776859505,0.04132231404958678,121.0,1.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Design and Development,Architectural Modelling of Cyber Physical Systems Using UML,"<jats:p>Cyber-physical systems (CPS) is an exciting emerging research area that has drawn the attention of many researchers. However, the difficulties of computing and physical paradigm introduce a lot of trials while developing CPS, such as incorporation of heterogeneous physical entities, system verification, security assurance, and so on. A common or unified architecture plays an important role in the process of CPS design. This article introduces the architectural modeling representation of CPS. The layers of models are integrated from high level to lower level to get the general Meta model. Architecture captures the essential attributes of a CPS. Despite the rapid growth in IoT and CPS a general principled modeling approach for the systematic development of these new engineering systems is still missing. System modeling is one of the important aspects of developing abstract models of a system wherein, each model represents a different view or perspective of that system. With Unified Modeling Language (UML), the graphical analogy of such complex systems can be successfully presented.</jats:p>",https://doi.org/10.4018/ijcps.2019070102,CrossRef,architectural modelling cyber physical system use uml,jatspcyberphysical system exciting emerge research area draw attention many researcher however difficulty compute physical paradigm introduce lot trial develop incorporation heterogeneous physical entity system verification security assurance common unified architecture play important role process design article introduce architectural modeling representation layer model integrate high level low level get general meta model architecture capture essential attribute despite rapid growth iot general principle modeling approach systematic development new engineering system still miss system modeling one important aspect develop abstract model system wherein model represent different view perspective system unified modeling language uml graphical analogy complex system successfully presentedjatsp,architectural modelling cyber physical system use uml jatspcyberphysical system exciting emerge research area draw attention many researcher however difficulty compute physical paradigm introduce lot trial develop incorporation heterogeneous physical entity system verification security assurance common unified architecture play important role process design article introduce architectural modeling representation layer model integrate high level low level get general meta model architecture capture essential attribute despite rapid growth iot general principle modeling approach systematic development new engineering system still miss system modeling one important aspect develop abstract model system wherein model represent different view perspective system unified modeling language uml graphical analogy complex system successfully presentedjatsp,0.5208333333333334,0.14583333333333334,0.25,0.03125,96.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Design and Development,Resilience quantification model for cyber‐physical power systems,"<jats:title>Abstract</jats:title><jats:p>As power grids develop, their structure becomes more complex, multi‐dimensional, and digitalised—hence, it is referred to as cyber‐physical infrastructure. The sensitivity of grids to extreme cyber and physical events is becoming a hot research topic due to the increasing rate of such events and their catastrophic consequences. To produce accurate and comprehensive measures, modelling and assessing the resilience of power systems must include both the physical and cyber domains. However, resilience quantification models that include both domains have not received sufficient attention. A novel resilience model and quantification framework are proposed. The model is based on a resilience trapezoid that depicts the different phases of the cyber and physical domains during severe natural or anthropogenic events. A resilience index is also proposed to measure the resilience levels of local nodes and entire systems, including various factors that contribute to the modelled degradation states. Severe weather conditions were modelled to examine the impact of this category of events on the proposed resilience model.</jats:p>",https://doi.org/10.1049/cps2.12098,CrossRef,resilience quantification model power system,jatstitleabstractjatstitlejatspas power grid develop structure become complex digitalised hence refer infrastructure sensitivity grid extreme cyber physical event become hot research topic due increase rate event catastrophic consequence produce accurate comprehensive measure model assess resilience power system must include physical cyber domain however resilience quantification model include domain receive sufficient attention novel resilience model quantification framework propose model base resilience trapezoid depict different phase cyber physical domain severe natural anthropogenic event resilience index also propose measure resilience level local node entire system include various factor contribute modelled degradation state severe weather condition model examine impact category event propose resilience modeljatsp,resilience quantification model power system jatstitleabstractjatstitlejatspas power grid develop structure become complex digitalised hence refer infrastructure sensitivity grid extreme cyber physical event become hot research topic due increase rate event catastrophic consequence produce accurate comprehensive measure model assess resilience power system must include physical cyber domain however resilience quantification model include domain receive sufficient attention novel resilience model quantification framework propose model base resilience trapezoid depict different phase cyber physical domain severe natural anthropogenic event resilience index also propose measure resilience level local node entire system include various factor contribute modelled degradation state severe weather condition model examine impact category event propose resilience modeljatsp,0.5353535353535354,0.15151515151515152,0.20202020202020202,0.030303030303030304,99.0,1.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Design and Development,Traffic-type Assignment for TSN-based Mixed-criticality Cyber-physical Systems,"<jats:p>This article focuses on mixed-criticality applications with functions that have different timing requirements, i.e., hard real-time (HRT), soft real-time (SRT), and functions that are not time-critical (NC). The applications are implemented on distributed cyber-physical systems that use IEEE Time-sensitive Networking (TSN). TSN is the product of an IEEE effort to bring deterministic real-time capabilities to IEEE 802.3 Ethernet. TSN supports the convergence of multiple traffic types, i.e., critical, real-time, and regular “best-effort” traffic within a single network: Time-triggered (TT), where the messages are transmitted based on static schedule tables, Audio-video Bridging (AVB), for dynamically scheduled messages with a guaranteed bandwidth and bounded delays, and Best Effort (BE), for which no timing guarantees are provided. The HRT messages have deadlines, whereas we capture the quality-of-service for the SRT messages using “utility functions.” Given the network topology, the set of application messages, including their routing, and the set of available AVB classes, we are interested in determining the traffic type of each message, such that all the HRT messages are schedulable and the total utility for the SRT messages is maximized. We propose a Tabu Search-based metaheuristic to solve this optimization problem. The proposed proof-of-concept tool has been evaluated using several benchmarks, including two realistic test cases.</jats:p>",https://doi.org/10.1145/3371708,CrossRef,traffictype assignment tsnbase mixedcriticality cyberphysical system,jatspthis article focus mixedcriticality application function different timing requirement hard realtime hrt soft realtime srt function timecritical application implement distribute cyberphysical system use ieee timesensitive network tsn tsn product ieee effort bring deterministic realtime capability ieee ethernet tsn support convergence multiple traffic type critical realtime regular besteffort traffic within single network timetriggere message transmit base static schedule table audiovideo bridge avb dynamically schedule message guarantee bandwidth bounded delay good effort timing guarantee provide hrt message deadline whereas capture qualityofservice srt message use utility function give network topology set application message include routing set available avb class interested determine traffic type message hrt message schedulable total utility srt message maximize propose tabu searchbase metaheuristic solve optimization problem propose proofofconcept tool evaluate use several benchmark include two realistic test casesjatsp,traffictype assignment tsnbase mixedcriticality cyberphysical system jatspthis article focus mixedcriticality application function different timing requirement hard realtime hrt soft realtime srt function timecritical application implement distribute cyberphysical system use ieee timesensitive network tsn tsn product ieee effort bring deterministic realtime capability ieee ethernet tsn support convergence multiple traffic type critical realtime regular besteffort traffic within single network timetriggere message transmit base static schedule table audiovideo bridge avb dynamically schedule message guarantee bandwidth bounded delay good effort timing guarantee provide hrt message deadline whereas capture qualityofservice srt message use utility function give network topology set application message include routing set available avb class interested determine traffic type message hrt message schedulable total utility srt message maximize propose tabu searchbase metaheuristic solve optimization problem propose proofofconcept tool evaluate use several benchmark include two realistic test casesjatsp,0.546875,0.1640625,0.1875,0.0234375,128.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Design and Development,Detecting covert channel attacks on cyber‐physical systems,"<jats:title>Abstract</jats:title><jats:p>Cyberattacks on cyber‐physical systems (CPS) have the potential to cause widespread disruption and affect the safety of millions of people. Machine learning can be an effective tool for detecting attacks on CPS, including the most stealthy types of attacks, known as covert channel attacks. In this study, the authors describe a novel hierarchical ensemble architecture for detecting covert channel attacks in CPS. Our proposed approach uses a combination of TCP payload entropy and network flows for feature engineering. Our approach achieves high detection performance, shortens the model training duration, and shows promise for effective detection of covert channel communications. This novel architecture closely mirrors the CPS attack stages in real‐life, providing flexibility and adaptability in detecting new types of attacks.</jats:p>",https://doi.org/10.1049/cps2.12078,CrossRef,detect covert channel attack system,jatstitleabstractjatstitlejatspcyberattack system potential cause widespread disruption affect safety million people machine learning effective tool detect attack include stealthy type attack know covert channel attack study author describe novel hierarchical ensemble architecture detect covert channel attack propose approach use combination tcp payload entropy network flow feature engineer approach achieve high detection performance shorten model training duration show promise effective detection covert channel communication novel architecture closely mirror attack stage provide flexibility adaptability detect new type attacksjatsp,detect covert channel attack system jatstitleabstractjatstitlejatspcyberattack system potential cause widespread disruption affect safety million people machine learning effective tool detect attack include stealthy type attack know covert channel attack study author describe novel hierarchical ensemble architecture detect covert channel attack propose approach use combination tcp payload entropy network flow feature engineer approach achieve high detection performance shorten model training duration show promise effective detection covert channel communication novel architecture closely mirror attack stage provide flexibility adaptability detect new type attacksjatsp,0.5866666666666667,0.14666666666666667,0.2,0.013333333333333334,75.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Design and Development,Control Software Engineering Approaches for Cyber-Physical Systems: A Systematic Mapping Study,"<jats:p>Cyber-Physical Systems (CPS), robotics, the Internet of Things (IoT), and automotive systems are integral to modern technology. They are characterized by their safety criticality, accuracy, and real-time control requirements. Control software plays a crucial role in achieving these objectives by managing and coordinating the operations of various sub-systems. This article presents a novel Systematic Mapping Study (SMS) for control software engineering, analyzing 115 peer-reviewed papers. The study identifies, classifies, and maps existing solutions, providing a comprehensive and structured overview for practitioners and researchers. Our contributions include (1) a unique classification of literature into six research themes—engineering phases, engineering approaches, engineering paradigms, engineering artifacts, target application domains, and engineering concerns; (2) insights into the specificity of approaches to target technologies and phases; (3) the prominence of model-driven approaches for design and testing; (4) the lack of end-to-end engineering support in existing approaches; and (5) the emerging role of agile-based methods versus the dominance of waterfall-based methods. This article's significance lies in its thorough analysis and the high-level mapping of the solution space, offering new perspectives and a detailed roadmap for future research and innovation in control software engineering. The findings will guide advancements and best practices in the field, underscoring the article's impact.</jats:p>",https://doi.org/10.1145/3704737,CrossRef,control software engineering approach cyberphysical system systematic mapping study,jatspcyberphysical system robotic internet thing iot automotive system integral modern technology characterize safety criticality accuracy realtime control requirement control software play crucial role achieve objective manage coordinate operation various subsystem article present novel systematic mapping study sms control software engineering analyze peerreviewe paper study identify classifie map exist solution provide comprehensive structured overview practitioner researcher contribution include unique classification literature six research theme engineering phase engineering approach engineering paradigm engineering artifact target application domain engineering concern insight specificity approach target technology phase prominence modeldriven approach design test lack endtoend engineering support exist approach emerge role agilebased method versus dominance waterfallbase method article significance lie thorough analysis highlevel mapping solution space offer new perspective detailed roadmap future research innovation control software engineer finding guide advancement good practice field underscore article impactjatsp,control software engineering approach cyberphysical system systematic mapping study jatspcyberphysical system robotic internet thing iot automotive system integral modern technology characterize safety criticality accuracy realtime control requirement control software play crucial role achieve objective manage coordinate operation various subsystem article present novel systematic mapping study sms control software engineering analyze peerreviewe paper study identify classifie map exist solution provide comprehensive structured overview practitioner researcher contribution include unique classification literature six research theme engineering phase engineering approach engineering paradigm engineering artifact target application domain engineering concern insight specificity approach target technology phase prominence modeldriven approach design test lack endtoend engineering support exist approach emerge role agilebased method versus dominance waterfallbase method article significance lie thorough analysis highlevel mapping solution space offer new perspective detailed roadmap future research innovation control software engineer finding guide advancement good practice field underscore article impactjatsp,0.6538461538461539,0.11538461538461539,0.16153846153846155,0.0,130.0,1.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Theoretical / Conceptual,Complex Systems + Systems Engineering = Complex Systems Engineeri,"One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering.",http://arxiv.org/abs/cs/0603127v1,arXiv,complex system system engineering complex system engineeri,one may define complex system system phenomena emerge consequence multiscale interaction among system component environment field complex system study systemsusually naturally occur either biological social system engineering may understand include conceptualising building system consist large number concurrently operate interact componentsusually include human nonhuman element become increasingly apparent kind system system engineer build many multiscale characteristic naturally occur complex system word system engineering engineering complex system paper associated panel explore connection field complex system system engineering,complex system system engineering complex system engineeri one may define complex system system phenomena emerge consequence multiscale interaction among system component environment field complex system study systemsusually naturally occur either biological social system engineering may understand include conceptualising building system consist large number concurrently operate interact componentsusually include human nonhuman element become increasingly apparent kind system system engineer build many multiscale characteristic naturally occur complex system word system engineering engineering complex system paper associated panel explore connection field complex system system engineering,0.5066666666666667,0.17333333333333334,0.16,0.08,75.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Theoretical / Conceptual,"Expansion of situations theory for exploring shared awareness in
  human-intelligent autonomous systems","Intelligent autonomous systems are part of a system of systems that interact
with other agents to accomplish tasks in complex environments. However,
intelligent autonomous systems integrated system of systems add additional
layers of complexity based on their limited cognitive processes, specifically
shared situation awareness that allows a team to respond to novel tasks.
Intelligent autonomous systems' lack of shared situation awareness adversely
influences team effectiveness in complex task environments, such as military
command-and-control. A complementary approach of shared situation awareness,
called situations theory, is beneficial for understanding the relationship
between system of systems shared situation awareness and effectiveness. The
current study elucidates a conceptual discussion on situations theory to
investigate the development of an system of systems shared situational
awareness when humans team with intelligent autonomous system agents. To ground
the discussion, the reviewed studies expanded situations theory within the
context of a system of systems that result in three major conjectures that can
be beneficial to the design and development of future systems of systems.",http://arxiv.org/abs/2406.04956v1,arXiv,expansion situation theory explore share awareness humanintelligent autonomous system,intelligent autonomous system part system system interact agent accomplish task complex environment however intelligent autonomous system integrate system system add additional layer complexity base limited cognitive process specifically share situation awareness allow team respond novel task intelligent autonomous system lack share situation awareness adversely influence team effectiveness complex task environment military commandandcontrol complementary approach share situation awareness call situation theory beneficial understand relationship system system share situation awareness effectiveness current study elucidate conceptual discussion situation theory investigate development system system share situational awareness human team intelligent autonomous system agent ground discussion review study expand situation theory within context system system result three major conjecture beneficial design development future system system,expansion situation theory explore share awareness humanintelligent autonomous system intelligent autonomous system part system system interact agent accomplish task complex environment however intelligent autonomous system integrate system system add additional layer complexity base limited cognitive process specifically share situation awareness allow team respond novel task intelligent autonomous system lack share situation awareness adversely influence team effectiveness complex task environment military commandandcontrol complementary approach share situation awareness call situation theory beneficial understand relationship system system share situation awareness effectiveness current study elucidate conceptual discussion situation theory investigate development system system share situational awareness human team intelligent autonomous system agent ground discussion review study expand situation theory within context system system result three major conjecture beneficial design development future system system,0.6545454545454545,0.08181818181818182,0.21818181818181817,0.02727272727272727,110.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Theoretical / Conceptual,Fractal trajectories of the dynamical system,"The scope of the paper is a theoretical analysis of the dynamical system, the
model of which was reduced to Weierstrasse function. A fractal structure of the
trajectory was proved and the entropy of the system information designated.",http://arxiv.org/abs/1604.03152v1,arXiv,fractal trajectory dynamical system,scope paper theoretical analysis dynamical system model reduce weierstrasse function fractal structure trajectory prove entropy system information designate,fractal trajectory dynamical system scope paper theoretical analysis dynamical system model reduce weierstrasse function fractal structure trajectory prove entropy system information designate,0.6666666666666666,0.1111111111111111,0.16666666666666666,0.0,18.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Theoretical / Conceptual,Encrypted Control System with Quantizer,"This paper considers the design of encrypted control systems to secure data
privacy when the control systems operate over a network. In particular, we
propose to combine Paillier cryptosystem with a quantizer whose sensitivity
changes with the evolution of the system. This allows the encrypted control
system to balance between the cipher strength and processing time. Such an
ability is essential for control systems that are expected to run real-time. It
also allows the closed-loop system to achieve the asymptotic stability for
linear systems. Extensions to event-triggered control and nonlinear control
systems are also discussed.",http://arxiv.org/abs/1807.06717v1,arXiv,encrypt control system quantizer,paper consider design encrypt control system secure datum privacy control system operate network particular propose combine paillier cryptosystem quantizer whose sensitivity change evolution system allow encrypt control system balance cipher strength processing time ability essential control system expect run realtime also allow closedloop system achieve asymptotic stability linear system extension eventtriggere control nonlinear control system also discuss,encrypt control system quantizer paper consider design encrypt control system secure datum privacy control system operate network particular propose combine paillier cryptosystem quantizer whose sensitivity change evolution system allow encrypt control system balance cipher strength processing time ability essential control system expect run realtime also allow closedloop system achieve asymptotic stability linear system extension eventtriggere control nonlinear control system also discuss,0.631578947368421,0.17543859649122806,0.10526315789473684,0.03508771929824561,57.0,0.0,0.0,0.0,0.0
Computer Engineering,Cyber-Physical Systems,Theoretical / Conceptual,The Bouncing Penny and Nonholonomic Impacts,"The evolution of a Lagrangian mechanical system is variational. Likewise,
when dealing with a hybrid Lagrangian system (a system with discontinuous
impacts), the impacts can also be described by variations. These variational
impacts are given by the so-called Weierstrass-Erdmann corner conditions.
Therefore, hybrid Lagrangian systems can be completely understood by
variational principles.
  Unlike typical (unconstrained / holonomic) Lagrangian systems,
nonholonomically constrained Lagrangian systems are not variational. However,
by using the Lagrange-d'Alembert principle, nonholonomic systems can be
described as projections of variational systems. This paper works out the
analogous version of the Weierstrass-Erdmann corner conditions for nonholonomic
systems and examines the billiard problem with a rolling disk.",http://arxiv.org/abs/1909.11192v1,arXiv,bounce penny nonholonomic impact,evolution lagrangian mechanical system variational likewise deal hybrid lagrangian system system discontinuous impact impact also describe variation variational impact give socalled weierstrasserdmann corner condition therefore hybrid lagrangian system completely understand variational principle unlike typical unconstrained holonomic lagrangian system nonholonomically constrain lagrangian system variational however use lagrangedalembert principle nonholonomic system describe projection variational system paper work analogous version weierstrasserdmann corner condition nonholonomic system examine billiard problem rolling disk,bounce penny nonholonomic impact evolution lagrangian mechanical system variational likewise deal hybrid lagrangian system system discontinuous impact impact also describe variation variational impact give socalled weierstrasserdmann corner condition therefore hybrid lagrangian system completely understand variational principle unlike typical unconstrained holonomic lagrangian system nonholonomically constrain lagrangian system variational however use lagrangedalembert principle nonholonomic system describe projection variational system paper work analogous version weierstrasserdmann corner condition nonholonomic system examine billiard problem rolling disk,0.34328358208955223,0.13432835820895522,0.2835820895522388,0.08955223880597014,67.0,2.0,0.0,0.0,0.0

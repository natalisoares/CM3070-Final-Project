{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fab8f1-9700-45a9-a0a7-967a81b9e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b9960-7741-4091-afbb-4660715e794b",
   "metadata": {},
   "source": [
    "Discipline to subfields keywords mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c563aa-dc5c-430b-8a96-56cf2c0cb2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as discipline_keywords.json\n"
     ]
    }
   ],
   "source": [
    "# Discipline to subfields keywords mapping\n",
    "\n",
    "discipline_keywords = {\n",
    "    \"Computer Science\": {\n",
    "        \"Algorithms and Data Structures\": [\"algorithm\", \"data structure\", \"graph\", \"tree\", \"heap\", \"sorting\", \"searching\", \"complexity\", \"recursion\", \"hashing\"],\n",
    "        \"Artificial Intelligence and Machine Learning\": [\"machine learning\", \"deep learning\", \"neural network\", \"supervised\", \"unsupervised\", \"reinforcement learning\", \"AI\", \"classification\", \"prediction\", \"regression\"],\n",
    "        \"Computer Systems and Architecture\": [\"operating system\", \"kernel\", \"process\", \"memory\", \"cpu\", \"thread\", \"architecture\", \"cache\", \"multicore\", \"interrupt\"],\n",
    "        \"Human-Computer Interaction\": [\"user interface\", \"usability\", \"HCI\", \"interaction\", \"user experience\", \"UX\", \"design\", \"cognitive\", \"feedback\", \"accessibility\"],\n",
    "        \"Software Engineering Principles\": [\"software development\", \"design pattern\", \"architecture\", \"refactoring\", \"agile\", \"scrum\", \"version control\", \"testing\", \"modularity\", \"code quality\"]\n",
    "    },\n",
    "    \"Software Engineering\": {\n",
    "        \"Software Development Processes\": [\"agile\", \"scrum\", \"waterfall\", \"lifecycle\", \"iteration\", \"process model\", \"CI/CD\", \"devops\", \"release\", \"deployment\"],\n",
    "        \"Software Design and Architecture\": [\"architecture\", \"design pattern\", \"modularity\", \"system design\", \"layered\", \"MVC\", \"abstraction\", \"component\", \"interface\", \"reuse\"],\n",
    "        \"Software Testing and Quality Assurance\": [\"testing\", \"unit test\", \"integration test\", \"test case\", \"test suite\", \"coverage\", \"assertion\", \"bug\", \"defect\", \"QA\"],\n",
    "        \"Requirements Engineering\": [\"requirement\", \"elicitation\", \"stakeholder\", \"user story\", \"specification\", \"goal modeling\", \"validation\", \"traceability\", \"analysis\", \"needs\"],\n",
    "        \"Project Management\": [\"project\", \"planning\", \"scheduling\", \"cost estimation\", \"milestone\", \"risk management\", \"Gantt\", \"team\", \"roles\", \"budget\"]\n",
    "    },\n",
    "    \"Information Systems\": {\n",
    "        \"Enterprise Systems\": [\"ERP\", \"CRM\", \"enterprise\", \"integration\", \"SAP\", \"system deployment\", \"workflow\", \"enterprise application\", \"business logic\", \"intranet\"],\n",
    "        \"Decision Support Systems\": [\"DSS\", \"decision making\", \"analytics\", \"data warehouse\", \"BI\", \"what-if\", \"dashboards\", \"support tool\", \"modelling\", \"simulation\"],\n",
    "        \"Knowledge Management\": [\"knowledge sharing\", \"repository\", \"ontology\", \"knowledge base\", \"tacit knowledge\", \"expert system\", \"semantic\", \"taxonomy\", \"knowledge transfer\", \"capture\"],\n",
    "        \"Information Security\": [\"access control\", \"encryption\", \"security\", \"authentication\", \"cybersecurity\", \"firewall\", \"data breach\", \"confidentiality\", \"risk\", \"compliance\"],\n",
    "        \"E-Government and E-Commerce\": [\"e-government\", \"e-service\", \"e-commerce\", \"transaction\", \"digital platform\", \"public service\", \"online portal\", \"citizen\", \"service quality\", \"B2C\"]\n",
    "    },\n",
    "    \"Information Technology\": {\n",
    "        \"Network and Infrastructure\": [\"network\", \"server\", \"router\", \"infrastructure\", \"LAN\", \"WAN\", \"firewall\", \"switch\", \"IP address\", \"protocol\"],\n",
    "        \"Cybersecurity\": [\"malware\", \"vulnerability\", \"intrusion detection\", \"zero trust\", \"TLS\", \"phishing\", \"cyber attack\", \"penetration\", \"incident\", \"threat\"],\n",
    "        \"IT Service Management\": [\"ITIL\", \"helpdesk\", \"ticketing\", \"support\", \"service delivery\", \"SLA\", \"incident\", \"configuration\", \"availability\", \"uptime\"],\n",
    "        \"Data Management\": [\"database\", \"data integrity\", \"governance\", \"ETL\", \"data quality\", \"metadata\", \"data warehouse\", \"big data\", \"preprocessing\", \"storage\"],\n",
    "        \"User Support\": [\"help desk\", \"technical support\", \"user training\", \"ticket\", \"issue resolution\", \"FAQ\", \"call centre\", \"troubleshoot\", \"remote support\", \"documentation\"]\n",
    "    },\n",
    "    \"Computer Engineering\": {\n",
    "        \"Hardware Systems\": [\"hardware\", \"microcontroller\", \"microprocessor\", \"circuit\", \"GPIO\", \"sensor\", \"actuator\", \"register\", \"peripheral\", \"driver\"],\n",
    "        \"Computer Architecture\": [\"architecture\", \"instruction set\", \"pipeline\", \"cache\", \"ALU\", \"control unit\", \"memory hierarchy\", \"fetch\", \"decode\", \"execute\"],\n",
    "        \"Digital Systems Design\": [\"VHDL\", \"Verilog\", \"FPGA\", \"logic gate\", \"flip-flop\", \"circuit design\", \"state machine\", \"clock\", \"synchronous\", \"combinational\"],\n",
    "        \"Signal Processing\": [\"FFT\", \"filter\", \"signal\", \"modulation\", \"frequency\", \"noise\", \"DSP\", \"audio\", \"image\", \"waveform\"],\n",
    "        \"Cyber-Physical Systems\": [\"IoT\", \"real-time\", \"sensor\", \"embedded\", \"CPS\", \"control\", \"autonomous\", \"robot\", \"actuation\", \"feedback loop\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"discipline_keywords.json\", \"w\") as f:\n",
    "    json.dump(discipline_keywords, f, indent=4)\n",
    "\n",
    "print(\"Saved as discipline_keywords.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009fd19-a941-4bb0-bd44-b6ae2326c2e8",
   "metadata": {},
   "source": [
    "Discipline and subfield mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b76fa9-42b1-4049-b58f-2d8ce5167896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as discipline_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# Create and save discipline subfield mapping\n",
    "discipline_mapping = {\n",
    "    discipline: list(subfields.keys())\n",
    "    for discipline, subfields in discipline_keywords.items()\n",
    "}\n",
    "\n",
    "with open(\"discipline_mapping.json\", \"w\") as f:\n",
    "    json.dump(discipline_mapping, f, indent=4)\n",
    "\n",
    "print(\"Saved as discipline_mapping.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7844b6-ef79-4a68-821b-828bef4f54bf",
   "metadata": {},
   "source": [
    "Methodology keywords mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f78e668-0034-499d-8ed2-f7ec1e340e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methodology keywords\n",
    "\n",
    "methodology_keywords = {\n",
    "    \"Quantitative\": [\n",
    "        \"quantitative\", \"statistical\", \"survey\", \"questionnaire\", \"regression\", \"correlation\",\n",
    "        \"t-test\", \"f-test\", \"anova\", \"chi-square\", \"numerical analysis\", \"metric\",\n",
    "        \"hypothesis testing\", \"likert scale\", \"parametric\", \"nonparametric\", \"sampling\",\n",
    "        \"statistical model\", \"structural equation modeling\", \"variance\", \"data analysis\",\n",
    "        \"empirical analysis\", \"experimental design\", \"descriptive statistics\", \"inferential statistics\"\n",
    "    ],\n",
    "    \"Qualitative\": [\n",
    "        \"qualitative\", \"interview\", \"interviews\", \"semi-structured\", \"case study\",\n",
    "        \"focus group\", \"observation\", \"fieldwork\", \"ethnography\", \"thematic analysis\",\n",
    "        \"content analysis\", \"discourse analysis\", \"grounded theory\", \"narrative analysis\",\n",
    "        \"interpretive\", \"phenomenology\", \"manual coding\", \"participant observation\",\n",
    "        \"open-ended\", \"in-depth interview\", \"interpretivist\"\n",
    "    ],\n",
    "    \"Mixed Methods\": [\n",
    "        \"mixed methods\", \"mixed methodology\", \"qualitative and quantitative\", \"quantitative and qualitative\",\n",
    "        \"both qualitative and quantitative\", \"survey and interview\", \"interviews and surveys\", \"combined methods\",\n",
    "        \"combining methods\", \"integration of methods\", \"multi-method study\", \"triangulation\", \n",
    "        \"integrated approach\", \"mixed research design\", \"complementary methods\"\n",
    "    ],\n",
    "    \"Design and Development\": [\n",
    "        \"design science\", \"prototype\", \"framework\", \"architecture\", \"implementation\", \"system design\",\n",
    "        \"tool development\", \"software design\", \"we propose\", \"we build\", \"we implement\",\n",
    "        \"development process\", \"model-driven\", \"platform design\", \"design approach\",\n",
    "        \"developed a tool\", \"technical artefact\", \"solution development\", \"design-oriented\"\n",
    "    ],\n",
    "    \"Theoretical / Conceptual\": [\n",
    "        \"theoretical\", \"conceptual\", \"taxonomy\", \"classification scheme\", \"analytical model\",\n",
    "        \"argumentation\", \"framework development\", \"literature review\", \"model proposal\",\n",
    "        \"reference model\", \"theoretical framework\", \"ontology\", \"perspective\", \"review of the literature\",\n",
    "        \"conceptual model\", \"mathematical theory\", \"historical overview\", \"evolution of\", \"principle-based\",\n",
    "        \"conceptual discussion\", \"theoretical lens\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"methodology_keywords.json\", \"w\") as f:\n",
    "    json.dump(methodology_keywords, f, indent=4)\n",
    "print(\"Saved as methodology_keywords.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9de7c1-05ab-4e59-b9c2-db7dfaec543d",
   "metadata": {},
   "source": [
    "Load discipline and methodology kewords mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410978fc-9ec1-40a5-bc92-2f60996e4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kewords mappings\n",
    "with open(\"discipline_keywords.json\", \"r\") as f:\n",
    "    discipline_keywords = json.load(f)\n",
    "with open(\"methodology_keywords.json\", \"r\") as f:\n",
    "    methodology_keywords = json.load(f)\n",
    "all_methods = list(methodology_keywords.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ea156-3a87-46dd-9faa-e62911c2d333",
   "metadata": {},
   "source": [
    "Classifier for methodology Mixed methods, keyword and balance rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44213816-9a73-4003-9372-45d9e0691e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier \n",
    "def classify_methodology(text, keywords):\n",
    "    text = text.lower()\n",
    "\n",
    "    quant_score = sum(1 for kw in keywords[\"Quantitative\"] if kw in text)\n",
    "    qual_score = sum(1 for kw in keywords[\"Qualitative\"] if kw in text)\n",
    "    mixed_score = sum(1 for kw in keywords[\"Mixed Methods\"] if kw in text)\n",
    "\n",
    "    # If both quant and qual appear than Mixed\n",
    "    if quant_score >= 2 and qual_score >= 2:\n",
    "        if abs(quant_score - qual_score) <= 1:\n",
    "            return \"Mixed Methods\"\n",
    "        # Otherwise return dominant side\n",
    "        return \"Quantitative\" if quant_score > qual_score else \"Qualitative\"\n",
    "\n",
    "    # Strong Mixed \n",
    "    if mixed_score >= 2:\n",
    "        return \"Mixed Methods\"\n",
    "\n",
    "    # Fallback to best single method\n",
    "    scores = {\n",
    "        method: sum(1 for kw in kw_list if kw in text)\n",
    "        for method, kw_list in keywords.items()\n",
    "        if method not in [\"Mixed Methods\"]\n",
    "    }\n",
    "\n",
    "    top_method, score = max(scores.items(), key=lambda x: x[1])\n",
    "    return top_method if score >= 2 else \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91828aed-87ed-4b69-a982-1bd7f59977f8",
   "metadata": {},
   "source": [
    "Scrappers functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61ed574-7bf2-4f5e-949f-9e55a8f7f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from CrossRef \n",
    "def scrape_crossref(query: str, n: int = 1000):\n",
    "    n = min(n, 1000)  # Limit to 1000 results (max limit)\n",
    "    try:\n",
    "        # API query\n",
    "        url = \"https://api.crossref.org/works\"\n",
    "        params = {\"query\": query, \"rows\": n, \"filter\": \"type:journal-article\"}\n",
    "        r = requests.get(url, params=params, timeout=10) # Send request\n",
    "        r.raise_for_status()\n",
    "        items = r.json()[\"message\"][\"items\"]\n",
    "        # Extract relevant fields\n",
    "        return [\n",
    "            {\n",
    "                \"title\": i[\"title\"][0] if isinstance(i[\"title\"], list) else i[\"title\"],\n",
    "                \"abstract\": i.get(\"abstract\", \"\"),\n",
    "                \"url\": i[\"URL\"],\n",
    "                \"source\": \"CrossRef\"\n",
    "            }\n",
    "            for i in items if \"abstract\" in i\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(\"CrossRef error:\", e)\n",
    "        return []\n",
    "\n",
    "# Scrape data from arXiv\n",
    "def scrape_arxiv(query: str, n: int = 300):\n",
    "    n = min(n, 300) # Limit to 300 results \n",
    "    try:\n",
    "         # API query\n",
    "        url = f\"http://export.arxiv.org/api/query?search_query=all:{query.replace(' ', '+')}&start=0&max_results={n}\"\n",
    "        feed = feedparser.parse(url)\n",
    "        # Extract relevant fields\n",
    "        return [\n",
    "            {\n",
    "                \"title\": entry.title,\n",
    "                \"abstract\": entry.summary,\n",
    "                \"url\": entry.link,\n",
    "                \"source\": \"arXiv\"\n",
    "            }\n",
    "            for entry in feed.entries\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(\"arXiv error:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f4ac-05c6-4023-8ae4-744d2911536d",
   "metadata": {},
   "source": [
    "Collect articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65079ae1-af0e-4285-a0b9-3a5ffd3aa666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discipline: Computer Science\n",
      "Subfield: Algorithms and Data Structures\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Artificial Intelligence and Machine Learning\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 4 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Computer Systems and Architecture\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 4 articles found\n",
      "Subfield: Human-Computer Interaction\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Trying scrape_crossref for Quantitative\n",
      "CrossRef error: HTTPSConnectionPool(host='api.crossref.org', port=443): Read timed out. (read timeout=10)\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 1 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 1 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Software Engineering Principles\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "\n",
      "Discipline: Software Engineering\n",
      "Subfield: Software Development Processes\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Software Design and Architecture\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Software Testing and Quality Assurance\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Requirements Engineering\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Project Management\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "\n",
      "Discipline: Information Systems\n",
      "Subfield: Enterprise Systems\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "CrossRef error: HTTPSConnectionPool(host='api.crossref.org', port=443): Read timed out.\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "CrossRef error: HTTPSConnectionPool(host='api.crossref.org', port=443): Read timed out. (read timeout=10)\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Decision Support Systems\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Knowledge Management\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Information Security\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: E-Government and E-Commerce\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "\n",
      "Discipline: Information Technology\n",
      "Subfield: Network and Infrastructure\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Cybersecurity\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: IT Service Management\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Data Management\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: User Support\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "\n",
      "Discipline: Computer Engineering\n",
      "Subfield: Hardware Systems\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Computer Architecture\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 2 articles found\n",
      "Subfield: Digital Systems Design\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Signal Processing\n",
      "  Trying scrape_arxiv for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_arxiv for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_crossref for Design and Development\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_arxiv for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n",
      "Subfield: Cyber-Physical Systems\n",
      "  Trying scrape_crossref for Quantitative\n",
      "  Quantitative: 5 articles found\n",
      "  Trying scrape_arxiv for Qualitative\n",
      "  Trying scrape_crossref for Qualitative\n",
      "  Qualitative: 5 articles found\n",
      "  Trying scrape_crossref for Mixed Methods\n",
      "  Mixed Methods: 5 articles found\n",
      "  Trying scrape_arxiv for Design and Development\n",
      "  Design and Development: 5 articles found\n",
      "  Trying scrape_crossref for Theoretical / Conceptual\n",
      "  Theoretical / Conceptual: 5 articles found\n"
     ]
    }
   ],
   "source": [
    "# Scrapers and storage\n",
    "scrapers = [scrape_crossref, scrape_arxiv]\n",
    "collected = []\n",
    "scraper_index = 0\n",
    "\n",
    "# Loop through discipline,subfield, methodology combinations\n",
    "for discipline, subfields in discipline_keywords.items():\n",
    "    print(f\"\\nDiscipline: {discipline}\")\n",
    "    for subfield in subfields:\n",
    "        print(f\"Subfield: {subfield}\")\n",
    "        for method in all_methods:\n",
    "            found = []\n",
    "            # Round scraping with limits\n",
    "            current_index = scraper_index % len(scrapers)\n",
    "            attempts = 0\n",
    "            max_attempts = len(scrapers) * 5\n",
    "\n",
    "            # Try to get 5 articles or max attempts reached\n",
    "            while len(found) < 5 and attempts < max_attempts:\n",
    "                scraper = scrapers[current_index]\n",
    "                print(f\"  Trying {scraper.__name__} for {method}\")\n",
    "                try:\n",
    "                    results = scraper(subfield)\n",
    "                    for article in results:\n",
    "                        if len(found) >= 5:\n",
    "                            break\n",
    "                        predicted = classify_methodology(article[\"abstract\"], methodology_keywords)\n",
    "                        if predicted == method and article not in found:\n",
    "                            found.append(article)\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error with {scraper.__name__}: {e}\")\n",
    "                # Move to next scraper\n",
    "                current_index = (current_index + 1) % len(scrapers)\n",
    "                attempts += 1\n",
    "                time.sleep(2)  # Polite pause\n",
    "\n",
    "            # Update scraper index \n",
    "            scraper_index = (scraper_index + 1) % len(scrapers)\n",
    "\n",
    "            # Store articles with metadata\n",
    "            for article in found:\n",
    "                collected.append({\n",
    "                    \"Discipline\": discipline,\n",
    "                    \"Subfield\": subfield,\n",
    "                    \"Methodology\": method,\n",
    "                    \"Title\": article[\"title\"],\n",
    "                    \"Abstract\": article[\"abstract\"],\n",
    "                    \"URL\": article[\"url\"],\n",
    "                    \"Source\": article[\"source\"]\n",
    "                })\n",
    "\n",
    "            print(f\"  {method}: {len(found)} articles found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e63c0f6-6c73-4316-a1f9-b60bfada75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as collected_articles.csv\n"
     ]
    }
   ],
   "source": [
    "# Save articles\n",
    "df = pd.DataFrame(collected)\n",
    "df.to_csv(\"collected_articles.csv\", index=False)\n",
    "print(\"Saved as collected_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0245a-b71b-4904-9cd6-eb041454cc16",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9061bea0-467e-4e15-86a4-476d8bcee87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nataliribeiro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as cleaned_data.csv\n",
      "Saved as tfidf_features.pkl\n",
      "Saved as tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load stopwords and spaCy model\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"collected_articles.csv\")\n",
    "\n",
    "# Cleaning\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if token.lemma_ not in stop_words\n",
    "        and not token.is_space\n",
    "        and token.is_alpha\n",
    "        and len(token.lemma_) > 2\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Extract syntactic features\n",
    "def extract_syntactic_features(text):\n",
    "    doc = nlp(str(text))\n",
    "    pos_counts = {\"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"ADV\": 0}\n",
    "    sent_lengths = []\n",
    "    ent_counts = {\"ORG\": 0, \"GPE\": 0, \"DATE\": 0, \"PERSON\": 0}\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in pos_counts:\n",
    "            pos_counts[token.pos_] += 1\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_lengths.append(len(sent))\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ent_counts:\n",
    "            ent_counts[ent.label_] += 1\n",
    "\n",
    "    total_tokens = len([t for t in doc if t.is_alpha])\n",
    "    pos_ratios = {k.lower() + \"_ratio\": (v / total_tokens if total_tokens else 0) for k, v in pos_counts.items()}\n",
    "    avg_sent_length = sum(sent_lengths) / len(sent_lengths) if sent_lengths else 0\n",
    "\n",
    "    features = {\n",
    "        **pos_ratios,\n",
    "        \"avg_sentence_length\": avg_sent_length,\n",
    "        **{f\"ner_{k.lower()}\": v for k, v in ent_counts.items()}\n",
    "    }\n",
    "    return pd.Series(features)\n",
    "\n",
    "# Apply cleaning and feature extraction\n",
    "data[\"clean_title\"] = data[\"Title\"].apply(clean_text)\n",
    "data[\"clean_abstract\"] = data[\"Abstract\"].apply(clean_text)\n",
    "data[\"clean_text\"] = data[\"clean_title\"] + \" \" + data[\"clean_abstract\"]\n",
    "\n",
    "# Extract syntactic features\n",
    "syntactic_features = data[\"clean_abstract\"].apply(extract_syntactic_features)\n",
    "data = pd.concat([data, syntactic_features], axis=1)\n",
    "\n",
    "# TF-IDF vectorisation\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, stop_words='english')\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data[\"clean_text\"])\n",
    "\n",
    "# Save results\n",
    "data.to_csv(\"cleaned_data.csv\", index=False)\n",
    "print(\"Saved as cleaned_data.csv\")\n",
    "\n",
    "joblib.dump(tfidf_features, \"tfidf_features.pkl\")\n",
    "print(\"Saved as tfidf_features.pkl\")\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "print(\"Saved as tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d22b1-fa68-4634-b805-5dc294d7a322",
   "metadata": {},
   "source": [
    "Data plus methodology keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fd919b-3428-41e7-984f-1cdb07e8700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as data_plus_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Load methodology keywords\n",
    "with open(\"methodology_keywords.json\", \"r\") as f:\n",
    "    methodology_keywords = json.load(f)\n",
    "\n",
    "# Flatten all keywords across all methods\n",
    "all_keywords = []\n",
    "for keywords in methodology_keywords.values():\n",
    "    all_keywords.extend(keywords)\n",
    "\n",
    "# Remove duplicates and lowercase\n",
    "all_keywords = list(set([kw.lower() for kw in all_keywords]))\n",
    "\n",
    "# Function to generate one binary feature per keyword\n",
    "def extract_methodology_features(text, keyword_list):\n",
    "    text_lower = str(text).lower()\n",
    "    return [1 if kw in text_lower else 0 for kw in keyword_list]\n",
    "\n",
    "# Apply to all abstracts\n",
    "keyword_features = data[\"clean_abstract\"].apply(lambda x: extract_methodology_features(x, all_keywords))\n",
    "\n",
    "# Convert to DataFrame\n",
    "keyword_df = pd.DataFrame(keyword_features.tolist(), columns=[f\"kw_{kw}\" for kw in all_keywords])\n",
    "\n",
    "# Merge with original data\n",
    "data = pd.concat([data, keyword_df], axis=1)\n",
    "\n",
    "# Save updated dataset\n",
    "data.to_csv(\"data_plus_keywords.csv\", index=False)\n",
    "print(\"Saved as data_plus_keywords.csv\" )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (breakout-env)",
   "language": "python",
   "name": "breakout-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
